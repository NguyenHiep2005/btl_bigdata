2025-12-28 14:36:06,116 - INFO - üöÄ Initializing PySpark Session...
2025-12-28 14:36:12,536 - INFO - ‚úì Spark Session Created!
2025-12-28 14:36:12,537 - INFO - ‚è∞ Starting Spark Prediction Service (interval: 30s)...
2025-12-28 14:36:12,558 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 14:36:12,559 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 14:36:12,559 - INFO - Scheduler started
2025-12-28 14:36:42,567 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:36:42 +07)" (scheduled at 2025-12-28 14:36:42.558188+07:00)
2025-12-28 14:36:42,567 - INFO - ü§ñ Training Spark model...
2025-12-28 14:36:47,293 - INFO - ‚úì Model trained successfully!
2025-12-28 14:36:47,293 - INFO - üîÆ Running predictions...
2025-12-28 14:36:47,606 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:36:47,606 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:37:12 +07)" executed successfully
2025-12-28 14:37:12,565 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:37:42 +07)" (scheduled at 2025-12-28 14:37:12.558188+07:00)
2025-12-28 14:37:12,565 - INFO - üîÆ Running predictions...
2025-12-28 14:37:12,862 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:37:12,862 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:37:42 +07)" executed successfully
2025-12-28 14:37:42,562 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:38:12 +07)" (scheduled at 2025-12-28 14:37:42.558188+07:00)
2025-12-28 14:37:42,563 - INFO - üîÆ Running predictions...
2025-12-28 14:37:42,874 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:37:42,875 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:38:12 +07)" executed successfully
2025-12-28 14:38:12,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:38:42 +07)" (scheduled at 2025-12-28 14:38:12.558188+07:00)
2025-12-28 14:38:12,559 - INFO - üîÆ Running predictions...
2025-12-28 14:38:12,872 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:38:12,872 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:38:42 +07)" executed successfully
2025-12-28 14:38:42,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:39:12 +07)" (scheduled at 2025-12-28 14:38:42.558188+07:00)
2025-12-28 14:38:42,559 - INFO - üîÆ Running predictions...
2025-12-28 14:38:42,816 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:38:42,817 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:39:12 +07)" executed successfully
2025-12-28 14:39:12,558 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:39:42 +07)" (scheduled at 2025-12-28 14:39:12.558188+07:00)
2025-12-28 14:39:12,559 - INFO - üîÆ Running predictions...
2025-12-28 14:39:12,908 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:39:12,912 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:39:42 +07)" executed successfully
2025-12-28 14:39:42,561 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:40:12 +07)" (scheduled at 2025-12-28 14:39:42.558188+07:00)
2025-12-28 14:39:42,561 - INFO - üîÆ Running predictions...
2025-12-28 14:39:42,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:39:42,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:40:12 +07)" executed successfully
2025-12-28 14:40:12,561 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:40:42 +07)" (scheduled at 2025-12-28 14:40:12.558188+07:00)
2025-12-28 14:40:12,563 - INFO - üîÆ Running predictions...
2025-12-28 14:40:12,822 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:40:12,822 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:40:42 +07)" executed successfully
2025-12-28 14:40:42,558 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:41:12 +07)" (scheduled at 2025-12-28 14:40:42.558188+07:00)
2025-12-28 14:40:42,559 - INFO - üîÆ Running predictions...
2025-12-28 14:40:42,839 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:40:42,839 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:41:12 +07)" executed successfully
2025-12-28 14:41:12,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:41:42 +07)" (scheduled at 2025-12-28 14:41:12.558188+07:00)
2025-12-28 14:41:12,559 - INFO - üîÆ Running predictions...
2025-12-28 14:41:12,801 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:41:12,801 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:41:42 +07)" executed successfully
2025-12-28 14:41:42,577 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:42:12 +07)" (scheduled at 2025-12-28 14:41:42.558188+07:00)
2025-12-28 14:41:42,577 - INFO - üîÆ Running predictions...
2025-12-28 14:41:42,783 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:41:42,783 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:42:12 +07)" executed successfully
2025-12-28 14:42:12,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:42:42 +07)" (scheduled at 2025-12-28 14:42:12.558188+07:00)
2025-12-28 14:42:12,559 - INFO - üîÆ Running predictions...
2025-12-28 14:42:12,857 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:42:12,857 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:42:42 +07)" executed successfully
2025-12-28 14:42:42,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:43:12 +07)" (scheduled at 2025-12-28 14:42:42.558188+07:00)
2025-12-28 14:42:42,559 - INFO - üîÆ Running predictions...
2025-12-28 14:42:42,757 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:42:42,757 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:43:12 +07)" executed successfully
2025-12-28 14:43:12,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:43:42 +07)" (scheduled at 2025-12-28 14:43:12.558188+07:00)
2025-12-28 14:43:12,559 - INFO - üîÆ Running predictions...
2025-12-28 14:43:12,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:43:12,841 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:43:42 +07)" executed successfully
2025-12-28 14:43:42,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:44:12 +07)" (scheduled at 2025-12-28 14:43:42.558188+07:00)
2025-12-28 14:43:42,560 - INFO - üîÆ Running predictions...
2025-12-28 14:43:42,735 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:43:42,735 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:44:12 +07)" executed successfully
2025-12-28 14:44:12,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:44:42 +07)" (scheduled at 2025-12-28 14:44:12.558188+07:00)
2025-12-28 14:44:12,560 - INFO - üîÆ Running predictions...
2025-12-28 14:44:12,819 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:44:12,819 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:44:42 +07)" executed successfully
2025-12-28 14:44:42,559 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:45:12 +07)" (scheduled at 2025-12-28 14:44:42.558188+07:00)
2025-12-28 14:44:42,559 - INFO - üîÆ Running predictions...
2025-12-28 14:44:42,773 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 14:44:42,773 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:30], next run at: 2025-12-28 14:45:12 +07)" executed successfully
2025-12-28 14:44:56,009 - INFO - üõë Stopping Spark Session...
2025-12-28 14:44:56,405 - INFO - Closing down clientserver connection
2025-12-28 14:44:56,406 - INFO - Scheduler has been shut down
2025-12-28 14:44:56,407 - INFO - Closing down clientserver connection
2025-12-28 14:44:58,433 - INFO - üöÄ Initializing PySpark Session...
2025-12-28 14:45:01,464 - INFO - ‚úì Spark Session Created!
2025-12-28 14:45:01,464 - INFO - ‚è∞ Starting Spark Prediction Service (interval: 30s)...
2025-12-28 14:45:01,488 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 14:45:01,489 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 14:45:01,489 - INFO - Scheduler started
2025-12-28 14:45:16,721 - INFO - üõë Stopping Spark Session...
2025-12-28 14:45:17,112 - INFO - Scheduler has been shut down
2025-12-28 14:45:17,113 - INFO - Closing down clientserver connection
2025-12-28 15:58:36,280 - INFO - üöÄ Initializing PySpark Session...
2025-12-28 15:58:43,005 - INFO - ‚úì Spark Session Created!
2025-12-28 15:58:43,005 - INFO - Starting Spark Prediction Service (interval: 30s)...
2025-12-28 15:58:43,038 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 15:58:43,038 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 15:58:43,038 - INFO - Scheduler started
2025-12-28 15:58:48,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:58:48 +07)" (scheduled at 2025-12-28 15:58:48.038060+07:00)
2025-12-28 15:58:48,041 - INFO -  Training Spark model...
2025-12-28 15:58:53,039 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:58:53 +07)" skipped: maximum number of running instances reached (1)
2025-12-28 15:58:53,789 - INFO - ‚úì Model trained successfully!
2025-12-28 15:58:53,790 - INFO -  Running predictions...
2025-12-28 15:58:54,117 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:58:54,117 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:58:58 +07)" executed successfully
2025-12-28 15:58:58,045 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:03 +07)" (scheduled at 2025-12-28 15:58:58.038060+07:00)
2025-12-28 15:58:58,046 - INFO -  Running predictions...
2025-12-28 15:58:58,796 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:58:58,797 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:03 +07)" executed successfully
2025-12-28 15:59:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:08 +07)" (scheduled at 2025-12-28 15:59:03.038060+07:00)
2025-12-28 15:59:03,040 - INFO -  Running predictions...
2025-12-28 15:59:03,221 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:03,221 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:08 +07)" executed successfully
2025-12-28 15:59:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:13 +07)" (scheduled at 2025-12-28 15:59:08.038060+07:00)
2025-12-28 15:59:08,039 - INFO -  Running predictions...
2025-12-28 15:59:08,224 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:08,224 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:13 +07)" executed successfully
2025-12-28 15:59:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:18 +07)" (scheduled at 2025-12-28 15:59:13.038060+07:00)
2025-12-28 15:59:13,040 - INFO -  Running predictions...
2025-12-28 15:59:13,170 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:13,170 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:18 +07)" executed successfully
2025-12-28 15:59:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:23 +07)" (scheduled at 2025-12-28 15:59:18.038060+07:00)
2025-12-28 15:59:18,042 - INFO -  Running predictions...
2025-12-28 15:59:18,257 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:18,258 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:23 +07)" executed successfully
2025-12-28 15:59:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:28 +07)" (scheduled at 2025-12-28 15:59:23.038060+07:00)
2025-12-28 15:59:23,041 - INFO -  Running predictions...
2025-12-28 15:59:23,218 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:23,219 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:28 +07)" executed successfully
2025-12-28 15:59:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:33 +07)" (scheduled at 2025-12-28 15:59:28.038060+07:00)
2025-12-28 15:59:28,040 - INFO -  Running predictions...
2025-12-28 15:59:28,203 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:28,203 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:33 +07)" executed successfully
2025-12-28 15:59:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:38 +07)" (scheduled at 2025-12-28 15:59:33.038060+07:00)
2025-12-28 15:59:33,039 - INFO -  Running predictions...
2025-12-28 15:59:33,189 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:33,189 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:38 +07)" executed successfully
2025-12-28 15:59:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:43 +07)" (scheduled at 2025-12-28 15:59:38.038060+07:00)
2025-12-28 15:59:38,039 - INFO -  Running predictions...
2025-12-28 15:59:38,246 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:38,246 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:43 +07)" executed successfully
2025-12-28 15:59:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:48 +07)" (scheduled at 2025-12-28 15:59:43.038060+07:00)
2025-12-28 15:59:43,040 - INFO -  Running predictions...
2025-12-28 15:59:43,214 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:43,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:48 +07)" executed successfully
2025-12-28 15:59:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:53 +07)" (scheduled at 2025-12-28 15:59:48.038060+07:00)
2025-12-28 15:59:48,039 - INFO -  Running predictions...
2025-12-28 15:59:48,328 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:48,328 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:53 +07)" executed successfully
2025-12-28 15:59:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:58 +07)" (scheduled at 2025-12-28 15:59:53.038060+07:00)
2025-12-28 15:59:53,041 - INFO -  Running predictions...
2025-12-28 15:59:53,187 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:53,187 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 15:59:58 +07)" executed successfully
2025-12-28 15:59:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:03 +07)" (scheduled at 2025-12-28 15:59:58.038060+07:00)
2025-12-28 15:59:58,039 - INFO -  Running predictions...
2025-12-28 15:59:58,173 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 15:59:58,173 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:03 +07)" executed successfully
2025-12-28 16:00:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:08 +07)" (scheduled at 2025-12-28 16:00:03.038060+07:00)
2025-12-28 16:00:03,038 - INFO -  Running predictions...
2025-12-28 16:00:03,204 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:03,205 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:08 +07)" executed successfully
2025-12-28 16:00:08,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:13 +07)" (scheduled at 2025-12-28 16:00:08.038060+07:00)
2025-12-28 16:00:08,041 - INFO -  Running predictions...
2025-12-28 16:00:08,163 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:08,163 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:13 +07)" executed successfully
2025-12-28 16:00:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:18 +07)" (scheduled at 2025-12-28 16:00:13.038060+07:00)
2025-12-28 16:00:13,038 - INFO -  Running predictions...
2025-12-28 16:00:13,158 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:13,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:18 +07)" executed successfully
2025-12-28 16:00:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:23 +07)" (scheduled at 2025-12-28 16:00:18.038060+07:00)
2025-12-28 16:00:18,040 - INFO -  Running predictions...
2025-12-28 16:00:18,215 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:18,216 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:23 +07)" executed successfully
2025-12-28 16:00:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:28 +07)" (scheduled at 2025-12-28 16:00:23.038060+07:00)
2025-12-28 16:00:23,040 - INFO -  Running predictions...
2025-12-28 16:00:23,277 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:23,277 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:28 +07)" executed successfully
2025-12-28 16:00:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:33 +07)" (scheduled at 2025-12-28 16:00:28.038060+07:00)
2025-12-28 16:00:28,039 - INFO -  Running predictions...
2025-12-28 16:00:28,233 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:28,235 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:33 +07)" executed successfully
2025-12-28 16:00:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:38 +07)" (scheduled at 2025-12-28 16:00:33.038060+07:00)
2025-12-28 16:00:33,039 - INFO -  Running predictions...
2025-12-28 16:00:33,190 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:33,191 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:38 +07)" executed successfully
2025-12-28 16:00:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:43 +07)" (scheduled at 2025-12-28 16:00:38.038060+07:00)
2025-12-28 16:00:38,039 - INFO -  Running predictions...
2025-12-28 16:00:38,197 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:38,197 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:43 +07)" executed successfully
2025-12-28 16:00:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:48 +07)" (scheduled at 2025-12-28 16:00:43.038060+07:00)
2025-12-28 16:00:43,040 - INFO -  Running predictions...
2025-12-28 16:00:43,237 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:43,237 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:48 +07)" executed successfully
2025-12-28 16:00:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:53 +07)" (scheduled at 2025-12-28 16:00:48.038060+07:00)
2025-12-28 16:00:48,038 - INFO -  Running predictions...
2025-12-28 16:00:48,208 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:48,208 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:53 +07)" executed successfully
2025-12-28 16:00:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:58 +07)" (scheduled at 2025-12-28 16:00:53.038060+07:00)
2025-12-28 16:00:53,039 - INFO -  Running predictions...
2025-12-28 16:00:53,189 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:53,190 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:00:58 +07)" executed successfully
2025-12-28 16:00:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:03 +07)" (scheduled at 2025-12-28 16:00:58.038060+07:00)
2025-12-28 16:00:58,039 - INFO -  Running predictions...
2025-12-28 16:00:58,262 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:00:58,263 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:03 +07)" executed successfully
2025-12-28 16:01:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:08 +07)" (scheduled at 2025-12-28 16:01:03.038060+07:00)
2025-12-28 16:01:03,040 - INFO -  Running predictions...
2025-12-28 16:01:03,184 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:03,184 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:08 +07)" executed successfully
2025-12-28 16:01:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:13 +07)" (scheduled at 2025-12-28 16:01:08.038060+07:00)
2025-12-28 16:01:08,039 - INFO -  Running predictions...
2025-12-28 16:01:08,175 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:08,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:13 +07)" executed successfully
2025-12-28 16:01:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:18 +07)" (scheduled at 2025-12-28 16:01:13.038060+07:00)
2025-12-28 16:01:13,039 - INFO -  Running predictions...
2025-12-28 16:01:13,160 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:13,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:18 +07)" executed successfully
2025-12-28 16:01:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:23 +07)" (scheduled at 2025-12-28 16:01:18.038060+07:00)
2025-12-28 16:01:18,038 - INFO -  Running predictions...
2025-12-28 16:01:18,165 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:18,165 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:23 +07)" executed successfully
2025-12-28 16:01:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:28 +07)" (scheduled at 2025-12-28 16:01:23.038060+07:00)
2025-12-28 16:01:23,039 - INFO -  Running predictions...
2025-12-28 16:01:23,279 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:23,279 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:28 +07)" executed successfully
2025-12-28 16:01:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:33 +07)" (scheduled at 2025-12-28 16:01:28.038060+07:00)
2025-12-28 16:01:28,040 - INFO -  Running predictions...
2025-12-28 16:01:28,204 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:28,204 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:33 +07)" executed successfully
2025-12-28 16:01:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:38 +07)" (scheduled at 2025-12-28 16:01:33.038060+07:00)
2025-12-28 16:01:33,040 - INFO -  Running predictions...
2025-12-28 16:01:33,181 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:33,181 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:38 +07)" executed successfully
2025-12-28 16:01:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:43 +07)" (scheduled at 2025-12-28 16:01:38.038060+07:00)
2025-12-28 16:01:38,038 - INFO -  Running predictions...
2025-12-28 16:01:38,269 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:38,269 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:43 +07)" executed successfully
2025-12-28 16:01:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:48 +07)" (scheduled at 2025-12-28 16:01:43.038060+07:00)
2025-12-28 16:01:43,040 - INFO -  Running predictions...
2025-12-28 16:01:43,175 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:43,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:48 +07)" executed successfully
2025-12-28 16:01:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:53 +07)" (scheduled at 2025-12-28 16:01:48.038060+07:00)
2025-12-28 16:01:48,039 - INFO -  Running predictions...
2025-12-28 16:01:48,304 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:48,306 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:53 +07)" executed successfully
2025-12-28 16:01:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:58 +07)" (scheduled at 2025-12-28 16:01:53.038060+07:00)
2025-12-28 16:01:53,040 - INFO -  Running predictions...
2025-12-28 16:01:53,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:53,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:01:58 +07)" executed successfully
2025-12-28 16:01:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:03 +07)" (scheduled at 2025-12-28 16:01:58.038060+07:00)
2025-12-28 16:01:58,039 - INFO -  Running predictions...
2025-12-28 16:01:58,184 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:01:58,184 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:03 +07)" executed successfully
2025-12-28 16:02:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:08 +07)" (scheduled at 2025-12-28 16:02:03.038060+07:00)
2025-12-28 16:02:03,039 - INFO -  Running predictions...
2025-12-28 16:02:03,208 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:03,209 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:08 +07)" executed successfully
2025-12-28 16:02:08,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:13 +07)" (scheduled at 2025-12-28 16:02:08.038060+07:00)
2025-12-28 16:02:08,040 - INFO -  Running predictions...
2025-12-28 16:02:08,163 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:08,163 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:13 +07)" executed successfully
2025-12-28 16:02:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:18 +07)" (scheduled at 2025-12-28 16:02:13.038060+07:00)
2025-12-28 16:02:13,040 - INFO -  Running predictions...
2025-12-28 16:02:13,162 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:13,162 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:18 +07)" executed successfully
2025-12-28 16:02:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:23 +07)" (scheduled at 2025-12-28 16:02:18.038060+07:00)
2025-12-28 16:02:18,039 - INFO -  Running predictions...
2025-12-28 16:02:18,285 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:18,285 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:23 +07)" executed successfully
2025-12-28 16:02:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:28 +07)" (scheduled at 2025-12-28 16:02:23.038060+07:00)
2025-12-28 16:02:23,039 - INFO -  Running predictions...
2025-12-28 16:02:23,194 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:23,194 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:28 +07)" executed successfully
2025-12-28 16:02:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:33 +07)" (scheduled at 2025-12-28 16:02:28.038060+07:00)
2025-12-28 16:02:28,040 - INFO -  Running predictions...
2025-12-28 16:02:28,244 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:28,244 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:33 +07)" executed successfully
2025-12-28 16:02:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:38 +07)" (scheduled at 2025-12-28 16:02:33.038060+07:00)
2025-12-28 16:02:33,039 - INFO -  Running predictions...
2025-12-28 16:02:33,215 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:33,216 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:38 +07)" executed successfully
2025-12-28 16:02:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:43 +07)" (scheduled at 2025-12-28 16:02:38.038060+07:00)
2025-12-28 16:02:38,039 - INFO -  Running predictions...
2025-12-28 16:02:38,219 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:38,219 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:43 +07)" executed successfully
2025-12-28 16:02:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:48 +07)" (scheduled at 2025-12-28 16:02:43.038060+07:00)
2025-12-28 16:02:43,039 - INFO -  Running predictions...
2025-12-28 16:02:43,210 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:43,210 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:48 +07)" executed successfully
2025-12-28 16:02:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:53 +07)" (scheduled at 2025-12-28 16:02:48.038060+07:00)
2025-12-28 16:02:48,040 - INFO -  Running predictions...
2025-12-28 16:02:48,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:48,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:53 +07)" executed successfully
2025-12-28 16:02:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:58 +07)" (scheduled at 2025-12-28 16:02:53.038060+07:00)
2025-12-28 16:02:53,040 - INFO -  Running predictions...
2025-12-28 16:02:53,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:53,169 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:02:58 +07)" executed successfully
2025-12-28 16:02:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:03 +07)" (scheduled at 2025-12-28 16:02:58.038060+07:00)
2025-12-28 16:02:58,039 - INFO -  Running predictions...
2025-12-28 16:02:58,411 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:02:58,411 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:03 +07)" executed successfully
2025-12-28 16:03:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:08 +07)" (scheduled at 2025-12-28 16:03:03.038060+07:00)
2025-12-28 16:03:03,039 - INFO -  Running predictions...
2025-12-28 16:03:03,188 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:03,188 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:08 +07)" executed successfully
2025-12-28 16:03:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:13 +07)" (scheduled at 2025-12-28 16:03:08.038060+07:00)
2025-12-28 16:03:08,039 - INFO -  Running predictions...
2025-12-28 16:03:08,182 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:08,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:13 +07)" executed successfully
2025-12-28 16:03:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:18 +07)" (scheduled at 2025-12-28 16:03:13.038060+07:00)
2025-12-28 16:03:13,040 - INFO -  Running predictions...
2025-12-28 16:03:13,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:13,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:18 +07)" executed successfully
2025-12-28 16:03:18,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:23 +07)" (scheduled at 2025-12-28 16:03:18.038060+07:00)
2025-12-28 16:03:18,040 - INFO -  Running predictions...
2025-12-28 16:03:18,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:18,145 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:23 +07)" executed successfully
2025-12-28 16:03:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:28 +07)" (scheduled at 2025-12-28 16:03:23.038060+07:00)
2025-12-28 16:03:23,040 - INFO -  Running predictions...
2025-12-28 16:03:23,234 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:23,234 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:28 +07)" executed successfully
2025-12-28 16:03:28,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:33 +07)" (scheduled at 2025-12-28 16:03:28.038060+07:00)
2025-12-28 16:03:28,041 - INFO -  Running predictions...
2025-12-28 16:03:28,264 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:28,265 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:33 +07)" executed successfully
2025-12-28 16:03:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:38 +07)" (scheduled at 2025-12-28 16:03:33.038060+07:00)
2025-12-28 16:03:33,041 - INFO -  Running predictions...
2025-12-28 16:03:33,225 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:33,226 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:38 +07)" executed successfully
2025-12-28 16:03:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:43 +07)" (scheduled at 2025-12-28 16:03:38.038060+07:00)
2025-12-28 16:03:38,040 - INFO -  Running predictions...
2025-12-28 16:03:38,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:38,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:43 +07)" executed successfully
2025-12-28 16:03:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:48 +07)" (scheduled at 2025-12-28 16:03:43.038060+07:00)
2025-12-28 16:03:43,039 - INFO -  Running predictions...
2025-12-28 16:03:43,199 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:43,199 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:48 +07)" executed successfully
2025-12-28 16:03:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:53 +07)" (scheduled at 2025-12-28 16:03:48.038060+07:00)
2025-12-28 16:03:48,039 - INFO -  Running predictions...
2025-12-28 16:03:48,213 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:48,213 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:53 +07)" executed successfully
2025-12-28 16:03:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:58 +07)" (scheduled at 2025-12-28 16:03:53.038060+07:00)
2025-12-28 16:03:53,040 - INFO -  Running predictions...
2025-12-28 16:03:53,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:53,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:03:58 +07)" executed successfully
2025-12-28 16:03:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:03 +07)" (scheduled at 2025-12-28 16:03:58.038060+07:00)
2025-12-28 16:03:58,039 - INFO -  Running predictions...
2025-12-28 16:03:58,243 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:03:58,243 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:03 +07)" executed successfully
2025-12-28 16:04:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:08 +07)" (scheduled at 2025-12-28 16:04:03.038060+07:00)
2025-12-28 16:04:03,039 - INFO -  Running predictions...
2025-12-28 16:04:03,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:03,145 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:08 +07)" executed successfully
2025-12-28 16:04:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:13 +07)" (scheduled at 2025-12-28 16:04:08.038060+07:00)
2025-12-28 16:04:08,038 - INFO -  Running predictions...
2025-12-28 16:04:08,208 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:08,208 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:13 +07)" executed successfully
2025-12-28 16:04:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:18 +07)" (scheduled at 2025-12-28 16:04:13.038060+07:00)
2025-12-28 16:04:13,038 - INFO -  Running predictions...
2025-12-28 16:04:13,183 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:13,184 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:18 +07)" executed successfully
2025-12-28 16:04:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:23 +07)" (scheduled at 2025-12-28 16:04:18.038060+07:00)
2025-12-28 16:04:18,039 - INFO -  Running predictions...
2025-12-28 16:04:18,204 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:18,205 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:23 +07)" executed successfully
2025-12-28 16:04:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:28 +07)" (scheduled at 2025-12-28 16:04:23.038060+07:00)
2025-12-28 16:04:23,039 - INFO -  Running predictions...
2025-12-28 16:04:23,189 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:23,189 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:28 +07)" executed successfully
2025-12-28 16:04:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:33 +07)" (scheduled at 2025-12-28 16:04:28.038060+07:00)
2025-12-28 16:04:28,039 - INFO -  Running predictions...
2025-12-28 16:04:28,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:28,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:33 +07)" executed successfully
2025-12-28 16:04:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:38 +07)" (scheduled at 2025-12-28 16:04:33.038060+07:00)
2025-12-28 16:04:33,039 - INFO -  Running predictions...
2025-12-28 16:04:33,273 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:33,273 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:38 +07)" executed successfully
2025-12-28 16:04:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:43 +07)" (scheduled at 2025-12-28 16:04:38.038060+07:00)
2025-12-28 16:04:38,039 - INFO -  Running predictions...
2025-12-28 16:04:38,206 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:38,206 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:43 +07)" executed successfully
2025-12-28 16:04:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:48 +07)" (scheduled at 2025-12-28 16:04:43.038060+07:00)
2025-12-28 16:04:43,038 - INFO -  Running predictions...
2025-12-28 16:04:43,201 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:43,201 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:48 +07)" executed successfully
2025-12-28 16:04:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:53 +07)" (scheduled at 2025-12-28 16:04:48.038060+07:00)
2025-12-28 16:04:48,039 - INFO -  Running predictions...
2025-12-28 16:04:48,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:48,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:53 +07)" executed successfully
2025-12-28 16:04:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:58 +07)" (scheduled at 2025-12-28 16:04:53.038060+07:00)
2025-12-28 16:04:53,039 - INFO -  Running predictions...
2025-12-28 16:04:53,181 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:53,181 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:04:58 +07)" executed successfully
2025-12-28 16:04:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:03 +07)" (scheduled at 2025-12-28 16:04:58.038060+07:00)
2025-12-28 16:04:58,040 - INFO -  Running predictions...
2025-12-28 16:04:58,183 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:04:58,183 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:03 +07)" executed successfully
2025-12-28 16:05:03,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:08 +07)" (scheduled at 2025-12-28 16:05:03.038060+07:00)
2025-12-28 16:05:03,040 - INFO -  Running predictions...
2025-12-28 16:05:03,171 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:03,172 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:08 +07)" executed successfully
2025-12-28 16:05:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:13 +07)" (scheduled at 2025-12-28 16:05:08.038060+07:00)
2025-12-28 16:05:08,038 - INFO -  Running predictions...
2025-12-28 16:05:08,234 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:08,234 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:13 +07)" executed successfully
2025-12-28 16:05:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:18 +07)" (scheduled at 2025-12-28 16:05:13.038060+07:00)
2025-12-28 16:05:13,040 - INFO -  Running predictions...
2025-12-28 16:05:13,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:13,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:18 +07)" executed successfully
2025-12-28 16:05:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:23 +07)" (scheduled at 2025-12-28 16:05:18.038060+07:00)
2025-12-28 16:05:18,039 - INFO -  Running predictions...
2025-12-28 16:05:18,196 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:18,196 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:23 +07)" executed successfully
2025-12-28 16:05:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:28 +07)" (scheduled at 2025-12-28 16:05:23.038060+07:00)
2025-12-28 16:05:23,040 - INFO -  Running predictions...
2025-12-28 16:05:23,179 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:23,179 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:28 +07)" executed successfully
2025-12-28 16:05:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:33 +07)" (scheduled at 2025-12-28 16:05:28.038060+07:00)
2025-12-28 16:05:28,039 - INFO -  Running predictions...
2025-12-28 16:05:28,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:28,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:33 +07)" executed successfully
2025-12-28 16:05:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:38 +07)" (scheduled at 2025-12-28 16:05:33.038060+07:00)
2025-12-28 16:05:33,038 - INFO -  Running predictions...
2025-12-28 16:05:33,151 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:33,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:38 +07)" executed successfully
2025-12-28 16:05:38,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:43 +07)" (scheduled at 2025-12-28 16:05:38.038060+07:00)
2025-12-28 16:05:38,040 - INFO -  Running predictions...
2025-12-28 16:05:38,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:38,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:43 +07)" executed successfully
2025-12-28 16:05:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:48 +07)" (scheduled at 2025-12-28 16:05:43.038060+07:00)
2025-12-28 16:05:43,039 - INFO -  Running predictions...
2025-12-28 16:05:43,201 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:43,201 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:48 +07)" executed successfully
2025-12-28 16:05:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:53 +07)" (scheduled at 2025-12-28 16:05:48.038060+07:00)
2025-12-28 16:05:48,039 - INFO -  Running predictions...
2025-12-28 16:05:48,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:48,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:53 +07)" executed successfully
2025-12-28 16:05:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:58 +07)" (scheduled at 2025-12-28 16:05:53.038060+07:00)
2025-12-28 16:05:53,039 - INFO -  Running predictions...
2025-12-28 16:05:53,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:53,185 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:05:58 +07)" executed successfully
2025-12-28 16:05:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:03 +07)" (scheduled at 2025-12-28 16:05:58.038060+07:00)
2025-12-28 16:05:58,038 - INFO -  Running predictions...
2025-12-28 16:05:58,151 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:05:58,151 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:03 +07)" executed successfully
2025-12-28 16:06:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:08 +07)" (scheduled at 2025-12-28 16:06:03.038060+07:00)
2025-12-28 16:06:03,039 - INFO -  Running predictions...
2025-12-28 16:06:03,184 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:03,187 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:08 +07)" executed successfully
2025-12-28 16:06:08,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:13 +07)" (scheduled at 2025-12-28 16:06:08.038060+07:00)
2025-12-28 16:06:08,041 - INFO -  Running predictions...
2025-12-28 16:06:08,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:08,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:13 +07)" executed successfully
2025-12-28 16:06:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:18 +07)" (scheduled at 2025-12-28 16:06:13.038060+07:00)
2025-12-28 16:06:13,039 - INFO -  Running predictions...
2025-12-28 16:06:13,150 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:13,150 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:18 +07)" executed successfully
2025-12-28 16:06:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:23 +07)" (scheduled at 2025-12-28 16:06:18.038060+07:00)
2025-12-28 16:06:18,039 - INFO -  Running predictions...
2025-12-28 16:06:18,192 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:18,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:23 +07)" executed successfully
2025-12-28 16:06:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:28 +07)" (scheduled at 2025-12-28 16:06:23.038060+07:00)
2025-12-28 16:06:23,039 - INFO -  Running predictions...
2025-12-28 16:06:23,276 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:23,277 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:28 +07)" executed successfully
2025-12-28 16:06:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:33 +07)" (scheduled at 2025-12-28 16:06:28.038060+07:00)
2025-12-28 16:06:28,039 - INFO -  Running predictions...
2025-12-28 16:06:28,247 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:28,247 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:33 +07)" executed successfully
2025-12-28 16:06:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:38 +07)" (scheduled at 2025-12-28 16:06:33.038060+07:00)
2025-12-28 16:06:33,039 - INFO -  Running predictions...
2025-12-28 16:06:33,182 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:33,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:38 +07)" executed successfully
2025-12-28 16:06:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:43 +07)" (scheduled at 2025-12-28 16:06:38.038060+07:00)
2025-12-28 16:06:38,039 - INFO -  Running predictions...
2025-12-28 16:06:38,237 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:38,237 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:43 +07)" executed successfully
2025-12-28 16:06:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:48 +07)" (scheduled at 2025-12-28 16:06:43.038060+07:00)
2025-12-28 16:06:43,038 - INFO -  Running predictions...
2025-12-28 16:06:43,226 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:43,226 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:48 +07)" executed successfully
2025-12-28 16:06:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:53 +07)" (scheduled at 2025-12-28 16:06:48.038060+07:00)
2025-12-28 16:06:48,039 - INFO -  Running predictions...
2025-12-28 16:06:48,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:48,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:53 +07)" executed successfully
2025-12-28 16:06:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:58 +07)" (scheduled at 2025-12-28 16:06:53.038060+07:00)
2025-12-28 16:06:53,039 - INFO -  Running predictions...
2025-12-28 16:06:53,182 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:53,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:06:58 +07)" executed successfully
2025-12-28 16:06:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:03 +07)" (scheduled at 2025-12-28 16:06:58.038060+07:00)
2025-12-28 16:06:58,039 - INFO -  Running predictions...
2025-12-28 16:06:58,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:06:58,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:03 +07)" executed successfully
2025-12-28 16:07:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:08 +07)" (scheduled at 2025-12-28 16:07:03.038060+07:00)
2025-12-28 16:07:03,039 - INFO -  Running predictions...
2025-12-28 16:07:03,181 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:03,181 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:08 +07)" executed successfully
2025-12-28 16:07:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:13 +07)" (scheduled at 2025-12-28 16:07:08.038060+07:00)
2025-12-28 16:07:08,039 - INFO -  Running predictions...
2025-12-28 16:07:08,149 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:08,149 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:13 +07)" executed successfully
2025-12-28 16:07:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:18 +07)" (scheduled at 2025-12-28 16:07:13.038060+07:00)
2025-12-28 16:07:13,040 - INFO -  Running predictions...
2025-12-28 16:07:13,171 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:13,171 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:18 +07)" executed successfully
2025-12-28 16:07:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:23 +07)" (scheduled at 2025-12-28 16:07:18.038060+07:00)
2025-12-28 16:07:18,039 - INFO -  Running predictions...
2025-12-28 16:07:18,144 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:18,144 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:23 +07)" executed successfully
2025-12-28 16:07:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:28 +07)" (scheduled at 2025-12-28 16:07:23.038060+07:00)
2025-12-28 16:07:23,040 - INFO -  Running predictions...
2025-12-28 16:07:23,205 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:23,205 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:28 +07)" executed successfully
2025-12-28 16:07:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:33 +07)" (scheduled at 2025-12-28 16:07:28.038060+07:00)
2025-12-28 16:07:28,039 - INFO -  Running predictions...
2025-12-28 16:07:28,192 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:28,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:33 +07)" executed successfully
2025-12-28 16:07:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:38 +07)" (scheduled at 2025-12-28 16:07:33.038060+07:00)
2025-12-28 16:07:33,040 - INFO -  Running predictions...
2025-12-28 16:07:33,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:33,140 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:38 +07)" executed successfully
2025-12-28 16:07:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:43 +07)" (scheduled at 2025-12-28 16:07:38.038060+07:00)
2025-12-28 16:07:38,038 - INFO -  Running predictions...
2025-12-28 16:07:38,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:38,185 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:43 +07)" executed successfully
2025-12-28 16:07:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:48 +07)" (scheduled at 2025-12-28 16:07:43.038060+07:00)
2025-12-28 16:07:43,041 - INFO -  Running predictions...
2025-12-28 16:07:43,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:43,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:48 +07)" executed successfully
2025-12-28 16:07:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:53 +07)" (scheduled at 2025-12-28 16:07:48.038060+07:00)
2025-12-28 16:07:48,039 - INFO -  Running predictions...
2025-12-28 16:07:48,177 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:48,177 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:53 +07)" executed successfully
2025-12-28 16:07:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:58 +07)" (scheduled at 2025-12-28 16:07:53.038060+07:00)
2025-12-28 16:07:53,039 - INFO -  Running predictions...
2025-12-28 16:07:53,136 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:53,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:07:58 +07)" executed successfully
2025-12-28 16:07:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:03 +07)" (scheduled at 2025-12-28 16:07:58.038060+07:00)
2025-12-28 16:07:58,039 - INFO -  Running predictions...
2025-12-28 16:07:58,233 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:07:58,234 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:03 +07)" executed successfully
2025-12-28 16:08:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:08 +07)" (scheduled at 2025-12-28 16:08:03.038060+07:00)
2025-12-28 16:08:03,040 - INFO -  Running predictions...
2025-12-28 16:08:03,224 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:03,224 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:08 +07)" executed successfully
2025-12-28 16:08:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:13 +07)" (scheduled at 2025-12-28 16:08:08.038060+07:00)
2025-12-28 16:08:08,040 - INFO -  Running predictions...
2025-12-28 16:08:08,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:08,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:13 +07)" executed successfully
2025-12-28 16:08:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:18 +07)" (scheduled at 2025-12-28 16:08:13.038060+07:00)
2025-12-28 16:08:13,040 - INFO -  Running predictions...
2025-12-28 16:08:13,184 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:13,184 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:18 +07)" executed successfully
2025-12-28 16:08:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:23 +07)" (scheduled at 2025-12-28 16:08:18.038060+07:00)
2025-12-28 16:08:18,039 - INFO -  Running predictions...
2025-12-28 16:08:18,142 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:18,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:23 +07)" executed successfully
2025-12-28 16:08:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:28 +07)" (scheduled at 2025-12-28 16:08:23.038060+07:00)
2025-12-28 16:08:23,038 - INFO -  Running predictions...
2025-12-28 16:08:23,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:23,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:28 +07)" executed successfully
2025-12-28 16:08:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:33 +07)" (scheduled at 2025-12-28 16:08:28.038060+07:00)
2025-12-28 16:08:28,039 - INFO -  Running predictions...
2025-12-28 16:08:28,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:28,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:33 +07)" executed successfully
2025-12-28 16:08:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:38 +07)" (scheduled at 2025-12-28 16:08:33.038060+07:00)
2025-12-28 16:08:33,038 - INFO -  Running predictions...
2025-12-28 16:08:33,127 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:33,127 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:38 +07)" executed successfully
2025-12-28 16:08:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:43 +07)" (scheduled at 2025-12-28 16:08:38.038060+07:00)
2025-12-28 16:08:38,039 - INFO -  Running predictions...
2025-12-28 16:08:38,218 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:38,218 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:43 +07)" executed successfully
2025-12-28 16:08:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:48 +07)" (scheduled at 2025-12-28 16:08:43.038060+07:00)
2025-12-28 16:08:43,038 - INFO -  Running predictions...
2025-12-28 16:08:43,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:43,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:48 +07)" executed successfully
2025-12-28 16:08:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:53 +07)" (scheduled at 2025-12-28 16:08:48.038060+07:00)
2025-12-28 16:08:48,038 - INFO -  Running predictions...
2025-12-28 16:08:48,179 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:48,179 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:53 +07)" executed successfully
2025-12-28 16:08:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:58 +07)" (scheduled at 2025-12-28 16:08:53.038060+07:00)
2025-12-28 16:08:53,038 - INFO -  Running predictions...
2025-12-28 16:08:53,165 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:53,166 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:08:58 +07)" executed successfully
2025-12-28 16:08:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:03 +07)" (scheduled at 2025-12-28 16:08:58.038060+07:00)
2025-12-28 16:08:58,039 - INFO -  Running predictions...
2025-12-28 16:08:58,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:08:58,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:03 +07)" executed successfully
2025-12-28 16:09:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:08 +07)" (scheduled at 2025-12-28 16:09:03.038060+07:00)
2025-12-28 16:09:03,039 - INFO -  Running predictions...
2025-12-28 16:09:03,162 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:03,162 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:08 +07)" executed successfully
2025-12-28 16:09:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:13 +07)" (scheduled at 2025-12-28 16:09:08.038060+07:00)
2025-12-28 16:09:08,039 - INFO -  Running predictions...
2025-12-28 16:09:08,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:08,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:13 +07)" executed successfully
2025-12-28 16:09:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:18 +07)" (scheduled at 2025-12-28 16:09:13.038060+07:00)
2025-12-28 16:09:13,038 - INFO -  Running predictions...
2025-12-28 16:09:13,248 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:13,248 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:18 +07)" executed successfully
2025-12-28 16:09:18,043 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:23 +07)" (scheduled at 2025-12-28 16:09:18.038060+07:00)
2025-12-28 16:09:18,043 - INFO -  Running predictions...
2025-12-28 16:09:18,302 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:18,303 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:23 +07)" executed successfully
2025-12-28 16:09:23,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:28 +07)" (scheduled at 2025-12-28 16:09:23.038060+07:00)
2025-12-28 16:09:23,040 - INFO -  Running predictions...
2025-12-28 16:09:23,234 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:23,235 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:28 +07)" executed successfully
2025-12-28 16:09:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:33 +07)" (scheduled at 2025-12-28 16:09:28.038060+07:00)
2025-12-28 16:09:28,038 - INFO -  Running predictions...
2025-12-28 16:09:28,174 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:28,174 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:33 +07)" executed successfully
2025-12-28 16:09:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:38 +07)" (scheduled at 2025-12-28 16:09:33.038060+07:00)
2025-12-28 16:09:33,038 - INFO -  Running predictions...
2025-12-28 16:09:33,220 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:33,221 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:38 +07)" executed successfully
2025-12-28 16:09:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:43 +07)" (scheduled at 2025-12-28 16:09:38.038060+07:00)
2025-12-28 16:09:38,039 - INFO -  Running predictions...
2025-12-28 16:09:38,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:38,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:43 +07)" executed successfully
2025-12-28 16:09:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:48 +07)" (scheduled at 2025-12-28 16:09:43.038060+07:00)
2025-12-28 16:09:43,038 - INFO -  Running predictions...
2025-12-28 16:09:43,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:43,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:48 +07)" executed successfully
2025-12-28 16:09:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:53 +07)" (scheduled at 2025-12-28 16:09:48.038060+07:00)
2025-12-28 16:09:48,040 - INFO -  Running predictions...
2025-12-28 16:09:48,179 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:48,179 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:53 +07)" executed successfully
2025-12-28 16:09:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:58 +07)" (scheduled at 2025-12-28 16:09:53.038060+07:00)
2025-12-28 16:09:53,040 - INFO -  Running predictions...
2025-12-28 16:09:53,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:53,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:09:58 +07)" executed successfully
2025-12-28 16:09:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:03 +07)" (scheduled at 2025-12-28 16:09:58.038060+07:00)
2025-12-28 16:09:58,039 - INFO -  Running predictions...
2025-12-28 16:09:58,180 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:09:58,181 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:03 +07)" executed successfully
2025-12-28 16:10:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:08 +07)" (scheduled at 2025-12-28 16:10:03.038060+07:00)
2025-12-28 16:10:03,039 - INFO -  Running predictions...
2025-12-28 16:10:03,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:03,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:08 +07)" executed successfully
2025-12-28 16:10:08,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:13 +07)" (scheduled at 2025-12-28 16:10:08.038060+07:00)
2025-12-28 16:10:08,041 - INFO -  Running predictions...
2025-12-28 16:10:08,151 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:08,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:13 +07)" executed successfully
2025-12-28 16:10:13,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:18 +07)" (scheduled at 2025-12-28 16:10:13.038060+07:00)
2025-12-28 16:10:13,042 - INFO -  Running predictions...
2025-12-28 16:10:13,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:13,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:18 +07)" executed successfully
2025-12-28 16:10:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:23 +07)" (scheduled at 2025-12-28 16:10:18.038060+07:00)
2025-12-28 16:10:18,039 - INFO -  Running predictions...
2025-12-28 16:10:18,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:18,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:23 +07)" executed successfully
2025-12-28 16:10:23,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:28 +07)" (scheduled at 2025-12-28 16:10:23.038060+07:00)
2025-12-28 16:10:23,040 - INFO -  Running predictions...
2025-12-28 16:10:23,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:23,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:28 +07)" executed successfully
2025-12-28 16:10:28,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:33 +07)" (scheduled at 2025-12-28 16:10:28.038060+07:00)
2025-12-28 16:10:28,041 - INFO -  Running predictions...
2025-12-28 16:10:28,126 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:28,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:33 +07)" executed successfully
2025-12-28 16:10:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:38 +07)" (scheduled at 2025-12-28 16:10:33.038060+07:00)
2025-12-28 16:10:33,039 - INFO -  Running predictions...
2025-12-28 16:10:33,166 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:33,166 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:38 +07)" executed successfully
2025-12-28 16:10:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:43 +07)" (scheduled at 2025-12-28 16:10:38.038060+07:00)
2025-12-28 16:10:38,039 - INFO -  Running predictions...
2025-12-28 16:10:38,131 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:38,131 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:43 +07)" executed successfully
2025-12-28 16:10:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:48 +07)" (scheduled at 2025-12-28 16:10:43.038060+07:00)
2025-12-28 16:10:43,040 - INFO -  Running predictions...
2025-12-28 16:10:43,156 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:43,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:48 +07)" executed successfully
2025-12-28 16:10:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:53 +07)" (scheduled at 2025-12-28 16:10:48.038060+07:00)
2025-12-28 16:10:48,039 - INFO -  Running predictions...
2025-12-28 16:10:48,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:48,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:53 +07)" executed successfully
2025-12-28 16:10:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:58 +07)" (scheduled at 2025-12-28 16:10:53.038060+07:00)
2025-12-28 16:10:53,039 - INFO -  Running predictions...
2025-12-28 16:10:53,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:53,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:10:58 +07)" executed successfully
2025-12-28 16:10:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:03 +07)" (scheduled at 2025-12-28 16:10:58.038060+07:00)
2025-12-28 16:10:58,039 - INFO -  Running predictions...
2025-12-28 16:10:58,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:10:58,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:03 +07)" executed successfully
2025-12-28 16:11:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:08 +07)" (scheduled at 2025-12-28 16:11:03.038060+07:00)
2025-12-28 16:11:03,040 - INFO -  Running predictions...
2025-12-28 16:11:03,160 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:03,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:08 +07)" executed successfully
2025-12-28 16:11:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:13 +07)" (scheduled at 2025-12-28 16:11:08.038060+07:00)
2025-12-28 16:11:08,040 - INFO -  Running predictions...
2025-12-28 16:11:08,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:08,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:13 +07)" executed successfully
2025-12-28 16:11:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:18 +07)" (scheduled at 2025-12-28 16:11:13.038060+07:00)
2025-12-28 16:11:13,040 - INFO -  Running predictions...
2025-12-28 16:11:13,173 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:13,173 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:18 +07)" executed successfully
2025-12-28 16:11:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:23 +07)" (scheduled at 2025-12-28 16:11:18.038060+07:00)
2025-12-28 16:11:18,040 - INFO -  Running predictions...
2025-12-28 16:11:18,140 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:18,140 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:23 +07)" executed successfully
2025-12-28 16:11:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:28 +07)" (scheduled at 2025-12-28 16:11:23.038060+07:00)
2025-12-28 16:11:23,040 - INFO -  Running predictions...
2025-12-28 16:11:23,146 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:23,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:28 +07)" executed successfully
2025-12-28 16:11:28,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:33 +07)" (scheduled at 2025-12-28 16:11:28.038060+07:00)
2025-12-28 16:11:28,040 - INFO -  Running predictions...
2025-12-28 16:11:28,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:28,135 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:33 +07)" executed successfully
2025-12-28 16:11:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:38 +07)" (scheduled at 2025-12-28 16:11:33.038060+07:00)
2025-12-28 16:11:33,039 - INFO -  Running predictions...
2025-12-28 16:11:33,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:33,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:38 +07)" executed successfully
2025-12-28 16:11:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:43 +07)" (scheduled at 2025-12-28 16:11:38.038060+07:00)
2025-12-28 16:11:38,040 - INFO -  Running predictions...
2025-12-28 16:11:38,125 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:38,125 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:43 +07)" executed successfully
2025-12-28 16:11:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:48 +07)" (scheduled at 2025-12-28 16:11:43.038060+07:00)
2025-12-28 16:11:43,041 - INFO -  Running predictions...
2025-12-28 16:11:43,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:43,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:48 +07)" executed successfully
2025-12-28 16:11:48,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:53 +07)" (scheduled at 2025-12-28 16:11:48.038060+07:00)
2025-12-28 16:11:48,041 - INFO -  Running predictions...
2025-12-28 16:11:48,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:48,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:53 +07)" executed successfully
2025-12-28 16:11:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:58 +07)" (scheduled at 2025-12-28 16:11:53.038060+07:00)
2025-12-28 16:11:53,040 - INFO -  Running predictions...
2025-12-28 16:11:53,146 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:53,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:11:58 +07)" executed successfully
2025-12-28 16:11:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:03 +07)" (scheduled at 2025-12-28 16:11:58.038060+07:00)
2025-12-28 16:11:58,039 - INFO -  Running predictions...
2025-12-28 16:11:58,124 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:11:58,124 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:03 +07)" executed successfully
2025-12-28 16:12:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:08 +07)" (scheduled at 2025-12-28 16:12:03.038060+07:00)
2025-12-28 16:12:03,040 - INFO -  Running predictions...
2025-12-28 16:12:03,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:03,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:08 +07)" executed successfully
2025-12-28 16:12:08,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:13 +07)" (scheduled at 2025-12-28 16:12:08.038060+07:00)
2025-12-28 16:12:08,040 - INFO -  Running predictions...
2025-12-28 16:12:08,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:08,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:13 +07)" executed successfully
2025-12-28 16:12:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:18 +07)" (scheduled at 2025-12-28 16:12:13.038060+07:00)
2025-12-28 16:12:13,040 - INFO -  Running predictions...
2025-12-28 16:12:13,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:13,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:18 +07)" executed successfully
2025-12-28 16:12:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:23 +07)" (scheduled at 2025-12-28 16:12:18.038060+07:00)
2025-12-28 16:12:18,040 - INFO -  Running predictions...
2025-12-28 16:12:18,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:18,135 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:23 +07)" executed successfully
2025-12-28 16:12:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:28 +07)" (scheduled at 2025-12-28 16:12:23.038060+07:00)
2025-12-28 16:12:23,039 - INFO -  Running predictions...
2025-12-28 16:12:23,190 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:23,190 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:28 +07)" executed successfully
2025-12-28 16:12:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:33 +07)" (scheduled at 2025-12-28 16:12:28.038060+07:00)
2025-12-28 16:12:28,039 - INFO -  Running predictions...
2025-12-28 16:12:28,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:28,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:33 +07)" executed successfully
2025-12-28 16:12:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:38 +07)" (scheduled at 2025-12-28 16:12:33.038060+07:00)
2025-12-28 16:12:33,039 - INFO -  Running predictions...
2025-12-28 16:12:33,153 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:33,153 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:38 +07)" executed successfully
2025-12-28 16:12:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:43 +07)" (scheduled at 2025-12-28 16:12:38.038060+07:00)
2025-12-28 16:12:38,040 - INFO -  Running predictions...
2025-12-28 16:12:38,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:38,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:43 +07)" executed successfully
2025-12-28 16:12:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:48 +07)" (scheduled at 2025-12-28 16:12:43.038060+07:00)
2025-12-28 16:12:43,040 - INFO -  Running predictions...
2025-12-28 16:12:43,153 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:43,153 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:48 +07)" executed successfully
2025-12-28 16:12:48,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:53 +07)" (scheduled at 2025-12-28 16:12:48.038060+07:00)
2025-12-28 16:12:48,040 - INFO -  Running predictions...
2025-12-28 16:12:48,140 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:48,140 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:53 +07)" executed successfully
2025-12-28 16:12:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:58 +07)" (scheduled at 2025-12-28 16:12:53.038060+07:00)
2025-12-28 16:12:53,039 - INFO -  Running predictions...
2025-12-28 16:12:53,171 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:53,171 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:12:58 +07)" executed successfully
2025-12-28 16:12:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:03 +07)" (scheduled at 2025-12-28 16:12:58.038060+07:00)
2025-12-28 16:12:58,040 - INFO -  Running predictions...
2025-12-28 16:12:58,170 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:12:58,170 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:03 +07)" executed successfully
2025-12-28 16:13:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:08 +07)" (scheduled at 2025-12-28 16:13:03.038060+07:00)
2025-12-28 16:13:03,039 - INFO -  Running predictions...
2025-12-28 16:13:03,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:03,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:08 +07)" executed successfully
2025-12-28 16:13:08,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:13 +07)" (scheduled at 2025-12-28 16:13:08.038060+07:00)
2025-12-28 16:13:08,041 - INFO -  Running predictions...
2025-12-28 16:13:08,131 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:08,131 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:13 +07)" executed successfully
2025-12-28 16:13:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:18 +07)" (scheduled at 2025-12-28 16:13:13.038060+07:00)
2025-12-28 16:13:13,038 - INFO -  Running predictions...
2025-12-28 16:13:13,238 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:13,238 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:18 +07)" executed successfully
2025-12-28 16:13:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:23 +07)" (scheduled at 2025-12-28 16:13:18.038060+07:00)
2025-12-28 16:13:18,038 - INFO -  Running predictions...
2025-12-28 16:13:18,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:18,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:23 +07)" executed successfully
2025-12-28 16:13:23,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:28 +07)" (scheduled at 2025-12-28 16:13:23.038060+07:00)
2025-12-28 16:13:23,040 - INFO -  Running predictions...
2025-12-28 16:13:23,192 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:23,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:28 +07)" executed successfully
2025-12-28 16:13:28,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:33 +07)" (scheduled at 2025-12-28 16:13:28.038060+07:00)
2025-12-28 16:13:28,040 - INFO -  Running predictions...
2025-12-28 16:13:28,235 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:28,236 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:33 +07)" executed successfully
2025-12-28 16:13:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:38 +07)" (scheduled at 2025-12-28 16:13:33.038060+07:00)
2025-12-28 16:13:33,040 - INFO -  Running predictions...
2025-12-28 16:13:33,171 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:33,171 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:38 +07)" executed successfully
2025-12-28 16:13:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:43 +07)" (scheduled at 2025-12-28 16:13:38.038060+07:00)
2025-12-28 16:13:38,039 - INFO -  Running predictions...
2025-12-28 16:13:38,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:38,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:43 +07)" executed successfully
2025-12-28 16:13:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:48 +07)" (scheduled at 2025-12-28 16:13:43.038060+07:00)
2025-12-28 16:13:43,039 - INFO -  Running predictions...
2025-12-28 16:13:43,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:43,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:48 +07)" executed successfully
2025-12-28 16:13:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:53 +07)" (scheduled at 2025-12-28 16:13:48.038060+07:00)
2025-12-28 16:13:48,039 - INFO -  Running predictions...
2025-12-28 16:13:48,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:48,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:53 +07)" executed successfully
2025-12-28 16:13:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:58 +07)" (scheduled at 2025-12-28 16:13:53.038060+07:00)
2025-12-28 16:13:53,039 - INFO -  Running predictions...
2025-12-28 16:13:53,189 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:53,189 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:13:58 +07)" executed successfully
2025-12-28 16:13:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:03 +07)" (scheduled at 2025-12-28 16:13:58.038060+07:00)
2025-12-28 16:13:58,039 - INFO -  Running predictions...
2025-12-28 16:13:58,194 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:13:58,195 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:03 +07)" executed successfully
2025-12-28 16:14:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:08 +07)" (scheduled at 2025-12-28 16:14:03.038060+07:00)
2025-12-28 16:14:03,039 - INFO -  Running predictions...
2025-12-28 16:14:03,191 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:03,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:08 +07)" executed successfully
2025-12-28 16:14:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:13 +07)" (scheduled at 2025-12-28 16:14:08.038060+07:00)
2025-12-28 16:14:08,039 - INFO -  Running predictions...
2025-12-28 16:14:08,144 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:08,144 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:13 +07)" executed successfully
2025-12-28 16:14:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:18 +07)" (scheduled at 2025-12-28 16:14:13.038060+07:00)
2025-12-28 16:14:13,038 - INFO -  Running predictions...
2025-12-28 16:14:13,256 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:13,257 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:18 +07)" executed successfully
2025-12-28 16:14:18,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:23 +07)" (scheduled at 2025-12-28 16:14:18.038060+07:00)
2025-12-28 16:14:18,041 - INFO -  Running predictions...
2025-12-28 16:14:18,124 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:18,124 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:23 +07)" executed successfully
2025-12-28 16:14:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:28 +07)" (scheduled at 2025-12-28 16:14:23.038060+07:00)
2025-12-28 16:14:23,039 - INFO -  Running predictions...
2025-12-28 16:14:23,153 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:23,154 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:28 +07)" executed successfully
2025-12-28 16:14:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:33 +07)" (scheduled at 2025-12-28 16:14:28.038060+07:00)
2025-12-28 16:14:28,039 - INFO -  Running predictions...
2025-12-28 16:14:28,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:28,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:33 +07)" executed successfully
2025-12-28 16:14:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:38 +07)" (scheduled at 2025-12-28 16:14:33.038060+07:00)
2025-12-28 16:14:33,039 - INFO -  Running predictions...
2025-12-28 16:14:33,182 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:33,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:38 +07)" executed successfully
2025-12-28 16:14:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:43 +07)" (scheduled at 2025-12-28 16:14:38.038060+07:00)
2025-12-28 16:14:38,039 - INFO -  Running predictions...
2025-12-28 16:14:38,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:38,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:43 +07)" executed successfully
2025-12-28 16:14:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:48 +07)" (scheduled at 2025-12-28 16:14:43.038060+07:00)
2025-12-28 16:14:43,039 - INFO -  Running predictions...
2025-12-28 16:14:43,197 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:43,197 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:48 +07)" executed successfully
2025-12-28 16:14:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:53 +07)" (scheduled at 2025-12-28 16:14:48.038060+07:00)
2025-12-28 16:14:48,039 - INFO -  Running predictions...
2025-12-28 16:14:48,164 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:48,164 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:53 +07)" executed successfully
2025-12-28 16:14:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:58 +07)" (scheduled at 2025-12-28 16:14:53.038060+07:00)
2025-12-28 16:14:53,039 - INFO -  Running predictions...
2025-12-28 16:14:53,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:53,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:14:58 +07)" executed successfully
2025-12-28 16:14:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:03 +07)" (scheduled at 2025-12-28 16:14:58.038060+07:00)
2025-12-28 16:14:58,039 - INFO -  Running predictions...
2025-12-28 16:14:58,194 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:14:58,194 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:03 +07)" executed successfully
2025-12-28 16:15:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:08 +07)" (scheduled at 2025-12-28 16:15:03.038060+07:00)
2025-12-28 16:15:03,040 - INFO -  Running predictions...
2025-12-28 16:15:03,192 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:03,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:08 +07)" executed successfully
2025-12-28 16:15:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:13 +07)" (scheduled at 2025-12-28 16:15:08.038060+07:00)
2025-12-28 16:15:08,039 - INFO -  Running predictions...
2025-12-28 16:15:08,163 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:08,164 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:13 +07)" executed successfully
2025-12-28 16:15:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:18 +07)" (scheduled at 2025-12-28 16:15:13.038060+07:00)
2025-12-28 16:15:13,041 - INFO -  Running predictions...
2025-12-28 16:15:13,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:13,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:18 +07)" executed successfully
2025-12-28 16:15:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:23 +07)" (scheduled at 2025-12-28 16:15:18.038060+07:00)
2025-12-28 16:15:18,039 - INFO -  Running predictions...
2025-12-28 16:15:18,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:18,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:23 +07)" executed successfully
2025-12-28 16:15:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:28 +07)" (scheduled at 2025-12-28 16:15:23.038060+07:00)
2025-12-28 16:15:23,040 - INFO -  Running predictions...
2025-12-28 16:15:23,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:23,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:28 +07)" executed successfully
2025-12-28 16:15:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:33 +07)" (scheduled at 2025-12-28 16:15:28.038060+07:00)
2025-12-28 16:15:28,039 - INFO -  Running predictions...
2025-12-28 16:15:28,160 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:28,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:33 +07)" executed successfully
2025-12-28 16:15:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:38 +07)" (scheduled at 2025-12-28 16:15:33.038060+07:00)
2025-12-28 16:15:33,040 - INFO -  Running predictions...
2025-12-28 16:15:33,149 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:33,149 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:38 +07)" executed successfully
2025-12-28 16:15:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:43 +07)" (scheduled at 2025-12-28 16:15:38.038060+07:00)
2025-12-28 16:15:38,038 - INFO -  Running predictions...
2025-12-28 16:15:38,136 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:38,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:43 +07)" executed successfully
2025-12-28 16:15:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:48 +07)" (scheduled at 2025-12-28 16:15:43.038060+07:00)
2025-12-28 16:15:43,039 - INFO -  Running predictions...
2025-12-28 16:15:43,192 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:43,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:48 +07)" executed successfully
2025-12-28 16:15:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:53 +07)" (scheduled at 2025-12-28 16:15:48.038060+07:00)
2025-12-28 16:15:48,040 - INFO -  Running predictions...
2025-12-28 16:15:48,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:48,145 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:53 +07)" executed successfully
2025-12-28 16:15:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:58 +07)" (scheduled at 2025-12-28 16:15:53.038060+07:00)
2025-12-28 16:15:53,039 - INFO -  Running predictions...
2025-12-28 16:15:53,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:53,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:15:58 +07)" executed successfully
2025-12-28 16:15:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:03 +07)" (scheduled at 2025-12-28 16:15:58.038060+07:00)
2025-12-28 16:15:58,038 - INFO -  Running predictions...
2025-12-28 16:15:58,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:15:58,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:03 +07)" executed successfully
2025-12-28 16:16:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:08 +07)" (scheduled at 2025-12-28 16:16:03.038060+07:00)
2025-12-28 16:16:03,040 - INFO -  Running predictions...
2025-12-28 16:16:03,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:03,145 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:08 +07)" executed successfully
2025-12-28 16:16:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:13 +07)" (scheduled at 2025-12-28 16:16:08.038060+07:00)
2025-12-28 16:16:08,039 - INFO -  Running predictions...
2025-12-28 16:16:08,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:08,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:13 +07)" executed successfully
2025-12-28 16:16:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:18 +07)" (scheduled at 2025-12-28 16:16:13.038060+07:00)
2025-12-28 16:16:13,039 - INFO -  Running predictions...
2025-12-28 16:16:13,181 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:13,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:18 +07)" executed successfully
2025-12-28 16:16:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:23 +07)" (scheduled at 2025-12-28 16:16:18.038060+07:00)
2025-12-28 16:16:18,038 - INFO -  Running predictions...
2025-12-28 16:16:18,177 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:18,177 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:23 +07)" executed successfully
2025-12-28 16:16:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:28 +07)" (scheduled at 2025-12-28 16:16:23.038060+07:00)
2025-12-28 16:16:23,039 - INFO -  Running predictions...
2025-12-28 16:16:23,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:23,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:28 +07)" executed successfully
2025-12-28 16:16:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:33 +07)" (scheduled at 2025-12-28 16:16:28.038060+07:00)
2025-12-28 16:16:28,038 - INFO -  Running predictions...
2025-12-28 16:16:28,198 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:28,198 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:33 +07)" executed successfully
2025-12-28 16:16:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:38 +07)" (scheduled at 2025-12-28 16:16:33.038060+07:00)
2025-12-28 16:16:33,039 - INFO -  Running predictions...
2025-12-28 16:16:33,170 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:33,171 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:38 +07)" executed successfully
2025-12-28 16:16:38,041 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:43 +07)" (scheduled at 2025-12-28 16:16:38.038060+07:00)
2025-12-28 16:16:38,041 - INFO -  Running predictions...
2025-12-28 16:16:38,175 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:38,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:43 +07)" executed successfully
2025-12-28 16:16:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:48 +07)" (scheduled at 2025-12-28 16:16:43.038060+07:00)
2025-12-28 16:16:43,039 - INFO -  Running predictions...
2025-12-28 16:16:43,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:43,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:48 +07)" executed successfully
2025-12-28 16:16:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:53 +07)" (scheduled at 2025-12-28 16:16:48.038060+07:00)
2025-12-28 16:16:48,039 - INFO -  Running predictions...
2025-12-28 16:16:48,222 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:48,222 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:53 +07)" executed successfully
2025-12-28 16:16:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:58 +07)" (scheduled at 2025-12-28 16:16:53.038060+07:00)
2025-12-28 16:16:53,039 - INFO -  Running predictions...
2025-12-28 16:16:53,175 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:53,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:16:58 +07)" executed successfully
2025-12-28 16:16:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:03 +07)" (scheduled at 2025-12-28 16:16:58.038060+07:00)
2025-12-28 16:16:58,039 - INFO -  Running predictions...
2025-12-28 16:16:58,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:16:58,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:03 +07)" executed successfully
2025-12-28 16:17:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:08 +07)" (scheduled at 2025-12-28 16:17:03.038060+07:00)
2025-12-28 16:17:03,040 - INFO -  Running predictions...
2025-12-28 16:17:03,140 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:03,140 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:08 +07)" executed successfully
2025-12-28 16:17:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:13 +07)" (scheduled at 2025-12-28 16:17:08.038060+07:00)
2025-12-28 16:17:08,039 - INFO -  Running predictions...
2025-12-28 16:17:08,174 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:08,174 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:13 +07)" executed successfully
2025-12-28 16:17:13,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:18 +07)" (scheduled at 2025-12-28 16:17:13.038060+07:00)
2025-12-28 16:17:13,040 - INFO -  Running predictions...
2025-12-28 16:17:13,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:13,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:18 +07)" executed successfully
2025-12-28 16:17:18,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:23 +07)" (scheduled at 2025-12-28 16:17:18.038060+07:00)
2025-12-28 16:17:18,040 - INFO -  Running predictions...
2025-12-28 16:17:18,140 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:18,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:23 +07)" executed successfully
2025-12-28 16:17:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:28 +07)" (scheduled at 2025-12-28 16:17:23.038060+07:00)
2025-12-28 16:17:23,038 - INFO -  Running predictions...
2025-12-28 16:17:23,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:23,153 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:28 +07)" executed successfully
2025-12-28 16:17:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:33 +07)" (scheduled at 2025-12-28 16:17:28.038060+07:00)
2025-12-28 16:17:28,041 - INFO -  Running predictions...
2025-12-28 16:17:28,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:28,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:33 +07)" executed successfully
2025-12-28 16:17:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:38 +07)" (scheduled at 2025-12-28 16:17:33.038060+07:00)
2025-12-28 16:17:33,040 - INFO -  Running predictions...
2025-12-28 16:17:33,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:33,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:38 +07)" executed successfully
2025-12-28 16:17:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:43 +07)" (scheduled at 2025-12-28 16:17:38.038060+07:00)
2025-12-28 16:17:38,039 - INFO -  Running predictions...
2025-12-28 16:17:38,126 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:38,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:43 +07)" executed successfully
2025-12-28 16:17:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:48 +07)" (scheduled at 2025-12-28 16:17:43.038060+07:00)
2025-12-28 16:17:43,039 - INFO -  Running predictions...
2025-12-28 16:17:43,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:43,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:48 +07)" executed successfully
2025-12-28 16:17:48,042 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:53 +07)" (scheduled at 2025-12-28 16:17:48.038060+07:00)
2025-12-28 16:17:48,042 - INFO -  Running predictions...
2025-12-28 16:17:48,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:48,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:53 +07)" executed successfully
2025-12-28 16:17:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:58 +07)" (scheduled at 2025-12-28 16:17:53.038060+07:00)
2025-12-28 16:17:53,039 - INFO -  Running predictions...
2025-12-28 16:17:53,194 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:53,195 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:17:58 +07)" executed successfully
2025-12-28 16:17:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:03 +07)" (scheduled at 2025-12-28 16:17:58.038060+07:00)
2025-12-28 16:17:58,039 - INFO -  Running predictions...
2025-12-28 16:17:58,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:17:58,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:03 +07)" executed successfully
2025-12-28 16:18:03,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:08 +07)" (scheduled at 2025-12-28 16:18:03.038060+07:00)
2025-12-28 16:18:03,040 - INFO -  Running predictions...
2025-12-28 16:18:03,178 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:03,178 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:08 +07)" executed successfully
2025-12-28 16:18:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:13 +07)" (scheduled at 2025-12-28 16:18:08.038060+07:00)
2025-12-28 16:18:08,040 - INFO -  Running predictions...
2025-12-28 16:18:08,146 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:08,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:13 +07)" executed successfully
2025-12-28 16:18:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:18 +07)" (scheduled at 2025-12-28 16:18:13.038060+07:00)
2025-12-28 16:18:13,038 - INFO -  Running predictions...
2025-12-28 16:18:13,201 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:13,201 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:18 +07)" executed successfully
2025-12-28 16:18:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:23 +07)" (scheduled at 2025-12-28 16:18:18.038060+07:00)
2025-12-28 16:18:18,039 - INFO -  Running predictions...
2025-12-28 16:18:18,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:18,135 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:23 +07)" executed successfully
2025-12-28 16:18:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:28 +07)" (scheduled at 2025-12-28 16:18:23.038060+07:00)
2025-12-28 16:18:23,039 - INFO -  Running predictions...
2025-12-28 16:18:23,204 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:23,205 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:28 +07)" executed successfully
2025-12-28 16:18:28,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:33 +07)" (scheduled at 2025-12-28 16:18:28.038060+07:00)
2025-12-28 16:18:28,040 - INFO -  Running predictions...
2025-12-28 16:18:28,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:28,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:33 +07)" executed successfully
2025-12-28 16:18:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:38 +07)" (scheduled at 2025-12-28 16:18:33.038060+07:00)
2025-12-28 16:18:33,040 - INFO -  Running predictions...
2025-12-28 16:18:33,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:33,145 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:38 +07)" executed successfully
2025-12-28 16:18:38,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:43 +07)" (scheduled at 2025-12-28 16:18:38.038060+07:00)
2025-12-28 16:18:38,040 - INFO -  Running predictions...
2025-12-28 16:18:38,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:38,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:43 +07)" executed successfully
2025-12-28 16:18:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:48 +07)" (scheduled at 2025-12-28 16:18:43.038060+07:00)
2025-12-28 16:18:43,039 - INFO -  Running predictions...
2025-12-28 16:18:43,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:43,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:48 +07)" executed successfully
2025-12-28 16:18:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:53 +07)" (scheduled at 2025-12-28 16:18:48.038060+07:00)
2025-12-28 16:18:48,039 - INFO -  Running predictions...
2025-12-28 16:18:48,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:48,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:53 +07)" executed successfully
2025-12-28 16:18:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:58 +07)" (scheduled at 2025-12-28 16:18:53.038060+07:00)
2025-12-28 16:18:53,038 - INFO -  Running predictions...
2025-12-28 16:18:53,191 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:53,191 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:18:58 +07)" executed successfully
2025-12-28 16:18:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:03 +07)" (scheduled at 2025-12-28 16:18:58.038060+07:00)
2025-12-28 16:18:58,040 - INFO -  Running predictions...
2025-12-28 16:18:58,156 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:18:58,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:03 +07)" executed successfully
2025-12-28 16:19:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:08 +07)" (scheduled at 2025-12-28 16:19:03.038060+07:00)
2025-12-28 16:19:03,039 - INFO -  Running predictions...
2025-12-28 16:19:03,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:03,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:08 +07)" executed successfully
2025-12-28 16:19:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:13 +07)" (scheduled at 2025-12-28 16:19:08.038060+07:00)
2025-12-28 16:19:08,038 - INFO -  Running predictions...
2025-12-28 16:19:08,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:08,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:13 +07)" executed successfully
2025-12-28 16:19:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:18 +07)" (scheduled at 2025-12-28 16:19:13.038060+07:00)
2025-12-28 16:19:13,039 - INFO -  Running predictions...
2025-12-28 16:19:13,214 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:13,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:18 +07)" executed successfully
2025-12-28 16:19:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:23 +07)" (scheduled at 2025-12-28 16:19:18.038060+07:00)
2025-12-28 16:19:18,039 - INFO -  Running predictions...
2025-12-28 16:19:18,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:18,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:23 +07)" executed successfully
2025-12-28 16:19:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:28 +07)" (scheduled at 2025-12-28 16:19:23.038060+07:00)
2025-12-28 16:19:23,039 - INFO -  Running predictions...
2025-12-28 16:19:23,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:23,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:28 +07)" executed successfully
2025-12-28 16:19:28,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:33 +07)" (scheduled at 2025-12-28 16:19:28.038060+07:00)
2025-12-28 16:19:28,040 - INFO -  Running predictions...
2025-12-28 16:19:28,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:28,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:33 +07)" executed successfully
2025-12-28 16:19:33,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:38 +07)" (scheduled at 2025-12-28 16:19:33.038060+07:00)
2025-12-28 16:19:33,039 - INFO -  Running predictions...
2025-12-28 16:19:33,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:33,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:38 +07)" executed successfully
2025-12-28 16:19:38,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:43 +07)" (scheduled at 2025-12-28 16:19:38.038060+07:00)
2025-12-28 16:19:38,040 - INFO -  Running predictions...
2025-12-28 16:19:38,202 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:38,203 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:43 +07)" executed successfully
2025-12-28 16:19:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:48 +07)" (scheduled at 2025-12-28 16:19:43.038060+07:00)
2025-12-28 16:19:43,039 - INFO -  Running predictions...
2025-12-28 16:19:43,136 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:43,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:48 +07)" executed successfully
2025-12-28 16:19:48,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:53 +07)" (scheduled at 2025-12-28 16:19:48.038060+07:00)
2025-12-28 16:19:48,040 - INFO -  Running predictions...
2025-12-28 16:19:48,178 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:48,178 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:53 +07)" executed successfully
2025-12-28 16:19:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:58 +07)" (scheduled at 2025-12-28 16:19:53.038060+07:00)
2025-12-28 16:19:53,039 - INFO -  Running predictions...
2025-12-28 16:19:53,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:53,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:19:58 +07)" executed successfully
2025-12-28 16:19:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:03 +07)" (scheduled at 2025-12-28 16:19:58.038060+07:00)
2025-12-28 16:19:58,039 - INFO -  Running predictions...
2025-12-28 16:19:58,136 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:19:58,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:03 +07)" executed successfully
2025-12-28 16:20:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:08 +07)" (scheduled at 2025-12-28 16:20:03.038060+07:00)
2025-12-28 16:20:03,039 - INFO -  Running predictions...
2025-12-28 16:20:03,154 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:03,154 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:08 +07)" executed successfully
2025-12-28 16:20:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:13 +07)" (scheduled at 2025-12-28 16:20:08.038060+07:00)
2025-12-28 16:20:08,038 - INFO -  Running predictions...
2025-12-28 16:20:08,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:08,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:13 +07)" executed successfully
2025-12-28 16:20:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:18 +07)" (scheduled at 2025-12-28 16:20:13.038060+07:00)
2025-12-28 16:20:13,040 - INFO -  Running predictions...
2025-12-28 16:20:13,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:13,177 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:18 +07)" executed successfully
2025-12-28 16:20:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:23 +07)" (scheduled at 2025-12-28 16:20:18.038060+07:00)
2025-12-28 16:20:18,039 - INFO -  Running predictions...
2025-12-28 16:20:18,144 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:18,144 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:23 +07)" executed successfully
2025-12-28 16:20:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:28 +07)" (scheduled at 2025-12-28 16:20:23.038060+07:00)
2025-12-28 16:20:23,038 - INFO -  Running predictions...
2025-12-28 16:20:23,142 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:23,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:28 +07)" executed successfully
2025-12-28 16:20:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:33 +07)" (scheduled at 2025-12-28 16:20:28.038060+07:00)
2025-12-28 16:20:28,040 - INFO -  Running predictions...
2025-12-28 16:20:28,122 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:28,122 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:33 +07)" executed successfully
2025-12-28 16:20:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:38 +07)" (scheduled at 2025-12-28 16:20:33.038060+07:00)
2025-12-28 16:20:33,039 - INFO -  Running predictions...
2025-12-28 16:20:33,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:33,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:38 +07)" executed successfully
2025-12-28 16:20:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:43 +07)" (scheduled at 2025-12-28 16:20:38.038060+07:00)
2025-12-28 16:20:38,040 - INFO -  Running predictions...
2025-12-28 16:20:38,158 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:38,158 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:43 +07)" executed successfully
2025-12-28 16:20:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:48 +07)" (scheduled at 2025-12-28 16:20:43.038060+07:00)
2025-12-28 16:20:43,040 - INFO -  Running predictions...
2025-12-28 16:20:43,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:43,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:48 +07)" executed successfully
2025-12-28 16:20:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:53 +07)" (scheduled at 2025-12-28 16:20:48.038060+07:00)
2025-12-28 16:20:48,038 - INFO -  Running predictions...
2025-12-28 16:20:48,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:48,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:53 +07)" executed successfully
2025-12-28 16:20:53,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:58 +07)" (scheduled at 2025-12-28 16:20:53.038060+07:00)
2025-12-28 16:20:53,040 - INFO -  Running predictions...
2025-12-28 16:20:53,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:53,148 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:20:58 +07)" executed successfully
2025-12-28 16:20:58,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:03 +07)" (scheduled at 2025-12-28 16:20:58.038060+07:00)
2025-12-28 16:20:58,040 - INFO -  Running predictions...
2025-12-28 16:20:58,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:20:58,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:03 +07)" executed successfully
2025-12-28 16:21:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:08 +07)" (scheduled at 2025-12-28 16:21:03.038060+07:00)
2025-12-28 16:21:03,039 - INFO -  Running predictions...
2025-12-28 16:21:03,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:03,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:08 +07)" executed successfully
2025-12-28 16:21:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:13 +07)" (scheduled at 2025-12-28 16:21:08.038060+07:00)
2025-12-28 16:21:08,039 - INFO -  Running predictions...
2025-12-28 16:21:08,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:08,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:13 +07)" executed successfully
2025-12-28 16:21:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:18 +07)" (scheduled at 2025-12-28 16:21:13.038060+07:00)
2025-12-28 16:21:13,038 - INFO -  Running predictions...
2025-12-28 16:21:13,231 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:13,231 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:18 +07)" executed successfully
2025-12-28 16:21:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:23 +07)" (scheduled at 2025-12-28 16:21:18.038060+07:00)
2025-12-28 16:21:18,039 - INFO -  Running predictions...
2025-12-28 16:21:18,196 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:18,196 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:23 +07)" executed successfully
2025-12-28 16:21:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:28 +07)" (scheduled at 2025-12-28 16:21:23.038060+07:00)
2025-12-28 16:21:23,040 - INFO -  Running predictions...
2025-12-28 16:21:23,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:23,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:28 +07)" executed successfully
2025-12-28 16:21:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:33 +07)" (scheduled at 2025-12-28 16:21:28.038060+07:00)
2025-12-28 16:21:28,040 - INFO -  Running predictions...
2025-12-28 16:21:28,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:28,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:33 +07)" executed successfully
2025-12-28 16:21:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:38 +07)" (scheduled at 2025-12-28 16:21:33.038060+07:00)
2025-12-28 16:21:33,041 - INFO -  Running predictions...
2025-12-28 16:21:33,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:33,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:38 +07)" executed successfully
2025-12-28 16:21:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:43 +07)" (scheduled at 2025-12-28 16:21:38.038060+07:00)
2025-12-28 16:21:38,038 - INFO -  Running predictions...
2025-12-28 16:21:38,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:38,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:43 +07)" executed successfully
2025-12-28 16:21:43,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:48 +07)" (scheduled at 2025-12-28 16:21:43.038060+07:00)
2025-12-28 16:21:43,040 - INFO -  Running predictions...
2025-12-28 16:21:43,160 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:43,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:48 +07)" executed successfully
2025-12-28 16:21:48,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:53 +07)" (scheduled at 2025-12-28 16:21:48.038060+07:00)
2025-12-28 16:21:48,040 - INFO -  Running predictions...
2025-12-28 16:21:48,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:48,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:53 +07)" executed successfully
2025-12-28 16:21:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:58 +07)" (scheduled at 2025-12-28 16:21:53.038060+07:00)
2025-12-28 16:21:53,040 - INFO -  Running predictions...
2025-12-28 16:21:53,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:53,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:21:58 +07)" executed successfully
2025-12-28 16:21:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:03 +07)" (scheduled at 2025-12-28 16:21:58.038060+07:00)
2025-12-28 16:21:58,039 - INFO -  Running predictions...
2025-12-28 16:21:58,146 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:21:58,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:03 +07)" executed successfully
2025-12-28 16:22:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:08 +07)" (scheduled at 2025-12-28 16:22:03.038060+07:00)
2025-12-28 16:22:03,038 - INFO -  Running predictions...
2025-12-28 16:22:03,154 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:03,154 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:08 +07)" executed successfully
2025-12-28 16:22:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:13 +07)" (scheduled at 2025-12-28 16:22:08.038060+07:00)
2025-12-28 16:22:08,042 - INFO -  Running predictions...
2025-12-28 16:22:08,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:08,186 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:13 +07)" executed successfully
2025-12-28 16:22:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:18 +07)" (scheduled at 2025-12-28 16:22:13.038060+07:00)
2025-12-28 16:22:13,040 - INFO -  Running predictions...
2025-12-28 16:22:13,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:13,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:18 +07)" executed successfully
2025-12-28 16:22:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:23 +07)" (scheduled at 2025-12-28 16:22:18.038060+07:00)
2025-12-28 16:22:18,039 - INFO -  Running predictions...
2025-12-28 16:22:18,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:18,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:23 +07)" executed successfully
2025-12-28 16:22:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:28 +07)" (scheduled at 2025-12-28 16:22:23.038060+07:00)
2025-12-28 16:22:23,039 - INFO -  Running predictions...
2025-12-28 16:22:23,179 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:23,179 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:28 +07)" executed successfully
2025-12-28 16:22:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:33 +07)" (scheduled at 2025-12-28 16:22:28.038060+07:00)
2025-12-28 16:22:28,040 - INFO -  Running predictions...
2025-12-28 16:22:28,152 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:28,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:33 +07)" executed successfully
2025-12-28 16:22:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:38 +07)" (scheduled at 2025-12-28 16:22:33.038060+07:00)
2025-12-28 16:22:33,039 - INFO -  Running predictions...
2025-12-28 16:22:33,137 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:33,137 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:38 +07)" executed successfully
2025-12-28 16:22:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:43 +07)" (scheduled at 2025-12-28 16:22:38.038060+07:00)
2025-12-28 16:22:38,038 - INFO -  Running predictions...
2025-12-28 16:22:38,124 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:38,124 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:43 +07)" executed successfully
2025-12-28 16:22:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:48 +07)" (scheduled at 2025-12-28 16:22:43.038060+07:00)
2025-12-28 16:22:43,043 - INFO -  Running predictions...
2025-12-28 16:22:43,143 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:43,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:48 +07)" executed successfully
2025-12-28 16:22:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:53 +07)" (scheduled at 2025-12-28 16:22:48.038060+07:00)
2025-12-28 16:22:48,039 - INFO -  Running predictions...
2025-12-28 16:22:48,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:48,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:53 +07)" executed successfully
2025-12-28 16:22:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:58 +07)" (scheduled at 2025-12-28 16:22:53.038060+07:00)
2025-12-28 16:22:53,040 - INFO -  Running predictions...
2025-12-28 16:22:53,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:53,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:22:58 +07)" executed successfully
2025-12-28 16:22:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:03 +07)" (scheduled at 2025-12-28 16:22:58.038060+07:00)
2025-12-28 16:22:58,039 - INFO -  Running predictions...
2025-12-28 16:22:58,165 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:22:58,166 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:03 +07)" executed successfully
2025-12-28 16:23:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:08 +07)" (scheduled at 2025-12-28 16:23:03.038060+07:00)
2025-12-28 16:23:03,038 - INFO -  Running predictions...
2025-12-28 16:23:03,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:03,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:08 +07)" executed successfully
2025-12-28 16:23:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:13 +07)" (scheduled at 2025-12-28 16:23:08.038060+07:00)
2025-12-28 16:23:08,040 - INFO -  Running predictions...
2025-12-28 16:23:08,155 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:08,155 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:13 +07)" executed successfully
2025-12-28 16:23:13,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:18 +07)" (scheduled at 2025-12-28 16:23:13.038060+07:00)
2025-12-28 16:23:13,039 - INFO -  Running predictions...
2025-12-28 16:23:13,173 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:13,173 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:18 +07)" executed successfully
2025-12-28 16:23:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:23 +07)" (scheduled at 2025-12-28 16:23:18.038060+07:00)
2025-12-28 16:23:18,038 - INFO -  Running predictions...
2025-12-28 16:23:18,142 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:18,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:23 +07)" executed successfully
2025-12-28 16:23:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:28 +07)" (scheduled at 2025-12-28 16:23:23.038060+07:00)
2025-12-28 16:23:23,039 - INFO -  Running predictions...
2025-12-28 16:23:23,200 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:23,201 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:28 +07)" executed successfully
2025-12-28 16:23:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:33 +07)" (scheduled at 2025-12-28 16:23:28.038060+07:00)
2025-12-28 16:23:28,039 - INFO -  Running predictions...
2025-12-28 16:23:28,128 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:28,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:33 +07)" executed successfully
2025-12-28 16:23:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:38 +07)" (scheduled at 2025-12-28 16:23:33.038060+07:00)
2025-12-28 16:23:33,039 - INFO -  Running predictions...
2025-12-28 16:23:33,135 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:33,135 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:38 +07)" executed successfully
2025-12-28 16:23:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:43 +07)" (scheduled at 2025-12-28 16:23:38.038060+07:00)
2025-12-28 16:23:38,039 - INFO -  Running predictions...
2025-12-28 16:23:38,155 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:38,155 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:43 +07)" executed successfully
2025-12-28 16:23:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:48 +07)" (scheduled at 2025-12-28 16:23:43.038060+07:00)
2025-12-28 16:23:43,039 - INFO -  Running predictions...
2025-12-28 16:23:43,187 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:43,187 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:48 +07)" executed successfully
2025-12-28 16:23:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:53 +07)" (scheduled at 2025-12-28 16:23:48.038060+07:00)
2025-12-28 16:23:48,038 - INFO -  Running predictions...
2025-12-28 16:23:48,198 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:48,198 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:53 +07)" executed successfully
2025-12-28 16:23:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:58 +07)" (scheduled at 2025-12-28 16:23:53.038060+07:00)
2025-12-28 16:23:53,039 - INFO -  Running predictions...
2025-12-28 16:23:53,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:53,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:23:58 +07)" executed successfully
2025-12-28 16:23:58,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:03 +07)" (scheduled at 2025-12-28 16:23:58.038060+07:00)
2025-12-28 16:23:58,041 - INFO -  Running predictions...
2025-12-28 16:23:58,212 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:23:58,212 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:03 +07)" executed successfully
2025-12-28 16:24:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:08 +07)" (scheduled at 2025-12-28 16:24:03.038060+07:00)
2025-12-28 16:24:03,039 - INFO -  Running predictions...
2025-12-28 16:24:03,159 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:03,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:08 +07)" executed successfully
2025-12-28 16:24:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:13 +07)" (scheduled at 2025-12-28 16:24:08.038060+07:00)
2025-12-28 16:24:08,038 - INFO -  Running predictions...
2025-12-28 16:24:08,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:08,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:13 +07)" executed successfully
2025-12-28 16:24:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:18 +07)" (scheduled at 2025-12-28 16:24:13.038060+07:00)
2025-12-28 16:24:13,039 - INFO -  Running predictions...
2025-12-28 16:24:13,145 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:13,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:18 +07)" executed successfully
2025-12-28 16:24:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:23 +07)" (scheduled at 2025-12-28 16:24:18.038060+07:00)
2025-12-28 16:24:18,039 - INFO -  Running predictions...
2025-12-28 16:24:18,146 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:18,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:23 +07)" executed successfully
2025-12-28 16:24:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:28 +07)" (scheduled at 2025-12-28 16:24:23.038060+07:00)
2025-12-28 16:24:23,039 - INFO -  Running predictions...
2025-12-28 16:24:23,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:23,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:28 +07)" executed successfully
2025-12-28 16:24:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:33 +07)" (scheduled at 2025-12-28 16:24:28.038060+07:00)
2025-12-28 16:24:28,039 - INFO -  Running predictions...
2025-12-28 16:24:28,125 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:28,125 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:33 +07)" executed successfully
2025-12-28 16:24:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:38 +07)" (scheduled at 2025-12-28 16:24:33.038060+07:00)
2025-12-28 16:24:33,040 - INFO -  Running predictions...
2025-12-28 16:24:33,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:33,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:38 +07)" executed successfully
2025-12-28 16:24:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:43 +07)" (scheduled at 2025-12-28 16:24:38.038060+07:00)
2025-12-28 16:24:38,039 - INFO -  Running predictions...
2025-12-28 16:24:38,131 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:38,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:43 +07)" executed successfully
2025-12-28 16:24:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:48 +07)" (scheduled at 2025-12-28 16:24:43.038060+07:00)
2025-12-28 16:24:43,038 - INFO -  Running predictions...
2025-12-28 16:24:43,191 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:43,191 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:48 +07)" executed successfully
2025-12-28 16:24:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:53 +07)" (scheduled at 2025-12-28 16:24:48.038060+07:00)
2025-12-28 16:24:48,040 - INFO -  Running predictions...
2025-12-28 16:24:48,133 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:48,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:53 +07)" executed successfully
2025-12-28 16:24:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:58 +07)" (scheduled at 2025-12-28 16:24:53.038060+07:00)
2025-12-28 16:24:53,039 - INFO -  Running predictions...
2025-12-28 16:24:53,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:53,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:24:58 +07)" executed successfully
2025-12-28 16:24:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:03 +07)" (scheduled at 2025-12-28 16:24:58.038060+07:00)
2025-12-28 16:24:58,039 - INFO -  Running predictions...
2025-12-28 16:24:58,141 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:24:58,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:03 +07)" executed successfully
2025-12-28 16:25:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:08 +07)" (scheduled at 2025-12-28 16:25:03.038060+07:00)
2025-12-28 16:25:03,038 - INFO -  Running predictions...
2025-12-28 16:25:03,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:03,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:08 +07)" executed successfully
2025-12-28 16:25:08,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:13 +07)" (scheduled at 2025-12-28 16:25:08.038060+07:00)
2025-12-28 16:25:08,039 - INFO -  Running predictions...
2025-12-28 16:25:08,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:08,186 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:13 +07)" executed successfully
2025-12-28 16:25:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:18 +07)" (scheduled at 2025-12-28 16:25:13.038060+07:00)
2025-12-28 16:25:13,039 - INFO -  Running predictions...
2025-12-28 16:25:13,153 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:13,154 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:18 +07)" executed successfully
2025-12-28 16:25:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:23 +07)" (scheduled at 2025-12-28 16:25:18.038060+07:00)
2025-12-28 16:25:18,038 - INFO -  Running predictions...
2025-12-28 16:25:18,229 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:18,229 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:23 +07)" executed successfully
2025-12-28 16:25:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:28 +07)" (scheduled at 2025-12-28 16:25:23.038060+07:00)
2025-12-28 16:25:23,039 - INFO -  Running predictions...
2025-12-28 16:25:23,177 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:23,177 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:28 +07)" executed successfully
2025-12-28 16:25:28,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:33 +07)" (scheduled at 2025-12-28 16:25:28.038060+07:00)
2025-12-28 16:25:28,039 - INFO -  Running predictions...
2025-12-28 16:25:28,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:28,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:33 +07)" executed successfully
2025-12-28 16:25:33,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:38 +07)" (scheduled at 2025-12-28 16:25:33.038060+07:00)
2025-12-28 16:25:33,040 - INFO -  Running predictions...
2025-12-28 16:25:33,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:33,185 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:38 +07)" executed successfully
2025-12-28 16:25:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:43 +07)" (scheduled at 2025-12-28 16:25:38.038060+07:00)
2025-12-28 16:25:38,039 - INFO -  Running predictions...
2025-12-28 16:25:38,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:38,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:43 +07)" executed successfully
2025-12-28 16:25:43,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:48 +07)" (scheduled at 2025-12-28 16:25:43.038060+07:00)
2025-12-28 16:25:43,039 - INFO -  Running predictions...
2025-12-28 16:25:43,246 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:43,246 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:48 +07)" executed successfully
2025-12-28 16:25:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:53 +07)" (scheduled at 2025-12-28 16:25:48.038060+07:00)
2025-12-28 16:25:48,038 - INFO -  Running predictions...
2025-12-28 16:25:48,175 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:48,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:53 +07)" executed successfully
2025-12-28 16:25:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:58 +07)" (scheduled at 2025-12-28 16:25:53.038060+07:00)
2025-12-28 16:25:53,039 - INFO -  Running predictions...
2025-12-28 16:25:53,127 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:53,127 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:25:58 +07)" executed successfully
2025-12-28 16:25:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:03 +07)" (scheduled at 2025-12-28 16:25:58.038060+07:00)
2025-12-28 16:25:58,039 - INFO -  Running predictions...
2025-12-28 16:25:58,193 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:25:58,194 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:03 +07)" executed successfully
2025-12-28 16:26:03,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:08 +07)" (scheduled at 2025-12-28 16:26:03.038060+07:00)
2025-12-28 16:26:03,041 - INFO -  Running predictions...
2025-12-28 16:26:03,132 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:03,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:08 +07)" executed successfully
2025-12-28 16:26:08,040 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:13 +07)" (scheduled at 2025-12-28 16:26:08.038060+07:00)
2025-12-28 16:26:08,040 - INFO -  Running predictions...
2025-12-28 16:26:08,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:08,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:13 +07)" executed successfully
2025-12-28 16:26:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:18 +07)" (scheduled at 2025-12-28 16:26:13.038060+07:00)
2025-12-28 16:26:13,040 - INFO -  Running predictions...
2025-12-28 16:26:13,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:13,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:18 +07)" executed successfully
2025-12-28 16:26:18,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:23 +07)" (scheduled at 2025-12-28 16:26:18.038060+07:00)
2025-12-28 16:26:18,039 - INFO -  Running predictions...
2025-12-28 16:26:18,128 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:18,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:23 +07)" executed successfully
2025-12-28 16:26:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:28 +07)" (scheduled at 2025-12-28 16:26:23.038060+07:00)
2025-12-28 16:26:23,040 - INFO -  Running predictions...
2025-12-28 16:26:23,177 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:23,177 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:28 +07)" executed successfully
2025-12-28 16:26:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:33 +07)" (scheduled at 2025-12-28 16:26:28.038060+07:00)
2025-12-28 16:26:28,039 - INFO -  Running predictions...
2025-12-28 16:26:28,180 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:28,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:33 +07)" executed successfully
2025-12-28 16:26:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:38 +07)" (scheduled at 2025-12-28 16:26:33.038060+07:00)
2025-12-28 16:26:33,039 - INFO -  Running predictions...
2025-12-28 16:26:33,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:33,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:38 +07)" executed successfully
2025-12-28 16:26:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:43 +07)" (scheduled at 2025-12-28 16:26:38.038060+07:00)
2025-12-28 16:26:38,039 - INFO -  Running predictions...
2025-12-28 16:26:38,131 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:38,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:43 +07)" executed successfully
2025-12-28 16:26:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:48 +07)" (scheduled at 2025-12-28 16:26:43.038060+07:00)
2025-12-28 16:26:43,039 - INFO -  Running predictions...
2025-12-28 16:26:43,150 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:43,150 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:48 +07)" executed successfully
2025-12-28 16:26:48,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:53 +07)" (scheduled at 2025-12-28 16:26:48.038060+07:00)
2025-12-28 16:26:48,040 - INFO -  Running predictions...
2025-12-28 16:26:48,185 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:48,185 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:53 +07)" executed successfully
2025-12-28 16:26:53,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:58 +07)" (scheduled at 2025-12-28 16:26:53.038060+07:00)
2025-12-28 16:26:53,040 - INFO -  Running predictions...
2025-12-28 16:26:53,242 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:53,243 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:26:58 +07)" executed successfully
2025-12-28 16:26:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:03 +07)" (scheduled at 2025-12-28 16:26:58.038060+07:00)
2025-12-28 16:26:58,038 - INFO -  Running predictions...
2025-12-28 16:26:58,168 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:26:58,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:03 +07)" executed successfully
2025-12-28 16:27:03,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:08 +07)" (scheduled at 2025-12-28 16:27:03.038060+07:00)
2025-12-28 16:27:03,039 - INFO -  Running predictions...
2025-12-28 16:27:03,131 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:03,131 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:08 +07)" executed successfully
2025-12-28 16:27:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:13 +07)" (scheduled at 2025-12-28 16:27:08.038060+07:00)
2025-12-28 16:27:08,038 - INFO -  Running predictions...
2025-12-28 16:27:08,129 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:08,129 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:13 +07)" executed successfully
2025-12-28 16:27:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:18 +07)" (scheduled at 2025-12-28 16:27:13.038060+07:00)
2025-12-28 16:27:13,039 - INFO -  Running predictions...
2025-12-28 16:27:13,128 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:13,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:18 +07)" executed successfully
2025-12-28 16:27:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:23 +07)" (scheduled at 2025-12-28 16:27:18.038060+07:00)
2025-12-28 16:27:18,038 - INFO -  Running predictions...
2025-12-28 16:27:18,134 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:18,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:23 +07)" executed successfully
2025-12-28 16:27:23,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:28 +07)" (scheduled at 2025-12-28 16:27:23.038060+07:00)
2025-12-28 16:27:23,040 - INFO -  Running predictions...
2025-12-28 16:27:23,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:23,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:28 +07)" executed successfully
2025-12-28 16:27:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:33 +07)" (scheduled at 2025-12-28 16:27:28.038060+07:00)
2025-12-28 16:27:28,038 - INFO -  Running predictions...
2025-12-28 16:27:28,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:28,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:33 +07)" executed successfully
2025-12-28 16:27:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:38 +07)" (scheduled at 2025-12-28 16:27:33.038060+07:00)
2025-12-28 16:27:33,039 - INFO -  Running predictions...
2025-12-28 16:27:33,155 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:33,155 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:38 +07)" executed successfully
2025-12-28 16:27:38,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:43 +07)" (scheduled at 2025-12-28 16:27:38.038060+07:00)
2025-12-28 16:27:38,039 - INFO -  Running predictions...
2025-12-28 16:27:38,167 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:38,167 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:43 +07)" executed successfully
2025-12-28 16:27:43,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:48 +07)" (scheduled at 2025-12-28 16:27:43.038060+07:00)
2025-12-28 16:27:43,039 - INFO -  Running predictions...
2025-12-28 16:27:43,139 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:43,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:48 +07)" executed successfully
2025-12-28 16:27:48,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:53 +07)" (scheduled at 2025-12-28 16:27:48.038060+07:00)
2025-12-28 16:27:48,039 - INFO -  Running predictions...
2025-12-28 16:27:48,147 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:48,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:53 +07)" executed successfully
2025-12-28 16:27:53,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:58 +07)" (scheduled at 2025-12-28 16:27:53.038060+07:00)
2025-12-28 16:27:53,039 - INFO -  Running predictions...
2025-12-28 16:27:53,142 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:53,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:27:58 +07)" executed successfully
2025-12-28 16:27:58,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:03 +07)" (scheduled at 2025-12-28 16:27:58.038060+07:00)
2025-12-28 16:27:58,038 - INFO -  Running predictions...
2025-12-28 16:27:58,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:27:58,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:03 +07)" executed successfully
2025-12-28 16:28:03,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:08 +07)" (scheduled at 2025-12-28 16:28:03.038060+07:00)
2025-12-28 16:28:03,039 - INFO -  Running predictions...
2025-12-28 16:28:03,296 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:03,297 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:08 +07)" executed successfully
2025-12-28 16:28:08,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:13 +07)" (scheduled at 2025-12-28 16:28:08.038060+07:00)
2025-12-28 16:28:08,039 - INFO -  Running predictions...
2025-12-28 16:28:08,176 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:08,176 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:13 +07)" executed successfully
2025-12-28 16:28:13,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:18 +07)" (scheduled at 2025-12-28 16:28:13.038060+07:00)
2025-12-28 16:28:13,039 - INFO -  Running predictions...
2025-12-28 16:28:13,126 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:13,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:18 +07)" executed successfully
2025-12-28 16:28:18,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:23 +07)" (scheduled at 2025-12-28 16:28:18.038060+07:00)
2025-12-28 16:28:18,039 - INFO -  Running predictions...
2025-12-28 16:28:18,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:18,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:23 +07)" executed successfully
2025-12-28 16:28:23,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:28 +07)" (scheduled at 2025-12-28 16:28:23.038060+07:00)
2025-12-28 16:28:23,039 - INFO -  Running predictions...
2025-12-28 16:28:23,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:23,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:28 +07)" executed successfully
2025-12-28 16:28:28,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:33 +07)" (scheduled at 2025-12-28 16:28:28.038060+07:00)
2025-12-28 16:28:28,038 - INFO -  Running predictions...
2025-12-28 16:28:28,180 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:28,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:33 +07)" executed successfully
2025-12-28 16:28:33,039 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:38 +07)" (scheduled at 2025-12-28 16:28:33.038060+07:00)
2025-12-28 16:28:33,040 - INFO -  Running predictions...
2025-12-28 16:28:33,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:33,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:38 +07)" executed successfully
2025-12-28 16:28:38,038 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:43 +07)" (scheduled at 2025-12-28 16:28:38.038060+07:00)
2025-12-28 16:28:38,039 - INFO -  Running predictions...
2025-12-28 16:28:38,174 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:28:38,175 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:28:43 +07)" executed successfully
2025-12-28 16:28:42,201 - INFO - Stopping Spark Session...
2025-12-28 16:28:42,343 - INFO - Closing down clientserver connection
2025-12-28 16:28:42,344 - INFO - Scheduler has been shut down
2025-12-28 16:28:42,345 - INFO - Closing down clientserver connection
2025-12-28 16:28:49,723 - INFO -  Initializing PySpark Session...
2025-12-28 16:28:52,743 - INFO - ‚úì Spark Session Created!
2025-12-28 16:28:52,743 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 16:28:52,763 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 16:28:52,763 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 16:28:52,763 - INFO - Scheduler started
2025-12-28 16:29:02,765 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:02 +07)" (scheduled at 2025-12-28 16:29:02.763021+07:00)
2025-12-28 16:29:02,765 - INFO -  Training Spark model...
2025-12-28 16:29:07,577 - INFO - ‚úì Model trained successfully!
2025-12-28 16:29:07,577 - INFO -  Running predictions...
2025-12-28 16:29:07,860 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:07,861 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:12 +07)" executed successfully
2025-12-28 16:29:12,766 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:22 +07)" (scheduled at 2025-12-28 16:29:12.763021+07:00)
2025-12-28 16:29:12,767 - INFO -  Running predictions...
2025-12-28 16:29:12,957 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:12,957 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:22 +07)" executed successfully
2025-12-28 16:29:22,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:32 +07)" (scheduled at 2025-12-28 16:29:22.763021+07:00)
2025-12-28 16:29:22,765 - INFO -  Running predictions...
2025-12-28 16:29:23,082 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:23,083 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:32 +07)" executed successfully
2025-12-28 16:29:32,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:42 +07)" (scheduled at 2025-12-28 16:29:32.763021+07:00)
2025-12-28 16:29:32,764 - INFO -  Running predictions...
2025-12-28 16:29:32,934 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:32,935 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:42 +07)" executed successfully
2025-12-28 16:29:42,763 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:52 +07)" (scheduled at 2025-12-28 16:29:42.763021+07:00)
2025-12-28 16:29:42,763 - INFO -  Running predictions...
2025-12-28 16:29:42,986 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:42,986 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:29:52 +07)" executed successfully
2025-12-28 16:29:52,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:02 +07)" (scheduled at 2025-12-28 16:29:52.763021+07:00)
2025-12-28 16:29:52,765 - INFO -  Running predictions...
2025-12-28 16:29:52,922 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:29:52,923 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:02 +07)" executed successfully
2025-12-28 16:30:02,765 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:12 +07)" (scheduled at 2025-12-28 16:30:02.763021+07:00)
2025-12-28 16:30:02,766 - INFO -  Running predictions...
2025-12-28 16:30:02,901 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:02,901 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:12 +07)" executed successfully
2025-12-28 16:30:12,765 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:22 +07)" (scheduled at 2025-12-28 16:30:12.763021+07:00)
2025-12-28 16:30:12,765 - INFO -  Running predictions...
2025-12-28 16:30:13,049 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:13,049 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:22 +07)" executed successfully
2025-12-28 16:30:22,763 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:32 +07)" (scheduled at 2025-12-28 16:30:22.763021+07:00)
2025-12-28 16:30:22,764 - INFO -  Running predictions...
2025-12-28 16:30:22,944 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:22,944 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:32 +07)" executed successfully
2025-12-28 16:30:32,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:42 +07)" (scheduled at 2025-12-28 16:30:32.763021+07:00)
2025-12-28 16:30:32,765 - INFO -  Running predictions...
2025-12-28 16:30:32,896 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:32,896 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:42 +07)" executed successfully
2025-12-28 16:30:42,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:52 +07)" (scheduled at 2025-12-28 16:30:42.763021+07:00)
2025-12-28 16:30:42,765 - INFO -  Running predictions...
2025-12-28 16:30:42,978 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:42,978 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:30:52 +07)" executed successfully
2025-12-28 16:30:52,764 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:31:02 +07)" (scheduled at 2025-12-28 16:30:52.763021+07:00)
2025-12-28 16:30:52,764 - INFO -  Running predictions...
2025-12-28 16:30:52,902 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:30:52,902 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:10], next run at: 2025-12-28 16:31:02 +07)" executed successfully
2025-12-28 16:31:00,384 - INFO - Stopping Spark Session...
2025-12-28 16:31:00,509 - INFO - Closing down clientserver connection
2025-12-28 16:31:00,510 - INFO - Scheduler has been shut down
2025-12-28 16:31:00,510 - INFO - Closing down clientserver connection
2025-12-28 16:32:21,082 - INFO -  Initializing PySpark Session...
2025-12-28 16:32:24,015 - INFO - ‚úì Spark Session Created!
2025-12-28 16:32:24,015 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 16:32:24,035 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 16:32:24,035 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 16:32:24,035 - INFO - Scheduler started
2025-12-28 16:33:24,035 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:01:00], next run at: 2025-12-28 16:33:24 +07)" (scheduled at 2025-12-28 16:33:24.034847+07:00)
2025-12-28 16:33:24,036 - INFO -  Training Spark model...
2025-12-28 16:33:28,541 - INFO - ‚úì Model trained successfully!
2025-12-28 16:33:28,541 - INFO -  Running predictions...
2025-12-28 16:33:28,829 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:33:28,829 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:01:00], next run at: 2025-12-28 16:34:24 +07)" executed successfully
2025-12-28 16:34:24,037 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:01:00], next run at: 2025-12-28 16:35:24 +07)" (scheduled at 2025-12-28 16:34:24.034847+07:00)
2025-12-28 16:34:24,037 - INFO -  Running predictions...
2025-12-28 16:34:24,292 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:34:24,292 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:01:00], next run at: 2025-12-28 16:35:24 +07)" executed successfully
2025-12-28 16:34:37,337 - INFO - Stopping Spark Session...
2025-12-28 16:34:37,827 - INFO - Closing down clientserver connection
2025-12-28 16:34:37,828 - INFO - Scheduler has been shut down
2025-12-28 16:34:37,828 - INFO - Closing down clientserver connection
2025-12-28 16:42:42,508 - INFO -  Initializing PySpark Session...
2025-12-28 16:42:45,507 - INFO - ‚úì Spark Session Created!
2025-12-28 16:42:45,507 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 16:42:45,538 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 16:42:45,539 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 16:42:45,539 - INFO - Scheduler started
2025-12-28 16:42:50,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:42:50 +07)" (scheduled at 2025-12-28 16:42:50.538622+07:00)
2025-12-28 16:42:50,541 - INFO -  Training Spark model...
2025-12-28 16:42:55,541 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:42:55 +07)" skipped: maximum number of running instances reached (1)
2025-12-28 16:42:55,938 - INFO - ‚úì Model trained successfully!
2025-12-28 16:42:55,938 - INFO -  Running predictions...
2025-12-28 16:42:56,222 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:42:56,222 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:00 +07)" executed successfully
2025-12-28 16:43:00,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:05 +07)" (scheduled at 2025-12-28 16:43:00.538622+07:00)
2025-12-28 16:43:00,540 - INFO -  Running predictions...
2025-12-28 16:43:00,779 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:00,779 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:05 +07)" executed successfully
2025-12-28 16:43:05,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:10 +07)" (scheduled at 2025-12-28 16:43:05.538622+07:00)
2025-12-28 16:43:05,539 - INFO -  Running predictions...
2025-12-28 16:43:05,960 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:05,960 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:10 +07)" executed successfully
2025-12-28 16:43:10,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:15 +07)" (scheduled at 2025-12-28 16:43:10.538622+07:00)
2025-12-28 16:43:10,540 - INFO -  Running predictions...
2025-12-28 16:43:10,717 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:10,717 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:15 +07)" executed successfully
2025-12-28 16:43:15,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:20 +07)" (scheduled at 2025-12-28 16:43:15.538622+07:00)
2025-12-28 16:43:15,539 - INFO -  Running predictions...
2025-12-28 16:43:15,777 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:15,777 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:20 +07)" executed successfully
2025-12-28 16:43:20,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:25 +07)" (scheduled at 2025-12-28 16:43:20.538622+07:00)
2025-12-28 16:43:20,539 - INFO -  Running predictions...
2025-12-28 16:43:20,743 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:20,743 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:25 +07)" executed successfully
2025-12-28 16:43:25,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:30 +07)" (scheduled at 2025-12-28 16:43:25.538622+07:00)
2025-12-28 16:43:25,539 - INFO -  Running predictions...
2025-12-28 16:43:25,763 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:25,763 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:30 +07)" executed successfully
2025-12-28 16:43:30,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:35 +07)" (scheduled at 2025-12-28 16:43:30.538622+07:00)
2025-12-28 16:43:30,540 - INFO -  Running predictions...
2025-12-28 16:43:30,746 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:30,747 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:35 +07)" executed successfully
2025-12-28 16:43:35,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:40 +07)" (scheduled at 2025-12-28 16:43:35.538622+07:00)
2025-12-28 16:43:35,541 - INFO -  Running predictions...
2025-12-28 16:43:35,783 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:35,783 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:40 +07)" executed successfully
2025-12-28 16:43:40,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:45 +07)" (scheduled at 2025-12-28 16:43:40.538622+07:00)
2025-12-28 16:43:40,539 - INFO -  Running predictions...
2025-12-28 16:43:40,754 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:40,754 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:45 +07)" executed successfully
2025-12-28 16:43:45,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:50 +07)" (scheduled at 2025-12-28 16:43:45.538622+07:00)
2025-12-28 16:43:45,539 - INFO -  Running predictions...
2025-12-28 16:43:45,766 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:45,766 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:50 +07)" executed successfully
2025-12-28 16:43:50,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:55 +07)" (scheduled at 2025-12-28 16:43:50.538622+07:00)
2025-12-28 16:43:50,539 - INFO -  Running predictions...
2025-12-28 16:43:50,839 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:50,839 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:43:55 +07)" executed successfully
2025-12-28 16:43:55,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:00 +07)" (scheduled at 2025-12-28 16:43:55.538622+07:00)
2025-12-28 16:43:55,539 - INFO -  Running predictions...
2025-12-28 16:43:55,772 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:43:55,772 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:00 +07)" executed successfully
2025-12-28 16:44:00,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:05 +07)" (scheduled at 2025-12-28 16:44:00.538622+07:00)
2025-12-28 16:44:00,540 - INFO -  Running predictions...
2025-12-28 16:44:00,774 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:44:00,774 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:05 +07)" executed successfully
2025-12-28 16:44:05,539 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:10 +07)" (scheduled at 2025-12-28 16:44:05.538622+07:00)
2025-12-28 16:44:05,539 - INFO -  Running predictions...
2025-12-28 16:44:05,735 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:44:05,736 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:10 +07)" executed successfully
2025-12-28 16:44:10,540 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:15 +07)" (scheduled at 2025-12-28 16:44:10.538622+07:00)
2025-12-28 16:44:10,540 - INFO -  Running predictions...
2025-12-28 16:44:10,741 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 16:44:10,741 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 16:44:15 +07)" executed successfully
2025-12-28 16:44:13,697 - INFO - Stopping Spark Session...
2025-12-28 16:44:14,063 - INFO - Closing down clientserver connection
2025-12-28 16:44:14,063 - INFO - Scheduler has been shut down
2025-12-28 16:44:14,065 - INFO - Closing down clientserver connection
2025-12-28 17:01:39,902 - INFO -  Initializing PySpark Session...
2025-12-28 17:01:43,191 - INFO - ‚úì Spark Session Created!
2025-12-28 17:01:43,191 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 17:01:43,212 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 17:01:43,212 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 17:01:43,212 - INFO - Scheduler started
2025-12-28 17:01:48,213 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:01:48 +07)" (scheduled at 2025-12-28 17:01:48.211829+07:00)
2025-12-28 17:01:48,213 - INFO -  Training Spark model...
2025-12-28 17:01:53,212 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:01:53 +07)" skipped: maximum number of running instances reached (1)
2025-12-28 17:01:53,752 - INFO - ‚úì Model trained successfully!
2025-12-28 17:01:53,753 - INFO -  Running predictions...
2025-12-28 17:01:54,271 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:01:54,271 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:01:58 +07)" executed successfully
2025-12-28 17:01:58,215 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:03 +07)" (scheduled at 2025-12-28 17:01:58.211829+07:00)
2025-12-28 17:01:58,215 - INFO -  Running predictions...
2025-12-28 17:01:58,413 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:01:58,413 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:03 +07)" executed successfully
2025-12-28 17:02:03,212 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:08 +07)" (scheduled at 2025-12-28 17:02:03.211829+07:00)
2025-12-28 17:02:03,213 - INFO -  Running predictions...
2025-12-28 17:02:03,502 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:03,502 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:08 +07)" executed successfully
2025-12-28 17:02:08,213 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:13 +07)" (scheduled at 2025-12-28 17:02:08.211829+07:00)
2025-12-28 17:02:08,214 - INFO -  Running predictions...
2025-12-28 17:02:08,478 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:08,478 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:13 +07)" executed successfully
2025-12-28 17:02:13,212 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:18 +07)" (scheduled at 2025-12-28 17:02:13.211829+07:00)
2025-12-28 17:02:13,213 - INFO -  Running predictions...
2025-12-28 17:02:13,479 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:13,479 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:18 +07)" executed successfully
2025-12-28 17:02:18,212 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:23 +07)" (scheduled at 2025-12-28 17:02:18.211829+07:00)
2025-12-28 17:02:18,213 - INFO -  Running predictions...
2025-12-28 17:02:18,418 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:18,418 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:23 +07)" executed successfully
2025-12-28 17:02:23,213 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:28 +07)" (scheduled at 2025-12-28 17:02:23.211829+07:00)
2025-12-28 17:02:23,213 - INFO -  Running predictions...
2025-12-28 17:02:23,375 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:23,376 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:28 +07)" executed successfully
2025-12-28 17:02:28,213 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:33 +07)" (scheduled at 2025-12-28 17:02:28.211829+07:00)
2025-12-28 17:02:28,214 - INFO -  Running predictions...
2025-12-28 17:02:28,478 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:02:28,478 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:02:33 +07)" executed successfully
2025-12-28 17:02:30,581 - INFO - Stopping Spark Session...
2025-12-28 17:02:30,708 - INFO - Closing down clientserver connection
2025-12-28 17:02:30,708 - INFO - Scheduler has been shut down
2025-12-28 17:02:30,711 - INFO - Closing down clientserver connection
2025-12-28 17:03:08,278 - INFO -  Initializing PySpark Session...
2025-12-28 17:03:11,436 - INFO - ‚úì Spark Session Created!
2025-12-28 17:03:11,436 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 17:03:11,458 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 17:03:11,459 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 17:03:11,459 - INFO - Scheduler started
2025-12-28 17:03:16,459 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:16 +07)" (scheduled at 2025-12-28 17:03:16.458154+07:00)
2025-12-28 17:03:16,459 - INFO -  Training Spark model...
2025-12-28 17:03:21,459 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:21 +07)" skipped: maximum number of running instances reached (1)
2025-12-28 17:03:22,055 - INFO - ‚úì Model trained successfully!
2025-12-28 17:03:22,056 - INFO -  Running predictions...
2025-12-28 17:03:22,425 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:03:22,425 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:26 +07)" executed successfully
2025-12-28 17:03:26,459 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:31 +07)" (scheduled at 2025-12-28 17:03:26.458154+07:00)
2025-12-28 17:03:26,459 - INFO -  Running predictions...
2025-12-28 17:03:26,639 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:03:26,639 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:31 +07)" executed successfully
2025-12-28 17:03:31,459 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:36 +07)" (scheduled at 2025-12-28 17:03:31.458154+07:00)
2025-12-28 17:03:31,460 - INFO -  Running predictions...
2025-12-28 17:03:31,737 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:03:31,738 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:36 +07)" executed successfully
2025-12-28 17:03:36,458 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:41 +07)" (scheduled at 2025-12-28 17:03:36.458154+07:00)
2025-12-28 17:03:36,458 - INFO -  Running predictions...
2025-12-28 17:03:36,638 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:03:36,638 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:03:41 +07)" executed successfully
2025-12-28 17:03:39,102 - INFO - Stopping Spark Session...
2025-12-28 17:03:39,397 - INFO - Closing down clientserver connection
2025-12-28 17:03:39,398 - INFO - Scheduler has been shut down
2025-12-28 17:03:39,399 - INFO - Closing down clientserver connection
2025-12-28 17:03:55,979 - INFO -  Initializing PySpark Session...
2025-12-28 17:03:59,084 - INFO - ‚úì Spark Session Created!
2025-12-28 17:03:59,085 - INFO - Starting Spark Prediction Service (interval: 5s)...
2025-12-28 17:03:59,106 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-12-28 17:03:59,107 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2025-12-28 17:03:59,107 - INFO - Scheduler started
2025-12-28 17:04:04,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:04 +07)" (scheduled at 2025-12-28 17:04:04.106381+07:00)
2025-12-28 17:04:04,107 - INFO -  Training Spark model...
2025-12-28 17:04:09,107 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:09 +07)" skipped: maximum number of running instances reached (1)
2025-12-28 17:04:09,963 - INFO - ‚úì Model trained successfully!
2025-12-28 17:04:09,964 - INFO -  Running predictions...
2025-12-28 17:04:10,609 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:10,609 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:14 +07)" executed successfully
2025-12-28 17:04:14,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:19 +07)" (scheduled at 2025-12-28 17:04:14.106381+07:00)
2025-12-28 17:04:14,108 - INFO -  Running predictions...
2025-12-28 17:04:14,308 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:14,308 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:19 +07)" executed successfully
2025-12-28 17:04:19,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:24 +07)" (scheduled at 2025-12-28 17:04:19.106381+07:00)
2025-12-28 17:04:19,108 - INFO -  Running predictions...
2025-12-28 17:04:19,361 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:19,362 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:24 +07)" executed successfully
2025-12-28 17:04:24,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:29 +07)" (scheduled at 2025-12-28 17:04:24.106381+07:00)
2025-12-28 17:04:24,108 - INFO -  Running predictions...
2025-12-28 17:04:24,303 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:24,304 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:29 +07)" executed successfully
2025-12-28 17:04:29,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:34 +07)" (scheduled at 2025-12-28 17:04:29.106381+07:00)
2025-12-28 17:04:29,107 - INFO -  Running predictions...
2025-12-28 17:04:29,269 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:29,269 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:34 +07)" executed successfully
2025-12-28 17:04:34,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:39 +07)" (scheduled at 2025-12-28 17:04:34.106381+07:00)
2025-12-28 17:04:34,108 - INFO -  Running predictions...
2025-12-28 17:04:34,326 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:34,328 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:39 +07)" executed successfully
2025-12-28 17:04:39,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:44 +07)" (scheduled at 2025-12-28 17:04:39.106381+07:00)
2025-12-28 17:04:39,108 - INFO -  Running predictions...
2025-12-28 17:04:39,426 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:39,426 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:44 +07)" executed successfully
2025-12-28 17:04:44,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:49 +07)" (scheduled at 2025-12-28 17:04:44.106381+07:00)
2025-12-28 17:04:44,108 - INFO -  Running predictions...
2025-12-28 17:04:44,465 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:44,465 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:49 +07)" executed successfully
2025-12-28 17:04:49,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:54 +07)" (scheduled at 2025-12-28 17:04:49.106381+07:00)
2025-12-28 17:04:49,108 - INFO -  Running predictions...
2025-12-28 17:04:49,255 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:49,256 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:54 +07)" executed successfully
2025-12-28 17:04:54,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:59 +07)" (scheduled at 2025-12-28 17:04:54.106381+07:00)
2025-12-28 17:04:54,107 - INFO -  Running predictions...
2025-12-28 17:04:54,233 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:54,234 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:04:59 +07)" executed successfully
2025-12-28 17:04:59,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:04 +07)" (scheduled at 2025-12-28 17:04:59.106381+07:00)
2025-12-28 17:04:59,108 - INFO -  Running predictions...
2025-12-28 17:04:59,379 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:04:59,379 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:04 +07)" executed successfully
2025-12-28 17:05:04,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:09 +07)" (scheduled at 2025-12-28 17:05:04.106381+07:00)
2025-12-28 17:05:04,107 - INFO -  Running predictions...
2025-12-28 17:05:04,347 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:04,347 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:09 +07)" executed successfully
2025-12-28 17:05:09,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:14 +07)" (scheduled at 2025-12-28 17:05:09.106381+07:00)
2025-12-28 17:05:09,108 - INFO -  Running predictions...
2025-12-28 17:05:09,284 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:09,284 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:14 +07)" executed successfully
2025-12-28 17:05:14,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:19 +07)" (scheduled at 2025-12-28 17:05:14.106381+07:00)
2025-12-28 17:05:14,107 - INFO -  Running predictions...
2025-12-28 17:05:14,269 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:14,269 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:19 +07)" executed successfully
2025-12-28 17:05:19,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:24 +07)" (scheduled at 2025-12-28 17:05:19.106381+07:00)
2025-12-28 17:05:19,107 - INFO -  Running predictions...
2025-12-28 17:05:19,335 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:19,335 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:24 +07)" executed successfully
2025-12-28 17:05:24,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:29 +07)" (scheduled at 2025-12-28 17:05:24.106381+07:00)
2025-12-28 17:05:24,107 - INFO -  Running predictions...
2025-12-28 17:05:24,263 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:24,264 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:29 +07)" executed successfully
2025-12-28 17:05:29,109 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:34 +07)" (scheduled at 2025-12-28 17:05:29.106381+07:00)
2025-12-28 17:05:29,109 - INFO -  Running predictions...
2025-12-28 17:05:29,376 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:29,376 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:34 +07)" executed successfully
2025-12-28 17:05:34,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:39 +07)" (scheduled at 2025-12-28 17:05:34.106381+07:00)
2025-12-28 17:05:34,108 - INFO -  Running predictions...
2025-12-28 17:05:34,273 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:34,273 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:39 +07)" executed successfully
2025-12-28 17:05:39,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:44 +07)" (scheduled at 2025-12-28 17:05:39.106381+07:00)
2025-12-28 17:05:39,107 - INFO -  Running predictions...
2025-12-28 17:05:39,438 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:39,438 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:44 +07)" executed successfully
2025-12-28 17:05:44,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:49 +07)" (scheduled at 2025-12-28 17:05:44.106381+07:00)
2025-12-28 17:05:44,108 - INFO -  Running predictions...
2025-12-28 17:05:44,270 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:44,270 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:49 +07)" executed successfully
2025-12-28 17:05:49,106 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:54 +07)" (scheduled at 2025-12-28 17:05:49.106381+07:00)
2025-12-28 17:05:49,107 - INFO -  Running predictions...
2025-12-28 17:05:49,437 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:49,437 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:54 +07)" executed successfully
2025-12-28 17:05:54,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:59 +07)" (scheduled at 2025-12-28 17:05:54.106381+07:00)
2025-12-28 17:05:54,107 - INFO -  Running predictions...
2025-12-28 17:05:54,235 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:54,235 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:05:59 +07)" executed successfully
2025-12-28 17:05:59,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:04 +07)" (scheduled at 2025-12-28 17:05:59.106381+07:00)
2025-12-28 17:05:59,107 - INFO -  Running predictions...
2025-12-28 17:05:59,381 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:05:59,382 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:04 +07)" executed successfully
2025-12-28 17:06:04,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:09 +07)" (scheduled at 2025-12-28 17:06:04.106381+07:00)
2025-12-28 17:06:04,107 - INFO -  Running predictions...
2025-12-28 17:06:04,352 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:04,352 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:09 +07)" executed successfully
2025-12-28 17:06:09,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:14 +07)" (scheduled at 2025-12-28 17:06:09.106381+07:00)
2025-12-28 17:06:09,108 - INFO -  Running predictions...
2025-12-28 17:06:09,257 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:09,257 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:14 +07)" executed successfully
2025-12-28 17:06:14,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:19 +07)" (scheduled at 2025-12-28 17:06:14.106381+07:00)
2025-12-28 17:06:14,108 - INFO -  Running predictions...
2025-12-28 17:06:14,258 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:14,258 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:19 +07)" executed successfully
2025-12-28 17:06:19,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:24 +07)" (scheduled at 2025-12-28 17:06:19.106381+07:00)
2025-12-28 17:06:19,108 - INFO -  Running predictions...
2025-12-28 17:06:19,327 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:19,328 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:24 +07)" executed successfully
2025-12-28 17:06:24,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:29 +07)" (scheduled at 2025-12-28 17:06:24.106381+07:00)
2025-12-28 17:06:24,109 - INFO -  Running predictions...
2025-12-28 17:06:24,349 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:24,349 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:29 +07)" executed successfully
2025-12-28 17:06:29,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:34 +07)" (scheduled at 2025-12-28 17:06:29.106381+07:00)
2025-12-28 17:06:29,108 - INFO -  Running predictions...
2025-12-28 17:06:29,268 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:29,268 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:34 +07)" executed successfully
2025-12-28 17:06:34,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:39 +07)" (scheduled at 2025-12-28 17:06:34.106381+07:00)
2025-12-28 17:06:34,108 - INFO -  Running predictions...
2025-12-28 17:06:34,346 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:34,347 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:39 +07)" executed successfully
2025-12-28 17:06:39,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:44 +07)" (scheduled at 2025-12-28 17:06:39.106381+07:00)
2025-12-28 17:06:39,108 - INFO -  Running predictions...
2025-12-28 17:06:39,248 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:39,248 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:44 +07)" executed successfully
2025-12-28 17:06:44,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:49 +07)" (scheduled at 2025-12-28 17:06:44.106381+07:00)
2025-12-28 17:06:44,107 - INFO -  Running predictions...
2025-12-28 17:06:44,299 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:44,299 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:49 +07)" executed successfully
2025-12-28 17:06:49,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:54 +07)" (scheduled at 2025-12-28 17:06:49.106381+07:00)
2025-12-28 17:06:49,108 - INFO -  Running predictions...
2025-12-28 17:06:49,303 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:49,303 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:54 +07)" executed successfully
2025-12-28 17:06:54,109 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:59 +07)" (scheduled at 2025-12-28 17:06:54.106381+07:00)
2025-12-28 17:06:54,109 - INFO -  Running predictions...
2025-12-28 17:06:54,257 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:54,257 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:06:59 +07)" executed successfully
2025-12-28 17:06:59,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:04 +07)" (scheduled at 2025-12-28 17:06:59.106381+07:00)
2025-12-28 17:06:59,107 - INFO -  Running predictions...
2025-12-28 17:06:59,283 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:06:59,283 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:04 +07)" executed successfully
2025-12-28 17:07:04,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:09 +07)" (scheduled at 2025-12-28 17:07:04.106381+07:00)
2025-12-28 17:07:04,107 - INFO -  Running predictions...
2025-12-28 17:07:04,304 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:04,304 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:09 +07)" executed successfully
2025-12-28 17:07:09,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:14 +07)" (scheduled at 2025-12-28 17:07:09.106381+07:00)
2025-12-28 17:07:09,108 - INFO -  Running predictions...
2025-12-28 17:07:09,290 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:09,290 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:14 +07)" executed successfully
2025-12-28 17:07:14,110 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:19 +07)" (scheduled at 2025-12-28 17:07:14.106381+07:00)
2025-12-28 17:07:14,110 - INFO -  Running predictions...
2025-12-28 17:07:14,321 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:14,321 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:19 +07)" executed successfully
2025-12-28 17:07:19,109 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:24 +07)" (scheduled at 2025-12-28 17:07:19.106381+07:00)
2025-12-28 17:07:19,109 - INFO -  Running predictions...
2025-12-28 17:07:19,283 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:19,283 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:24 +07)" executed successfully
2025-12-28 17:07:24,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:29 +07)" (scheduled at 2025-12-28 17:07:24.106381+07:00)
2025-12-28 17:07:24,107 - INFO -  Running predictions...
2025-12-28 17:07:24,285 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:24,286 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:29 +07)" executed successfully
2025-12-28 17:07:29,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:34 +07)" (scheduled at 2025-12-28 17:07:29.106381+07:00)
2025-12-28 17:07:29,108 - INFO -  Running predictions...
2025-12-28 17:07:29,286 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:29,286 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:34 +07)" executed successfully
2025-12-28 17:07:34,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:39 +07)" (scheduled at 2025-12-28 17:07:34.106381+07:00)
2025-12-28 17:07:34,107 - INFO -  Running predictions...
2025-12-28 17:07:34,273 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:34,274 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:39 +07)" executed successfully
2025-12-28 17:07:39,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:44 +07)" (scheduled at 2025-12-28 17:07:39.106381+07:00)
2025-12-28 17:07:39,108 - INFO -  Running predictions...
2025-12-28 17:07:39,306 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:39,307 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:44 +07)" executed successfully
2025-12-28 17:07:44,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:49 +07)" (scheduled at 2025-12-28 17:07:44.106381+07:00)
2025-12-28 17:07:44,108 - INFO -  Running predictions...
2025-12-28 17:07:44,241 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:44,242 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:49 +07)" executed successfully
2025-12-28 17:07:49,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:54 +07)" (scheduled at 2025-12-28 17:07:49.106381+07:00)
2025-12-28 17:07:49,109 - INFO -  Running predictions...
2025-12-28 17:07:49,246 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:49,246 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:54 +07)" executed successfully
2025-12-28 17:07:54,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:59 +07)" (scheduled at 2025-12-28 17:07:54.106381+07:00)
2025-12-28 17:07:54,107 - INFO -  Running predictions...
2025-12-28 17:07:54,237 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:54,237 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:07:59 +07)" executed successfully
2025-12-28 17:07:59,109 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:04 +07)" (scheduled at 2025-12-28 17:07:59.106381+07:00)
2025-12-28 17:07:59,109 - INFO -  Running predictions...
2025-12-28 17:07:59,261 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:07:59,261 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:04 +07)" executed successfully
2025-12-28 17:08:04,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:09 +07)" (scheduled at 2025-12-28 17:08:04.106381+07:00)
2025-12-28 17:08:04,108 - INFO -  Running predictions...
2025-12-28 17:08:04,313 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:04,313 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:09 +07)" executed successfully
2025-12-28 17:08:09,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:14 +07)" (scheduled at 2025-12-28 17:08:09.106381+07:00)
2025-12-28 17:08:09,108 - INFO -  Running predictions...
2025-12-28 17:08:09,260 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:09,260 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:14 +07)" executed successfully
2025-12-28 17:08:14,109 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:19 +07)" (scheduled at 2025-12-28 17:08:14.106381+07:00)
2025-12-28 17:08:14,109 - INFO -  Running predictions...
2025-12-28 17:08:14,251 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:14,251 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:19 +07)" executed successfully
2025-12-28 17:08:19,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:24 +07)" (scheduled at 2025-12-28 17:08:19.106381+07:00)
2025-12-28 17:08:19,108 - INFO -  Running predictions...
2025-12-28 17:08:19,246 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:19,246 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:24 +07)" executed successfully
2025-12-28 17:08:24,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:29 +07)" (scheduled at 2025-12-28 17:08:24.106381+07:00)
2025-12-28 17:08:24,108 - INFO -  Running predictions...
2025-12-28 17:08:24,245 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:24,245 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:29 +07)" executed successfully
2025-12-28 17:08:29,107 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:34 +07)" (scheduled at 2025-12-28 17:08:29.106381+07:00)
2025-12-28 17:08:29,107 - INFO -  Running predictions...
2025-12-28 17:08:29,280 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:29,280 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:34 +07)" executed successfully
2025-12-28 17:08:34,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:39 +07)" (scheduled at 2025-12-28 17:08:34.106381+07:00)
2025-12-28 17:08:34,108 - INFO -  Running predictions...
2025-12-28 17:08:34,266 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:34,266 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:39 +07)" executed successfully
2025-12-28 17:08:39,108 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:44 +07)" (scheduled at 2025-12-28 17:08:39.106381+07:00)
2025-12-28 17:08:39,108 - INFO -  Running predictions...
2025-12-28 17:08:39,253 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:39,253 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:44 +07)" executed successfully
2025-12-28 17:08:44,106 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:49 +07)" (scheduled at 2025-12-28 17:08:44.106381+07:00)
2025-12-28 17:08:44,107 - INFO -  Running predictions...
2025-12-28 17:08:44,312 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2025-12-28 17:08:44,313 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2025-12-28 17:08:49 +07)" executed successfully
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         2026-01-05 22:31:39,599 - INFO -  Initializing PySpark Session...
2026-01-05 22:31:43,711 - INFO - ‚úì Spark Session Created!
2026-01-05 22:31:43,711 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-05 22:31:43,740 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-05 22:31:43,741 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-05 22:31:43,742 - INFO - Scheduler started
2026-01-05 22:31:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:31:48 +07)" (scheduled at 2026-01-05 22:31:48.740512+07:00)
2026-01-05 22:31:48,742 - INFO -  Training Spark model...
2026-01-05 22:31:52,013 - WARNING -  Not enough data to train.
2026-01-05 22:31:52,013 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:31:53 +07)" executed successfully
2026-01-05 22:31:53,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:31:58 +07)" (scheduled at 2026-01-05 22:31:53.740512+07:00)
2026-01-05 22:31:53,743 - INFO -  Training Spark model...
2026-01-05 22:31:54,025 - WARNING -  Not enough data to train.
2026-01-05 22:31:54,027 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:31:58 +07)" executed successfully
2026-01-05 22:31:58,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:03 +07)" (scheduled at 2026-01-05 22:31:58.740512+07:00)
2026-01-05 22:31:58,744 - INFO -  Training Spark model...
2026-01-05 22:31:58,888 - WARNING -  Not enough data to train.
2026-01-05 22:31:58,888 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:03 +07)" executed successfully
2026-01-05 22:32:03,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:08 +07)" (scheduled at 2026-01-05 22:32:03.740512+07:00)
2026-01-05 22:32:03,743 - INFO -  Training Spark model...
2026-01-05 22:32:04,051 - WARNING -  Not enough data to train.
2026-01-05 22:32:04,051 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:08 +07)" executed successfully
2026-01-05 22:32:08,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:13 +07)" (scheduled at 2026-01-05 22:32:08.740512+07:00)
2026-01-05 22:32:08,743 - INFO -  Training Spark model...
2026-01-05 22:32:10,450 - INFO - ‚úì Model trained successfully!
2026-01-05 22:32:10,451 - INFO -  Running predictions...
2026-01-05 22:32:10,798 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:10,799 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:13 +07)" executed successfully
2026-01-05 22:32:13,751 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:18 +07)" (scheduled at 2026-01-05 22:32:13.740512+07:00)
2026-01-05 22:32:13,751 - INFO -  Running predictions...
2026-01-05 22:32:14,107 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:14,108 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:18 +07)" executed successfully
2026-01-05 22:32:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:23 +07)" (scheduled at 2026-01-05 22:32:18.740512+07:00)
2026-01-05 22:32:18,743 - INFO -  Running predictions...
2026-01-05 22:32:18,955 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:18,955 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:23 +07)" executed successfully
2026-01-05 22:32:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:28 +07)" (scheduled at 2026-01-05 22:32:23.740512+07:00)
2026-01-05 22:32:23,742 - INFO -  Running predictions...
2026-01-05 22:32:23,944 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:23,944 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:28 +07)" executed successfully
2026-01-05 22:32:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:33 +07)" (scheduled at 2026-01-05 22:32:28.740512+07:00)
2026-01-05 22:32:28,742 - INFO -  Running predictions...
2026-01-05 22:32:28,979 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:28,979 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:33 +07)" executed successfully
2026-01-05 22:32:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:38 +07)" (scheduled at 2026-01-05 22:32:33.740512+07:00)
2026-01-05 22:32:33,741 - INFO -  Running predictions...
2026-01-05 22:32:33,923 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:33,923 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:38 +07)" executed successfully
2026-01-05 22:32:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:43 +07)" (scheduled at 2026-01-05 22:32:38.740512+07:00)
2026-01-05 22:32:38,742 - INFO -  Running predictions...
2026-01-05 22:32:38,951 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:38,951 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:43 +07)" executed successfully
2026-01-05 22:32:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:48 +07)" (scheduled at 2026-01-05 22:32:43.740512+07:00)
2026-01-05 22:32:43,741 - INFO -  Running predictions...
2026-01-05 22:32:43,910 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:43,910 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:48 +07)" executed successfully
2026-01-05 22:32:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:53 +07)" (scheduled at 2026-01-05 22:32:48.740512+07:00)
2026-01-05 22:32:48,742 - INFO -  Running predictions...
2026-01-05 22:32:48,953 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:48,953 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:53 +07)" executed successfully
2026-01-05 22:32:53,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:58 +07)" (scheduled at 2026-01-05 22:32:53.740512+07:00)
2026-01-05 22:32:53,743 - INFO -  Running predictions...
2026-01-05 22:32:53,994 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:53,994 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:32:58 +07)" executed successfully
2026-01-05 22:32:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:03 +07)" (scheduled at 2026-01-05 22:32:58.740512+07:00)
2026-01-05 22:32:58,742 - INFO -  Running predictions...
2026-01-05 22:32:58,939 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:32:58,939 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:03 +07)" executed successfully
2026-01-05 22:33:03,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:08 +07)" (scheduled at 2026-01-05 22:33:03.740512+07:00)
2026-01-05 22:33:03,743 - INFO -  Running predictions...
2026-01-05 22:33:03,970 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:03,970 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:08 +07)" executed successfully
2026-01-05 22:33:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:13 +07)" (scheduled at 2026-01-05 22:33:08.740512+07:00)
2026-01-05 22:33:08,741 - INFO -  Running predictions...
2026-01-05 22:33:08,990 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:08,990 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:13 +07)" executed successfully
2026-01-05 22:33:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:18 +07)" (scheduled at 2026-01-05 22:33:13.740512+07:00)
2026-01-05 22:33:13,742 - INFO -  Running predictions...
2026-01-05 22:33:13,964 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:13,964 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:18 +07)" executed successfully
2026-01-05 22:33:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:23 +07)" (scheduled at 2026-01-05 22:33:18.740512+07:00)
2026-01-05 22:33:18,742 - INFO -  Running predictions...
2026-01-05 22:33:18,940 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:18,940 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:23 +07)" executed successfully
2026-01-05 22:33:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:28 +07)" (scheduled at 2026-01-05 22:33:23.740512+07:00)
2026-01-05 22:33:23,743 - INFO -  Running predictions...
2026-01-05 22:33:24,003 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:24,003 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:28 +07)" executed successfully
2026-01-05 22:33:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:33 +07)" (scheduled at 2026-01-05 22:33:28.740512+07:00)
2026-01-05 22:33:28,742 - INFO -  Running predictions...
2026-01-05 22:33:29,018 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:29,018 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:33 +07)" executed successfully
2026-01-05 22:33:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:38 +07)" (scheduled at 2026-01-05 22:33:33.740512+07:00)
2026-01-05 22:33:33,743 - INFO -  Running predictions...
2026-01-05 22:33:34,051 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:34,051 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:38 +07)" executed successfully
2026-01-05 22:33:38,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:43 +07)" (scheduled at 2026-01-05 22:33:38.740512+07:00)
2026-01-05 22:33:38,751 - INFO -  Running predictions...
2026-01-05 22:33:39,452 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:39,452 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:43 +07)" executed successfully
2026-01-05 22:33:43,740 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:48 +07)" (scheduled at 2026-01-05 22:33:43.740512+07:00)
2026-01-05 22:33:43,741 - INFO -  Running predictions...
2026-01-05 22:33:43,996 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:43,996 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:48 +07)" executed successfully
2026-01-05 22:33:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:53 +07)" (scheduled at 2026-01-05 22:33:48.740512+07:00)
2026-01-05 22:33:48,743 - INFO -  Running predictions...
2026-01-05 22:33:48,999 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:48,999 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:53 +07)" executed successfully
2026-01-05 22:33:53,746 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:58 +07)" (scheduled at 2026-01-05 22:33:53.740512+07:00)
2026-01-05 22:33:53,746 - INFO -  Running predictions...
2026-01-05 22:33:53,983 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:53,983 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:33:58 +07)" executed successfully
2026-01-05 22:33:58,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:03 +07)" (scheduled at 2026-01-05 22:33:58.740512+07:00)
2026-01-05 22:33:58,743 - INFO -  Running predictions...
2026-01-05 22:33:58,996 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:33:58,996 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:03 +07)" executed successfully
2026-01-05 22:34:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:08 +07)" (scheduled at 2026-01-05 22:34:03.740512+07:00)
2026-01-05 22:34:03,742 - INFO -  Running predictions...
2026-01-05 22:34:03,969 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:03,970 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:08 +07)" executed successfully
2026-01-05 22:34:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:13 +07)" (scheduled at 2026-01-05 22:34:08.740512+07:00)
2026-01-05 22:34:08,742 - INFO -  Running predictions...
2026-01-05 22:34:08,915 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:08,915 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:13 +07)" executed successfully
2026-01-05 22:34:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:18 +07)" (scheduled at 2026-01-05 22:34:13.740512+07:00)
2026-01-05 22:34:13,741 - INFO -  Running predictions...
2026-01-05 22:34:13,961 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:13,961 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:18 +07)" executed successfully
2026-01-05 22:34:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:23 +07)" (scheduled at 2026-01-05 22:34:18.740512+07:00)
2026-01-05 22:34:18,742 - INFO -  Running predictions...
2026-01-05 22:34:18,944 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:18,944 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:23 +07)" executed successfully
2026-01-05 22:34:23,752 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:28 +07)" (scheduled at 2026-01-05 22:34:23.740512+07:00)
2026-01-05 22:34:23,752 - INFO -  Running predictions...
2026-01-05 22:34:23,959 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:23,960 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:28 +07)" executed successfully
2026-01-05 22:34:28,752 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:33 +07)" (scheduled at 2026-01-05 22:34:28.740512+07:00)
2026-01-05 22:34:28,752 - INFO -  Running predictions...
2026-01-05 22:34:28,958 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:28,959 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:33 +07)" executed successfully
2026-01-05 22:34:33,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:38 +07)" (scheduled at 2026-01-05 22:34:33.740512+07:00)
2026-01-05 22:34:33,742 - INFO -  Running predictions...
2026-01-05 22:34:33,955 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:33,955 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:38 +07)" executed successfully
2026-01-05 22:34:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:43 +07)" (scheduled at 2026-01-05 22:34:38.740512+07:00)
2026-01-05 22:34:38,742 - INFO -  Running predictions...
2026-01-05 22:34:38,927 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:38,927 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:43 +07)" executed successfully
2026-01-05 22:34:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:48 +07)" (scheduled at 2026-01-05 22:34:43.740512+07:00)
2026-01-05 22:34:43,742 - INFO -  Running predictions...
2026-01-05 22:34:43,892 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:43,892 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:48 +07)" executed successfully
2026-01-05 22:34:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:53 +07)" (scheduled at 2026-01-05 22:34:48.740512+07:00)
2026-01-05 22:34:48,743 - INFO -  Running predictions...
2026-01-05 22:34:48,962 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:48,962 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:53 +07)" executed successfully
2026-01-05 22:34:53,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:58 +07)" (scheduled at 2026-01-05 22:34:53.740512+07:00)
2026-01-05 22:34:53,745 - INFO -  Running predictions...
2026-01-05 22:34:53,949 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:53,950 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:34:58 +07)" executed successfully
2026-01-05 22:34:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:03 +07)" (scheduled at 2026-01-05 22:34:58.740512+07:00)
2026-01-05 22:34:58,742 - INFO -  Running predictions...
2026-01-05 22:34:58,883 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:34:58,883 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:03 +07)" executed successfully
2026-01-05 22:35:03,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:08 +07)" (scheduled at 2026-01-05 22:35:03.740512+07:00)
2026-01-05 22:35:03,742 - INFO -  Running predictions...
2026-01-05 22:35:03,917 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:03,917 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:08 +07)" executed successfully
2026-01-05 22:35:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:13 +07)" (scheduled at 2026-01-05 22:35:08.740512+07:00)
2026-01-05 22:35:08,742 - INFO -  Running predictions...
2026-01-05 22:35:08,912 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:08,912 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:13 +07)" executed successfully
2026-01-05 22:35:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:18 +07)" (scheduled at 2026-01-05 22:35:13.740512+07:00)
2026-01-05 22:35:13,741 - INFO -  Running predictions...
2026-01-05 22:35:13,891 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:13,892 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:18 +07)" executed successfully
2026-01-05 22:35:18,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:23 +07)" (scheduled at 2026-01-05 22:35:18.740512+07:00)
2026-01-05 22:35:18,744 - INFO -  Running predictions...
2026-01-05 22:35:18,922 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:18,922 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:23 +07)" executed successfully
2026-01-05 22:35:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:28 +07)" (scheduled at 2026-01-05 22:35:23.740512+07:00)
2026-01-05 22:35:23,742 - INFO -  Running predictions...
2026-01-05 22:35:23,874 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:23,874 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:28 +07)" executed successfully
2026-01-05 22:35:28,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:33 +07)" (scheduled at 2026-01-05 22:35:28.740512+07:00)
2026-01-05 22:35:28,744 - INFO -  Running predictions...
2026-01-05 22:35:28,903 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:28,903 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:33 +07)" executed successfully
2026-01-05 22:35:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:38 +07)" (scheduled at 2026-01-05 22:35:33.740512+07:00)
2026-01-05 22:35:33,742 - INFO -  Running predictions...
2026-01-05 22:35:33,917 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:33,917 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:38 +07)" executed successfully
2026-01-05 22:35:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:43 +07)" (scheduled at 2026-01-05 22:35:38.740512+07:00)
2026-01-05 22:35:38,741 - INFO -  Running predictions...
2026-01-05 22:35:38,871 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:38,871 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:43 +07)" executed successfully
2026-01-05 22:35:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:48 +07)" (scheduled at 2026-01-05 22:35:43.740512+07:00)
2026-01-05 22:35:43,743 - INFO -  Running predictions...
2026-01-05 22:35:43,942 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:43,943 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:48 +07)" executed successfully
2026-01-05 22:35:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:53 +07)" (scheduled at 2026-01-05 22:35:48.740512+07:00)
2026-01-05 22:35:48,741 - INFO -  Running predictions...
2026-01-05 22:35:48,967 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:48,967 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:53 +07)" executed successfully
2026-01-05 22:35:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:58 +07)" (scheduled at 2026-01-05 22:35:53.740512+07:00)
2026-01-05 22:35:53,742 - INFO -  Running predictions...
2026-01-05 22:35:53,968 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:53,968 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:35:58 +07)" executed successfully
2026-01-05 22:35:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:03 +07)" (scheduled at 2026-01-05 22:35:58.740512+07:00)
2026-01-05 22:35:58,741 - INFO -  Running predictions...
2026-01-05 22:35:58,987 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:35:58,987 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:03 +07)" executed successfully
2026-01-05 22:36:03,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:08 +07)" (scheduled at 2026-01-05 22:36:03.740512+07:00)
2026-01-05 22:36:03,742 - INFO -  Running predictions...
2026-01-05 22:36:04,016 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:04,016 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:08 +07)" executed successfully
2026-01-05 22:36:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:13 +07)" (scheduled at 2026-01-05 22:36:08.740512+07:00)
2026-01-05 22:36:08,742 - INFO -  Running predictions...
2026-01-05 22:36:08,997 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:08,997 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:13 +07)" executed successfully
2026-01-05 22:36:13,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:18 +07)" (scheduled at 2026-01-05 22:36:13.740512+07:00)
2026-01-05 22:36:13,743 - INFO -  Running predictions...
2026-01-05 22:36:13,999 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:13,999 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:18 +07)" executed successfully
2026-01-05 22:36:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:23 +07)" (scheduled at 2026-01-05 22:36:18.740512+07:00)
2026-01-05 22:36:18,742 - INFO -  Running predictions...
2026-01-05 22:36:18,872 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:18,872 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:23 +07)" executed successfully
2026-01-05 22:36:23,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:28 +07)" (scheduled at 2026-01-05 22:36:23.740512+07:00)
2026-01-05 22:36:23,744 - INFO -  Running predictions...
2026-01-05 22:36:23,887 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:23,887 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:28 +07)" executed successfully
2026-01-05 22:36:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:33 +07)" (scheduled at 2026-01-05 22:36:28.740512+07:00)
2026-01-05 22:36:28,742 - INFO -  Running predictions...
2026-01-05 22:36:28,865 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:28,865 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:33 +07)" executed successfully
2026-01-05 22:36:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:38 +07)" (scheduled at 2026-01-05 22:36:33.740512+07:00)
2026-01-05 22:36:33,741 - INFO -  Running predictions...
2026-01-05 22:36:33,897 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:33,897 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:38 +07)" executed successfully
2026-01-05 22:36:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:43 +07)" (scheduled at 2026-01-05 22:36:38.740512+07:00)
2026-01-05 22:36:38,742 - INFO -  Running predictions...
2026-01-05 22:36:38,863 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:38,863 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:43 +07)" executed successfully
2026-01-05 22:36:43,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:48 +07)" (scheduled at 2026-01-05 22:36:43.740512+07:00)
2026-01-05 22:36:43,743 - INFO -  Running predictions...
2026-01-05 22:36:43,892 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:43,893 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:48 +07)" executed successfully
2026-01-05 22:36:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:53 +07)" (scheduled at 2026-01-05 22:36:48.740512+07:00)
2026-01-05 22:36:48,743 - INFO -  Running predictions...
2026-01-05 22:36:48,855 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:48,855 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:53 +07)" executed successfully
2026-01-05 22:36:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:58 +07)" (scheduled at 2026-01-05 22:36:53.740512+07:00)
2026-01-05 22:36:53,742 - INFO -  Running predictions...
2026-01-05 22:36:53,857 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:53,857 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:36:58 +07)" executed successfully
2026-01-05 22:36:58,754 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:03 +07)" (scheduled at 2026-01-05 22:36:58.740512+07:00)
2026-01-05 22:36:58,754 - INFO -  Running predictions...
2026-01-05 22:36:58,919 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:36:58,919 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:03 +07)" executed successfully
2026-01-05 22:37:03,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:08 +07)" (scheduled at 2026-01-05 22:37:03.740512+07:00)
2026-01-05 22:37:03,742 - INFO -  Running predictions...
2026-01-05 22:37:03,853 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:03,853 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:08 +07)" executed successfully
2026-01-05 22:37:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:13 +07)" (scheduled at 2026-01-05 22:37:08.740512+07:00)
2026-01-05 22:37:08,742 - INFO -  Running predictions...
2026-01-05 22:37:08,868 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:08,868 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:13 +07)" executed successfully
2026-01-05 22:37:13,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:18 +07)" (scheduled at 2026-01-05 22:37:13.740512+07:00)
2026-01-05 22:37:13,744 - INFO -  Running predictions...
2026-01-05 22:37:13,858 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:13,858 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:18 +07)" executed successfully
2026-01-05 22:37:18,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:23 +07)" (scheduled at 2026-01-05 22:37:18.740512+07:00)
2026-01-05 22:37:18,743 - INFO -  Running predictions...
2026-01-05 22:37:18,898 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:18,898 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:23 +07)" executed successfully
2026-01-05 22:37:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:28 +07)" (scheduled at 2026-01-05 22:37:23.740512+07:00)
2026-01-05 22:37:23,741 - INFO -  Running predictions...
2026-01-05 22:37:23,888 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:23,888 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:28 +07)" executed successfully
2026-01-05 22:37:28,753 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:33 +07)" (scheduled at 2026-01-05 22:37:28.740512+07:00)
2026-01-05 22:37:28,753 - INFO -  Running predictions...
2026-01-05 22:37:28,889 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:28,890 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:33 +07)" executed successfully
2026-01-05 22:37:33,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:38 +07)" (scheduled at 2026-01-05 22:37:33.740512+07:00)
2026-01-05 22:37:33,742 - INFO -  Running predictions...
2026-01-05 22:37:33,886 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:33,886 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:38 +07)" executed successfully
2026-01-05 22:37:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:43 +07)" (scheduled at 2026-01-05 22:37:38.740512+07:00)
2026-01-05 22:37:38,741 - INFO -  Running predictions...
2026-01-05 22:37:38,890 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:38,890 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:43 +07)" executed successfully
2026-01-05 22:37:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:48 +07)" (scheduled at 2026-01-05 22:37:43.740512+07:00)
2026-01-05 22:37:43,742 - INFO -  Running predictions...
2026-01-05 22:37:43,915 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:43,915 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:48 +07)" executed successfully
2026-01-05 22:37:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:53 +07)" (scheduled at 2026-01-05 22:37:48.740512+07:00)
2026-01-05 22:37:48,744 - INFO -  Running predictions...
2026-01-05 22:37:48,963 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:48,963 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:53 +07)" executed successfully
2026-01-05 22:37:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:58 +07)" (scheduled at 2026-01-05 22:37:53.740512+07:00)
2026-01-05 22:37:53,743 - INFO -  Running predictions...
2026-01-05 22:37:53,998 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:53,998 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:37:58 +07)" executed successfully
2026-01-05 22:37:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:03 +07)" (scheduled at 2026-01-05 22:37:58.740512+07:00)
2026-01-05 22:37:58,743 - INFO -  Running predictions...
2026-01-05 22:37:58,881 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:37:58,881 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:03 +07)" executed successfully
2026-01-05 22:38:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:08 +07)" (scheduled at 2026-01-05 22:38:03.740512+07:00)
2026-01-05 22:38:03,742 - INFO -  Running predictions...
2026-01-05 22:38:03,955 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:03,956 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:08 +07)" executed successfully
2026-01-05 22:38:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:13 +07)" (scheduled at 2026-01-05 22:38:08.740512+07:00)
2026-01-05 22:38:08,741 - INFO -  Running predictions...
2026-01-05 22:38:08,866 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:08,866 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:13 +07)" executed successfully
2026-01-05 22:38:13,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:18 +07)" (scheduled at 2026-01-05 22:38:13.740512+07:00)
2026-01-05 22:38:13,742 - INFO -  Running predictions...
2026-01-05 22:38:13,952 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:13,952 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:18 +07)" executed successfully
2026-01-05 22:38:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:23 +07)" (scheduled at 2026-01-05 22:38:18.740512+07:00)
2026-01-05 22:38:18,743 - INFO -  Running predictions...
2026-01-05 22:38:18,881 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:18,882 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:23 +07)" executed successfully
2026-01-05 22:38:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:28 +07)" (scheduled at 2026-01-05 22:38:23.740512+07:00)
2026-01-05 22:38:23,742 - INFO -  Running predictions...
2026-01-05 22:38:23,870 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:23,870 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:28 +07)" executed successfully
2026-01-05 22:38:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:33 +07)" (scheduled at 2026-01-05 22:38:28.740512+07:00)
2026-01-05 22:38:28,741 - INFO -  Running predictions...
2026-01-05 22:38:28,886 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:28,887 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:33 +07)" executed successfully
2026-01-05 22:38:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:38 +07)" (scheduled at 2026-01-05 22:38:33.740512+07:00)
2026-01-05 22:38:33,741 - INFO -  Running predictions...
2026-01-05 22:38:33,890 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:33,890 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:38 +07)" executed successfully
2026-01-05 22:38:38,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:43 +07)" (scheduled at 2026-01-05 22:38:38.740512+07:00)
2026-01-05 22:38:38,743 - INFO -  Running predictions...
2026-01-05 22:38:38,883 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:38,883 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:43 +07)" executed successfully
2026-01-05 22:38:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:48 +07)" (scheduled at 2026-01-05 22:38:43.740512+07:00)
2026-01-05 22:38:43,742 - INFO -  Running predictions...
2026-01-05 22:38:43,866 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:43,866 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:48 +07)" executed successfully
2026-01-05 22:38:48,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:53 +07)" (scheduled at 2026-01-05 22:38:48.740512+07:00)
2026-01-05 22:38:48,742 - INFO -  Running predictions...
2026-01-05 22:38:49,324 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:49,324 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:53 +07)" executed successfully
2026-01-05 22:38:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:58 +07)" (scheduled at 2026-01-05 22:38:53.740512+07:00)
2026-01-05 22:38:53,742 - INFO -  Running predictions...
2026-01-05 22:38:53,907 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:53,907 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:38:58 +07)" executed successfully
2026-01-05 22:38:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:03 +07)" (scheduled at 2026-01-05 22:38:58.740512+07:00)
2026-01-05 22:38:58,742 - INFO -  Running predictions...
2026-01-05 22:38:58,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:38:58,834 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:03 +07)" executed successfully
2026-01-05 22:39:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:08 +07)" (scheduled at 2026-01-05 22:39:03.740512+07:00)
2026-01-05 22:39:03,742 - INFO -  Running predictions...
2026-01-05 22:39:03,859 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:03,859 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:08 +07)" executed successfully
2026-01-05 22:39:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:13 +07)" (scheduled at 2026-01-05 22:39:08.740512+07:00)
2026-01-05 22:39:08,741 - INFO -  Running predictions...
2026-01-05 22:39:08,830 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:08,830 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:13 +07)" executed successfully
2026-01-05 22:39:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:18 +07)" (scheduled at 2026-01-05 22:39:13.740512+07:00)
2026-01-05 22:39:13,741 - INFO -  Running predictions...
2026-01-05 22:39:13,854 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:13,854 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:18 +07)" executed successfully
2026-01-05 22:39:18,740 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:23 +07)" (scheduled at 2026-01-05 22:39:18.740512+07:00)
2026-01-05 22:39:18,741 - INFO -  Running predictions...
2026-01-05 22:39:18,899 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:18,900 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:23 +07)" executed successfully
2026-01-05 22:39:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:28 +07)" (scheduled at 2026-01-05 22:39:23.740512+07:00)
2026-01-05 22:39:23,742 - INFO -  Running predictions...
2026-01-05 22:39:23,847 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:23,847 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:28 +07)" executed successfully
2026-01-05 22:39:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:33 +07)" (scheduled at 2026-01-05 22:39:28.740512+07:00)
2026-01-05 22:39:28,742 - INFO -  Running predictions...
2026-01-05 22:39:28,876 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:28,877 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:33 +07)" executed successfully
2026-01-05 22:39:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:38 +07)" (scheduled at 2026-01-05 22:39:33.740512+07:00)
2026-01-05 22:39:33,741 - INFO -  Running predictions...
2026-01-05 22:39:33,907 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:33,907 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:38 +07)" executed successfully
2026-01-05 22:39:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:43 +07)" (scheduled at 2026-01-05 22:39:38.740512+07:00)
2026-01-05 22:39:38,742 - INFO -  Running predictions...
2026-01-05 22:39:38,880 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:38,880 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:43 +07)" executed successfully
2026-01-05 22:39:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:48 +07)" (scheduled at 2026-01-05 22:39:43.740512+07:00)
2026-01-05 22:39:43,741 - INFO -  Running predictions...
2026-01-05 22:39:43,861 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:43,861 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:48 +07)" executed successfully
2026-01-05 22:39:48,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:53 +07)" (scheduled at 2026-01-05 22:39:48.740512+07:00)
2026-01-05 22:39:48,742 - INFO -  Running predictions...
2026-01-05 22:39:48,982 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:48,982 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:53 +07)" executed successfully
2026-01-05 22:39:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:58 +07)" (scheduled at 2026-01-05 22:39:53.740512+07:00)
2026-01-05 22:39:53,741 - INFO -  Running predictions...
2026-01-05 22:39:53,874 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:53,874 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:39:58 +07)" executed successfully
2026-01-05 22:39:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:03 +07)" (scheduled at 2026-01-05 22:39:58.740512+07:00)
2026-01-05 22:39:58,742 - INFO -  Running predictions...
2026-01-05 22:39:58,897 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:39:58,898 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:03 +07)" executed successfully
2026-01-05 22:40:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:08 +07)" (scheduled at 2026-01-05 22:40:03.740512+07:00)
2026-01-05 22:40:03,741 - INFO -  Running predictions...
2026-01-05 22:40:03,908 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:03,908 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:08 +07)" executed successfully
2026-01-05 22:40:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:13 +07)" (scheduled at 2026-01-05 22:40:08.740512+07:00)
2026-01-05 22:40:08,741 - INFO -  Running predictions...
2026-01-05 22:40:08,896 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:08,896 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:13 +07)" executed successfully
2026-01-05 22:40:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:18 +07)" (scheduled at 2026-01-05 22:40:13.740512+07:00)
2026-01-05 22:40:13,741 - INFO -  Running predictions...
2026-01-05 22:40:13,889 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:13,889 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:18 +07)" executed successfully
2026-01-05 22:40:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:23 +07)" (scheduled at 2026-01-05 22:40:18.740512+07:00)
2026-01-05 22:40:18,741 - INFO -  Running predictions...
2026-01-05 22:40:18,954 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:18,954 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:23 +07)" executed successfully
2026-01-05 22:40:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:28 +07)" (scheduled at 2026-01-05 22:40:23.740512+07:00)
2026-01-05 22:40:23,741 - INFO -  Running predictions...
2026-01-05 22:40:23,850 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:23,851 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:28 +07)" executed successfully
2026-01-05 22:40:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:33 +07)" (scheduled at 2026-01-05 22:40:28.740512+07:00)
2026-01-05 22:40:28,741 - INFO -  Running predictions...
2026-01-05 22:40:28,906 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:28,907 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:33 +07)" executed successfully
2026-01-05 22:40:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:38 +07)" (scheduled at 2026-01-05 22:40:33.740512+07:00)
2026-01-05 22:40:33,741 - INFO -  Running predictions...
2026-01-05 22:40:33,880 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:33,880 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:38 +07)" executed successfully
2026-01-05 22:40:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:43 +07)" (scheduled at 2026-01-05 22:40:38.740512+07:00)
2026-01-05 22:40:38,742 - INFO -  Running predictions...
2026-01-05 22:40:38,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:38,843 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:43 +07)" executed successfully
2026-01-05 22:40:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:48 +07)" (scheduled at 2026-01-05 22:40:43.740512+07:00)
2026-01-05 22:40:43,741 - INFO -  Running predictions...
2026-01-05 22:40:43,895 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:43,896 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:48 +07)" executed successfully
2026-01-05 22:40:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:53 +07)" (scheduled at 2026-01-05 22:40:48.740512+07:00)
2026-01-05 22:40:48,744 - INFO -  Running predictions...
2026-01-05 22:40:48,858 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:48,858 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:53 +07)" executed successfully
2026-01-05 22:40:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:58 +07)" (scheduled at 2026-01-05 22:40:53.740512+07:00)
2026-01-05 22:40:53,743 - INFO -  Running predictions...
2026-01-05 22:40:53,895 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:53,895 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:40:58 +07)" executed successfully
2026-01-05 22:40:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:03 +07)" (scheduled at 2026-01-05 22:40:58.740512+07:00)
2026-01-05 22:40:58,741 - INFO -  Running predictions...
2026-01-05 22:40:58,853 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:40:58,854 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:03 +07)" executed successfully
2026-01-05 22:41:03,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:08 +07)" (scheduled at 2026-01-05 22:41:03.740512+07:00)
2026-01-05 22:41:03,742 - INFO -  Running predictions...
2026-01-05 22:41:03,851 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:03,851 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:08 +07)" executed successfully
2026-01-05 22:41:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:13 +07)" (scheduled at 2026-01-05 22:41:08.740512+07:00)
2026-01-05 22:41:08,743 - INFO -  Running predictions...
2026-01-05 22:41:08,896 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:08,896 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:13 +07)" executed successfully
2026-01-05 22:41:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:18 +07)" (scheduled at 2026-01-05 22:41:13.740512+07:00)
2026-01-05 22:41:13,741 - INFO -  Running predictions...
2026-01-05 22:41:13,864 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:13,864 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:18 +07)" executed successfully
2026-01-05 22:41:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:23 +07)" (scheduled at 2026-01-05 22:41:18.740512+07:00)
2026-01-05 22:41:18,741 - INFO -  Running predictions...
2026-01-05 22:41:18,876 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:18,877 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:23 +07)" executed successfully
2026-01-05 22:41:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:28 +07)" (scheduled at 2026-01-05 22:41:23.740512+07:00)
2026-01-05 22:41:23,741 - INFO -  Running predictions...
2026-01-05 22:41:23,885 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:23,886 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:28 +07)" executed successfully
2026-01-05 22:41:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:33 +07)" (scheduled at 2026-01-05 22:41:28.740512+07:00)
2026-01-05 22:41:28,741 - INFO -  Running predictions...
2026-01-05 22:41:28,880 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:28,881 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:33 +07)" executed successfully
2026-01-05 22:41:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:38 +07)" (scheduled at 2026-01-05 22:41:33.740512+07:00)
2026-01-05 22:41:33,741 - INFO -  Running predictions...
2026-01-05 22:41:33,989 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:33,989 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:38 +07)" executed successfully
2026-01-05 22:41:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:43 +07)" (scheduled at 2026-01-05 22:41:38.740512+07:00)
2026-01-05 22:41:38,742 - INFO -  Running predictions...
2026-01-05 22:41:38,880 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:38,880 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:43 +07)" executed successfully
2026-01-05 22:41:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:48 +07)" (scheduled at 2026-01-05 22:41:43.740512+07:00)
2026-01-05 22:41:43,742 - INFO -  Running predictions...
2026-01-05 22:41:43,988 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:43,988 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:48 +07)" executed successfully
2026-01-05 22:41:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:53 +07)" (scheduled at 2026-01-05 22:41:48.740512+07:00)
2026-01-05 22:41:48,741 - INFO -  Running predictions...
2026-01-05 22:41:48,924 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:48,924 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:53 +07)" executed successfully
2026-01-05 22:41:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:58 +07)" (scheduled at 2026-01-05 22:41:53.740512+07:00)
2026-01-05 22:41:53,741 - INFO -  Running predictions...
2026-01-05 22:41:53,897 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:53,898 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:41:58 +07)" executed successfully
2026-01-05 22:41:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:03 +07)" (scheduled at 2026-01-05 22:41:58.740512+07:00)
2026-01-05 22:41:58,741 - INFO -  Running predictions...
2026-01-05 22:41:58,849 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:41:58,849 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:03 +07)" executed successfully
2026-01-05 22:42:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:08 +07)" (scheduled at 2026-01-05 22:42:03.740512+07:00)
2026-01-05 22:42:03,741 - INFO -  Running predictions...
2026-01-05 22:42:03,848 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:03,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:08 +07)" executed successfully
2026-01-05 22:42:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:13 +07)" (scheduled at 2026-01-05 22:42:08.740512+07:00)
2026-01-05 22:42:08,742 - INFO -  Running predictions...
2026-01-05 22:42:08,881 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:08,881 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:13 +07)" executed successfully
2026-01-05 22:42:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:18 +07)" (scheduled at 2026-01-05 22:42:13.740512+07:00)
2026-01-05 22:42:13,742 - INFO -  Running predictions...
2026-01-05 22:42:13,959 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:13,959 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:18 +07)" executed successfully
2026-01-05 22:42:18,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:23 +07)" (scheduled at 2026-01-05 22:42:18.740512+07:00)
2026-01-05 22:42:18,744 - INFO -  Running predictions...
2026-01-05 22:42:18,835 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:18,836 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:23 +07)" executed successfully
2026-01-05 22:42:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:28 +07)" (scheduled at 2026-01-05 22:42:23.740512+07:00)
2026-01-05 22:42:23,744 - INFO -  Running predictions...
2026-01-05 22:42:23,885 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:23,885 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:28 +07)" executed successfully
2026-01-05 22:42:28,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:33 +07)" (scheduled at 2026-01-05 22:42:28.740512+07:00)
2026-01-05 22:42:28,743 - INFO -  Running predictions...
2026-01-05 22:42:28,902 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:28,902 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:33 +07)" executed successfully
2026-01-05 22:42:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:38 +07)" (scheduled at 2026-01-05 22:42:33.740512+07:00)
2026-01-05 22:42:33,741 - INFO -  Running predictions...
2026-01-05 22:42:33,883 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:33,883 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:38 +07)" executed successfully
2026-01-05 22:42:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:43 +07)" (scheduled at 2026-01-05 22:42:38.740512+07:00)
2026-01-05 22:42:38,741 - INFO -  Running predictions...
2026-01-05 22:42:38,867 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:38,867 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:43 +07)" executed successfully
2026-01-05 22:42:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:48 +07)" (scheduled at 2026-01-05 22:42:43.740512+07:00)
2026-01-05 22:42:43,741 - INFO -  Running predictions...
2026-01-05 22:42:43,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:43,840 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:48 +07)" executed successfully
2026-01-05 22:42:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:53 +07)" (scheduled at 2026-01-05 22:42:48.740512+07:00)
2026-01-05 22:42:48,741 - INFO -  Running predictions...
2026-01-05 22:42:48,857 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:48,858 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:53 +07)" executed successfully
2026-01-05 22:42:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:58 +07)" (scheduled at 2026-01-05 22:42:53.740512+07:00)
2026-01-05 22:42:53,742 - INFO -  Running predictions...
2026-01-05 22:42:53,859 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:53,859 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:42:58 +07)" executed successfully
2026-01-05 22:42:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:03 +07)" (scheduled at 2026-01-05 22:42:58.740512+07:00)
2026-01-05 22:42:58,741 - INFO -  Running predictions...
2026-01-05 22:42:58,837 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:42:58,837 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:03 +07)" executed successfully
2026-01-05 22:43:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:08 +07)" (scheduled at 2026-01-05 22:43:03.740512+07:00)
2026-01-05 22:43:03,741 - INFO -  Running predictions...
2026-01-05 22:43:03,839 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:03,839 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:08 +07)" executed successfully
2026-01-05 22:43:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:13 +07)" (scheduled at 2026-01-05 22:43:08.740512+07:00)
2026-01-05 22:43:08,741 - INFO -  Running predictions...
2026-01-05 22:43:08,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:08,835 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:13 +07)" executed successfully
2026-01-05 22:43:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:18 +07)" (scheduled at 2026-01-05 22:43:13.740512+07:00)
2026-01-05 22:43:13,742 - INFO -  Running predictions...
2026-01-05 22:43:13,857 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:13,857 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:18 +07)" executed successfully
2026-01-05 22:43:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:23 +07)" (scheduled at 2026-01-05 22:43:18.740512+07:00)
2026-01-05 22:43:18,742 - INFO -  Running predictions...
2026-01-05 22:43:18,847 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:18,847 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:23 +07)" executed successfully
2026-01-05 22:43:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:28 +07)" (scheduled at 2026-01-05 22:43:23.740512+07:00)
2026-01-05 22:43:23,741 - INFO -  Running predictions...
2026-01-05 22:43:23,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:23,834 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:28 +07)" executed successfully
2026-01-05 22:43:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:33 +07)" (scheduled at 2026-01-05 22:43:28.740512+07:00)
2026-01-05 22:43:28,742 - INFO -  Running predictions...
2026-01-05 22:43:28,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:28,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:33 +07)" executed successfully
2026-01-05 22:43:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:38 +07)" (scheduled at 2026-01-05 22:43:33.740512+07:00)
2026-01-05 22:43:33,742 - INFO -  Running predictions...
2026-01-05 22:43:33,836 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:33,836 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:38 +07)" executed successfully
2026-01-05 22:43:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:43 +07)" (scheduled at 2026-01-05 22:43:38.740512+07:00)
2026-01-05 22:43:38,742 - INFO -  Running predictions...
2026-01-05 22:43:38,849 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:38,849 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:43 +07)" executed successfully
2026-01-05 22:43:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:48 +07)" (scheduled at 2026-01-05 22:43:43.740512+07:00)
2026-01-05 22:43:43,742 - INFO -  Running predictions...
2026-01-05 22:43:43,861 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:43,861 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:48 +07)" executed successfully
2026-01-05 22:43:48,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:53 +07)" (scheduled at 2026-01-05 22:43:48.740512+07:00)
2026-01-05 22:43:48,742 - INFO -  Running predictions...
2026-01-05 22:43:48,839 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:48,839 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:53 +07)" executed successfully
2026-01-05 22:43:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:58 +07)" (scheduled at 2026-01-05 22:43:53.740512+07:00)
2026-01-05 22:43:53,741 - INFO -  Running predictions...
2026-01-05 22:43:53,847 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:53,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:43:58 +07)" executed successfully
2026-01-05 22:43:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:03 +07)" (scheduled at 2026-01-05 22:43:58.740512+07:00)
2026-01-05 22:43:58,742 - INFO -  Running predictions...
2026-01-05 22:43:58,829 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:43:58,829 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:03 +07)" executed successfully
2026-01-05 22:44:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:08 +07)" (scheduled at 2026-01-05 22:44:03.740512+07:00)
2026-01-05 22:44:03,742 - INFO -  Running predictions...
2026-01-05 22:44:03,869 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:03,869 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:08 +07)" executed successfully
2026-01-05 22:44:08,740 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:13 +07)" (scheduled at 2026-01-05 22:44:08.740512+07:00)
2026-01-05 22:44:08,741 - INFO -  Running predictions...
2026-01-05 22:44:08,899 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:08,899 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:13 +07)" executed successfully
2026-01-05 22:44:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:18 +07)" (scheduled at 2026-01-05 22:44:13.740512+07:00)
2026-01-05 22:44:13,741 - INFO -  Running predictions...
2026-01-05 22:44:13,865 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:13,865 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:18 +07)" executed successfully
2026-01-05 22:44:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:23 +07)" (scheduled at 2026-01-05 22:44:18.740512+07:00)
2026-01-05 22:44:18,741 - INFO -  Running predictions...
2026-01-05 22:44:18,858 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:18,858 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:23 +07)" executed successfully
2026-01-05 22:44:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:28 +07)" (scheduled at 2026-01-05 22:44:23.740512+07:00)
2026-01-05 22:44:23,741 - INFO -  Running predictions...
2026-01-05 22:44:23,902 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:23,902 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:28 +07)" executed successfully
2026-01-05 22:44:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:33 +07)" (scheduled at 2026-01-05 22:44:28.740512+07:00)
2026-01-05 22:44:28,743 - INFO -  Running predictions...
2026-01-05 22:44:28,875 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:28,876 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:33 +07)" executed successfully
2026-01-05 22:44:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:38 +07)" (scheduled at 2026-01-05 22:44:33.740512+07:00)
2026-01-05 22:44:33,742 - INFO -  Running predictions...
2026-01-05 22:44:33,907 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:33,907 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:38 +07)" executed successfully
2026-01-05 22:44:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:43 +07)" (scheduled at 2026-01-05 22:44:38.740512+07:00)
2026-01-05 22:44:38,742 - INFO -  Running predictions...
2026-01-05 22:44:38,897 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:38,897 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:43 +07)" executed successfully
2026-01-05 22:44:43,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:48 +07)" (scheduled at 2026-01-05 22:44:43.740512+07:00)
2026-01-05 22:44:43,744 - INFO -  Running predictions...
2026-01-05 22:44:43,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:43,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:48 +07)" executed successfully
2026-01-05 22:44:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:53 +07)" (scheduled at 2026-01-05 22:44:48.740512+07:00)
2026-01-05 22:44:48,742 - INFO -  Running predictions...
2026-01-05 22:44:48,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:48,840 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:53 +07)" executed successfully
2026-01-05 22:44:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:58 +07)" (scheduled at 2026-01-05 22:44:53.740512+07:00)
2026-01-05 22:44:53,743 - INFO -  Running predictions...
2026-01-05 22:44:53,841 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:53,841 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:44:58 +07)" executed successfully
2026-01-05 22:44:58,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:03 +07)" (scheduled at 2026-01-05 22:44:58.740512+07:00)
2026-01-05 22:44:58,744 - INFO -  Running predictions...
2026-01-05 22:44:58,824 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:44:58,824 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:03 +07)" executed successfully
2026-01-05 22:45:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:08 +07)" (scheduled at 2026-01-05 22:45:03.740512+07:00)
2026-01-05 22:45:03,742 - INFO -  Running predictions...
2026-01-05 22:45:03,862 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:03,862 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:08 +07)" executed successfully
2026-01-05 22:45:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:13 +07)" (scheduled at 2026-01-05 22:45:08.740512+07:00)
2026-01-05 22:45:08,741 - INFO -  Running predictions...
2026-01-05 22:45:08,848 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:08,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:13 +07)" executed successfully
2026-01-05 22:45:13,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:18 +07)" (scheduled at 2026-01-05 22:45:13.740512+07:00)
2026-01-05 22:45:13,742 - INFO -  Running predictions...
2026-01-05 22:45:13,937 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:13,938 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:18 +07)" executed successfully
2026-01-05 22:45:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:23 +07)" (scheduled at 2026-01-05 22:45:18.740512+07:00)
2026-01-05 22:45:18,742 - INFO -  Running predictions...
2026-01-05 22:45:18,844 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:18,844 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:23 +07)" executed successfully
2026-01-05 22:45:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:28 +07)" (scheduled at 2026-01-05 22:45:23.740512+07:00)
2026-01-05 22:45:23,742 - INFO -  Running predictions...
2026-01-05 22:45:23,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:23,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:28 +07)" executed successfully
2026-01-05 22:45:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:33 +07)" (scheduled at 2026-01-05 22:45:28.740512+07:00)
2026-01-05 22:45:28,742 - INFO -  Running predictions...
2026-01-05 22:45:28,863 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:28,863 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:33 +07)" executed successfully
2026-01-05 22:45:33,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:38 +07)" (scheduled at 2026-01-05 22:45:33.740512+07:00)
2026-01-05 22:45:33,743 - INFO -  Running predictions...
2026-01-05 22:45:33,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:33,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:38 +07)" executed successfully
2026-01-05 22:45:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:43 +07)" (scheduled at 2026-01-05 22:45:38.740512+07:00)
2026-01-05 22:45:38,742 - INFO -  Running predictions...
2026-01-05 22:45:38,877 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:38,877 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:43 +07)" executed successfully
2026-01-05 22:45:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:48 +07)" (scheduled at 2026-01-05 22:45:43.740512+07:00)
2026-01-05 22:45:43,743 - INFO -  Running predictions...
2026-01-05 22:45:43,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:43,840 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:48 +07)" executed successfully
2026-01-05 22:45:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:53 +07)" (scheduled at 2026-01-05 22:45:48.740512+07:00)
2026-01-05 22:45:48,741 - INFO -  Running predictions...
2026-01-05 22:45:48,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:48,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:53 +07)" executed successfully
2026-01-05 22:45:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:58 +07)" (scheduled at 2026-01-05 22:45:53.740512+07:00)
2026-01-05 22:45:53,742 - INFO -  Running predictions...
2026-01-05 22:45:53,849 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:53,849 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:45:58 +07)" executed successfully
2026-01-05 22:45:58,740 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:03 +07)" (scheduled at 2026-01-05 22:45:58.740512+07:00)
2026-01-05 22:45:58,741 - INFO -  Running predictions...
2026-01-05 22:45:58,979 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:45:58,980 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:03 +07)" executed successfully
2026-01-05 22:46:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:08 +07)" (scheduled at 2026-01-05 22:46:03.740512+07:00)
2026-01-05 22:46:03,741 - INFO -  Running predictions...
2026-01-05 22:46:03,921 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:03,921 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:08 +07)" executed successfully
2026-01-05 22:46:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:13 +07)" (scheduled at 2026-01-05 22:46:08.740512+07:00)
2026-01-05 22:46:08,742 - INFO -  Running predictions...
2026-01-05 22:46:08,869 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:08,869 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:13 +07)" executed successfully
2026-01-05 22:46:13,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:18 +07)" (scheduled at 2026-01-05 22:46:13.740512+07:00)
2026-01-05 22:46:13,742 - INFO -  Running predictions...
2026-01-05 22:46:13,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:13,834 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:18 +07)" executed successfully
2026-01-05 22:46:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:23 +07)" (scheduled at 2026-01-05 22:46:18.740512+07:00)
2026-01-05 22:46:18,742 - INFO -  Running predictions...
2026-01-05 22:46:18,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:18,840 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:23 +07)" executed successfully
2026-01-05 22:46:23,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:28 +07)" (scheduled at 2026-01-05 22:46:23.740512+07:00)
2026-01-05 22:46:23,743 - INFO -  Running predictions...
2026-01-05 22:46:23,827 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:23,827 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:28 +07)" executed successfully
2026-01-05 22:46:28,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:33 +07)" (scheduled at 2026-01-05 22:46:28.740512+07:00)
2026-01-05 22:46:28,744 - INFO -  Running predictions...
2026-01-05 22:46:28,831 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:28,831 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:33 +07)" executed successfully
2026-01-05 22:46:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:38 +07)" (scheduled at 2026-01-05 22:46:33.740512+07:00)
2026-01-05 22:46:33,741 - INFO -  Running predictions...
2026-01-05 22:46:33,930 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:33,930 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:38 +07)" executed successfully
2026-01-05 22:46:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:43 +07)" (scheduled at 2026-01-05 22:46:38.740512+07:00)
2026-01-05 22:46:38,742 - INFO -  Running predictions...
2026-01-05 22:46:38,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:38,833 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:43 +07)" executed successfully
2026-01-05 22:46:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:48 +07)" (scheduled at 2026-01-05 22:46:43.740512+07:00)
2026-01-05 22:46:43,742 - INFO -  Running predictions...
2026-01-05 22:46:43,870 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:43,870 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:48 +07)" executed successfully
2026-01-05 22:46:48,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:53 +07)" (scheduled at 2026-01-05 22:46:48.740512+07:00)
2026-01-05 22:46:48,742 - INFO -  Running predictions...
2026-01-05 22:46:48,829 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:48,829 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:53 +07)" executed successfully
2026-01-05 22:46:53,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:58 +07)" (scheduled at 2026-01-05 22:46:53.740512+07:00)
2026-01-05 22:46:53,744 - INFO -  Running predictions...
2026-01-05 22:46:53,835 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:53,836 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:46:58 +07)" executed successfully
2026-01-05 22:46:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:03 +07)" (scheduled at 2026-01-05 22:46:58.740512+07:00)
2026-01-05 22:46:58,742 - INFO -  Running predictions...
2026-01-05 22:46:58,828 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:46:58,828 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:03 +07)" executed successfully
2026-01-05 22:47:03,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:08 +07)" (scheduled at 2026-01-05 22:47:03.740512+07:00)
2026-01-05 22:47:03,742 - INFO -  Running predictions...
2026-01-05 22:47:03,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:03,835 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:08 +07)" executed successfully
2026-01-05 22:47:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:13 +07)" (scheduled at 2026-01-05 22:47:08.740512+07:00)
2026-01-05 22:47:08,743 - INFO -  Running predictions...
2026-01-05 22:47:08,861 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:08,862 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:13 +07)" executed successfully
2026-01-05 22:47:13,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:18 +07)" (scheduled at 2026-01-05 22:47:13.740512+07:00)
2026-01-05 22:47:13,743 - INFO -  Running predictions...
2026-01-05 22:47:13,848 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:13,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:18 +07)" executed successfully
2026-01-05 22:47:18,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:23 +07)" (scheduled at 2026-01-05 22:47:18.740512+07:00)
2026-01-05 22:47:18,744 - INFO -  Running predictions...
2026-01-05 22:47:18,837 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:18,838 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:23 +07)" executed successfully
2026-01-05 22:47:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:28 +07)" (scheduled at 2026-01-05 22:47:23.740512+07:00)
2026-01-05 22:47:23,743 - INFO -  Running predictions...
2026-01-05 22:47:23,825 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:23,825 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:28 +07)" executed successfully
2026-01-05 22:47:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:33 +07)" (scheduled at 2026-01-05 22:47:28.740512+07:00)
2026-01-05 22:47:28,741 - INFO -  Running predictions...
2026-01-05 22:47:28,835 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:28,835 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:33 +07)" executed successfully
2026-01-05 22:47:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:38 +07)" (scheduled at 2026-01-05 22:47:33.740512+07:00)
2026-01-05 22:47:33,741 - INFO -  Running predictions...
2026-01-05 22:47:33,867 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:33,868 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:38 +07)" executed successfully
2026-01-05 22:47:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:43 +07)" (scheduled at 2026-01-05 22:47:38.740512+07:00)
2026-01-05 22:47:38,741 - INFO -  Running predictions...
2026-01-05 22:47:38,897 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:38,897 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:43 +07)" executed successfully
2026-01-05 22:47:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:48 +07)" (scheduled at 2026-01-05 22:47:43.740512+07:00)
2026-01-05 22:47:43,741 - INFO -  Running predictions...
2026-01-05 22:47:43,843 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:43,844 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:48 +07)" executed successfully
2026-01-05 22:47:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:53 +07)" (scheduled at 2026-01-05 22:47:48.740512+07:00)
2026-01-05 22:47:48,741 - INFO -  Running predictions...
2026-01-05 22:47:48,851 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:48,851 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:53 +07)" executed successfully
2026-01-05 22:47:53,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:58 +07)" (scheduled at 2026-01-05 22:47:53.740512+07:00)
2026-01-05 22:47:53,741 - INFO -  Running predictions...
2026-01-05 22:47:53,989 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:53,989 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:47:58 +07)" executed successfully
2026-01-05 22:47:58,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:03 +07)" (scheduled at 2026-01-05 22:47:58.740512+07:00)
2026-01-05 22:47:58,741 - INFO -  Running predictions...
2026-01-05 22:47:58,865 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:47:58,865 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:03 +07)" executed successfully
2026-01-05 22:48:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:08 +07)" (scheduled at 2026-01-05 22:48:03.740512+07:00)
2026-01-05 22:48:03,741 - INFO -  Running predictions...
2026-01-05 22:48:03,830 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:03,830 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:08 +07)" executed successfully
2026-01-05 22:48:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:13 +07)" (scheduled at 2026-01-05 22:48:08.740512+07:00)
2026-01-05 22:48:08,741 - INFO -  Running predictions...
2026-01-05 22:48:08,831 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:08,831 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:13 +07)" executed successfully
2026-01-05 22:48:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:18 +07)" (scheduled at 2026-01-05 22:48:13.740512+07:00)
2026-01-05 22:48:13,741 - INFO -  Running predictions...
2026-01-05 22:48:13,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:13,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:18 +07)" executed successfully
2026-01-05 22:48:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:23 +07)" (scheduled at 2026-01-05 22:48:18.740512+07:00)
2026-01-05 22:48:18,742 - INFO -  Running predictions...
2026-01-05 22:48:18,862 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:18,862 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:23 +07)" executed successfully
2026-01-05 22:48:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:28 +07)" (scheduled at 2026-01-05 22:48:23.740512+07:00)
2026-01-05 22:48:23,741 - INFO -  Running predictions...
2026-01-05 22:48:23,859 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:23,859 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:28 +07)" executed successfully
2026-01-05 22:48:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:33 +07)" (scheduled at 2026-01-05 22:48:28.740512+07:00)
2026-01-05 22:48:28,742 - INFO -  Running predictions...
2026-01-05 22:48:28,832 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:28,832 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:33 +07)" executed successfully
2026-01-05 22:48:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:38 +07)" (scheduled at 2026-01-05 22:48:33.740512+07:00)
2026-01-05 22:48:33,741 - INFO -  Running predictions...
2026-01-05 22:48:33,866 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:33,866 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:38 +07)" executed successfully
2026-01-05 22:48:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:43 +07)" (scheduled at 2026-01-05 22:48:38.740512+07:00)
2026-01-05 22:48:38,741 - INFO -  Running predictions...
2026-01-05 22:48:38,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:38,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:43 +07)" executed successfully
2026-01-05 22:48:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:48 +07)" (scheduled at 2026-01-05 22:48:43.740512+07:00)
2026-01-05 22:48:43,742 - INFO -  Running predictions...
2026-01-05 22:48:43,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:43,841 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:48 +07)" executed successfully
2026-01-05 22:48:48,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:53 +07)" (scheduled at 2026-01-05 22:48:48.740512+07:00)
2026-01-05 22:48:48,741 - INFO -  Running predictions...
2026-01-05 22:48:48,844 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:48,844 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:53 +07)" executed successfully
2026-01-05 22:48:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:58 +07)" (scheduled at 2026-01-05 22:48:53.740512+07:00)
2026-01-05 22:48:53,742 - INFO -  Running predictions...
2026-01-05 22:48:53,864 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:53,864 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:48:58 +07)" executed successfully
2026-01-05 22:48:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:03 +07)" (scheduled at 2026-01-05 22:48:58.740512+07:00)
2026-01-05 22:48:58,743 - INFO -  Running predictions...
2026-01-05 22:48:58,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:48:58,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:03 +07)" executed successfully
2026-01-05 22:49:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:08 +07)" (scheduled at 2026-01-05 22:49:03.740512+07:00)
2026-01-05 22:49:03,742 - INFO -  Running predictions...
2026-01-05 22:49:03,845 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:03,845 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:08 +07)" executed successfully
2026-01-05 22:49:08,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:13 +07)" (scheduled at 2026-01-05 22:49:08.740512+07:00)
2026-01-05 22:49:08,741 - INFO -  Running predictions...
2026-01-05 22:49:08,880 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:08,881 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:13 +07)" executed successfully
2026-01-05 22:49:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:18 +07)" (scheduled at 2026-01-05 22:49:13.740512+07:00)
2026-01-05 22:49:13,741 - INFO -  Running predictions...
2026-01-05 22:49:13,883 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:13,883 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:18 +07)" executed successfully
2026-01-05 22:49:18,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:23 +07)" (scheduled at 2026-01-05 22:49:18.740512+07:00)
2026-01-05 22:49:18,741 - INFO -  Running predictions...
2026-01-05 22:49:18,866 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:18,866 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:23 +07)" executed successfully
2026-01-05 22:49:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:28 +07)" (scheduled at 2026-01-05 22:49:23.740512+07:00)
2026-01-05 22:49:23,741 - INFO -  Running predictions...
2026-01-05 22:49:23,855 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:23,855 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:28 +07)" executed successfully
2026-01-05 22:49:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:33 +07)" (scheduled at 2026-01-05 22:49:28.740512+07:00)
2026-01-05 22:49:28,742 - INFO -  Running predictions...
2026-01-05 22:49:28,874 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:28,874 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:33 +07)" executed successfully
2026-01-05 22:49:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:38 +07)" (scheduled at 2026-01-05 22:49:33.740512+07:00)
2026-01-05 22:49:33,741 - INFO -  Running predictions...
2026-01-05 22:49:33,863 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:33,863 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:38 +07)" executed successfully
2026-01-05 22:49:38,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:43 +07)" (scheduled at 2026-01-05 22:49:38.740512+07:00)
2026-01-05 22:49:38,741 - INFO -  Running predictions...
2026-01-05 22:49:38,902 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:38,903 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:43 +07)" executed successfully
2026-01-05 22:49:43,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:48 +07)" (scheduled at 2026-01-05 22:49:43.740512+07:00)
2026-01-05 22:49:43,741 - INFO -  Running predictions...
2026-01-05 22:49:43,844 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:43,844 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:48 +07)" executed successfully
2026-01-05 22:49:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:53 +07)" (scheduled at 2026-01-05 22:49:48.740512+07:00)
2026-01-05 22:49:48,743 - INFO -  Running predictions...
2026-01-05 22:49:48,824 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:48,825 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:53 +07)" executed successfully
2026-01-05 22:49:53,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:58 +07)" (scheduled at 2026-01-05 22:49:53.740512+07:00)
2026-01-05 22:49:53,742 - INFO -  Running predictions...
2026-01-05 22:49:53,837 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:53,837 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:49:58 +07)" executed successfully
2026-01-05 22:49:58,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:03 +07)" (scheduled at 2026-01-05 22:49:58.740512+07:00)
2026-01-05 22:49:58,744 - INFO -  Running predictions...
2026-01-05 22:49:58,831 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:49:58,831 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:03 +07)" executed successfully
2026-01-05 22:50:03,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:08 +07)" (scheduled at 2026-01-05 22:50:03.740512+07:00)
2026-01-05 22:50:03,743 - INFO -  Running predictions...
2026-01-05 22:50:03,838 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:03,838 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:08 +07)" executed successfully
2026-01-05 22:50:08,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:13 +07)" (scheduled at 2026-01-05 22:50:08.740512+07:00)
2026-01-05 22:50:08,744 - INFO -  Running predictions...
2026-01-05 22:50:08,846 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:08,846 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:13 +07)" executed successfully
2026-01-05 22:50:13,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:18 +07)" (scheduled at 2026-01-05 22:50:13.740512+07:00)
2026-01-05 22:50:13,743 - INFO -  Running predictions...
2026-01-05 22:50:13,859 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:13,859 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:18 +07)" executed successfully
2026-01-05 22:50:18,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:23 +07)" (scheduled at 2026-01-05 22:50:18.740512+07:00)
2026-01-05 22:50:18,744 - INFO -  Running predictions...
2026-01-05 22:50:18,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:18,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:23 +07)" executed successfully
2026-01-05 22:50:23,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:28 +07)" (scheduled at 2026-01-05 22:50:23.740512+07:00)
2026-01-05 22:50:23,742 - INFO -  Running predictions...
2026-01-05 22:50:23,820 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:23,821 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:28 +07)" executed successfully
2026-01-05 22:50:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:33 +07)" (scheduled at 2026-01-05 22:50:28.740512+07:00)
2026-01-05 22:50:28,743 - INFO -  Running predictions...
2026-01-05 22:50:28,887 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:28,887 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:33 +07)" executed successfully
2026-01-05 22:50:33,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:38 +07)" (scheduled at 2026-01-05 22:50:33.740512+07:00)
2026-01-05 22:50:33,743 - INFO -  Running predictions...
2026-01-05 22:50:33,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:33,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:38 +07)" executed successfully
2026-01-05 22:50:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:43 +07)" (scheduled at 2026-01-05 22:50:38.740512+07:00)
2026-01-05 22:50:38,742 - INFO -  Running predictions...
2026-01-05 22:50:38,838 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:38,838 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:43 +07)" executed successfully
2026-01-05 22:50:43,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:48 +07)" (scheduled at 2026-01-05 22:50:43.740512+07:00)
2026-01-05 22:50:43,742 - INFO -  Running predictions...
2026-01-05 22:50:43,833 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:43,833 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:48 +07)" executed successfully
2026-01-05 22:50:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:53 +07)" (scheduled at 2026-01-05 22:50:48.740512+07:00)
2026-01-05 22:50:48,743 - INFO -  Running predictions...
2026-01-05 22:50:48,827 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:48,827 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:53 +07)" executed successfully
2026-01-05 22:50:53,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:58 +07)" (scheduled at 2026-01-05 22:50:53.740512+07:00)
2026-01-05 22:50:53,744 - INFO -  Running predictions...
2026-01-05 22:50:53,844 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:53,844 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:50:58 +07)" executed successfully
2026-01-05 22:50:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:03 +07)" (scheduled at 2026-01-05 22:50:58.740512+07:00)
2026-01-05 22:50:58,743 - INFO -  Running predictions...
2026-01-05 22:50:58,863 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:50:58,863 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:03 +07)" executed successfully
2026-01-05 22:51:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:08 +07)" (scheduled at 2026-01-05 22:51:03.740512+07:00)
2026-01-05 22:51:03,742 - INFO -  Running predictions...
2026-01-05 22:51:03,838 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:03,839 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:08 +07)" executed successfully
2026-01-05 22:51:08,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:13 +07)" (scheduled at 2026-01-05 22:51:08.740512+07:00)
2026-01-05 22:51:08,742 - INFO -  Running predictions...
2026-01-05 22:51:08,836 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:08,837 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:13 +07)" executed successfully
2026-01-05 22:51:13,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:18 +07)" (scheduled at 2026-01-05 22:51:13.740512+07:00)
2026-01-05 22:51:13,741 - INFO -  Running predictions...
2026-01-05 22:51:13,835 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:13,836 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:18 +07)" executed successfully
2026-01-05 22:51:18,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:23 +07)" (scheduled at 2026-01-05 22:51:18.740512+07:00)
2026-01-05 22:51:18,743 - INFO -  Running predictions...
2026-01-05 22:51:18,842 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:18,842 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:23 +07)" executed successfully
2026-01-05 22:51:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:28 +07)" (scheduled at 2026-01-05 22:51:23.740512+07:00)
2026-01-05 22:51:23,744 - INFO -  Running predictions...
2026-01-05 22:51:23,831 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:23,831 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:28 +07)" executed successfully
2026-01-05 22:51:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:33 +07)" (scheduled at 2026-01-05 22:51:28.740512+07:00)
2026-01-05 22:51:28,743 - INFO -  Running predictions...
2026-01-05 22:51:28,834 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:28,834 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:33 +07)" executed successfully
2026-01-05 22:51:33,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:38 +07)" (scheduled at 2026-01-05 22:51:33.740512+07:00)
2026-01-05 22:51:33,742 - INFO -  Running predictions...
2026-01-05 22:51:33,852 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:33,852 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:38 +07)" executed successfully
2026-01-05 22:51:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:43 +07)" (scheduled at 2026-01-05 22:51:38.740512+07:00)
2026-01-05 22:51:38,742 - INFO -  Running predictions...
2026-01-05 22:51:38,836 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:38,836 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:43 +07)" executed successfully
2026-01-05 22:51:43,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:48 +07)" (scheduled at 2026-01-05 22:51:43.740512+07:00)
2026-01-05 22:51:43,743 - INFO -  Running predictions...
2026-01-05 22:51:43,853 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:43,853 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:48 +07)" executed successfully
2026-01-05 22:51:48,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:53 +07)" (scheduled at 2026-01-05 22:51:48.740512+07:00)
2026-01-05 22:51:48,742 - INFO -  Running predictions...
2026-01-05 22:51:48,848 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:48,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:53 +07)" executed successfully
2026-01-05 22:51:53,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:58 +07)" (scheduled at 2026-01-05 22:51:53.740512+07:00)
2026-01-05 22:51:53,743 - INFO -  Running predictions...
2026-01-05 22:51:53,840 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:53,840 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:51:58 +07)" executed successfully
2026-01-05 22:51:58,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:03 +07)" (scheduled at 2026-01-05 22:51:58.740512+07:00)
2026-01-05 22:51:58,742 - INFO -  Running predictions...
2026-01-05 22:51:58,826 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:51:58,826 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:03 +07)" executed successfully
2026-01-05 22:52:03,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:08 +07)" (scheduled at 2026-01-05 22:52:03.740512+07:00)
2026-01-05 22:52:03,741 - INFO -  Running predictions...
2026-01-05 22:52:03,877 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:03,877 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:08 +07)" executed successfully
2026-01-05 22:52:08,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:13 +07)" (scheduled at 2026-01-05 22:52:08.740512+07:00)
2026-01-05 22:52:08,743 - INFO -  Running predictions...
2026-01-05 22:52:08,848 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:08,848 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:13 +07)" executed successfully
2026-01-05 22:52:13,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:18 +07)" (scheduled at 2026-01-05 22:52:13.740512+07:00)
2026-01-05 22:52:13,743 - INFO -  Running predictions...
2026-01-05 22:52:13,835 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:13,835 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:18 +07)" executed successfully
2026-01-05 22:52:18,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:23 +07)" (scheduled at 2026-01-05 22:52:18.740512+07:00)
2026-01-05 22:52:18,742 - INFO -  Running predictions...
2026-01-05 22:52:18,830 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:18,830 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:23 +07)" executed successfully
2026-01-05 22:52:23,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:28 +07)" (scheduled at 2026-01-05 22:52:23.740512+07:00)
2026-01-05 22:52:23,743 - INFO -  Running predictions...
2026-01-05 22:52:23,871 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:23,872 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:28 +07)" executed successfully
2026-01-05 22:52:28,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:33 +07)" (scheduled at 2026-01-05 22:52:28.740512+07:00)
2026-01-05 22:52:28,742 - INFO -  Running predictions...
2026-01-05 22:52:28,861 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:28,861 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:33 +07)" executed successfully
2026-01-05 22:52:33,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:38 +07)" (scheduled at 2026-01-05 22:52:33.740512+07:00)
2026-01-05 22:52:33,742 - INFO -  Running predictions...
2026-01-05 22:52:33,862 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 22:52:33,862 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:38 +07)" executed successfully
2026-01-05 22:52:38,742 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:43 +07)" (scheduled at 2026-01-05 22:52:38.740512+07:00)
2026-01-05 22:52:38,742 - INFO -  Running predictions...
2026-01-05 22:52:43,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:43 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:52:48,742 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:48 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:52:53,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:53 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:52:58,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:52:58 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:03,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:03 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:08,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:08 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:08,767 - ERROR - Error reading data: An error occurred while calling o30465.load.
: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=localhost:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.ConnectException: K·∫øt n·ªëi b·ªã t·ª´ ch·ªëi (Connection refused)}}]
	at com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:177)
	at com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)
	at com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:147)
	at com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:98)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:278)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:182)
	at com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:194)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:163)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:158)
	at com.mongodb.spark.MongoConnector.$anonfun$hasSampleAggregateOperator$1(MongoConnector.scala:234)
	at com.mongodb.spark.MongoConnector.$anonfun$withDatabaseDo$1(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:154)
	at com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:234)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)
	at com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at jdk.internal.reflect.GeneratedMethodAccessor71.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-05 22:53:08,772 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-05 22:53:08,772 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:13 +07)" executed successfully
2026-01-05 22:53:13,746 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:18 +07)" (scheduled at 2026-01-05 22:53:13.740512+07:00)
2026-01-05 22:53:13,746 - INFO -  Running predictions...
2026-01-05 22:53:18,743 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:18 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:23,741 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:23 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:28,742 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:28 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:33,742 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:33 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:34,996 - INFO - Stopping Spark Session...
2026-01-05 22:53:42,357 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 22:53:38 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 22:53:42,365 - INFO - Closing down clientserver connection
2026-01-05 23:25:44,609 - INFO -  Initializing PySpark Session...
2026-01-05 23:25:48,598 - INFO - ‚úì Spark Session Created!
2026-01-05 23:25:48,600 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-05 23:25:48,623 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-05 23:25:48,624 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-05 23:25:48,624 - INFO - Scheduler started
2026-01-05 23:25:53,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:25:53 +07)" (scheduled at 2026-01-05 23:25:53.622837+07:00)
2026-01-05 23:25:53,623 - INFO -  Training Spark model...
2026-01-05 23:25:58,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:25:58 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:25:58,672 - INFO - ‚úì Model trained successfully!
2026-01-05 23:25:58,672 - INFO -  Running predictions...
2026-01-05 23:25:59,003 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:25:59,003 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:03 +07)" executed successfully
2026-01-05 23:26:03,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:08 +07)" (scheduled at 2026-01-05 23:26:03.622837+07:00)
2026-01-05 23:26:03,625 - INFO -  Running predictions...
2026-01-05 23:26:03,837 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:03,838 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:08 +07)" executed successfully
2026-01-05 23:26:08,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:13 +07)" (scheduled at 2026-01-05 23:26:08.622837+07:00)
2026-01-05 23:26:08,624 - INFO -  Running predictions...
2026-01-05 23:26:08,904 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:08,905 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:13 +07)" executed successfully
2026-01-05 23:26:13,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:18 +07)" (scheduled at 2026-01-05 23:26:13.622837+07:00)
2026-01-05 23:26:13,624 - INFO -  Running predictions...
2026-01-05 23:26:13,817 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:13,817 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:18 +07)" executed successfully
2026-01-05 23:26:18,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:23 +07)" (scheduled at 2026-01-05 23:26:18.622837+07:00)
2026-01-05 23:26:18,624 - INFO -  Running predictions...
2026-01-05 23:26:18,791 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:18,791 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:23 +07)" executed successfully
2026-01-05 23:26:23,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:28 +07)" (scheduled at 2026-01-05 23:26:23.622837+07:00)
2026-01-05 23:26:23,623 - INFO -  Running predictions...
2026-01-05 23:26:23,819 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:23,819 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:28 +07)" executed successfully
2026-01-05 23:26:28,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:33 +07)" (scheduled at 2026-01-05 23:26:28.622837+07:00)
2026-01-05 23:26:28,624 - INFO -  Running predictions...
2026-01-05 23:26:28,785 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:28,785 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:33 +07)" executed successfully
2026-01-05 23:26:33,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:38 +07)" (scheduled at 2026-01-05 23:26:33.622837+07:00)
2026-01-05 23:26:33,624 - INFO -  Running predictions...
2026-01-05 23:26:33,820 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:33,820 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:38 +07)" executed successfully
2026-01-05 23:26:38,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:43 +07)" (scheduled at 2026-01-05 23:26:38.622837+07:00)
2026-01-05 23:26:38,624 - INFO -  Running predictions...
2026-01-05 23:26:38,772 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:38,772 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:43 +07)" executed successfully
2026-01-05 23:26:43,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:48 +07)" (scheduled at 2026-01-05 23:26:43.622837+07:00)
2026-01-05 23:26:43,624 - INFO -  Running predictions...
2026-01-05 23:26:43,780 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:43,780 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:48 +07)" executed successfully
2026-01-05 23:26:48,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:53 +07)" (scheduled at 2026-01-05 23:26:48.622837+07:00)
2026-01-05 23:26:48,623 - INFO -  Running predictions...
2026-01-05 23:26:48,857 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:48,857 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:53 +07)" executed successfully
2026-01-05 23:26:53,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:58 +07)" (scheduled at 2026-01-05 23:26:53.622837+07:00)
2026-01-05 23:26:53,623 - INFO -  Running predictions...
2026-01-05 23:26:53,846 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:53,846 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:26:58 +07)" executed successfully
2026-01-05 23:26:58,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:03 +07)" (scheduled at 2026-01-05 23:26:58.622837+07:00)
2026-01-05 23:26:58,623 - INFO -  Running predictions...
2026-01-05 23:26:58,851 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:26:58,851 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:03 +07)" executed successfully
2026-01-05 23:27:03,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:08 +07)" (scheduled at 2026-01-05 23:27:03.622837+07:00)
2026-01-05 23:27:03,624 - INFO -  Running predictions...
2026-01-05 23:27:03,888 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:03,888 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:08 +07)" executed successfully
2026-01-05 23:27:08,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:13 +07)" (scheduled at 2026-01-05 23:27:08.622837+07:00)
2026-01-05 23:27:08,626 - INFO -  Running predictions...
2026-01-05 23:27:08,905 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:08,905 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:13 +07)" executed successfully
2026-01-05 23:27:13,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:18 +07)" (scheduled at 2026-01-05 23:27:13.622837+07:00)
2026-01-05 23:27:13,625 - INFO -  Running predictions...
2026-01-05 23:27:13,831 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:13,831 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:18 +07)" executed successfully
2026-01-05 23:27:18,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:23 +07)" (scheduled at 2026-01-05 23:27:18.622837+07:00)
2026-01-05 23:27:18,625 - INFO -  Running predictions...
2026-01-05 23:27:18,804 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:18,804 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:23 +07)" executed successfully
2026-01-05 23:27:23,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:28 +07)" (scheduled at 2026-01-05 23:27:23.622837+07:00)
2026-01-05 23:27:23,624 - INFO -  Running predictions...
2026-01-05 23:27:23,901 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:23,901 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:28 +07)" executed successfully
2026-01-05 23:27:28,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:33 +07)" (scheduled at 2026-01-05 23:27:28.622837+07:00)
2026-01-05 23:27:28,623 - INFO -  Running predictions...
2026-01-05 23:27:28,821 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:28,821 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:33 +07)" executed successfully
2026-01-05 23:27:33,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:38 +07)" (scheduled at 2026-01-05 23:27:33.622837+07:00)
2026-01-05 23:27:33,624 - INFO -  Running predictions...
2026-01-05 23:27:33,837 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:27:33,837 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:38 +07)" executed successfully
2026-01-05 23:27:38,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:43 +07)" (scheduled at 2026-01-05 23:27:38.622837+07:00)
2026-01-05 23:27:38,624 - INFO -  Running predictions...
2026-01-05 23:27:43,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:43 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:27:48,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:48 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:27:53,625 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:53 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:27:58,625 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:27:58 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:03,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:03 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:08,625 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:08 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:08,651 - ERROR - Error reading data: An error occurred while calling o2619.load.
: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=localhost:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.ConnectException: K·∫øt n·ªëi b·ªã t·ª´ ch·ªëi (Connection refused)}}]
	at com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:177)
	at com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)
	at com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:147)
	at com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:98)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:278)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:182)
	at com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:194)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:163)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:158)
	at com.mongodb.spark.MongoConnector.$anonfun$hasSampleAggregateOperator$1(MongoConnector.scala:234)
	at com.mongodb.spark.MongoConnector.$anonfun$withDatabaseDo$1(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:154)
	at com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:234)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)
	at com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at jdk.internal.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-05 23:28:08,666 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-05 23:28:08,667 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:13 +07)" executed successfully
2026-01-05 23:28:13,624 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:18 +07)" (scheduled at 2026-01-05 23:28:13.622837+07:00)
2026-01-05 23:28:13,624 - INFO -  Running predictions...
2026-01-05 23:28:18,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:18 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:23,623 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:23 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:28,626 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:28 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:33,623 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:33 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:38,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:38 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:43,623 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:43 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:43,640 - ERROR - Error reading data: An error occurred while calling o2631.load.
: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=localhost:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.ConnectException: K·∫øt n·ªëi b·ªã t·ª´ ch·ªëi (Connection refused)}}]
	at com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:177)
	at com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)
	at com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:147)
	at com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:98)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:278)
	at com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:182)
	at com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:194)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:163)
	at com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:158)
	at com.mongodb.spark.MongoConnector.$anonfun$hasSampleAggregateOperator$1(MongoConnector.scala:234)
	at com.mongodb.spark.MongoConnector.$anonfun$withDatabaseDo$1(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:154)
	at com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:171)
	at com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:234)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)
	at com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)
	at com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at jdk.internal.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-05 23:28:43,648 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-05 23:28:43,648 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:48 +07)" executed successfully
2026-01-05 23:28:48,625 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:53 +07)" (scheduled at 2026-01-05 23:28:48.622837+07:00)
2026-01-05 23:28:48,626 - INFO -  Running predictions...
2026-01-05 23:28:53,624 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:53 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:28:54,341 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:28:54,341 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:28:58 +07)" executed successfully
2026-01-05 23:28:58,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:03 +07)" (scheduled at 2026-01-05 23:28:58.622837+07:00)
2026-01-05 23:28:58,624 - INFO -  Running predictions...
2026-01-05 23:28:58,829 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:28:58,829 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:03 +07)" executed successfully
2026-01-05 23:29:03,623 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:08 +07)" (scheduled at 2026-01-05 23:29:03.622837+07:00)
2026-01-05 23:29:03,623 - INFO -  Running predictions...
2026-01-05 23:29:03,868 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:29:03,868 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:08 +07)" executed successfully
2026-01-05 23:29:06,780 - INFO - Stopping Spark Session...
2026-01-05 23:29:07,046 - INFO - Closing down clientserver connection
2026-01-05 23:29:07,047 - INFO - Scheduler has been shut down
2026-01-05 23:29:07,048 - INFO - Closing down clientserver connection
2026-01-05 23:29:08,241 - INFO -  Initializing PySpark Session...
2026-01-05 23:29:11,078 - INFO - ‚úì Spark Session Created!
2026-01-05 23:29:11,078 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-05 23:29:11,099 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-05 23:29:11,100 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-05 23:29:11,100 - INFO - Scheduler started
2026-01-05 23:29:16,100 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:16 +07)" (scheduled at 2026-01-05 23:29:16.099410+07:00)
2026-01-05 23:29:16,100 - INFO -  Training Spark model...
2026-01-05 23:29:21,102 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:21 +07)" skipped: maximum number of running instances reached (1)
2026-01-05 23:29:21,175 - INFO - ‚úì Model trained successfully!
2026-01-05 23:29:21,175 - INFO -  Running predictions...
2026-01-05 23:29:21,428 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:29:21,428 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:26 +07)" executed successfully
2026-01-05 23:29:26,101 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:31 +07)" (scheduled at 2026-01-05 23:29:26.099410+07:00)
2026-01-05 23:29:26,101 - INFO -  Running predictions...
2026-01-05 23:29:26,297 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:29:26,297 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:31 +07)" executed successfully
2026-01-05 23:29:31,101 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:36 +07)" (scheduled at 2026-01-05 23:29:31.099410+07:00)
2026-01-05 23:29:31,101 - INFO -  Running predictions...
2026-01-05 23:29:31,232 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:29:31,232 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:36 +07)" executed successfully
2026-01-05 23:29:36,112 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:41 +07)" (scheduled at 2026-01-05 23:29:36.099410+07:00)
2026-01-05 23:29:36,113 - INFO -  Running predictions...
2026-01-05 23:29:36,316 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:29:36,316 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:29:41 +07)" executed successfully
2026-01-05 23:29:39,780 - INFO - Stopping Spark Session...
2026-01-05 23:29:40,106 - INFO - Closing down clientserver connection
2026-01-05 23:29:40,107 - INFO - Scheduler has been shut down
2026-01-05 23:29:40,108 - INFO - Closing down clientserver connection
2026-01-05 23:43:06,108 - INFO -  Initializing PySpark Session...
2026-01-05 23:43:08,962 - INFO - ‚úì Spark Session Created!
2026-01-05 23:43:08,962 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-05 23:43:08,989 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-05 23:43:08,990 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-05 23:43:08,990 - INFO - Scheduler started
2026-01-05 23:43:13,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:13 +07)" (scheduled at 2026-01-05 23:43:13.989094+07:00)
2026-01-05 23:43:13,991 - INFO -  Training Spark model...
2026-01-05 23:43:18,252 - INFO - ‚úì Model trained successfully!
2026-01-05 23:43:18,252 - INFO -  Running predictions...
2026-01-05 23:43:18,602 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:18,602 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:18 +07)" executed successfully
2026-01-05 23:43:18,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:23 +07)" (scheduled at 2026-01-05 23:43:18.989094+07:00)
2026-01-05 23:43:18,992 - INFO -  Running predictions...
2026-01-05 23:43:19,193 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:19,195 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:23 +07)" executed successfully
2026-01-05 23:43:23,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:28 +07)" (scheduled at 2026-01-05 23:43:23.989094+07:00)
2026-01-05 23:43:23,990 - INFO -  Running predictions...
2026-01-05 23:43:24,180 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:24,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:28 +07)" executed successfully
2026-01-05 23:43:28,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:33 +07)" (scheduled at 2026-01-05 23:43:28.989094+07:00)
2026-01-05 23:43:28,990 - INFO -  Running predictions...
2026-01-05 23:43:29,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:29,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:33 +07)" executed successfully
2026-01-05 23:43:33,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:38 +07)" (scheduled at 2026-01-05 23:43:33.989094+07:00)
2026-01-05 23:43:33,992 - INFO -  Running predictions...
2026-01-05 23:43:34,297 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:34,297 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:38 +07)" executed successfully
2026-01-05 23:43:38,992 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:43 +07)" (scheduled at 2026-01-05 23:43:38.989094+07:00)
2026-01-05 23:43:38,992 - INFO -  Running predictions...
2026-01-05 23:43:39,157 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:39,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:43 +07)" executed successfully
2026-01-05 23:43:43,991 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:48 +07)" (scheduled at 2026-01-05 23:43:43.989094+07:00)
2026-01-05 23:43:43,991 - INFO -  Running predictions...
2026-01-05 23:43:44,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:44,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:48 +07)" executed successfully
2026-01-05 23:43:48,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:53 +07)" (scheduled at 2026-01-05 23:43:48.989094+07:00)
2026-01-05 23:43:48,991 - INFO -  Running predictions...
2026-01-05 23:43:49,150 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:49,150 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:53 +07)" executed successfully
2026-01-05 23:43:53,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:58 +07)" (scheduled at 2026-01-05 23:43:53.989094+07:00)
2026-01-05 23:43:53,990 - INFO -  Running predictions...
2026-01-05 23:43:54,101 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:54,102 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:43:58 +07)" executed successfully
2026-01-05 23:43:58,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:03 +07)" (scheduled at 2026-01-05 23:43:58.989094+07:00)
2026-01-05 23:43:58,990 - INFO -  Running predictions...
2026-01-05 23:43:59,148 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:43:59,149 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:03 +07)" executed successfully
2026-01-05 23:44:03,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:08 +07)" (scheduled at 2026-01-05 23:44:03.989094+07:00)
2026-01-05 23:44:03,991 - INFO -  Running predictions...
2026-01-05 23:44:04,162 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:04,163 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:08 +07)" executed successfully
2026-01-05 23:44:08,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:13 +07)" (scheduled at 2026-01-05 23:44:08.989094+07:00)
2026-01-05 23:44:08,990 - INFO -  Running predictions...
2026-01-05 23:44:09,130 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:09,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:13 +07)" executed successfully
2026-01-05 23:44:13,991 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:18 +07)" (scheduled at 2026-01-05 23:44:13.989094+07:00)
2026-01-05 23:44:13,991 - INFO -  Running predictions...
2026-01-05 23:44:14,174 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:14,174 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:18 +07)" executed successfully
2026-01-05 23:44:18,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:23 +07)" (scheduled at 2026-01-05 23:44:18.989094+07:00)
2026-01-05 23:44:18,990 - INFO -  Running predictions...
2026-01-05 23:44:19,128 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:19,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:23 +07)" executed successfully
2026-01-05 23:44:23,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:28 +07)" (scheduled at 2026-01-05 23:44:23.989094+07:00)
2026-01-05 23:44:23,990 - INFO -  Running predictions...
2026-01-05 23:44:24,180 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:24,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:28 +07)" executed successfully
2026-01-05 23:44:28,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:33 +07)" (scheduled at 2026-01-05 23:44:28.989094+07:00)
2026-01-05 23:44:28,990 - INFO -  Running predictions...
2026-01-05 23:44:29,161 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:29,161 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:33 +07)" executed successfully
2026-01-05 23:44:33,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:38 +07)" (scheduled at 2026-01-05 23:44:33.989094+07:00)
2026-01-05 23:44:33,991 - INFO -  Running predictions...
2026-01-05 23:44:34,115 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:34,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:38 +07)" executed successfully
2026-01-05 23:44:38,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:43 +07)" (scheduled at 2026-01-05 23:44:38.989094+07:00)
2026-01-05 23:44:38,990 - INFO -  Running predictions...
2026-01-05 23:44:39,160 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:39,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:43 +07)" executed successfully
2026-01-05 23:44:43,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:48 +07)" (scheduled at 2026-01-05 23:44:43.989094+07:00)
2026-01-05 23:44:43,991 - INFO -  Running predictions...
2026-01-05 23:44:44,117 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:44,117 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:48 +07)" executed successfully
2026-01-05 23:44:48,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:53 +07)" (scheduled at 2026-01-05 23:44:48.989094+07:00)
2026-01-05 23:44:48,990 - INFO -  Running predictions...
2026-01-05 23:44:49,207 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:49,207 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:53 +07)" executed successfully
2026-01-05 23:44:53,990 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:58 +07)" (scheduled at 2026-01-05 23:44:53.989094+07:00)
2026-01-05 23:44:53,990 - INFO -  Running predictions...
2026-01-05 23:44:54,138 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:44:54,139 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:44:58 +07)" executed successfully
2026-01-05 23:44:58,989 - INFO - Stopping Spark Session...
2026-01-05 23:44:58,989 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:45:03 +07)" (scheduled at 2026-01-05 23:44:58.989094+07:00)
2026-01-05 23:44:58,989 - INFO -  Running predictions...
2026-01-05 23:44:58,994 - ERROR - Error reading data: An error occurred while calling o2743.load.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
	at com.mongodb.spark.MongoSpark.rdd(MongoSpark.scala:530)
	at com.mongodb.spark.MongoSpark.toRDD(MongoSpark.scala:542)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:93)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at jdk.internal.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-05 23:44:59,000 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-05 23:44:59,000 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:45:03 +07)" executed successfully
2026-01-05 23:44:59,149 - INFO - Closing down clientserver connection
2026-01-05 23:44:59,151 - INFO - Scheduler has been shut down
2026-01-05 23:44:59,152 - INFO - Closing down clientserver connection
2026-01-05 23:50:07,792 - INFO -  Initializing PySpark Session...
2026-01-05 23:50:10,698 - INFO - ‚úì Spark Session Created!
2026-01-05 23:50:10,699 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-05 23:50:10,724 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-05 23:50:10,725 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-05 23:50:10,725 - INFO - Scheduler started
2026-01-05 23:50:15,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:15 +07)" (scheduled at 2026-01-05 23:50:15.724762+07:00)
2026-01-05 23:50:15,725 - INFO -  Training Spark model...
2026-01-05 23:50:20,253 - INFO - ‚úì Model trained successfully!
2026-01-05 23:50:20,254 - INFO -  Running predictions...
2026-01-05 23:50:20,592 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:50:20,592 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:20 +07)" executed successfully
2026-01-05 23:50:20,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:25 +07)" (scheduled at 2026-01-05 23:50:20.724762+07:00)
2026-01-05 23:50:20,726 - INFO -  Running predictions...
2026-01-05 23:50:21,003 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:50:21,003 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:25 +07)" executed successfully
2026-01-05 23:50:25,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:30 +07)" (scheduled at 2026-01-05 23:50:25.724762+07:00)
2026-01-05 23:50:25,725 - INFO -  Running predictions...
2026-01-05 23:50:25,983 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-05 23:50:25,983 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-05 23:50:30 +07)" executed successfully
2026-01-05 23:50:29,578 - INFO - Stopping Spark Session...
2026-01-05 23:50:29,729 - INFO - Closing down clientserver connection
2026-01-05 23:50:29,729 - INFO - Scheduler has been shut down
2026-01-05 23:50:29,729 - INFO - Closing down clientserver connection
2026-01-06 00:02:10,257 - INFO -  Initializing PySpark Session...
2026-01-06 00:02:13,098 - INFO - ‚úì Spark Session Created!
2026-01-06 00:02:13,098 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-06 00:02:13,120 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 00:02:13,121 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 00:02:13,121 - INFO - Scheduler started
2026-01-06 00:02:18,120 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:18 +07)" (scheduled at 2026-01-06 00:02:18.120066+07:00)
2026-01-06 00:02:18,121 - INFO -  Training Spark model...
2026-01-06 00:02:22,491 - INFO - ‚úì Model trained successfully!
2026-01-06 00:02:22,492 - INFO -  Running predictions...
2026-01-06 00:02:22,777 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:22,777 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:23 +07)" executed successfully
2026-01-06 00:02:23,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:28 +07)" (scheduled at 2026-01-06 00:02:23.120066+07:00)
2026-01-06 00:02:23,122 - INFO -  Running predictions...
2026-01-06 00:02:23,355 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:23,357 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:28 +07)" executed successfully
2026-01-06 00:02:28,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:33 +07)" (scheduled at 2026-01-06 00:02:28.120066+07:00)
2026-01-06 00:02:28,122 - INFO -  Running predictions...
2026-01-06 00:02:28,352 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:28,353 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:33 +07)" executed successfully
2026-01-06 00:02:33,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:38 +07)" (scheduled at 2026-01-06 00:02:33.120066+07:00)
2026-01-06 00:02:33,121 - INFO -  Running predictions...
2026-01-06 00:02:33,301 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:33,301 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:38 +07)" executed successfully
2026-01-06 00:02:38,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:43 +07)" (scheduled at 2026-01-06 00:02:38.120066+07:00)
2026-01-06 00:02:38,122 - INFO -  Running predictions...
2026-01-06 00:02:38,383 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:38,383 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:43 +07)" executed successfully
2026-01-06 00:02:43,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:48 +07)" (scheduled at 2026-01-06 00:02:43.120066+07:00)
2026-01-06 00:02:43,121 - INFO -  Running predictions...
2026-01-06 00:02:43,306 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:43,306 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:48 +07)" executed successfully
2026-01-06 00:02:48,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:53 +07)" (scheduled at 2026-01-06 00:02:48.120066+07:00)
2026-01-06 00:02:48,123 - INFO -  Running predictions...
2026-01-06 00:02:48,314 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:48,314 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:53 +07)" executed successfully
2026-01-06 00:02:53,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:58 +07)" (scheduled at 2026-01-06 00:02:53.120066+07:00)
2026-01-06 00:02:53,121 - INFO -  Running predictions...
2026-01-06 00:02:53,239 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:53,239 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:02:58 +07)" executed successfully
2026-01-06 00:02:58,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:03 +07)" (scheduled at 2026-01-06 00:02:58.120066+07:00)
2026-01-06 00:02:58,122 - INFO -  Running predictions...
2026-01-06 00:02:58,292 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:02:58,292 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:03 +07)" executed successfully
2026-01-06 00:03:03,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:08 +07)" (scheduled at 2026-01-06 00:03:03.120066+07:00)
2026-01-06 00:03:03,122 - INFO -  Running predictions...
2026-01-06 00:03:03,278 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:03,278 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:08 +07)" executed successfully
2026-01-06 00:03:08,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:13 +07)" (scheduled at 2026-01-06 00:03:08.120066+07:00)
2026-01-06 00:03:08,121 - INFO -  Running predictions...
2026-01-06 00:03:08,327 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:08,327 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:13 +07)" executed successfully
2026-01-06 00:03:13,120 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:18 +07)" (scheduled at 2026-01-06 00:03:13.120066+07:00)
2026-01-06 00:03:13,123 - INFO -  Running predictions...
2026-01-06 00:03:13,302 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:13,302 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:18 +07)" executed successfully
2026-01-06 00:03:18,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:23 +07)" (scheduled at 2026-01-06 00:03:18.120066+07:00)
2026-01-06 00:03:18,121 - INFO -  Running predictions...
2026-01-06 00:03:18,277 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:18,277 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:23 +07)" executed successfully
2026-01-06 00:03:23,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:28 +07)" (scheduled at 2026-01-06 00:03:23.120066+07:00)
2026-01-06 00:03:23,121 - INFO -  Running predictions...
2026-01-06 00:03:23,329 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:23,330 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:28 +07)" executed successfully
2026-01-06 00:03:28,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:33 +07)" (scheduled at 2026-01-06 00:03:28.120066+07:00)
2026-01-06 00:03:28,122 - INFO -  Running predictions...
2026-01-06 00:03:28,288 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:28,289 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:33 +07)" executed successfully
2026-01-06 00:03:33,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:38 +07)" (scheduled at 2026-01-06 00:03:33.120066+07:00)
2026-01-06 00:03:33,123 - INFO -  Running predictions...
2026-01-06 00:03:33,313 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:33,313 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:38 +07)" executed successfully
2026-01-06 00:03:38,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:43 +07)" (scheduled at 2026-01-06 00:03:38.120066+07:00)
2026-01-06 00:03:38,123 - INFO -  Running predictions...
2026-01-06 00:03:38,305 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:38,307 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:43 +07)" executed successfully
2026-01-06 00:03:43,120 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:48 +07)" (scheduled at 2026-01-06 00:03:43.120066+07:00)
2026-01-06 00:03:43,121 - INFO -  Running predictions...
2026-01-06 00:03:43,303 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:43,304 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:48 +07)" executed successfully
2026-01-06 00:03:48,122 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:53 +07)" (scheduled at 2026-01-06 00:03:48.120066+07:00)
2026-01-06 00:03:48,123 - INFO -  Running predictions...
2026-01-06 00:03:48,328 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:48,328 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:53 +07)" executed successfully
2026-01-06 00:03:53,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:58 +07)" (scheduled at 2026-01-06 00:03:53.120066+07:00)
2026-01-06 00:03:53,121 - INFO -  Running predictions...
2026-01-06 00:03:53,430 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:53,430 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:03:58 +07)" executed successfully
2026-01-06 00:03:58,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:03 +07)" (scheduled at 2026-01-06 00:03:58.120066+07:00)
2026-01-06 00:03:58,121 - INFO -  Running predictions...
2026-01-06 00:03:58,507 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:03:58,507 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:03 +07)" executed successfully
2026-01-06 00:04:03,121 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:08 +07)" (scheduled at 2026-01-06 00:04:03.120066+07:00)
2026-01-06 00:04:03,121 - INFO -  Running predictions...
2026-01-06 00:04:03,272 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 00:04:03,272 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:08 +07)" executed successfully
2026-01-06 00:04:07,957 - INFO - Stopping Spark Session...
2026-01-06 00:04:08,120 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:13 +07)" (scheduled at 2026-01-06 00:04:08.120066+07:00)
2026-01-06 00:04:08,121 - INFO -  Running predictions...
2026-01-06 00:04:08,138 - ERROR - Error reading data: An error occurred while calling o2866.load.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)

The currently active SparkContext was created at:

(No active SparkContext.)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
	at com.mongodb.spark.MongoSpark.rdd(MongoSpark.scala:530)
	at com.mongodb.spark.MongoSpark.toRDD(MongoSpark.scala:542)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:93)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at jdk.internal.reflect.GeneratedMethodAccessor70.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-06 00:04:08,146 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-06 00:04:08,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 00:04:13 +07)" executed successfully
2026-01-06 00:04:08,340 - INFO - Closing down clientserver connection
2026-01-06 00:04:08,340 - INFO - Scheduler has been shut down
2026-01-06 00:04:08,341 - INFO - Closing down clientserver connection
2026-01-06 11:57:15,927 - INFO -  Initializing PySpark Session...
2026-01-06 11:57:19,447 - INFO - ‚úì Spark Session Created!
2026-01-06 11:57:19,448 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-06 11:57:19,475 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 11:57:19,476 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 11:57:19,476 - INFO - Scheduler started
2026-01-06 11:57:24,478 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:24 +07)" (scheduled at 2026-01-06 11:57:24.474989+07:00)
2026-01-06 11:57:24,478 - INFO -  Training Spark model...
2026-01-06 11:57:29,400 - INFO - ‚úì Model trained successfully!
2026-01-06 11:57:29,400 - INFO -  Running predictions...
2026-01-06 11:57:29,476 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:29 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 11:57:29,762 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:29,762 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:34 +07)" executed successfully
2026-01-06 11:57:34,479 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:39 +07)" (scheduled at 2026-01-06 11:57:34.474989+07:00)
2026-01-06 11:57:34,479 - INFO -  Running predictions...
2026-01-06 11:57:34,681 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:34,682 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:39 +07)" executed successfully
2026-01-06 11:57:39,476 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:44 +07)" (scheduled at 2026-01-06 11:57:39.474989+07:00)
2026-01-06 11:57:39,477 - INFO -  Running predictions...
2026-01-06 11:57:39,682 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:39,682 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:44 +07)" executed successfully
2026-01-06 11:57:44,482 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:49 +07)" (scheduled at 2026-01-06 11:57:44.474989+07:00)
2026-01-06 11:57:44,482 - INFO -  Running predictions...
2026-01-06 11:57:44,682 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:44,682 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:49 +07)" executed successfully
2026-01-06 11:57:49,476 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:54 +07)" (scheduled at 2026-01-06 11:57:49.474989+07:00)
2026-01-06 11:57:49,476 - INFO -  Running predictions...
2026-01-06 11:57:49,633 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:49,633 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:54 +07)" executed successfully
2026-01-06 11:57:54,481 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:59 +07)" (scheduled at 2026-01-06 11:57:54.474989+07:00)
2026-01-06 11:57:54,482 - INFO -  Running predictions...
2026-01-06 11:57:54,606 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:54,607 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:57:59 +07)" executed successfully
2026-01-06 11:57:59,478 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:04 +07)" (scheduled at 2026-01-06 11:57:59.474989+07:00)
2026-01-06 11:57:59,478 - INFO -  Running predictions...
2026-01-06 11:57:59,673 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:57:59,673 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:04 +07)" executed successfully
2026-01-06 11:58:04,475 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:09 +07)" (scheduled at 2026-01-06 11:58:04.474989+07:00)
2026-01-06 11:58:04,478 - INFO -  Running predictions...
2026-01-06 11:58:04,748 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:58:04,750 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:09 +07)" executed successfully
2026-01-06 11:58:09,476 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:14 +07)" (scheduled at 2026-01-06 11:58:09.474989+07:00)
2026-01-06 11:58:09,476 - INFO -  Running predictions...
2026-01-06 11:58:09,632 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:58:09,632 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:14 +07)" executed successfully
2026-01-06 11:58:14,475 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:19 +07)" (scheduled at 2026-01-06 11:58:14.474989+07:00)
2026-01-06 11:58:14,476 - INFO -  Running predictions...
2026-01-06 11:58:14,659 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:58:14,659 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:19 +07)" executed successfully
2026-01-06 11:58:19,475 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:24 +07)" (scheduled at 2026-01-06 11:58:19.474989+07:00)
2026-01-06 11:58:19,476 - INFO -  Running predictions...
2026-01-06 11:58:19,599 - ERROR - Prediction error: Could not serialize object: RuntimeError: It appears that you are attempting to reference SparkContext from a broadcast variable, action, or transformation. SparkContext can only be used on the driver, not in code that it run on workers. For more information, see SPARK-5063.
2026-01-06 11:58:19,599 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 11:58:24 +07)" executed successfully
2026-01-06 11:58:21,189 - INFO - Stopping Spark Session...
2026-01-06 11:58:21,469 - INFO - Closing down clientserver connection
2026-01-06 11:58:21,469 - INFO - Scheduler has been shut down
2026-01-06 11:58:21,470 - INFO - Closing down clientserver connection
2026-01-06 12:00:44,406 - INFO -  Initializing PySpark Session...
2026-01-06 12:00:48,694 - INFO - ‚úì Spark Session Created!
2026-01-06 12:00:48,694 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-06 12:00:48,722 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:00:48,723 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 12:00:48,723 - INFO - Scheduler started
2026-01-06 12:00:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:00:53 +07)" (scheduled at 2026-01-06 12:00:53.722662+07:00)
2026-01-06 12:00:53,724 - INFO -  Training Spark model...
2026-01-06 12:00:58,725 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:00:58 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 12:01:00,491 - INFO - ‚úì Model trained successfully!
2026-01-06 12:01:00,491 - INFO -  Running predictions...
2026-01-06 12:01:02,374 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:02,375 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:03 +07)" executed successfully
2026-01-06 12:01:03,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:08 +07)" (scheduled at 2026-01-06 12:01:03.722662+07:00)
2026-01-06 12:01:03,726 - INFO -  Running predictions...
2026-01-06 12:01:04,977 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:04,978 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:08 +07)" executed successfully
2026-01-06 12:01:08,788 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:13 +07)" (scheduled at 2026-01-06 12:01:08.722662+07:00)
2026-01-06 12:01:08,788 - INFO -  Running predictions...
2026-01-06 12:01:09,777 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:09,777 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:13 +07)" executed successfully
2026-01-06 12:01:13,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:18 +07)" (scheduled at 2026-01-06 12:01:13.722662+07:00)
2026-01-06 12:01:13,724 - INFO -  Running predictions...
2026-01-06 12:01:14,601 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:14,602 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:18 +07)" executed successfully
2026-01-06 12:01:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:23 +07)" (scheduled at 2026-01-06 12:01:18.722662+07:00)
2026-01-06 12:01:18,723 - INFO -  Running predictions...
2026-01-06 12:01:19,647 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:19,647 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:23 +07)" executed successfully
2026-01-06 12:01:23,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:28 +07)" (scheduled at 2026-01-06 12:01:23.722662+07:00)
2026-01-06 12:01:23,728 - INFO -  Running predictions...
2026-01-06 12:01:24,386 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:24,386 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:28 +07)" executed successfully
2026-01-06 12:01:28,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:33 +07)" (scheduled at 2026-01-06 12:01:28.722662+07:00)
2026-01-06 12:01:28,726 - INFO -  Running predictions...
2026-01-06 12:01:29,534 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:29,534 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:33 +07)" executed successfully
2026-01-06 12:01:33,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:38 +07)" (scheduled at 2026-01-06 12:01:33.722662+07:00)
2026-01-06 12:01:33,726 - INFO -  Running predictions...
2026-01-06 12:01:34,519 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:34,519 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:38 +07)" executed successfully
2026-01-06 12:01:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:43 +07)" (scheduled at 2026-01-06 12:01:38.722662+07:00)
2026-01-06 12:01:38,723 - INFO -  Running predictions...
2026-01-06 12:01:39,770 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:39,770 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:43 +07)" executed successfully
2026-01-06 12:01:43,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:48 +07)" (scheduled at 2026-01-06 12:01:43.722662+07:00)
2026-01-06 12:01:43,726 - INFO -  Running predictions...
2026-01-06 12:01:44,823 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:44,823 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:48 +07)" executed successfully
2026-01-06 12:01:48,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:53 +07)" (scheduled at 2026-01-06 12:01:48.722662+07:00)
2026-01-06 12:01:48,728 - INFO -  Running predictions...
2026-01-06 12:01:49,427 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:49,427 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:53 +07)" executed successfully
2026-01-06 12:01:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:58 +07)" (scheduled at 2026-01-06 12:01:53.722662+07:00)
2026-01-06 12:01:53,724 - INFO -  Running predictions...
2026-01-06 12:01:54,475 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:54,475 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:01:58 +07)" executed successfully
2026-01-06 12:01:58,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:03 +07)" (scheduled at 2026-01-06 12:01:58.722662+07:00)
2026-01-06 12:01:58,724 - INFO -  Running predictions...
2026-01-06 12:01:59,275 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:01:59,275 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:03 +07)" executed successfully
2026-01-06 12:02:03,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:08 +07)" (scheduled at 2026-01-06 12:02:03.722662+07:00)
2026-01-06 12:02:03,729 - INFO -  Running predictions...
2026-01-06 12:02:04,221 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:04,221 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:08 +07)" executed successfully
2026-01-06 12:02:08,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:13 +07)" (scheduled at 2026-01-06 12:02:08.722662+07:00)
2026-01-06 12:02:08,723 - INFO -  Running predictions...
2026-01-06 12:02:09,433 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:09,433 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:13 +07)" executed successfully
2026-01-06 12:02:13,736 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:18 +07)" (scheduled at 2026-01-06 12:02:13.722662+07:00)
2026-01-06 12:02:13,736 - INFO -  Running predictions...
2026-01-06 12:02:14,286 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:14,287 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:18 +07)" executed successfully
2026-01-06 12:02:18,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:23 +07)" (scheduled at 2026-01-06 12:02:18.722662+07:00)
2026-01-06 12:02:18,724 - INFO -  Running predictions...
2026-01-06 12:02:19,419 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:19,419 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:23 +07)" executed successfully
2026-01-06 12:02:23,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:28 +07)" (scheduled at 2026-01-06 12:02:23.722662+07:00)
2026-01-06 12:02:23,725 - INFO -  Running predictions...
2026-01-06 12:02:24,290 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:24,290 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:28 +07)" executed successfully
2026-01-06 12:02:28,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:33 +07)" (scheduled at 2026-01-06 12:02:28.722662+07:00)
2026-01-06 12:02:28,727 - INFO -  Running predictions...
2026-01-06 12:02:29,273 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:29,274 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:33 +07)" executed successfully
2026-01-06 12:02:33,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:38 +07)" (scheduled at 2026-01-06 12:02:33.722662+07:00)
2026-01-06 12:02:33,729 - INFO -  Running predictions...
2026-01-06 12:02:34,333 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:34,333 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:38 +07)" executed successfully
2026-01-06 12:02:38,738 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:43 +07)" (scheduled at 2026-01-06 12:02:38.722662+07:00)
2026-01-06 12:02:38,738 - INFO -  Running predictions...
2026-01-06 12:02:39,227 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:39,228 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:43 +07)" executed successfully
2026-01-06 12:02:39,482 - INFO -  Initializing PySpark Session...
2026-01-06 12:02:42,575 - INFO - ‚úì Spark Session Created!
2026-01-06 12:02:42,576 - INFO - Starting Spark Prediction Service (interval: 5s)...
2026-01-06 12:02:42,598 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:02:42,599 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 12:02:42,599 - INFO - Scheduler started
2026-01-06 12:02:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:48 +07)" (scheduled at 2026-01-06 12:02:43.722662+07:00)
2026-01-06 12:02:43,724 - INFO -  Running predictions...
2026-01-06 12:02:44,435 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:44,436 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:48 +07)" executed successfully
2026-01-06 12:02:47,602 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:47 +07)" (scheduled at 2026-01-06 12:02:47.598779+07:00)
2026-01-06 12:02:47,603 - INFO -  Training Spark model...
2026-01-06 12:02:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:53 +07)" (scheduled at 2026-01-06 12:02:48.722662+07:00)
2026-01-06 12:02:48,724 - INFO -  Running predictions...
2026-01-06 12:02:49,587 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:49,587 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:53 +07)" executed successfully
2026-01-06 12:02:52,380 - INFO - ‚úì Model trained successfully!
2026-01-06 12:02:52,381 - INFO -  Running predictions...
2026-01-06 12:02:52,601 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:52 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 12:02:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:58 +07)" (scheduled at 2026-01-06 12:02:53.722662+07:00)
2026-01-06 12:02:53,724 - INFO -  Running predictions...
2026-01-06 12:02:54,170 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:54,170 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:57 +07)" executed successfully
2026-01-06 12:02:54,411 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:54,411 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:02:58 +07)" executed successfully
2026-01-06 12:02:57,601 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:02 +07)" (scheduled at 2026-01-06 12:02:57.598779+07:00)
2026-01-06 12:02:57,602 - INFO -  Running predictions...
2026-01-06 12:02:58,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:03 +07)" (scheduled at 2026-01-06 12:02:58.722662+07:00)
2026-01-06 12:02:58,724 - INFO -  Running predictions...
2026-01-06 12:02:58,901 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:58,901 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:02 +07)" executed successfully
2026-01-06 12:02:59,403 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:02:59,403 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:03 +07)" executed successfully
2026-01-06 12:03:02,602 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:07 +07)" (scheduled at 2026-01-06 12:03:02.598779+07:00)
2026-01-06 12:03:02,602 - INFO -  Running predictions...
2026-01-06 12:03:03,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:08 +07)" (scheduled at 2026-01-06 12:03:03.722662+07:00)
2026-01-06 12:03:03,728 - INFO -  Running predictions...
2026-01-06 12:03:03,884 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:03,884 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:07 +07)" executed successfully
2026-01-06 12:03:04,472 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:04,473 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:08 +07)" executed successfully
2026-01-06 12:03:07,600 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:12 +07)" (scheduled at 2026-01-06 12:03:07.598779+07:00)
2026-01-06 12:03:07,601 - INFO -  Running predictions...
2026-01-06 12:03:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:13 +07)" (scheduled at 2026-01-06 12:03:08.722662+07:00)
2026-01-06 12:03:08,724 - INFO -  Running predictions...
2026-01-06 12:03:08,818 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:08,818 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:12 +07)" executed successfully
2026-01-06 12:03:09,253 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:09,253 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:13 +07)" executed successfully
2026-01-06 12:03:12,600 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:17 +07)" (scheduled at 2026-01-06 12:03:12.598779+07:00)
2026-01-06 12:03:12,600 - INFO -  Running predictions...
2026-01-06 12:03:13,535 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:13,535 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:17 +07)" executed successfully
2026-01-06 12:03:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:18 +07)" (scheduled at 2026-01-06 12:03:13.722662+07:00)
2026-01-06 12:03:13,723 - INFO -  Running predictions...
2026-01-06 12:03:14,225 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:14,225 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:18 +07)" executed successfully
2026-01-06 12:03:17,589 - INFO - Stopping Spark Session...
2026-01-06 12:03:17,599 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:22 +07)" (scheduled at 2026-01-06 12:03:17.598779+07:00)
2026-01-06 12:03:17,600 - INFO -  Running predictions...
2026-01-06 12:03:17,622 - ERROR - Error reading data: An error occurred while calling o905.load.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)
	at com.mongodb.spark.MongoSpark.rdd(MongoSpark.scala:530)
	at com.mongodb.spark.MongoSpark.toRDD(MongoSpark.scala:542)
	at com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:93)
	at com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-06 12:03:17,637 - ERROR - Prediction error: 'NoneType' object has no attribute 'withColumn'
2026-01-06 12:03:17,637 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:22 +07)" executed successfully
2026-01-06 12:03:18,285 - INFO - Closing down clientserver connection
2026-01-06 12:03:18,286 - INFO - Scheduler has been shut down
2026-01-06 12:03:18,286 - INFO - Closing down clientserver connection
2026-01-06 12:03:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:23 +07)" (scheduled at 2026-01-06 12:03:18.722662+07:00)
2026-01-06 12:03:18,723 - INFO -  Running predictions...
2026-01-06 12:03:19,160 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:19,160 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:23 +07)" executed successfully
2026-01-06 12:03:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:28 +07)" (scheduled at 2026-01-06 12:03:23.722662+07:00)
2026-01-06 12:03:23,724 - INFO -  Running predictions...
2026-01-06 12:03:24,136 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:24,136 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:28 +07)" executed successfully
2026-01-06 12:03:28,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:33 +07)" (scheduled at 2026-01-06 12:03:28.722662+07:00)
2026-01-06 12:03:28,726 - INFO -  Running predictions...
2026-01-06 12:03:29,214 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:29,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:33 +07)" executed successfully
2026-01-06 12:03:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:38 +07)" (scheduled at 2026-01-06 12:03:33.722662+07:00)
2026-01-06 12:03:33,724 - INFO -  Running predictions...
2026-01-06 12:03:34,116 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:34,116 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:38 +07)" executed successfully
2026-01-06 12:03:38,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:43 +07)" (scheduled at 2026-01-06 12:03:38.722662+07:00)
2026-01-06 12:03:38,726 - INFO -  Running predictions...
2026-01-06 12:03:39,129 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:39,129 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:43 +07)" executed successfully
2026-01-06 12:03:43,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:48 +07)" (scheduled at 2026-01-06 12:03:43.722662+07:00)
2026-01-06 12:03:43,725 - INFO -  Running predictions...
2026-01-06 12:03:44,152 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:44,152 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:48 +07)" executed successfully
2026-01-06 12:03:48,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:53 +07)" (scheduled at 2026-01-06 12:03:48.722662+07:00)
2026-01-06 12:03:48,734 - INFO -  Running predictions...
2026-01-06 12:03:49,128 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:49,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:53 +07)" executed successfully
2026-01-06 12:03:53,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:58 +07)" (scheduled at 2026-01-06 12:03:53.722662+07:00)
2026-01-06 12:03:53,731 - INFO -  Running predictions...
2026-01-06 12:03:54,142 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:54,142 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:03:58 +07)" executed successfully
2026-01-06 12:03:58,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:03 +07)" (scheduled at 2026-01-06 12:03:58.722662+07:00)
2026-01-06 12:03:58,726 - INFO -  Running predictions...
2026-01-06 12:03:59,124 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:03:59,124 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:03 +07)" executed successfully
2026-01-06 12:04:03,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:08 +07)" (scheduled at 2026-01-06 12:04:03.722662+07:00)
2026-01-06 12:04:03,725 - INFO -  Running predictions...
2026-01-06 12:04:04,403 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:04,404 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:08 +07)" executed successfully
2026-01-06 12:04:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:13 +07)" (scheduled at 2026-01-06 12:04:08.722662+07:00)
2026-01-06 12:04:08,724 - INFO -  Running predictions...
2026-01-06 12:04:09,213 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:09,213 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:13 +07)" executed successfully
2026-01-06 12:04:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:18 +07)" (scheduled at 2026-01-06 12:04:13.722662+07:00)
2026-01-06 12:04:13,723 - INFO -  Running predictions...
2026-01-06 12:04:14,156 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:14,157 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:18 +07)" executed successfully
2026-01-06 12:04:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:23 +07)" (scheduled at 2026-01-06 12:04:18.722662+07:00)
2026-01-06 12:04:18,724 - INFO -  Running predictions...
2026-01-06 12:04:19,103 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:19,103 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:23 +07)" executed successfully
2026-01-06 12:04:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:28 +07)" (scheduled at 2026-01-06 12:04:23.722662+07:00)
2026-01-06 12:04:23,723 - INFO -  Running predictions...
2026-01-06 12:04:24,180 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:24,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:28 +07)" executed successfully
2026-01-06 12:04:28,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:33 +07)" (scheduled at 2026-01-06 12:04:28.722662+07:00)
2026-01-06 12:04:28,725 - INFO -  Running predictions...
2026-01-06 12:04:29,180 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:29,180 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:33 +07)" executed successfully
2026-01-06 12:04:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:38 +07)" (scheduled at 2026-01-06 12:04:33.722662+07:00)
2026-01-06 12:04:33,724 - INFO -  Running predictions...
2026-01-06 12:04:34,170 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:34,170 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:38 +07)" executed successfully
2026-01-06 12:04:38,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:43 +07)" (scheduled at 2026-01-06 12:04:38.722662+07:00)
2026-01-06 12:04:38,726 - INFO -  Running predictions...
2026-01-06 12:04:39,122 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:39,122 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:43 +07)" executed successfully
2026-01-06 12:04:43,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:48 +07)" (scheduled at 2026-01-06 12:04:43.722662+07:00)
2026-01-06 12:04:43,726 - INFO -  Running predictions...
2026-01-06 12:04:44,149 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:44,150 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:48 +07)" executed successfully
2026-01-06 12:04:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:53 +07)" (scheduled at 2026-01-06 12:04:48.722662+07:00)
2026-01-06 12:04:48,743 - INFO -  Running predictions...
2026-01-06 12:04:49,128 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:49,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:53 +07)" executed successfully
2026-01-06 12:04:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:58 +07)" (scheduled at 2026-01-06 12:04:53.722662+07:00)
2026-01-06 12:04:53,724 - INFO -  Running predictions...
2026-01-06 12:04:54,198 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:54,198 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:04:58 +07)" executed successfully
2026-01-06 12:04:58,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:03 +07)" (scheduled at 2026-01-06 12:04:58.722662+07:00)
2026-01-06 12:04:58,726 - INFO -  Running predictions...
2026-01-06 12:04:59,487 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:04:59,488 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:03 +07)" executed successfully
2026-01-06 12:05:03,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:08 +07)" (scheduled at 2026-01-06 12:05:03.722662+07:00)
2026-01-06 12:05:03,729 - INFO -  Running predictions...
2026-01-06 12:05:04,100 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:04,100 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:08 +07)" executed successfully
2026-01-06 12:05:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:13 +07)" (scheduled at 2026-01-06 12:05:08.722662+07:00)
2026-01-06 12:05:08,724 - INFO -  Running predictions...
2026-01-06 12:05:09,128 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:09,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:13 +07)" executed successfully
2026-01-06 12:05:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:18 +07)" (scheduled at 2026-01-06 12:05:13.722662+07:00)
2026-01-06 12:05:13,723 - INFO -  Running predictions...
2026-01-06 12:05:14,347 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:14,347 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:18 +07)" executed successfully
2026-01-06 12:05:18,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:23 +07)" (scheduled at 2026-01-06 12:05:18.722662+07:00)
2026-01-06 12:05:18,729 - INFO -  Running predictions...
2026-01-06 12:05:19,107 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:19,107 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:23 +07)" executed successfully
2026-01-06 12:05:23,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:28 +07)" (scheduled at 2026-01-06 12:05:23.722662+07:00)
2026-01-06 12:05:23,724 - INFO -  Running predictions...
2026-01-06 12:05:24,134 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:24,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:28 +07)" executed successfully
2026-01-06 12:05:28,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:33 +07)" (scheduled at 2026-01-06 12:05:28.722662+07:00)
2026-01-06 12:05:28,724 - INFO -  Running predictions...
2026-01-06 12:05:29,178 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:29,178 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:33 +07)" executed successfully
2026-01-06 12:05:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:38 +07)" (scheduled at 2026-01-06 12:05:33.722662+07:00)
2026-01-06 12:05:33,723 - INFO -  Running predictions...
2026-01-06 12:05:34,186 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:34,186 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:38 +07)" executed successfully
2026-01-06 12:05:38,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:43 +07)" (scheduled at 2026-01-06 12:05:38.722662+07:00)
2026-01-06 12:05:38,729 - INFO -  Running predictions...
2026-01-06 12:05:39,178 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:39,178 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:43 +07)" executed successfully
2026-01-06 12:05:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:48 +07)" (scheduled at 2026-01-06 12:05:43.722662+07:00)
2026-01-06 12:05:43,724 - INFO -  Running predictions...
2026-01-06 12:05:44,174 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:44,174 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:48 +07)" executed successfully
2026-01-06 12:05:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:53 +07)" (scheduled at 2026-01-06 12:05:48.722662+07:00)
2026-01-06 12:05:48,724 - INFO -  Running predictions...
2026-01-06 12:05:49,092 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:49,093 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:53 +07)" executed successfully
2026-01-06 12:05:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:58 +07)" (scheduled at 2026-01-06 12:05:53.722662+07:00)
2026-01-06 12:05:53,723 - INFO -  Running predictions...
2026-01-06 12:05:54,112 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:54,112 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:05:58 +07)" executed successfully
2026-01-06 12:05:58,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:03 +07)" (scheduled at 2026-01-06 12:05:58.722662+07:00)
2026-01-06 12:05:58,725 - INFO -  Running predictions...
2026-01-06 12:05:59,099 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:05:59,099 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:03 +07)" executed successfully
2026-01-06 12:06:03,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:08 +07)" (scheduled at 2026-01-06 12:06:03.722662+07:00)
2026-01-06 12:06:03,725 - INFO -  Running predictions...
2026-01-06 12:06:04,110 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:04,111 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:08 +07)" executed successfully
2026-01-06 12:06:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:13 +07)" (scheduled at 2026-01-06 12:06:08.722662+07:00)
2026-01-06 12:06:08,724 - INFO -  Running predictions...
2026-01-06 12:06:09,148 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:09,149 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:13 +07)" executed successfully
2026-01-06 12:06:13,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:18 +07)" (scheduled at 2026-01-06 12:06:13.722662+07:00)
2026-01-06 12:06:13,728 - INFO -  Running predictions...
2026-01-06 12:06:14,146 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:14,146 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:18 +07)" executed successfully
2026-01-06 12:06:18,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:23 +07)" (scheduled at 2026-01-06 12:06:18.722662+07:00)
2026-01-06 12:06:18,725 - INFO -  Running predictions...
2026-01-06 12:06:19,109 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:19,109 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:23 +07)" executed successfully
2026-01-06 12:06:23,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:28 +07)" (scheduled at 2026-01-06 12:06:23.722662+07:00)
2026-01-06 12:06:23,724 - INFO -  Running predictions...
2026-01-06 12:06:24,168 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:24,168 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:28 +07)" executed successfully
2026-01-06 12:06:28,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:33 +07)" (scheduled at 2026-01-06 12:06:28.722662+07:00)
2026-01-06 12:06:28,728 - INFO -  Running predictions...
2026-01-06 12:06:29,091 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:29,091 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:33 +07)" executed successfully
2026-01-06 12:06:33,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:38 +07)" (scheduled at 2026-01-06 12:06:33.722662+07:00)
2026-01-06 12:06:33,727 - INFO -  Running predictions...
2026-01-06 12:06:34,086 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:34,087 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:38 +07)" executed successfully
2026-01-06 12:06:38,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:43 +07)" (scheduled at 2026-01-06 12:06:38.722662+07:00)
2026-01-06 12:06:38,725 - INFO -  Running predictions...
2026-01-06 12:06:39,093 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:39,093 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:43 +07)" executed successfully
2026-01-06 12:06:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:48 +07)" (scheduled at 2026-01-06 12:06:43.722662+07:00)
2026-01-06 12:06:43,724 - INFO -  Running predictions...
2026-01-06 12:06:44,127 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:44,127 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:48 +07)" executed successfully
2026-01-06 12:06:48,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:53 +07)" (scheduled at 2026-01-06 12:06:48.722662+07:00)
2026-01-06 12:06:48,726 - INFO -  Running predictions...
2026-01-06 12:06:49,059 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:49,059 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:53 +07)" executed successfully
2026-01-06 12:06:53,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:58 +07)" (scheduled at 2026-01-06 12:06:53.722662+07:00)
2026-01-06 12:06:53,726 - INFO -  Running predictions...
2026-01-06 12:06:54,066 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:54,066 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:06:58 +07)" executed successfully
2026-01-06 12:06:58,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:03 +07)" (scheduled at 2026-01-06 12:06:58.722662+07:00)
2026-01-06 12:06:58,724 - INFO -  Running predictions...
2026-01-06 12:06:59,115 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:06:59,116 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:03 +07)" executed successfully
2026-01-06 12:07:03,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:08 +07)" (scheduled at 2026-01-06 12:07:03.722662+07:00)
2026-01-06 12:07:03,726 - INFO -  Running predictions...
2026-01-06 12:07:04,138 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:04,138 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:08 +07)" executed successfully
2026-01-06 12:07:08,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:13 +07)" (scheduled at 2026-01-06 12:07:08.722662+07:00)
2026-01-06 12:07:08,724 - INFO -  Running predictions...
2026-01-06 12:07:09,065 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:09,065 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:13 +07)" executed successfully
2026-01-06 12:07:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:18 +07)" (scheduled at 2026-01-06 12:07:13.722662+07:00)
2026-01-06 12:07:13,723 - INFO -  Running predictions...
2026-01-06 12:07:14,170 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:14,170 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:18 +07)" executed successfully
2026-01-06 12:07:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:23 +07)" (scheduled at 2026-01-06 12:07:18.722662+07:00)
2026-01-06 12:07:18,723 - INFO -  Running predictions...
2026-01-06 12:07:19,153 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:19,153 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:23 +07)" executed successfully
2026-01-06 12:07:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:28 +07)" (scheduled at 2026-01-06 12:07:23.722662+07:00)
2026-01-06 12:07:23,723 - INFO -  Running predictions...
2026-01-06 12:07:24,147 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:24,147 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:28 +07)" executed successfully
2026-01-06 12:07:28,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:33 +07)" (scheduled at 2026-01-06 12:07:28.722662+07:00)
2026-01-06 12:07:28,726 - INFO -  Running predictions...
2026-01-06 12:07:29,202 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:29,202 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:33 +07)" executed successfully
2026-01-06 12:07:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:38 +07)" (scheduled at 2026-01-06 12:07:33.722662+07:00)
2026-01-06 12:07:33,724 - INFO -  Running predictions...
2026-01-06 12:07:34,347 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:34,347 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:38 +07)" executed successfully
2026-01-06 12:07:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:43 +07)" (scheduled at 2026-01-06 12:07:38.722662+07:00)
2026-01-06 12:07:38,724 - INFO -  Running predictions...
2026-01-06 12:07:39,285 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:39,286 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:43 +07)" executed successfully
2026-01-06 12:07:43,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:48 +07)" (scheduled at 2026-01-06 12:07:43.722662+07:00)
2026-01-06 12:07:43,725 - INFO -  Running predictions...
2026-01-06 12:07:44,256 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:44,256 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:48 +07)" executed successfully
2026-01-06 12:07:48,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:53 +07)" (scheduled at 2026-01-06 12:07:48.722662+07:00)
2026-01-06 12:07:48,723 - INFO -  Running predictions...
2026-01-06 12:07:49,350 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:49,350 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:53 +07)" executed successfully
2026-01-06 12:07:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:58 +07)" (scheduled at 2026-01-06 12:07:53.722662+07:00)
2026-01-06 12:07:53,724 - INFO -  Running predictions...
2026-01-06 12:07:54,504 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:54,504 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:07:58 +07)" executed successfully
2026-01-06 12:07:58,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:03 +07)" (scheduled at 2026-01-06 12:07:58.722662+07:00)
2026-01-06 12:07:58,724 - INFO -  Running predictions...
2026-01-06 12:07:59,293 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:07:59,293 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:03 +07)" executed successfully
2026-01-06 12:08:03,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:08 +07)" (scheduled at 2026-01-06 12:08:03.722662+07:00)
2026-01-06 12:08:03,727 - INFO -  Running predictions...
2026-01-06 12:08:04,090 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:04,091 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:08 +07)" executed successfully
2026-01-06 12:08:08,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:13 +07)" (scheduled at 2026-01-06 12:08:08.722662+07:00)
2026-01-06 12:08:08,725 - INFO -  Running predictions...
2026-01-06 12:08:09,240 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:09,240 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:13 +07)" executed successfully
2026-01-06 12:08:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:18 +07)" (scheduled at 2026-01-06 12:08:13.722662+07:00)
2026-01-06 12:08:13,723 - INFO -  Running predictions...
2026-01-06 12:08:14,321 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:14,321 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:18 +07)" executed successfully
2026-01-06 12:08:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:23 +07)" (scheduled at 2026-01-06 12:08:18.722662+07:00)
2026-01-06 12:08:18,723 - INFO -  Running predictions...
2026-01-06 12:08:19,155 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:19,156 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:23 +07)" executed successfully
2026-01-06 12:08:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:28 +07)" (scheduled at 2026-01-06 12:08:23.722662+07:00)
2026-01-06 12:08:23,723 - INFO -  Running predictions...
2026-01-06 12:08:24,261 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:24,261 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:28 +07)" executed successfully
2026-01-06 12:08:28,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:33 +07)" (scheduled at 2026-01-06 12:08:28.722662+07:00)
2026-01-06 12:08:28,723 - INFO -  Running predictions...
2026-01-06 12:08:29,126 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:29,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:33 +07)" executed successfully
2026-01-06 12:08:33,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:38 +07)" (scheduled at 2026-01-06 12:08:33.722662+07:00)
2026-01-06 12:08:33,726 - INFO -  Running predictions...
2026-01-06 12:08:34,209 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:34,210 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:38 +07)" executed successfully
2026-01-06 12:08:38,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:43 +07)" (scheduled at 2026-01-06 12:08:38.722662+07:00)
2026-01-06 12:08:38,724 - INFO -  Running predictions...
2026-01-06 12:08:39,182 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:39,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:43 +07)" executed successfully
2026-01-06 12:08:43,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:48 +07)" (scheduled at 2026-01-06 12:08:43.722662+07:00)
2026-01-06 12:08:43,723 - INFO -  Running predictions...
2026-01-06 12:08:44,248 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:44,248 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:48 +07)" executed successfully
2026-01-06 12:08:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:53 +07)" (scheduled at 2026-01-06 12:08:48.722662+07:00)
2026-01-06 12:08:48,724 - INFO -  Running predictions...
2026-01-06 12:08:49,259 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:49,260 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:53 +07)" executed successfully
2026-01-06 12:08:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:58 +07)" (scheduled at 2026-01-06 12:08:53.722662+07:00)
2026-01-06 12:08:53,723 - INFO -  Running predictions...
2026-01-06 12:08:54,288 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:54,288 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:08:58 +07)" executed successfully
2026-01-06 12:08:58,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:03 +07)" (scheduled at 2026-01-06 12:08:58.722662+07:00)
2026-01-06 12:08:58,725 - INFO -  Running predictions...
2026-01-06 12:08:59,130 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:08:59,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:03 +07)" executed successfully
2026-01-06 12:09:03,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:08 +07)" (scheduled at 2026-01-06 12:09:03.722662+07:00)
2026-01-06 12:09:03,726 - INFO -  Running predictions...
2026-01-06 12:09:04,256 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:04,256 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:08 +07)" executed successfully
2026-01-06 12:09:08,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:13 +07)" (scheduled at 2026-01-06 12:09:08.722662+07:00)
2026-01-06 12:09:08,725 - INFO -  Running predictions...
2026-01-06 12:09:09,213 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:09,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:13 +07)" executed successfully
2026-01-06 12:09:13,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:18 +07)" (scheduled at 2026-01-06 12:09:13.722662+07:00)
2026-01-06 12:09:13,727 - INFO -  Running predictions...
2026-01-06 12:09:14,199 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:14,200 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:18 +07)" executed successfully
2026-01-06 12:09:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:23 +07)" (scheduled at 2026-01-06 12:09:18.722662+07:00)
2026-01-06 12:09:18,723 - INFO -  Running predictions...
2026-01-06 12:09:19,084 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:19,084 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:23 +07)" executed successfully
2026-01-06 12:09:23,731 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:28 +07)" (scheduled at 2026-01-06 12:09:23.722662+07:00)
2026-01-06 12:09:23,731 - INFO -  Running predictions...
2026-01-06 12:09:24,142 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:24,143 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:28 +07)" executed successfully
2026-01-06 12:09:28,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:33 +07)" (scheduled at 2026-01-06 12:09:28.722662+07:00)
2026-01-06 12:09:28,729 - INFO -  Running predictions...
2026-01-06 12:09:29,075 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:29,075 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:33 +07)" executed successfully
2026-01-06 12:09:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:38 +07)" (scheduled at 2026-01-06 12:09:33.722662+07:00)
2026-01-06 12:09:33,723 - INFO -  Running predictions...
2026-01-06 12:09:34,112 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:34,112 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:38 +07)" executed successfully
2026-01-06 12:09:38,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:43 +07)" (scheduled at 2026-01-06 12:09:38.722662+07:00)
2026-01-06 12:09:38,725 - INFO -  Running predictions...
2026-01-06 12:09:39,047 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:39,047 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:43 +07)" executed successfully
2026-01-06 12:09:43,761 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:48 +07)" (scheduled at 2026-01-06 12:09:43.722662+07:00)
2026-01-06 12:09:43,761 - INFO -  Running predictions...
2026-01-06 12:09:44,133 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:44,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:48 +07)" executed successfully
2026-01-06 12:09:48,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:53 +07)" (scheduled at 2026-01-06 12:09:48.722662+07:00)
2026-01-06 12:09:48,723 - INFO -  Running predictions...
2026-01-06 12:09:49,043 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:49,043 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:53 +07)" executed successfully
2026-01-06 12:09:53,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:58 +07)" (scheduled at 2026-01-06 12:09:53.722662+07:00)
2026-01-06 12:09:53,725 - INFO -  Running predictions...
2026-01-06 12:09:54,066 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:54,066 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:09:58 +07)" executed successfully
2026-01-06 12:09:58,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:03 +07)" (scheduled at 2026-01-06 12:09:58.722662+07:00)
2026-01-06 12:09:58,728 - INFO -  Running predictions...
2026-01-06 12:09:59,111 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:09:59,111 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:03 +07)" executed successfully
2026-01-06 12:10:03,739 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:08 +07)" (scheduled at 2026-01-06 12:10:03.722662+07:00)
2026-01-06 12:10:03,739 - INFO -  Running predictions...
2026-01-06 12:10:04,084 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:04,084 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:08 +07)" executed successfully
2026-01-06 12:10:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:13 +07)" (scheduled at 2026-01-06 12:10:08.722662+07:00)
2026-01-06 12:10:08,725 - INFO -  Running predictions...
2026-01-06 12:10:09,040 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:09,040 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:13 +07)" executed successfully
2026-01-06 12:10:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:18 +07)" (scheduled at 2026-01-06 12:10:13.722662+07:00)
2026-01-06 12:10:13,723 - INFO -  Running predictions...
2026-01-06 12:10:14,192 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:14,192 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:18 +07)" executed successfully
2026-01-06 12:10:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:23 +07)" (scheduled at 2026-01-06 12:10:18.722662+07:00)
2026-01-06 12:10:18,723 - INFO -  Running predictions...
2026-01-06 12:10:19,069 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:19,069 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:23 +07)" executed successfully
2026-01-06 12:10:23,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:28 +07)" (scheduled at 2026-01-06 12:10:23.722662+07:00)
2026-01-06 12:10:23,734 - INFO -  Running predictions...
2026-01-06 12:10:24,089 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:24,089 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:28 +07)" executed successfully
2026-01-06 12:10:28,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:33 +07)" (scheduled at 2026-01-06 12:10:28.722662+07:00)
2026-01-06 12:10:28,725 - INFO -  Running predictions...
2026-01-06 12:10:29,061 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:29,061 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:33 +07)" executed successfully
2026-01-06 12:10:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:38 +07)" (scheduled at 2026-01-06 12:10:33.722662+07:00)
2026-01-06 12:10:33,724 - INFO -  Running predictions...
2026-01-06 12:10:34,102 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:34,102 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:38 +07)" executed successfully
2026-01-06 12:10:38,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:43 +07)" (scheduled at 2026-01-06 12:10:38.722662+07:00)
2026-01-06 12:10:38,734 - INFO -  Running predictions...
2026-01-06 12:10:39,071 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:39,072 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:43 +07)" executed successfully
2026-01-06 12:10:43,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:48 +07)" (scheduled at 2026-01-06 12:10:43.722662+07:00)
2026-01-06 12:10:43,731 - INFO -  Running predictions...
2026-01-06 12:10:44,082 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:44,082 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:48 +07)" executed successfully
2026-01-06 12:10:48,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:53 +07)" (scheduled at 2026-01-06 12:10:48.722662+07:00)
2026-01-06 12:10:48,725 - INFO -  Running predictions...
2026-01-06 12:10:49,059 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:49,059 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:53 +07)" executed successfully
2026-01-06 12:10:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:58 +07)" (scheduled at 2026-01-06 12:10:53.722662+07:00)
2026-01-06 12:10:53,723 - INFO -  Running predictions...
2026-01-06 12:10:54,089 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:54,089 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:10:58 +07)" executed successfully
2026-01-06 12:10:58,778 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:03 +07)" (scheduled at 2026-01-06 12:10:58.722662+07:00)
2026-01-06 12:10:58,778 - INFO -  Running predictions...
2026-01-06 12:10:59,115 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:10:59,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:03 +07)" executed successfully
2026-01-06 12:11:03,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:08 +07)" (scheduled at 2026-01-06 12:11:03.722662+07:00)
2026-01-06 12:11:03,728 - INFO -  Running predictions...
2026-01-06 12:11:04,066 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:04,066 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:08 +07)" executed successfully
2026-01-06 12:11:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:13 +07)" (scheduled at 2026-01-06 12:11:08.722662+07:00)
2026-01-06 12:11:08,724 - INFO -  Running predictions...
2026-01-06 12:11:09,076 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:09,077 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:13 +07)" executed successfully
2026-01-06 12:11:13,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:18 +07)" (scheduled at 2026-01-06 12:11:13.722662+07:00)
2026-01-06 12:11:13,725 - INFO -  Running predictions...
2026-01-06 12:11:14,117 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:14,117 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:18 +07)" executed successfully
2026-01-06 12:11:18,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:23 +07)" (scheduled at 2026-01-06 12:11:18.722662+07:00)
2026-01-06 12:11:18,724 - INFO -  Running predictions...
2026-01-06 12:11:19,085 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:19,085 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:23 +07)" executed successfully
2026-01-06 12:11:23,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:28 +07)" (scheduled at 2026-01-06 12:11:23.722662+07:00)
2026-01-06 12:11:23,726 - INFO -  Running predictions...
2026-01-06 12:11:24,092 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:24,092 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:28 +07)" executed successfully
2026-01-06 12:11:28,737 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:33 +07)" (scheduled at 2026-01-06 12:11:28.722662+07:00)
2026-01-06 12:11:28,737 - INFO -  Running predictions...
2026-01-06 12:11:29,073 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:29,073 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:33 +07)" executed successfully
2026-01-06 12:11:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:38 +07)" (scheduled at 2026-01-06 12:11:33.722662+07:00)
2026-01-06 12:11:33,724 - INFO -  Running predictions...
2026-01-06 12:11:34,166 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:34,166 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:38 +07)" executed successfully
2026-01-06 12:11:38,731 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:43 +07)" (scheduled at 2026-01-06 12:11:38.722662+07:00)
2026-01-06 12:11:38,732 - INFO -  Running predictions...
2026-01-06 12:11:39,103 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:39,104 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:43 +07)" executed successfully
2026-01-06 12:11:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:48 +07)" (scheduled at 2026-01-06 12:11:43.722662+07:00)
2026-01-06 12:11:43,724 - INFO -  Running predictions...
2026-01-06 12:11:44,060 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:44,060 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:48 +07)" executed successfully
2026-01-06 12:11:48,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:53 +07)" (scheduled at 2026-01-06 12:11:48.722662+07:00)
2026-01-06 12:11:48,727 - INFO -  Running predictions...
2026-01-06 12:11:49,070 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:49,070 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:53 +07)" executed successfully
2026-01-06 12:11:53,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:58 +07)" (scheduled at 2026-01-06 12:11:53.722662+07:00)
2026-01-06 12:11:53,724 - INFO -  Running predictions...
2026-01-06 12:11:54,079 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:54,080 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:11:58 +07)" executed successfully
2026-01-06 12:11:58,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:03 +07)" (scheduled at 2026-01-06 12:11:58.722662+07:00)
2026-01-06 12:11:58,727 - INFO -  Running predictions...
2026-01-06 12:11:59,040 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:11:59,040 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:03 +07)" executed successfully
2026-01-06 12:12:03,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:08 +07)" (scheduled at 2026-01-06 12:12:03.722662+07:00)
2026-01-06 12:12:03,725 - INFO -  Running predictions...
2026-01-06 12:12:04,091 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:04,091 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:08 +07)" executed successfully
2026-01-06 12:12:08,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:13 +07)" (scheduled at 2026-01-06 12:12:08.722662+07:00)
2026-01-06 12:12:08,728 - INFO -  Running predictions...
2026-01-06 12:12:09,044 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:09,045 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:13 +07)" executed successfully
2026-01-06 12:12:13,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:18 +07)" (scheduled at 2026-01-06 12:12:13.722662+07:00)
2026-01-06 12:12:13,725 - INFO -  Running predictions...
2026-01-06 12:12:14,123 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:14,123 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:18 +07)" executed successfully
2026-01-06 12:12:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:23 +07)" (scheduled at 2026-01-06 12:12:18.722662+07:00)
2026-01-06 12:12:18,724 - INFO -  Running predictions...
2026-01-06 12:12:19,120 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:19,120 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:23 +07)" executed successfully
2026-01-06 12:12:23,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:28 +07)" (scheduled at 2026-01-06 12:12:23.722662+07:00)
2026-01-06 12:12:23,729 - INFO -  Running predictions...
2026-01-06 12:12:24,050 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:24,050 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:28 +07)" executed successfully
2026-01-06 12:12:28,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:33 +07)" (scheduled at 2026-01-06 12:12:28.722662+07:00)
2026-01-06 12:12:28,725 - INFO -  Running predictions...
2026-01-06 12:12:29,031 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:29,031 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:33 +07)" executed successfully
2026-01-06 12:12:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:38 +07)" (scheduled at 2026-01-06 12:12:33.722662+07:00)
2026-01-06 12:12:33,724 - INFO -  Running predictions...
2026-01-06 12:12:34,084 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:34,084 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:38 +07)" executed successfully
2026-01-06 12:12:38,732 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:43 +07)" (scheduled at 2026-01-06 12:12:38.722662+07:00)
2026-01-06 12:12:38,732 - INFO -  Running predictions...
2026-01-06 12:12:39,051 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:39,051 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:43 +07)" executed successfully
2026-01-06 12:12:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:48 +07)" (scheduled at 2026-01-06 12:12:43.722662+07:00)
2026-01-06 12:12:43,724 - INFO -  Running predictions...
2026-01-06 12:12:44,049 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:44,049 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:48 +07)" executed successfully
2026-01-06 12:12:48,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:53 +07)" (scheduled at 2026-01-06 12:12:48.722662+07:00)
2026-01-06 12:12:48,727 - INFO -  Running predictions...
2026-01-06 12:12:49,064 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:49,064 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:53 +07)" executed successfully
2026-01-06 12:12:53,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:58 +07)" (scheduled at 2026-01-06 12:12:53.722662+07:00)
2026-01-06 12:12:53,724 - INFO -  Running predictions...
2026-01-06 12:12:54,069 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:54,070 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:12:58 +07)" executed successfully
2026-01-06 12:12:58,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:03 +07)" (scheduled at 2026-01-06 12:12:58.722662+07:00)
2026-01-06 12:12:58,725 - INFO -  Running predictions...
2026-01-06 12:12:59,114 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:12:59,114 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:03 +07)" executed successfully
2026-01-06 12:13:03,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:08 +07)" (scheduled at 2026-01-06 12:13:03.722662+07:00)
2026-01-06 12:13:03,724 - INFO -  Running predictions...
2026-01-06 12:13:04,039 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:04,039 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:08 +07)" executed successfully
2026-01-06 12:13:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:13 +07)" (scheduled at 2026-01-06 12:13:08.722662+07:00)
2026-01-06 12:13:08,724 - INFO -  Running predictions...
2026-01-06 12:13:09,048 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:09,048 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:13 +07)" executed successfully
2026-01-06 12:13:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:18 +07)" (scheduled at 2026-01-06 12:13:13.722662+07:00)
2026-01-06 12:13:13,723 - INFO -  Running predictions...
2026-01-06 12:13:14,102 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:14,102 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:18 +07)" executed successfully
2026-01-06 12:13:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:23 +07)" (scheduled at 2026-01-06 12:13:18.722662+07:00)
2026-01-06 12:13:18,726 - INFO -  Running predictions...
2026-01-06 12:13:19,071 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:19,071 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:23 +07)" executed successfully
2026-01-06 12:13:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:28 +07)" (scheduled at 2026-01-06 12:13:23.722662+07:00)
2026-01-06 12:13:23,723 - INFO -  Running predictions...
2026-01-06 12:13:24,044 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:24,044 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:28 +07)" executed successfully
2026-01-06 12:13:28,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:33 +07)" (scheduled at 2026-01-06 12:13:28.722662+07:00)
2026-01-06 12:13:28,724 - INFO -  Running predictions...
2026-01-06 12:13:29,043 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:29,044 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:33 +07)" executed successfully
2026-01-06 12:13:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:38 +07)" (scheduled at 2026-01-06 12:13:33.722662+07:00)
2026-01-06 12:13:33,724 - INFO -  Running predictions...
2026-01-06 12:13:34,132 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:34,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:38 +07)" executed successfully
2026-01-06 12:13:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:43 +07)" (scheduled at 2026-01-06 12:13:38.722662+07:00)
2026-01-06 12:13:38,723 - INFO -  Running predictions...
2026-01-06 12:13:39,275 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:39,275 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:43 +07)" executed successfully
2026-01-06 12:13:43,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:48 +07)" (scheduled at 2026-01-06 12:13:43.722662+07:00)
2026-01-06 12:13:43,744 - INFO -  Running predictions...
2026-01-06 12:13:44,087 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:44,088 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:48 +07)" executed successfully
2026-01-06 12:13:48,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:53 +07)" (scheduled at 2026-01-06 12:13:48.722662+07:00)
2026-01-06 12:13:48,723 - INFO -  Running predictions...
2026-01-06 12:13:49,035 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:49,035 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:53 +07)" executed successfully
2026-01-06 12:13:53,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:58 +07)" (scheduled at 2026-01-06 12:13:53.722662+07:00)
2026-01-06 12:13:53,724 - INFO -  Running predictions...
2026-01-06 12:13:54,113 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:54,113 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:13:58 +07)" executed successfully
2026-01-06 12:13:58,733 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:03 +07)" (scheduled at 2026-01-06 12:13:58.722662+07:00)
2026-01-06 12:13:58,734 - INFO -  Running predictions...
2026-01-06 12:13:59,078 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:13:59,078 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:03 +07)" executed successfully
2026-01-06 12:14:03,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:08 +07)" (scheduled at 2026-01-06 12:14:03.722662+07:00)
2026-01-06 12:14:03,724 - INFO -  Running predictions...
2026-01-06 12:14:04,039 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:04,039 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:08 +07)" executed successfully
2026-01-06 12:14:08,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:13 +07)" (scheduled at 2026-01-06 12:14:08.722662+07:00)
2026-01-06 12:14:08,725 - INFO -  Running predictions...
2026-01-06 12:14:09,039 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:09,039 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:13 +07)" executed successfully
2026-01-06 12:14:13,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:18 +07)" (scheduled at 2026-01-06 12:14:13.722662+07:00)
2026-01-06 12:14:13,724 - INFO -  Running predictions...
2026-01-06 12:14:14,128 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:14,128 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:18 +07)" executed successfully
2026-01-06 12:14:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:23 +07)" (scheduled at 2026-01-06 12:14:18.722662+07:00)
2026-01-06 12:14:18,723 - INFO -  Running predictions...
2026-01-06 12:14:19,116 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:19,116 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:23 +07)" executed successfully
2026-01-06 12:14:23,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:28 +07)" (scheduled at 2026-01-06 12:14:23.722662+07:00)
2026-01-06 12:14:23,728 - INFO -  Running predictions...
2026-01-06 12:14:24,126 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:24,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:28 +07)" executed successfully
2026-01-06 12:14:28,736 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:33 +07)" (scheduled at 2026-01-06 12:14:28.722662+07:00)
2026-01-06 12:14:28,736 - INFO -  Running predictions...
2026-01-06 12:14:29,073 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:29,074 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:33 +07)" executed successfully
2026-01-06 12:14:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:38 +07)" (scheduled at 2026-01-06 12:14:33.722662+07:00)
2026-01-06 12:14:33,723 - INFO -  Running predictions...
2026-01-06 12:14:34,076 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:34,077 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:38 +07)" executed successfully
2026-01-06 12:14:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:43 +07)" (scheduled at 2026-01-06 12:14:38.722662+07:00)
2026-01-06 12:14:38,724 - INFO -  Running predictions...
2026-01-06 12:14:39,039 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:39,039 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:43 +07)" executed successfully
2026-01-06 12:14:43,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:48 +07)" (scheduled at 2026-01-06 12:14:43.722662+07:00)
2026-01-06 12:14:43,729 - INFO -  Running predictions...
2026-01-06 12:14:44,111 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:44,111 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:48 +07)" executed successfully
2026-01-06 12:14:48,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:53 +07)" (scheduled at 2026-01-06 12:14:48.722662+07:00)
2026-01-06 12:14:48,730 - INFO -  Running predictions...
2026-01-06 12:14:49,165 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:49,165 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:53 +07)" executed successfully
2026-01-06 12:14:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:58 +07)" (scheduled at 2026-01-06 12:14:53.722662+07:00)
2026-01-06 12:14:53,723 - INFO -  Running predictions...
2026-01-06 12:14:54,101 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:54,101 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:14:58 +07)" executed successfully
2026-01-06 12:14:58,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:03 +07)" (scheduled at 2026-01-06 12:14:58.722662+07:00)
2026-01-06 12:14:58,725 - INFO -  Running predictions...
2026-01-06 12:14:59,129 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:14:59,129 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:03 +07)" executed successfully
2026-01-06 12:15:03,732 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:08 +07)" (scheduled at 2026-01-06 12:15:03.722662+07:00)
2026-01-06 12:15:03,732 - INFO -  Running predictions...
2026-01-06 12:15:04,187 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:04,188 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:08 +07)" executed successfully
2026-01-06 12:15:08,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:13 +07)" (scheduled at 2026-01-06 12:15:08.722662+07:00)
2026-01-06 12:15:08,725 - INFO -  Running predictions...
2026-01-06 12:15:09,218 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:09,218 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:13 +07)" executed successfully
2026-01-06 12:15:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:18 +07)" (scheduled at 2026-01-06 12:15:13.722662+07:00)
2026-01-06 12:15:13,723 - INFO -  Running predictions...
2026-01-06 12:15:14,369 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:14,369 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:18 +07)" executed successfully
2026-01-06 12:15:18,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:23 +07)" (scheduled at 2026-01-06 12:15:18.722662+07:00)
2026-01-06 12:15:18,724 - INFO -  Running predictions...
2026-01-06 12:15:19,144 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:19,144 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:23 +07)" executed successfully
2026-01-06 12:15:23,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:28 +07)" (scheduled at 2026-01-06 12:15:23.722662+07:00)
2026-01-06 12:15:23,726 - INFO -  Running predictions...
2026-01-06 12:15:24,165 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:24,166 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:28 +07)" executed successfully
2026-01-06 12:15:28,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:33 +07)" (scheduled at 2026-01-06 12:15:28.722662+07:00)
2026-01-06 12:15:28,723 - INFO -  Running predictions...
2026-01-06 12:15:29,114 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:29,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:33 +07)" executed successfully
2026-01-06 12:15:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:38 +07)" (scheduled at 2026-01-06 12:15:33.722662+07:00)
2026-01-06 12:15:33,724 - INFO -  Running predictions...
2026-01-06 12:15:34,215 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:34,215 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:38 +07)" executed successfully
2026-01-06 12:15:38,737 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:43 +07)" (scheduled at 2026-01-06 12:15:38.722662+07:00)
2026-01-06 12:15:38,737 - INFO -  Running predictions...
2026-01-06 12:15:39,072 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:39,072 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:43 +07)" executed successfully
2026-01-06 12:15:43,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:48 +07)" (scheduled at 2026-01-06 12:15:43.722662+07:00)
2026-01-06 12:15:43,728 - INFO -  Running predictions...
2026-01-06 12:15:44,070 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:44,070 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:48 +07)" executed successfully
2026-01-06 12:15:48,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:53 +07)" (scheduled at 2026-01-06 12:15:48.722662+07:00)
2026-01-06 12:15:48,726 - INFO -  Running predictions...
2026-01-06 12:15:49,119 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:49,119 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:53 +07)" executed successfully
2026-01-06 12:15:53,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:58 +07)" (scheduled at 2026-01-06 12:15:53.722662+07:00)
2026-01-06 12:15:53,725 - INFO -  Running predictions...
2026-01-06 12:15:54,061 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:54,061 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:15:58 +07)" executed successfully
2026-01-06 12:15:58,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:03 +07)" (scheduled at 2026-01-06 12:15:58.722662+07:00)
2026-01-06 12:15:58,729 - INFO -  Running predictions...
2026-01-06 12:15:59,041 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:15:59,041 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:03 +07)" executed successfully
2026-01-06 12:16:03,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:08 +07)" (scheduled at 2026-01-06 12:16:03.722662+07:00)
2026-01-06 12:16:03,734 - INFO -  Running predictions...
2026-01-06 12:16:04,374 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:04,375 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:08 +07)" executed successfully
2026-01-06 12:16:08,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:13 +07)" (scheduled at 2026-01-06 12:16:08.722662+07:00)
2026-01-06 12:16:08,728 - INFO -  Running predictions...
2026-01-06 12:16:09,026 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:09,026 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:13 +07)" executed successfully
2026-01-06 12:16:13,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:18 +07)" (scheduled at 2026-01-06 12:16:13.722662+07:00)
2026-01-06 12:16:13,726 - INFO -  Running predictions...
2026-01-06 12:16:14,072 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:14,072 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:18 +07)" executed successfully
2026-01-06 12:16:18,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:23 +07)" (scheduled at 2026-01-06 12:16:18.722662+07:00)
2026-01-06 12:16:18,728 - INFO -  Running predictions...
2026-01-06 12:16:19,167 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:19,167 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:23 +07)" executed successfully
2026-01-06 12:16:23,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:28 +07)" (scheduled at 2026-01-06 12:16:23.722662+07:00)
2026-01-06 12:16:23,724 - INFO -  Running predictions...
2026-01-06 12:16:24,053 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:24,053 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:28 +07)" executed successfully
2026-01-06 12:16:28,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:33 +07)" (scheduled at 2026-01-06 12:16:28.722662+07:00)
2026-01-06 12:16:28,727 - INFO -  Running predictions...
2026-01-06 12:16:29,054 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:29,055 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:33 +07)" executed successfully
2026-01-06 12:16:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:38 +07)" (scheduled at 2026-01-06 12:16:33.722662+07:00)
2026-01-06 12:16:33,724 - INFO -  Running predictions...
2026-01-06 12:16:34,088 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:34,088 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:38 +07)" executed successfully
2026-01-06 12:16:38,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:43 +07)" (scheduled at 2026-01-06 12:16:38.722662+07:00)
2026-01-06 12:16:38,728 - INFO -  Running predictions...
2026-01-06 12:16:39,103 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:39,103 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:43 +07)" executed successfully
2026-01-06 12:16:43,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:48 +07)" (scheduled at 2026-01-06 12:16:43.722662+07:00)
2026-01-06 12:16:43,735 - INFO -  Running predictions...
2026-01-06 12:16:44,103 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:44,103 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:48 +07)" executed successfully
2026-01-06 12:16:48,743 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:53 +07)" (scheduled at 2026-01-06 12:16:48.722662+07:00)
2026-01-06 12:16:48,744 - INFO -  Running predictions...
2026-01-06 12:16:49,086 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:49,086 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:53 +07)" executed successfully
2026-01-06 12:16:53,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:58 +07)" (scheduled at 2026-01-06 12:16:53.722662+07:00)
2026-01-06 12:16:53,725 - INFO -  Running predictions...
2026-01-06 12:16:54,068 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:54,069 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:16:58 +07)" executed successfully
2026-01-06 12:16:58,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:03 +07)" (scheduled at 2026-01-06 12:16:58.722662+07:00)
2026-01-06 12:16:58,727 - INFO -  Running predictions...
2026-01-06 12:16:59,105 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:16:59,105 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:03 +07)" executed successfully
2026-01-06 12:17:03,734 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:08 +07)" (scheduled at 2026-01-06 12:17:03.722662+07:00)
2026-01-06 12:17:03,735 - INFO -  Running predictions...
2026-01-06 12:17:04,047 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:04,047 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:08 +07)" executed successfully
2026-01-06 12:17:08,745 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:13 +07)" (scheduled at 2026-01-06 12:17:08.722662+07:00)
2026-01-06 12:17:08,745 - INFO -  Running predictions...
2026-01-06 12:17:09,056 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:09,057 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:13 +07)" executed successfully
2026-01-06 12:17:13,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:18 +07)" (scheduled at 2026-01-06 12:17:13.722662+07:00)
2026-01-06 12:17:13,724 - INFO -  Running predictions...
2026-01-06 12:17:14,037 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:14,037 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:18 +07)" executed successfully
2026-01-06 12:17:18,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:23 +07)" (scheduled at 2026-01-06 12:17:18.722662+07:00)
2026-01-06 12:17:18,724 - INFO -  Running predictions...
2026-01-06 12:17:19,075 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:19,075 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:23 +07)" executed successfully
2026-01-06 12:17:23,733 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:28 +07)" (scheduled at 2026-01-06 12:17:23.722662+07:00)
2026-01-06 12:17:23,733 - INFO -  Running predictions...
2026-01-06 12:17:24,072 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:24,072 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:28 +07)" executed successfully
2026-01-06 12:17:28,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:33 +07)" (scheduled at 2026-01-06 12:17:28.722662+07:00)
2026-01-06 12:17:28,728 - INFO -  Running predictions...
2026-01-06 12:17:29,037 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:29,037 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:33 +07)" executed successfully
2026-01-06 12:17:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:38 +07)" (scheduled at 2026-01-06 12:17:33.722662+07:00)
2026-01-06 12:17:33,724 - INFO -  Running predictions...
2026-01-06 12:17:34,127 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:34,127 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:38 +07)" executed successfully
2026-01-06 12:17:38,735 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:43 +07)" (scheduled at 2026-01-06 12:17:38.722662+07:00)
2026-01-06 12:17:38,736 - INFO -  Running predictions...
2026-01-06 12:17:39,059 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:39,059 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:43 +07)" executed successfully
2026-01-06 12:17:43,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:48 +07)" (scheduled at 2026-01-06 12:17:43.722662+07:00)
2026-01-06 12:17:43,723 - INFO -  Running predictions...
2026-01-06 12:17:44,058 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:44,058 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:48 +07)" executed successfully
2026-01-06 12:17:48,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:53 +07)" (scheduled at 2026-01-06 12:17:48.722662+07:00)
2026-01-06 12:17:48,730 - INFO -  Running predictions...
2026-01-06 12:17:49,054 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:49,054 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:53 +07)" executed successfully
2026-01-06 12:17:53,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:58 +07)" (scheduled at 2026-01-06 12:17:53.722662+07:00)
2026-01-06 12:17:53,725 - INFO -  Running predictions...
2026-01-06 12:17:54,140 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:54,140 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:17:58 +07)" executed successfully
2026-01-06 12:17:58,749 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:03 +07)" (scheduled at 2026-01-06 12:17:58.722662+07:00)
2026-01-06 12:17:58,749 - INFO -  Running predictions...
2026-01-06 12:17:59,094 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:17:59,095 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:03 +07)" executed successfully
2026-01-06 12:18:03,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:08 +07)" (scheduled at 2026-01-06 12:18:03.722662+07:00)
2026-01-06 12:18:03,727 - INFO -  Running predictions...
2026-01-06 12:18:04,042 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:04,042 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:08 +07)" executed successfully
2026-01-06 12:18:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:13 +07)" (scheduled at 2026-01-06 12:18:08.722662+07:00)
2026-01-06 12:18:08,724 - INFO -  Running predictions...
2026-01-06 12:18:09,042 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:09,042 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:13 +07)" executed successfully
2026-01-06 12:18:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:18 +07)" (scheduled at 2026-01-06 12:18:13.722662+07:00)
2026-01-06 12:18:13,723 - INFO -  Running predictions...
2026-01-06 12:18:14,055 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:14,055 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:18 +07)" executed successfully
2026-01-06 12:18:18,740 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:23 +07)" (scheduled at 2026-01-06 12:18:18.722662+07:00)
2026-01-06 12:18:18,741 - INFO -  Running predictions...
2026-01-06 12:18:19,089 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:19,090 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:23 +07)" executed successfully
2026-01-06 12:18:23,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:28 +07)" (scheduled at 2026-01-06 12:18:23.722662+07:00)
2026-01-06 12:18:23,730 - INFO -  Running predictions...
2026-01-06 12:18:24,028 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:24,029 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:28 +07)" executed successfully
2026-01-06 12:18:28,741 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:33 +07)" (scheduled at 2026-01-06 12:18:28.722662+07:00)
2026-01-06 12:18:28,741 - INFO -  Running predictions...
2026-01-06 12:18:29,060 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:29,060 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:33 +07)" executed successfully
2026-01-06 12:18:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:38 +07)" (scheduled at 2026-01-06 12:18:33.722662+07:00)
2026-01-06 12:18:33,724 - INFO -  Running predictions...
2026-01-06 12:18:34,127 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:34,127 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:38 +07)" executed successfully
2026-01-06 12:18:38,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:43 +07)" (scheduled at 2026-01-06 12:18:38.722662+07:00)
2026-01-06 12:18:38,730 - INFO -  Running predictions...
2026-01-06 12:18:39,071 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:39,071 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:43 +07)" executed successfully
2026-01-06 12:18:43,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:48 +07)" (scheduled at 2026-01-06 12:18:43.722662+07:00)
2026-01-06 12:18:43,726 - INFO -  Running predictions...
2026-01-06 12:18:44,053 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:44,053 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:48 +07)" executed successfully
2026-01-06 12:18:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:53 +07)" (scheduled at 2026-01-06 12:18:48.722662+07:00)
2026-01-06 12:18:48,725 - INFO -  Running predictions...
2026-01-06 12:18:49,054 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:49,055 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:53 +07)" executed successfully
2026-01-06 12:18:53,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:58 +07)" (scheduled at 2026-01-06 12:18:53.722662+07:00)
2026-01-06 12:18:53,724 - INFO -  Running predictions...
2026-01-06 12:18:54,083 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:54,083 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:18:58 +07)" executed successfully
2026-01-06 12:18:58,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:03 +07)" (scheduled at 2026-01-06 12:18:58.722662+07:00)
2026-01-06 12:18:58,726 - INFO -  Running predictions...
2026-01-06 12:18:59,067 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:18:59,068 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:03 +07)" executed successfully
2026-01-06 12:19:03,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:08 +07)" (scheduled at 2026-01-06 12:19:03.722662+07:00)
2026-01-06 12:19:03,723 - INFO -  Running predictions...
2026-01-06 12:19:04,055 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:04,056 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:08 +07)" executed successfully
2026-01-06 12:19:08,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:13 +07)" (scheduled at 2026-01-06 12:19:08.722662+07:00)
2026-01-06 12:19:08,723 - INFO -  Running predictions...
2026-01-06 12:19:09,051 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:09,051 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:13 +07)" executed successfully
2026-01-06 12:19:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:18 +07)" (scheduled at 2026-01-06 12:19:13.722662+07:00)
2026-01-06 12:19:13,723 - INFO -  Running predictions...
2026-01-06 12:19:14,059 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:14,059 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:18 +07)" executed successfully
2026-01-06 12:19:18,739 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:23 +07)" (scheduled at 2026-01-06 12:19:18.722662+07:00)
2026-01-06 12:19:18,740 - INFO -  Running predictions...
2026-01-06 12:19:19,106 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:19,106 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:23 +07)" executed successfully
2026-01-06 12:19:23,744 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:28 +07)" (scheduled at 2026-01-06 12:19:23.722662+07:00)
2026-01-06 12:19:23,745 - INFO -  Running predictions...
2026-01-06 12:19:24,083 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:24,083 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:28 +07)" executed successfully
2026-01-06 12:19:28,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:33 +07)" (scheduled at 2026-01-06 12:19:28.722662+07:00)
2026-01-06 12:19:28,725 - INFO -  Running predictions...
2026-01-06 12:19:29,037 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:29,037 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:33 +07)" executed successfully
2026-01-06 12:19:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:38 +07)" (scheduled at 2026-01-06 12:19:33.722662+07:00)
2026-01-06 12:19:33,724 - INFO -  Running predictions...
2026-01-06 12:19:34,132 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:34,132 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:38 +07)" executed successfully
2026-01-06 12:19:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:43 +07)" (scheduled at 2026-01-06 12:19:38.722662+07:00)
2026-01-06 12:19:38,723 - INFO -  Running predictions...
2026-01-06 12:19:39,046 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:39,046 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:43 +07)" executed successfully
2026-01-06 12:19:43,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:48 +07)" (scheduled at 2026-01-06 12:19:43.722662+07:00)
2026-01-06 12:19:43,725 - INFO -  Running predictions...
2026-01-06 12:19:44,058 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:44,058 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:48 +07)" executed successfully
2026-01-06 12:19:48,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:53 +07)" (scheduled at 2026-01-06 12:19:48.722662+07:00)
2026-01-06 12:19:48,729 - INFO -  Running predictions...
2026-01-06 12:19:49,054 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:49,055 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:53 +07)" executed successfully
2026-01-06 12:19:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:58 +07)" (scheduled at 2026-01-06 12:19:53.722662+07:00)
2026-01-06 12:19:53,723 - INFO -  Running predictions...
2026-01-06 12:19:54,090 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:54,091 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:19:58 +07)" executed successfully
2026-01-06 12:19:58,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:03 +07)" (scheduled at 2026-01-06 12:19:58.722662+07:00)
2026-01-06 12:19:58,723 - INFO -  Running predictions...
2026-01-06 12:19:59,133 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:19:59,133 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:03 +07)" executed successfully
2026-01-06 12:20:03,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:08 +07)" (scheduled at 2026-01-06 12:20:03.722662+07:00)
2026-01-06 12:20:03,723 - INFO -  Running predictions...
2026-01-06 12:20:04,213 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:04,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:08 +07)" executed successfully
2026-01-06 12:20:08,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:13 +07)" (scheduled at 2026-01-06 12:20:08.722662+07:00)
2026-01-06 12:20:08,727 - INFO -  Running predictions...
2026-01-06 12:20:09,073 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:09,073 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:13 +07)" executed successfully
2026-01-06 12:20:13,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:18 +07)" (scheduled at 2026-01-06 12:20:13.722662+07:00)
2026-01-06 12:20:13,724 - INFO -  Running predictions...
2026-01-06 12:20:14,084 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:14,084 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:18 +07)" executed successfully
2026-01-06 12:20:18,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:23 +07)" (scheduled at 2026-01-06 12:20:18.722662+07:00)
2026-01-06 12:20:18,726 - INFO -  Running predictions...
2026-01-06 12:20:19,045 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:19,045 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:23 +07)" executed successfully
2026-01-06 12:20:23,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:28 +07)" (scheduled at 2026-01-06 12:20:23.722662+07:00)
2026-01-06 12:20:23,725 - INFO -  Running predictions...
2026-01-06 12:20:24,159 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:24,159 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:28 +07)" executed successfully
2026-01-06 12:20:28,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:33 +07)" (scheduled at 2026-01-06 12:20:28.722662+07:00)
2026-01-06 12:20:28,724 - INFO -  Running predictions...
2026-01-06 12:20:29,088 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:29,089 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:33 +07)" executed successfully
2026-01-06 12:20:33,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:38 +07)" (scheduled at 2026-01-06 12:20:33.722662+07:00)
2026-01-06 12:20:33,725 - INFO -  Running predictions...
2026-01-06 12:20:34,243 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:34,243 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:38 +07)" executed successfully
2026-01-06 12:20:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:43 +07)" (scheduled at 2026-01-06 12:20:38.722662+07:00)
2026-01-06 12:20:38,723 - INFO -  Running predictions...
2026-01-06 12:20:39,111 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:39,112 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:43 +07)" executed successfully
2026-01-06 12:20:43,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:48 +07)" (scheduled at 2026-01-06 12:20:43.722662+07:00)
2026-01-06 12:20:43,723 - INFO -  Running predictions...
2026-01-06 12:20:44,303 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:44,303 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:48 +07)" executed successfully
2026-01-06 12:20:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:53 +07)" (scheduled at 2026-01-06 12:20:48.722662+07:00)
2026-01-06 12:20:48,724 - INFO -  Running predictions...
2026-01-06 12:20:49,204 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:49,205 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:53 +07)" executed successfully
2026-01-06 12:20:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:58 +07)" (scheduled at 2026-01-06 12:20:53.722662+07:00)
2026-01-06 12:20:53,723 - INFO -  Running predictions...
2026-01-06 12:20:54,189 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:54,189 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:20:58 +07)" executed successfully
2026-01-06 12:20:58,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:03 +07)" (scheduled at 2026-01-06 12:20:58.722662+07:00)
2026-01-06 12:20:58,725 - INFO -  Running predictions...
2026-01-06 12:20:59,027 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:20:59,027 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:03 +07)" executed successfully
2026-01-06 12:21:03,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:08 +07)" (scheduled at 2026-01-06 12:21:03.722662+07:00)
2026-01-06 12:21:03,724 - INFO -  Running predictions...
2026-01-06 12:21:04,028 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:04,028 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:08 +07)" executed successfully
2026-01-06 12:21:08,739 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:13 +07)" (scheduled at 2026-01-06 12:21:08.722662+07:00)
2026-01-06 12:21:08,739 - INFO -  Running predictions...
2026-01-06 12:21:09,129 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:09,130 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:13 +07)" executed successfully
2026-01-06 12:21:13,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:18 +07)" (scheduled at 2026-01-06 12:21:13.722662+07:00)
2026-01-06 12:21:13,725 - INFO -  Running predictions...
2026-01-06 12:21:14,059 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:14,059 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:18 +07)" executed successfully
2026-01-06 12:21:18,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:23 +07)" (scheduled at 2026-01-06 12:21:18.722662+07:00)
2026-01-06 12:21:18,729 - INFO -  Running predictions...
2026-01-06 12:21:19,038 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:19,038 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:23 +07)" executed successfully
2026-01-06 12:21:23,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:28 +07)" (scheduled at 2026-01-06 12:21:23.722662+07:00)
2026-01-06 12:21:23,724 - INFO -  Running predictions...
2026-01-06 12:21:24,027 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:24,027 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:28 +07)" executed successfully
2026-01-06 12:21:28,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:33 +07)" (scheduled at 2026-01-06 12:21:28.722662+07:00)
2026-01-06 12:21:28,730 - INFO -  Running predictions...
2026-01-06 12:21:29,081 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:29,081 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:33 +07)" executed successfully
2026-01-06 12:21:33,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:38 +07)" (scheduled at 2026-01-06 12:21:33.722662+07:00)
2026-01-06 12:21:33,725 - INFO -  Running predictions...
2026-01-06 12:21:34,068 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:34,068 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:38 +07)" executed successfully
2026-01-06 12:21:38,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:43 +07)" (scheduled at 2026-01-06 12:21:38.722662+07:00)
2026-01-06 12:21:38,723 - INFO -  Running predictions...
2026-01-06 12:21:39,055 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:39,055 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:43 +07)" executed successfully
2026-01-06 12:21:43,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:48 +07)" (scheduled at 2026-01-06 12:21:43.722662+07:00)
2026-01-06 12:21:43,726 - INFO -  Running predictions...
2026-01-06 12:21:44,062 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:44,062 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:48 +07)" executed successfully
2026-01-06 12:21:48,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:53 +07)" (scheduled at 2026-01-06 12:21:48.722662+07:00)
2026-01-06 12:21:48,729 - INFO -  Running predictions...
2026-01-06 12:21:49,111 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:49,111 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:53 +07)" executed successfully
2026-01-06 12:21:53,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:58 +07)" (scheduled at 2026-01-06 12:21:53.722662+07:00)
2026-01-06 12:21:53,725 - INFO -  Running predictions...
2026-01-06 12:21:54,058 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:54,058 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:21:58 +07)" executed successfully
2026-01-06 12:21:58,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:03 +07)" (scheduled at 2026-01-06 12:21:58.722662+07:00)
2026-01-06 12:21:58,725 - INFO -  Running predictions...
2026-01-06 12:21:59,048 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:21:59,048 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:03 +07)" executed successfully
2026-01-06 12:22:03,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:08 +07)" (scheduled at 2026-01-06 12:22:03.722662+07:00)
2026-01-06 12:22:03,726 - INFO -  Running predictions...
2026-01-06 12:22:04,062 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:04,062 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:08 +07)" executed successfully
2026-01-06 12:22:08,738 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:13 +07)" (scheduled at 2026-01-06 12:22:08.722662+07:00)
2026-01-06 12:22:08,738 - INFO -  Running predictions...
2026-01-06 12:22:09,115 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:09,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:13 +07)" executed successfully
2026-01-06 12:22:13,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:18 +07)" (scheduled at 2026-01-06 12:22:13.722662+07:00)
2026-01-06 12:22:13,725 - INFO -  Running predictions...
2026-01-06 12:22:14,054 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:14,054 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:18 +07)" executed successfully
2026-01-06 12:22:18,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:23 +07)" (scheduled at 2026-01-06 12:22:18.722662+07:00)
2026-01-06 12:22:18,724 - INFO -  Running predictions...
2026-01-06 12:22:19,055 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:19,056 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:23 +07)" executed successfully
2026-01-06 12:22:23,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:28 +07)" (scheduled at 2026-01-06 12:22:23.722662+07:00)
2026-01-06 12:22:23,729 - INFO -  Running predictions...
2026-01-06 12:22:24,080 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:24,080 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:28 +07)" executed successfully
2026-01-06 12:22:28,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:33 +07)" (scheduled at 2026-01-06 12:22:28.722662+07:00)
2026-01-06 12:22:28,723 - INFO -  Running predictions...
2026-01-06 12:22:29,076 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:29,077 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:33 +07)" executed successfully
2026-01-06 12:22:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:38 +07)" (scheduled at 2026-01-06 12:22:33.722662+07:00)
2026-01-06 12:22:33,723 - INFO -  Running predictions...
2026-01-06 12:22:34,036 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:34,036 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:38 +07)" executed successfully
2026-01-06 12:22:38,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:43 +07)" (scheduled at 2026-01-06 12:22:38.722662+07:00)
2026-01-06 12:22:38,724 - INFO -  Running predictions...
2026-01-06 12:22:39,141 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:39,141 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:43 +07)" executed successfully
2026-01-06 12:22:43,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:48 +07)" (scheduled at 2026-01-06 12:22:43.722662+07:00)
2026-01-06 12:22:43,723 - INFO -  Running predictions...
2026-01-06 12:22:44,080 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:44,080 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:48 +07)" executed successfully
2026-01-06 12:22:48,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:53 +07)" (scheduled at 2026-01-06 12:22:48.722662+07:00)
2026-01-06 12:22:48,724 - INFO -  Running predictions...
2026-01-06 12:22:49,126 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:49,126 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:53 +07)" executed successfully
2026-01-06 12:22:53,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:58 +07)" (scheduled at 2026-01-06 12:22:53.722662+07:00)
2026-01-06 12:22:53,723 - INFO -  Running predictions...
2026-01-06 12:22:54,124 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:54,124 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:22:58 +07)" executed successfully
2026-01-06 12:22:58,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:03 +07)" (scheduled at 2026-01-06 12:22:58.722662+07:00)
2026-01-06 12:22:58,723 - INFO -  Running predictions...
2026-01-06 12:22:59,115 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:22:59,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:03 +07)" executed successfully
2026-01-06 12:23:03,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:08 +07)" (scheduled at 2026-01-06 12:23:03.722662+07:00)
2026-01-06 12:23:03,724 - INFO -  Running predictions...
2026-01-06 12:23:04,090 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:04,090 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:08 +07)" executed successfully
2026-01-06 12:23:08,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:13 +07)" (scheduled at 2026-01-06 12:23:08.722662+07:00)
2026-01-06 12:23:08,724 - INFO -  Running predictions...
2026-01-06 12:23:09,150 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:09,151 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:13 +07)" executed successfully
2026-01-06 12:23:13,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:18 +07)" (scheduled at 2026-01-06 12:23:13.722662+07:00)
2026-01-06 12:23:13,725 - INFO -  Running predictions...
2026-01-06 12:23:14,081 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:14,082 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:18 +07)" executed successfully
2026-01-06 12:23:18,731 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:23 +07)" (scheduled at 2026-01-06 12:23:18.722662+07:00)
2026-01-06 12:23:18,731 - INFO -  Running predictions...
2026-01-06 12:23:19,130 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:19,131 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:23 +07)" executed successfully
2026-01-06 12:23:23,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:28 +07)" (scheduled at 2026-01-06 12:23:23.722662+07:00)
2026-01-06 12:23:23,724 - INFO -  Running predictions...
2026-01-06 12:23:24,076 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:24,076 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:28 +07)" executed successfully
2026-01-06 12:23:28,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:33 +07)" (scheduled at 2026-01-06 12:23:28.722662+07:00)
2026-01-06 12:23:28,725 - INFO -  Running predictions...
2026-01-06 12:23:29,095 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:29,095 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:33 +07)" executed successfully
2026-01-06 12:23:33,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:38 +07)" (scheduled at 2026-01-06 12:23:33.722662+07:00)
2026-01-06 12:23:33,723 - INFO -  Running predictions...
2026-01-06 12:23:34,080 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:34,081 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:38 +07)" executed successfully
2026-01-06 12:23:38,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:43 +07)" (scheduled at 2026-01-06 12:23:38.722662+07:00)
2026-01-06 12:23:38,724 - INFO -  Running predictions...
2026-01-06 12:23:39,232 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:39,233 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:43 +07)" executed successfully
2026-01-06 12:23:43,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:48 +07)" (scheduled at 2026-01-06 12:23:43.722662+07:00)
2026-01-06 12:23:43,724 - INFO -  Running predictions...
2026-01-06 12:23:44,104 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:44,105 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:48 +07)" executed successfully
2026-01-06 12:23:48,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:53 +07)" (scheduled at 2026-01-06 12:23:48.722662+07:00)
2026-01-06 12:23:48,724 - INFO -  Running predictions...
2026-01-06 12:23:49,089 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:49,089 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:53 +07)" executed successfully
2026-01-06 12:23:53,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:58 +07)" (scheduled at 2026-01-06 12:23:53.722662+07:00)
2026-01-06 12:23:53,726 - INFO -  Running predictions...
2026-01-06 12:23:54,239 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:54,239 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:23:58 +07)" executed successfully
2026-01-06 12:23:58,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:03 +07)" (scheduled at 2026-01-06 12:23:58.722662+07:00)
2026-01-06 12:23:58,727 - INFO -  Running predictions...
2026-01-06 12:23:59,115 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:23:59,115 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:03 +07)" executed successfully
2026-01-06 12:24:03,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:08 +07)" (scheduled at 2026-01-06 12:24:03.722662+07:00)
2026-01-06 12:24:03,725 - INFO -  Running predictions...
2026-01-06 12:24:04,308 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:24:04,309 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:08 +07)" executed successfully
2026-01-06 12:24:08,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:13 +07)" (scheduled at 2026-01-06 12:24:08.722662+07:00)
2026-01-06 12:24:08,724 - INFO -  Running predictions...
2026-01-06 12:24:09,182 - INFO - ‚úì Predictions saved for 5 roads
2026-01-06 12:24:09,182 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:24:13 +07)" executed successfully
2026-01-06 12:29:04,405 - INFO -  Initializing PySpark Session...
2026-01-06 12:29:08,125 - INFO - ‚úì Spark Session Created!
2026-01-06 12:29:08,125 - INFO - Starting Spark Prediction Service (predictions interval: 5s, training interval: 60s)...
2026-01-06 12:29:08,157 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:29:08,157 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:29:08,161 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 12:29:08,161 - INFO - Added job "SparkPredictionService.train_model" to job store "default"
2026-01-06 12:29:08,161 - INFO - Scheduler started
2026-01-06 12:29:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:13 +07)" (scheduled at 2026-01-06 12:29:13.157382+07:00)
2026-01-06 12:29:13,158 - INFO -  Training Spark model...
2026-01-06 12:29:16,502 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_change#160, vehicle_count_lag#178, vehicle_count_change#197, avg(speed#18) windowspecdefinition(road_id#4, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#218]
+- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_change#160, vehicle_count_lag#178, CASE WHEN isnotnull(vehicle_count_lag#178) THEN (vehicle_count#28 - vehicle_count_lag#178) ELSE 0.0 END AS vehicle_count_change#197]
   +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_change#160, vehicle_count_lag#178]
      +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_change#160, vehicle_count_lag#178, vehicle_count_lag#178]
         +- Window [lag(vehicle_count#28, -1, null) windowspecdefinition(road_id#4, timestamp#7 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#178], [road_id#4], [timestamp#7 ASC NULLS FIRST]
            +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_change#160]
               +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, CASE WHEN isnotnull(speed_lag#143) THEN (speed#18 - speed_lag#143) ELSE 0.0 END AS speed_change#160]
                  +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143]
                     +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127, speed_lag#143, speed_lag#143]
                        +- Window [lag(speed#18, -1, null) windowspecdefinition(road_id#4, timestamp#7 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#143], [road_id#4], [timestamp#7 ASC NULLS FIRST]
                           +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, hour_cos#127]
                              +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, hour_sin#112, COS((0.2617993877991494 * cast(hour#62 as double))) AS hour_cos#127]
                                 +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, is_weekend#98, SIN((0.2617993877991494 * cast(hour#62 as double))) AS hour_sin#112]
                                    +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, day_of_week#85, CASE WHEN day_of_week#85 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#98]
                                       +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, is_peak#73, dayofweek(cast(timestamp#7 as date)) AS day_of_week#85]
                                          +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour#62, CASE WHEN hour#62 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#73]
                                             +- Project [_id#0, congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28, hour(timestamp#7, Some(Asia/Bangkok)) AS hour#62]
                                                +- Project [_id#0, cast(congestion_level#1 as double) AS congestion_level#38, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, vehicle_count#28]
                                                   +- Project [_id#0, congestion_level#1, lat#2, lon#3, road_id#4, road_name#5, speed#18, timestamp#7, cast(vehicle_count#8 as double) AS vehicle_count#28]
                                                      +- Project [_id#0, congestion_level#1, lat#2, lon#3, road_id#4, road_name#5, cast(speed#6 as double) AS speed#18, timestamp#7, vehicle_count#8]
                                                         +- Relation [_id#0,congestion_level#1,lat#2,lon#3,road_id#4,road_name#5,speed#6,timestamp#7,vehicle_count#8] MongoRelation(MongoRDD[0] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:16,502 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:18 +07)" executed successfully
2026-01-06 12:29:18,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:23 +07)" (scheduled at 2026-01-06 12:29:18.157382+07:00)
2026-01-06 12:29:18,160 - INFO -  Training Spark model...
2026-01-06 12:29:18,594 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_change#379, vehicle_count_lag#397, vehicle_count_change#416, avg(speed#237) windowspecdefinition(road_id#223, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#437]
+- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_change#379, vehicle_count_lag#397, CASE WHEN isnotnull(vehicle_count_lag#397) THEN (vehicle_count#247 - vehicle_count_lag#397) ELSE 0.0 END AS vehicle_count_change#416]
   +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_change#379, vehicle_count_lag#397]
      +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_change#379, vehicle_count_lag#397, vehicle_count_lag#397]
         +- Window [lag(vehicle_count#247, -1, null) windowspecdefinition(road_id#223, timestamp#226 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#397], [road_id#223], [timestamp#226 ASC NULLS FIRST]
            +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_change#379]
               +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, CASE WHEN isnotnull(speed_lag#362) THEN (speed#237 - speed_lag#362) ELSE 0.0 END AS speed_change#379]
                  +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362]
                     +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346, speed_lag#362, speed_lag#362]
                        +- Window [lag(speed#237, -1, null) windowspecdefinition(road_id#223, timestamp#226 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#362], [road_id#223], [timestamp#226 ASC NULLS FIRST]
                           +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, hour_cos#346]
                              +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, hour_sin#331, COS((0.2617993877991494 * cast(hour#281 as double))) AS hour_cos#346]
                                 +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, is_weekend#317, SIN((0.2617993877991494 * cast(hour#281 as double))) AS hour_sin#331]
                                    +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, day_of_week#304, CASE WHEN day_of_week#304 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#317]
                                       +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, is_peak#292, dayofweek(cast(timestamp#226 as date)) AS day_of_week#304]
                                          +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour#281, CASE WHEN hour#281 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#292]
                                             +- Project [_id#219, congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247, hour(timestamp#226, Some(Asia/Bangkok)) AS hour#281]
                                                +- Project [_id#219, cast(congestion_level#220 as double) AS congestion_level#257, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, vehicle_count#247]
                                                   +- Project [_id#219, congestion_level#220, lat#221, lon#222, road_id#223, road_name#224, speed#237, timestamp#226, cast(vehicle_count#227 as double) AS vehicle_count#247]
                                                      +- Project [_id#219, congestion_level#220, lat#221, lon#222, road_id#223, road_name#224, cast(speed#225 as double) AS speed#237, timestamp#226, vehicle_count#227]
                                                         +- Relation [_id#219,congestion_level#220,lat#221,lon#222,road_id#223,road_name#224,speed#225,timestamp#226,vehicle_count#227] MongoRelation(MongoRDD[13] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:18,595 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:23 +07)" executed successfully
2026-01-06 12:29:23,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:28 +07)" (scheduled at 2026-01-06 12:29:23.157382+07:00)
2026-01-06 12:29:23,163 - INFO -  Training Spark model...
2026-01-06 12:29:23,565 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_change#598, vehicle_count_lag#616, vehicle_count_change#635, avg(speed#456) windowspecdefinition(road_id#442, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#656]
+- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_change#598, vehicle_count_lag#616, CASE WHEN isnotnull(vehicle_count_lag#616) THEN (vehicle_count#466 - vehicle_count_lag#616) ELSE 0.0 END AS vehicle_count_change#635]
   +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_change#598, vehicle_count_lag#616]
      +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_change#598, vehicle_count_lag#616, vehicle_count_lag#616]
         +- Window [lag(vehicle_count#466, -1, null) windowspecdefinition(road_id#442, timestamp#445 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#616], [road_id#442], [timestamp#445 ASC NULLS FIRST]
            +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_change#598]
               +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, CASE WHEN isnotnull(speed_lag#581) THEN (speed#456 - speed_lag#581) ELSE 0.0 END AS speed_change#598]
                  +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581]
                     +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565, speed_lag#581, speed_lag#581]
                        +- Window [lag(speed#456, -1, null) windowspecdefinition(road_id#442, timestamp#445 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#581], [road_id#442], [timestamp#445 ASC NULLS FIRST]
                           +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, hour_cos#565]
                              +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, hour_sin#550, COS((0.2617993877991494 * cast(hour#500 as double))) AS hour_cos#565]
                                 +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, is_weekend#536, SIN((0.2617993877991494 * cast(hour#500 as double))) AS hour_sin#550]
                                    +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, day_of_week#523, CASE WHEN day_of_week#523 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#536]
                                       +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, is_peak#511, dayofweek(cast(timestamp#445 as date)) AS day_of_week#523]
                                          +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour#500, CASE WHEN hour#500 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#511]
                                             +- Project [_id#438, congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466, hour(timestamp#445, Some(Asia/Bangkok)) AS hour#500]
                                                +- Project [_id#438, cast(congestion_level#439 as double) AS congestion_level#476, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, vehicle_count#466]
                                                   +- Project [_id#438, congestion_level#439, lat#440, lon#441, road_id#442, road_name#443, speed#456, timestamp#445, cast(vehicle_count#446 as double) AS vehicle_count#466]
                                                      +- Project [_id#438, congestion_level#439, lat#440, lon#441, road_id#442, road_name#443, cast(speed#444 as double) AS speed#456, timestamp#445, vehicle_count#446]
                                                         +- Relation [_id#438,congestion_level#439,lat#440,lon#441,road_id#442,road_name#443,speed#444,timestamp#445,vehicle_count#446] MongoRelation(MongoRDD[26] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:23,565 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:28 +07)" executed successfully
2026-01-06 12:29:28,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:33 +07)" (scheduled at 2026-01-06 12:29:28.157382+07:00)
2026-01-06 12:29:28,158 - INFO -  Training Spark model...
2026-01-06 12:29:28,573 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_change#817, vehicle_count_lag#835, vehicle_count_change#854, avg(speed#675) windowspecdefinition(road_id#661, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#875]
+- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_change#817, vehicle_count_lag#835, CASE WHEN isnotnull(vehicle_count_lag#835) THEN (vehicle_count#685 - vehicle_count_lag#835) ELSE 0.0 END AS vehicle_count_change#854]
   +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_change#817, vehicle_count_lag#835]
      +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_change#817, vehicle_count_lag#835, vehicle_count_lag#835]
         +- Window [lag(vehicle_count#685, -1, null) windowspecdefinition(road_id#661, timestamp#664 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#835], [road_id#661], [timestamp#664 ASC NULLS FIRST]
            +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_change#817]
               +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, CASE WHEN isnotnull(speed_lag#800) THEN (speed#675 - speed_lag#800) ELSE 0.0 END AS speed_change#817]
                  +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800]
                     +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784, speed_lag#800, speed_lag#800]
                        +- Window [lag(speed#675, -1, null) windowspecdefinition(road_id#661, timestamp#664 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#800], [road_id#661], [timestamp#664 ASC NULLS FIRST]
                           +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, hour_cos#784]
                              +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, hour_sin#769, COS((0.2617993877991494 * cast(hour#719 as double))) AS hour_cos#784]
                                 +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, is_weekend#755, SIN((0.2617993877991494 * cast(hour#719 as double))) AS hour_sin#769]
                                    +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, day_of_week#742, CASE WHEN day_of_week#742 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#755]
                                       +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, is_peak#730, dayofweek(cast(timestamp#664 as date)) AS day_of_week#742]
                                          +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour#719, CASE WHEN hour#719 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#730]
                                             +- Project [_id#657, congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685, hour(timestamp#664, Some(Asia/Bangkok)) AS hour#719]
                                                +- Project [_id#657, cast(congestion_level#658 as double) AS congestion_level#695, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, vehicle_count#685]
                                                   +- Project [_id#657, congestion_level#658, lat#659, lon#660, road_id#661, road_name#662, speed#675, timestamp#664, cast(vehicle_count#665 as double) AS vehicle_count#685]
                                                      +- Project [_id#657, congestion_level#658, lat#659, lon#660, road_id#661, road_name#662, cast(speed#663 as double) AS speed#675, timestamp#664, vehicle_count#665]
                                                         +- Relation [_id#657,congestion_level#658,lat#659,lon#660,road_id#661,road_name#662,speed#663,timestamp#664,vehicle_count#665] MongoRelation(MongoRDD[39] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:28,573 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:33 +07)" executed successfully
2026-01-06 12:29:33,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:38 +07)" (scheduled at 2026-01-06 12:29:33.157382+07:00)
2026-01-06 12:29:33,160 - INFO -  Training Spark model...
2026-01-06 12:29:33,498 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_change#1036, vehicle_count_lag#1054, vehicle_count_change#1073, avg(speed#894) windowspecdefinition(road_id#880, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#1094]
+- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_change#1036, vehicle_count_lag#1054, CASE WHEN isnotnull(vehicle_count_lag#1054) THEN (vehicle_count#904 - vehicle_count_lag#1054) ELSE 0.0 END AS vehicle_count_change#1073]
   +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_change#1036, vehicle_count_lag#1054]
      +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_change#1036, vehicle_count_lag#1054, vehicle_count_lag#1054]
         +- Window [lag(vehicle_count#904, -1, null) windowspecdefinition(road_id#880, timestamp#883 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#1054], [road_id#880], [timestamp#883 ASC NULLS FIRST]
            +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_change#1036]
               +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, CASE WHEN isnotnull(speed_lag#1019) THEN (speed#894 - speed_lag#1019) ELSE 0.0 END AS speed_change#1036]
                  +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019]
                     +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003, speed_lag#1019, speed_lag#1019]
                        +- Window [lag(speed#894, -1, null) windowspecdefinition(road_id#880, timestamp#883 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#1019], [road_id#880], [timestamp#883 ASC NULLS FIRST]
                           +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, hour_cos#1003]
                              +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, hour_sin#988, COS((0.2617993877991494 * cast(hour#938 as double))) AS hour_cos#1003]
                                 +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, is_weekend#974, SIN((0.2617993877991494 * cast(hour#938 as double))) AS hour_sin#988]
                                    +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, day_of_week#961, CASE WHEN day_of_week#961 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#974]
                                       +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, is_peak#949, dayofweek(cast(timestamp#883 as date)) AS day_of_week#961]
                                          +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour#938, CASE WHEN hour#938 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#949]
                                             +- Project [_id#876, congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904, hour(timestamp#883, Some(Asia/Bangkok)) AS hour#938]
                                                +- Project [_id#876, cast(congestion_level#877 as double) AS congestion_level#914, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, vehicle_count#904]
                                                   +- Project [_id#876, congestion_level#877, lat#878, lon#879, road_id#880, road_name#881, speed#894, timestamp#883, cast(vehicle_count#884 as double) AS vehicle_count#904]
                                                      +- Project [_id#876, congestion_level#877, lat#878, lon#879, road_id#880, road_name#881, cast(speed#882 as double) AS speed#894, timestamp#883, vehicle_count#884]
                                                         +- Relation [_id#876,congestion_level#877,lat#878,lon#879,road_id#880,road_name#881,speed#882,timestamp#883,vehicle_count#884] MongoRelation(MongoRDD[52] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:33,498 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:38 +07)" executed successfully
2026-01-06 12:29:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:43 +07)" (scheduled at 2026-01-06 12:29:38.157382+07:00)
2026-01-06 12:29:38,158 - INFO -  Training Spark model...
2026-01-06 12:29:38,668 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_change#1255, vehicle_count_lag#1273, vehicle_count_change#1292, avg(speed#1113) windowspecdefinition(road_id#1099, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#1313]
+- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_change#1255, vehicle_count_lag#1273, CASE WHEN isnotnull(vehicle_count_lag#1273) THEN (vehicle_count#1123 - vehicle_count_lag#1273) ELSE 0.0 END AS vehicle_count_change#1292]
   +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_change#1255, vehicle_count_lag#1273]
      +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_change#1255, vehicle_count_lag#1273, vehicle_count_lag#1273]
         +- Window [lag(vehicle_count#1123, -1, null) windowspecdefinition(road_id#1099, timestamp#1102 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#1273], [road_id#1099], [timestamp#1102 ASC NULLS FIRST]
            +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_change#1255]
               +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, CASE WHEN isnotnull(speed_lag#1238) THEN (speed#1113 - speed_lag#1238) ELSE 0.0 END AS speed_change#1255]
                  +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238]
                     +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222, speed_lag#1238, speed_lag#1238]
                        +- Window [lag(speed#1113, -1, null) windowspecdefinition(road_id#1099, timestamp#1102 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#1238], [road_id#1099], [timestamp#1102 ASC NULLS FIRST]
                           +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, hour_cos#1222]
                              +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, hour_sin#1207, COS((0.2617993877991494 * cast(hour#1157 as double))) AS hour_cos#1222]
                                 +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, is_weekend#1193, SIN((0.2617993877991494 * cast(hour#1157 as double))) AS hour_sin#1207]
                                    +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, day_of_week#1180, CASE WHEN day_of_week#1180 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#1193]
                                       +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, is_peak#1168, dayofweek(cast(timestamp#1102 as date)) AS day_of_week#1180]
                                          +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour#1157, CASE WHEN hour#1157 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#1168]
                                             +- Project [_id#1095, congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123, hour(timestamp#1102, Some(Asia/Bangkok)) AS hour#1157]
                                                +- Project [_id#1095, cast(congestion_level#1096 as double) AS congestion_level#1133, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, vehicle_count#1123]
                                                   +- Project [_id#1095, congestion_level#1096, lat#1097, lon#1098, road_id#1099, road_name#1100, speed#1113, timestamp#1102, cast(vehicle_count#1103 as double) AS vehicle_count#1123]
                                                      +- Project [_id#1095, congestion_level#1096, lat#1097, lon#1098, road_id#1099, road_name#1100, cast(speed#1101 as double) AS speed#1113, timestamp#1102, vehicle_count#1103]
                                                         +- Relation [_id#1095,congestion_level#1096,lat#1097,lon#1098,road_id#1099,road_name#1100,speed#1101,timestamp#1102,vehicle_count#1103] MongoRelation(MongoRDD[65] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:38,668 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:43 +07)" executed successfully
2026-01-06 12:29:43,180 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:48 +07)" (scheduled at 2026-01-06 12:29:43.157382+07:00)
2026-01-06 12:29:43,181 - INFO -  Training Spark model...
2026-01-06 12:29:43,568 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_change#1474, vehicle_count_lag#1492, vehicle_count_change#1511, avg(speed#1332) windowspecdefinition(road_id#1318, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#1532]
+- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_change#1474, vehicle_count_lag#1492, CASE WHEN isnotnull(vehicle_count_lag#1492) THEN (vehicle_count#1342 - vehicle_count_lag#1492) ELSE 0.0 END AS vehicle_count_change#1511]
   +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_change#1474, vehicle_count_lag#1492]
      +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_change#1474, vehicle_count_lag#1492, vehicle_count_lag#1492]
         +- Window [lag(vehicle_count#1342, -1, null) windowspecdefinition(road_id#1318, timestamp#1321 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#1492], [road_id#1318], [timestamp#1321 ASC NULLS FIRST]
            +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_change#1474]
               +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, CASE WHEN isnotnull(speed_lag#1457) THEN (speed#1332 - speed_lag#1457) ELSE 0.0 END AS speed_change#1474]
                  +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457]
                     +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441, speed_lag#1457, speed_lag#1457]
                        +- Window [lag(speed#1332, -1, null) windowspecdefinition(road_id#1318, timestamp#1321 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#1457], [road_id#1318], [timestamp#1321 ASC NULLS FIRST]
                           +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, hour_cos#1441]
                              +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, hour_sin#1426, COS((0.2617993877991494 * cast(hour#1376 as double))) AS hour_cos#1441]
                                 +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, is_weekend#1412, SIN((0.2617993877991494 * cast(hour#1376 as double))) AS hour_sin#1426]
                                    +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, day_of_week#1399, CASE WHEN day_of_week#1399 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#1412]
                                       +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, is_peak#1387, dayofweek(cast(timestamp#1321 as date)) AS day_of_week#1399]
                                          +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour#1376, CASE WHEN hour#1376 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#1387]
                                             +- Project [_id#1314, congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342, hour(timestamp#1321, Some(Asia/Bangkok)) AS hour#1376]
                                                +- Project [_id#1314, cast(congestion_level#1315 as double) AS congestion_level#1352, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, vehicle_count#1342]
                                                   +- Project [_id#1314, congestion_level#1315, lat#1316, lon#1317, road_id#1318, road_name#1319, speed#1332, timestamp#1321, cast(vehicle_count#1322 as double) AS vehicle_count#1342]
                                                      +- Project [_id#1314, congestion_level#1315, lat#1316, lon#1317, road_id#1318, road_name#1319, cast(speed#1320 as double) AS speed#1332, timestamp#1321, vehicle_count#1322]
                                                         +- Relation [_id#1314,congestion_level#1315,lat#1316,lon#1317,road_id#1318,road_name#1319,speed#1320,timestamp#1321,vehicle_count#1322] MongoRelation(MongoRDD[78] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:43,568 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:48 +07)" executed successfully
2026-01-06 12:29:48,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:53 +07)" (scheduled at 2026-01-06 12:29:48.157382+07:00)
2026-01-06 12:29:48,164 - INFO -  Training Spark model...
2026-01-06 12:29:48,600 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_change#1693, vehicle_count_lag#1711, vehicle_count_change#1730, avg(speed#1551) windowspecdefinition(road_id#1537, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#1751]
+- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_change#1693, vehicle_count_lag#1711, CASE WHEN isnotnull(vehicle_count_lag#1711) THEN (vehicle_count#1561 - vehicle_count_lag#1711) ELSE 0.0 END AS vehicle_count_change#1730]
   +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_change#1693, vehicle_count_lag#1711]
      +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_change#1693, vehicle_count_lag#1711, vehicle_count_lag#1711]
         +- Window [lag(vehicle_count#1561, -1, null) windowspecdefinition(road_id#1537, timestamp#1540 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#1711], [road_id#1537], [timestamp#1540 ASC NULLS FIRST]
            +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_change#1693]
               +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, CASE WHEN isnotnull(speed_lag#1676) THEN (speed#1551 - speed_lag#1676) ELSE 0.0 END AS speed_change#1693]
                  +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676]
                     +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660, speed_lag#1676, speed_lag#1676]
                        +- Window [lag(speed#1551, -1, null) windowspecdefinition(road_id#1537, timestamp#1540 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#1676], [road_id#1537], [timestamp#1540 ASC NULLS FIRST]
                           +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, hour_cos#1660]
                              +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, hour_sin#1645, COS((0.2617993877991494 * cast(hour#1595 as double))) AS hour_cos#1660]
                                 +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, is_weekend#1631, SIN((0.2617993877991494 * cast(hour#1595 as double))) AS hour_sin#1645]
                                    +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, day_of_week#1618, CASE WHEN day_of_week#1618 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#1631]
                                       +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, is_peak#1606, dayofweek(cast(timestamp#1540 as date)) AS day_of_week#1618]
                                          +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour#1595, CASE WHEN hour#1595 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#1606]
                                             +- Project [_id#1533, congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561, hour(timestamp#1540, Some(Asia/Bangkok)) AS hour#1595]
                                                +- Project [_id#1533, cast(congestion_level#1534 as double) AS congestion_level#1571, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, vehicle_count#1561]
                                                   +- Project [_id#1533, congestion_level#1534, lat#1535, lon#1536, road_id#1537, road_name#1538, speed#1551, timestamp#1540, cast(vehicle_count#1541 as double) AS vehicle_count#1561]
                                                      +- Project [_id#1533, congestion_level#1534, lat#1535, lon#1536, road_id#1537, road_name#1538, cast(speed#1539 as double) AS speed#1551, timestamp#1540, vehicle_count#1541]
                                                         +- Relation [_id#1533,congestion_level#1534,lat#1535,lon#1536,road_id#1537,road_name#1538,speed#1539,timestamp#1540,vehicle_count#1541] MongoRelation(MongoRDD[91] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:48,600 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:53 +07)" executed successfully
2026-01-06 12:29:53,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:58 +07)" (scheduled at 2026-01-06 12:29:53.157382+07:00)
2026-01-06 12:29:53,160 - INFO -  Training Spark model...
2026-01-06 12:29:53,576 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_change#1912, vehicle_count_lag#1930, vehicle_count_change#1949, avg(speed#1770) windowspecdefinition(road_id#1756, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#1970]
+- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_change#1912, vehicle_count_lag#1930, CASE WHEN isnotnull(vehicle_count_lag#1930) THEN (vehicle_count#1780 - vehicle_count_lag#1930) ELSE 0.0 END AS vehicle_count_change#1949]
   +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_change#1912, vehicle_count_lag#1930]
      +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_change#1912, vehicle_count_lag#1930, vehicle_count_lag#1930]
         +- Window [lag(vehicle_count#1780, -1, null) windowspecdefinition(road_id#1756, timestamp#1759 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#1930], [road_id#1756], [timestamp#1759 ASC NULLS FIRST]
            +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_change#1912]
               +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, CASE WHEN isnotnull(speed_lag#1895) THEN (speed#1770 - speed_lag#1895) ELSE 0.0 END AS speed_change#1912]
                  +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895]
                     +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879, speed_lag#1895, speed_lag#1895]
                        +- Window [lag(speed#1770, -1, null) windowspecdefinition(road_id#1756, timestamp#1759 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#1895], [road_id#1756], [timestamp#1759 ASC NULLS FIRST]
                           +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, hour_cos#1879]
                              +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, hour_sin#1864, COS((0.2617993877991494 * cast(hour#1814 as double))) AS hour_cos#1879]
                                 +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, is_weekend#1850, SIN((0.2617993877991494 * cast(hour#1814 as double))) AS hour_sin#1864]
                                    +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, day_of_week#1837, CASE WHEN day_of_week#1837 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#1850]
                                       +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, is_peak#1825, dayofweek(cast(timestamp#1759 as date)) AS day_of_week#1837]
                                          +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour#1814, CASE WHEN hour#1814 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#1825]
                                             +- Project [_id#1752, congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780, hour(timestamp#1759, Some(Asia/Bangkok)) AS hour#1814]
                                                +- Project [_id#1752, cast(congestion_level#1753 as double) AS congestion_level#1790, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, vehicle_count#1780]
                                                   +- Project [_id#1752, congestion_level#1753, lat#1754, lon#1755, road_id#1756, road_name#1757, speed#1770, timestamp#1759, cast(vehicle_count#1760 as double) AS vehicle_count#1780]
                                                      +- Project [_id#1752, congestion_level#1753, lat#1754, lon#1755, road_id#1756, road_name#1757, cast(speed#1758 as double) AS speed#1770, timestamp#1759, vehicle_count#1760]
                                                         +- Relation [_id#1752,congestion_level#1753,lat#1754,lon#1755,road_id#1756,road_name#1757,speed#1758,timestamp#1759,vehicle_count#1760] MongoRelation(MongoRDD[104] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:53,576 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:29:58 +07)" executed successfully
2026-01-06 12:29:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:03 +07)" (scheduled at 2026-01-06 12:29:58.157382+07:00)
2026-01-06 12:29:58,158 - INFO -  Training Spark model...
2026-01-06 12:29:58,584 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_change#2131, vehicle_count_lag#2149, vehicle_count_change#2168, avg(speed#1989) windowspecdefinition(road_id#1975, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#2189]
+- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_change#2131, vehicle_count_lag#2149, CASE WHEN isnotnull(vehicle_count_lag#2149) THEN (vehicle_count#1999 - vehicle_count_lag#2149) ELSE 0.0 END AS vehicle_count_change#2168]
   +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_change#2131, vehicle_count_lag#2149]
      +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_change#2131, vehicle_count_lag#2149, vehicle_count_lag#2149]
         +- Window [lag(vehicle_count#1999, -1, null) windowspecdefinition(road_id#1975, timestamp#1978 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#2149], [road_id#1975], [timestamp#1978 ASC NULLS FIRST]
            +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_change#2131]
               +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, CASE WHEN isnotnull(speed_lag#2114) THEN (speed#1989 - speed_lag#2114) ELSE 0.0 END AS speed_change#2131]
                  +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114]
                     +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098, speed_lag#2114, speed_lag#2114]
                        +- Window [lag(speed#1989, -1, null) windowspecdefinition(road_id#1975, timestamp#1978 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#2114], [road_id#1975], [timestamp#1978 ASC NULLS FIRST]
                           +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, hour_cos#2098]
                              +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, hour_sin#2083, COS((0.2617993877991494 * cast(hour#2033 as double))) AS hour_cos#2098]
                                 +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, is_weekend#2069, SIN((0.2617993877991494 * cast(hour#2033 as double))) AS hour_sin#2083]
                                    +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, day_of_week#2056, CASE WHEN day_of_week#2056 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#2069]
                                       +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, is_peak#2044, dayofweek(cast(timestamp#1978 as date)) AS day_of_week#2056]
                                          +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour#2033, CASE WHEN hour#2033 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#2044]
                                             +- Project [_id#1971, congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999, hour(timestamp#1978, Some(Asia/Bangkok)) AS hour#2033]
                                                +- Project [_id#1971, cast(congestion_level#1972 as double) AS congestion_level#2009, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, vehicle_count#1999]
                                                   +- Project [_id#1971, congestion_level#1972, lat#1973, lon#1974, road_id#1975, road_name#1976, speed#1989, timestamp#1978, cast(vehicle_count#1979 as double) AS vehicle_count#1999]
                                                      +- Project [_id#1971, congestion_level#1972, lat#1973, lon#1974, road_id#1975, road_name#1976, cast(speed#1977 as double) AS speed#1989, timestamp#1978, vehicle_count#1979]
                                                         +- Relation [_id#1971,congestion_level#1972,lat#1973,lon#1974,road_id#1975,road_name#1976,speed#1977,timestamp#1978,vehicle_count#1979] MongoRelation(MongoRDD[117] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:29:58,585 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:03 +07)" executed successfully
2026-01-06 12:30:03,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:08 +07)" (scheduled at 2026-01-06 12:30:03.157382+07:00)
2026-01-06 12:30:03,159 - INFO -  Training Spark model...
2026-01-06 12:30:03,525 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_change#2350, vehicle_count_lag#2368, vehicle_count_change#2387, avg(speed#2208) windowspecdefinition(road_id#2194, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#2408]
+- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_change#2350, vehicle_count_lag#2368, CASE WHEN isnotnull(vehicle_count_lag#2368) THEN (vehicle_count#2218 - vehicle_count_lag#2368) ELSE 0.0 END AS vehicle_count_change#2387]
   +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_change#2350, vehicle_count_lag#2368]
      +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_change#2350, vehicle_count_lag#2368, vehicle_count_lag#2368]
         +- Window [lag(vehicle_count#2218, -1, null) windowspecdefinition(road_id#2194, timestamp#2197 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#2368], [road_id#2194], [timestamp#2197 ASC NULLS FIRST]
            +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_change#2350]
               +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, CASE WHEN isnotnull(speed_lag#2333) THEN (speed#2208 - speed_lag#2333) ELSE 0.0 END AS speed_change#2350]
                  +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333]
                     +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317, speed_lag#2333, speed_lag#2333]
                        +- Window [lag(speed#2208, -1, null) windowspecdefinition(road_id#2194, timestamp#2197 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#2333], [road_id#2194], [timestamp#2197 ASC NULLS FIRST]
                           +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, hour_cos#2317]
                              +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, hour_sin#2302, COS((0.2617993877991494 * cast(hour#2252 as double))) AS hour_cos#2317]
                                 +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, is_weekend#2288, SIN((0.2617993877991494 * cast(hour#2252 as double))) AS hour_sin#2302]
                                    +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, day_of_week#2275, CASE WHEN day_of_week#2275 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#2288]
                                       +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, is_peak#2263, dayofweek(cast(timestamp#2197 as date)) AS day_of_week#2275]
                                          +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour#2252, CASE WHEN hour#2252 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#2263]
                                             +- Project [_id#2190, congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218, hour(timestamp#2197, Some(Asia/Bangkok)) AS hour#2252]
                                                +- Project [_id#2190, cast(congestion_level#2191 as double) AS congestion_level#2228, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, vehicle_count#2218]
                                                   +- Project [_id#2190, congestion_level#2191, lat#2192, lon#2193, road_id#2194, road_name#2195, speed#2208, timestamp#2197, cast(vehicle_count#2198 as double) AS vehicle_count#2218]
                                                      +- Project [_id#2190, congestion_level#2191, lat#2192, lon#2193, road_id#2194, road_name#2195, cast(speed#2196 as double) AS speed#2208, timestamp#2197, vehicle_count#2198]
                                                         +- Relation [_id#2190,congestion_level#2191,lat#2192,lon#2193,road_id#2194,road_name#2195,speed#2196,timestamp#2197,vehicle_count#2198] MongoRelation(MongoRDD[130] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:03,526 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:08 +07)" executed successfully
2026-01-06 12:30:08,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:13 +07)" (scheduled at 2026-01-06 12:30:08.157382+07:00)
2026-01-06 12:30:08,159 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:30:08 +07)" (scheduled at 2026-01-06 12:30:08.157779+07:00)
2026-01-06 12:30:08,160 - INFO -  Training Spark model...
2026-01-06 12:30:08,160 - INFO -  Training Spark model...
2026-01-06 12:30:08,675 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_change#2713, vehicle_count_lag#2747, vehicle_count_change#2785, avg(speed#2465) windowspecdefinition(road_id#2431, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#2824]
+- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_change#2713, vehicle_count_lag#2747, CASE WHEN isnotnull(vehicle_count_lag#2747) THEN (vehicle_count#2485 - vehicle_count_lag#2747) ELSE 0.0 END AS vehicle_count_change#2785]
   +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_change#2713, vehicle_count_lag#2747]
      +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_change#2713, vehicle_count_lag#2747, vehicle_count_lag#2747]
         +- Window [lag(vehicle_count#2485, -1, null) windowspecdefinition(road_id#2431, timestamp#2434 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#2747], [road_id#2431], [timestamp#2434 ASC NULLS FIRST]
            +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_change#2713]
               +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, CASE WHEN isnotnull(speed_lag#2695) THEN (speed#2465 - speed_lag#2695) ELSE 0.0 END AS speed_change#2713]
                  +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695]
                     +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664, speed_lag#2695, speed_lag#2695]
                        +- Window [lag(speed#2465, -1, null) windowspecdefinition(road_id#2431, timestamp#2434 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#2695], [road_id#2431], [timestamp#2434 ASC NULLS FIRST]
                           +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, hour_cos#2664]
                              +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, hour_sin#2634, COS((0.2617993877991494 * cast(hour#2533 as double))) AS hour_cos#2664]
                                 +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, is_weekend#2619, SIN((0.2617993877991494 * cast(hour#2533 as double))) AS hour_sin#2634]
                                    +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, day_of_week#2579, CASE WHEN day_of_week#2579 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#2619]
                                       +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, is_peak#2555, dayofweek(cast(timestamp#2434 as date)) AS day_of_week#2579]
                                          +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour#2533, CASE WHEN hour#2533 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#2555]
                                             +- Project [_id#2427, congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485, hour(timestamp#2434, Some(Asia/Bangkok)) AS hour#2533]
                                                +- Project [_id#2427, cast(congestion_level#2428 as double) AS congestion_level#2507, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, vehicle_count#2485]
                                                   +- Project [_id#2427, congestion_level#2428, lat#2429, lon#2430, road_id#2431, road_name#2432, speed#2465, timestamp#2434, cast(vehicle_count#2435 as double) AS vehicle_count#2485]
                                                      +- Project [_id#2427, congestion_level#2428, lat#2429, lon#2430, road_id#2431, road_name#2432, cast(speed#2433 as double) AS speed#2465, timestamp#2434, vehicle_count#2435]
                                                         +- Relation [_id#2427,congestion_level#2428,lat#2429,lon#2430,road_id#2431,road_name#2432,speed#2433,timestamp#2434,vehicle_count#2435] MongoRelation(MongoRDD[144] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:08,675 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:31:08 +07)" executed successfully
2026-01-06 12:30:08,707 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_change#2748, vehicle_count_lag#2784, vehicle_count_change#2825, avg(speed#2436) windowspecdefinition(road_id#2413, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#2846]
+- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_change#2748, vehicle_count_lag#2784, CASE WHEN isnotnull(vehicle_count_lag#2784) THEN (vehicle_count#2455 - vehicle_count_lag#2784) ELSE 0.0 END AS vehicle_count_change#2825]
   +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_change#2748, vehicle_count_lag#2784]
      +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_change#2748, vehicle_count_lag#2784, vehicle_count_lag#2784]
         +- Window [lag(vehicle_count#2455, -1, null) windowspecdefinition(road_id#2413, timestamp#2416 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#2784], [road_id#2413], [timestamp#2416 ASC NULLS FIRST]
            +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_change#2748]
               +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, CASE WHEN isnotnull(speed_lag#2696) THEN (speed#2436 - speed_lag#2696) ELSE 0.0 END AS speed_change#2748]
                  +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696]
                     +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663, speed_lag#2696, speed_lag#2696]
                        +- Window [lag(speed#2436, -1, null) windowspecdefinition(road_id#2413, timestamp#2416 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#2696], [road_id#2413], [timestamp#2416 ASC NULLS FIRST]
                           +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, hour_cos#2663]
                              +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, hour_sin#2633, COS((0.2617993877991494 * cast(hour#2544 as double))) AS hour_cos#2663]
                                 +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, is_weekend#2605, SIN((0.2617993877991494 * cast(hour#2544 as double))) AS hour_sin#2633]
                                    +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, day_of_week#2580, CASE WHEN day_of_week#2580 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#2605]
                                       +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, is_peak#2567, dayofweek(cast(timestamp#2416 as date)) AS day_of_week#2580]
                                          +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour#2544, CASE WHEN hour#2544 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#2567]
                                             +- Project [_id#2409, congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455, hour(timestamp#2416, Some(Asia/Bangkok)) AS hour#2544]
                                                +- Project [_id#2409, cast(congestion_level#2410 as double) AS congestion_level#2475, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, vehicle_count#2455]
                                                   +- Project [_id#2409, congestion_level#2410, lat#2411, lon#2412, road_id#2413, road_name#2414, speed#2436, timestamp#2416, cast(vehicle_count#2417 as double) AS vehicle_count#2455]
                                                      +- Project [_id#2409, congestion_level#2410, lat#2411, lon#2412, road_id#2413, road_name#2414, cast(speed#2415 as double) AS speed#2436, timestamp#2416, vehicle_count#2417]
                                                         +- Relation [_id#2409,congestion_level#2410,lat#2411,lon#2412,road_id#2413,road_name#2414,speed#2415,timestamp#2416,vehicle_count#2417] MongoRelation(MongoRDD[143] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:08,707 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:13 +07)" executed successfully
2026-01-06 12:30:13,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:18 +07)" (scheduled at 2026-01-06 12:30:13.157382+07:00)
2026-01-06 12:30:13,166 - INFO -  Training Spark model...
2026-01-06 12:30:13,510 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_change#3007, vehicle_count_lag#3025, vehicle_count_change#3044, avg(speed#2865) windowspecdefinition(road_id#2851, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#3065]
+- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_change#3007, vehicle_count_lag#3025, CASE WHEN isnotnull(vehicle_count_lag#3025) THEN (vehicle_count#2875 - vehicle_count_lag#3025) ELSE 0.0 END AS vehicle_count_change#3044]
   +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_change#3007, vehicle_count_lag#3025]
      +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_change#3007, vehicle_count_lag#3025, vehicle_count_lag#3025]
         +- Window [lag(vehicle_count#2875, -1, null) windowspecdefinition(road_id#2851, timestamp#2854 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#3025], [road_id#2851], [timestamp#2854 ASC NULLS FIRST]
            +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_change#3007]
               +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, CASE WHEN isnotnull(speed_lag#2990) THEN (speed#2865 - speed_lag#2990) ELSE 0.0 END AS speed_change#3007]
                  +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990]
                     +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974, speed_lag#2990, speed_lag#2990]
                        +- Window [lag(speed#2865, -1, null) windowspecdefinition(road_id#2851, timestamp#2854 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#2990], [road_id#2851], [timestamp#2854 ASC NULLS FIRST]
                           +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, hour_cos#2974]
                              +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, hour_sin#2959, COS((0.2617993877991494 * cast(hour#2909 as double))) AS hour_cos#2974]
                                 +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, is_weekend#2945, SIN((0.2617993877991494 * cast(hour#2909 as double))) AS hour_sin#2959]
                                    +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, day_of_week#2932, CASE WHEN day_of_week#2932 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#2945]
                                       +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, is_peak#2920, dayofweek(cast(timestamp#2854 as date)) AS day_of_week#2932]
                                          +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour#2909, CASE WHEN hour#2909 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#2920]
                                             +- Project [_id#2847, congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875, hour(timestamp#2854, Some(Asia/Bangkok)) AS hour#2909]
                                                +- Project [_id#2847, cast(congestion_level#2848 as double) AS congestion_level#2885, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, vehicle_count#2875]
                                                   +- Project [_id#2847, congestion_level#2848, lat#2849, lon#2850, road_id#2851, road_name#2852, speed#2865, timestamp#2854, cast(vehicle_count#2855 as double) AS vehicle_count#2875]
                                                      +- Project [_id#2847, congestion_level#2848, lat#2849, lon#2850, road_id#2851, road_name#2852, cast(speed#2853 as double) AS speed#2865, timestamp#2854, vehicle_count#2855]
                                                         +- Relation [_id#2847,congestion_level#2848,lat#2849,lon#2850,road_id#2851,road_name#2852,speed#2853,timestamp#2854,vehicle_count#2855] MongoRelation(MongoRDD[169] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:13,510 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:18 +07)" executed successfully
2026-01-06 12:30:18,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:23 +07)" (scheduled at 2026-01-06 12:30:18.157382+07:00)
2026-01-06 12:30:18,158 - INFO -  Training Spark model...
2026-01-06 12:30:18,586 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_change#3226, vehicle_count_lag#3244, vehicle_count_change#3263, avg(speed#3084) windowspecdefinition(road_id#3070, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#3284]
+- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_change#3226, vehicle_count_lag#3244, CASE WHEN isnotnull(vehicle_count_lag#3244) THEN (vehicle_count#3094 - vehicle_count_lag#3244) ELSE 0.0 END AS vehicle_count_change#3263]
   +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_change#3226, vehicle_count_lag#3244]
      +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_change#3226, vehicle_count_lag#3244, vehicle_count_lag#3244]
         +- Window [lag(vehicle_count#3094, -1, null) windowspecdefinition(road_id#3070, timestamp#3073 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#3244], [road_id#3070], [timestamp#3073 ASC NULLS FIRST]
            +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_change#3226]
               +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, CASE WHEN isnotnull(speed_lag#3209) THEN (speed#3084 - speed_lag#3209) ELSE 0.0 END AS speed_change#3226]
                  +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209]
                     +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193, speed_lag#3209, speed_lag#3209]
                        +- Window [lag(speed#3084, -1, null) windowspecdefinition(road_id#3070, timestamp#3073 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#3209], [road_id#3070], [timestamp#3073 ASC NULLS FIRST]
                           +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, hour_cos#3193]
                              +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, hour_sin#3178, COS((0.2617993877991494 * cast(hour#3128 as double))) AS hour_cos#3193]
                                 +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, is_weekend#3164, SIN((0.2617993877991494 * cast(hour#3128 as double))) AS hour_sin#3178]
                                    +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, day_of_week#3151, CASE WHEN day_of_week#3151 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#3164]
                                       +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, is_peak#3139, dayofweek(cast(timestamp#3073 as date)) AS day_of_week#3151]
                                          +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour#3128, CASE WHEN hour#3128 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#3139]
                                             +- Project [_id#3066, congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094, hour(timestamp#3073, Some(Asia/Bangkok)) AS hour#3128]
                                                +- Project [_id#3066, cast(congestion_level#3067 as double) AS congestion_level#3104, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, vehicle_count#3094]
                                                   +- Project [_id#3066, congestion_level#3067, lat#3068, lon#3069, road_id#3070, road_name#3071, speed#3084, timestamp#3073, cast(vehicle_count#3074 as double) AS vehicle_count#3094]
                                                      +- Project [_id#3066, congestion_level#3067, lat#3068, lon#3069, road_id#3070, road_name#3071, cast(speed#3072 as double) AS speed#3084, timestamp#3073, vehicle_count#3074]
                                                         +- Relation [_id#3066,congestion_level#3067,lat#3068,lon#3069,road_id#3070,road_name#3071,speed#3072,timestamp#3073,vehicle_count#3074] MongoRelation(MongoRDD[182] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:18,586 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:23 +07)" executed successfully
2026-01-06 12:30:23,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:28 +07)" (scheduled at 2026-01-06 12:30:23.157382+07:00)
2026-01-06 12:30:23,163 - INFO -  Training Spark model...
2026-01-06 12:30:23,536 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_change#3445, vehicle_count_lag#3463, vehicle_count_change#3482, avg(speed#3303) windowspecdefinition(road_id#3289, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#3503]
+- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_change#3445, vehicle_count_lag#3463, CASE WHEN isnotnull(vehicle_count_lag#3463) THEN (vehicle_count#3313 - vehicle_count_lag#3463) ELSE 0.0 END AS vehicle_count_change#3482]
   +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_change#3445, vehicle_count_lag#3463]
      +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_change#3445, vehicle_count_lag#3463, vehicle_count_lag#3463]
         +- Window [lag(vehicle_count#3313, -1, null) windowspecdefinition(road_id#3289, timestamp#3292 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#3463], [road_id#3289], [timestamp#3292 ASC NULLS FIRST]
            +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_change#3445]
               +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, CASE WHEN isnotnull(speed_lag#3428) THEN (speed#3303 - speed_lag#3428) ELSE 0.0 END AS speed_change#3445]
                  +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428]
                     +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412, speed_lag#3428, speed_lag#3428]
                        +- Window [lag(speed#3303, -1, null) windowspecdefinition(road_id#3289, timestamp#3292 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#3428], [road_id#3289], [timestamp#3292 ASC NULLS FIRST]
                           +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, hour_cos#3412]
                              +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, hour_sin#3397, COS((0.2617993877991494 * cast(hour#3347 as double))) AS hour_cos#3412]
                                 +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, is_weekend#3383, SIN((0.2617993877991494 * cast(hour#3347 as double))) AS hour_sin#3397]
                                    +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, day_of_week#3370, CASE WHEN day_of_week#3370 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#3383]
                                       +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, is_peak#3358, dayofweek(cast(timestamp#3292 as date)) AS day_of_week#3370]
                                          +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour#3347, CASE WHEN hour#3347 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#3358]
                                             +- Project [_id#3285, congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313, hour(timestamp#3292, Some(Asia/Bangkok)) AS hour#3347]
                                                +- Project [_id#3285, cast(congestion_level#3286 as double) AS congestion_level#3323, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, vehicle_count#3313]
                                                   +- Project [_id#3285, congestion_level#3286, lat#3287, lon#3288, road_id#3289, road_name#3290, speed#3303, timestamp#3292, cast(vehicle_count#3293 as double) AS vehicle_count#3313]
                                                      +- Project [_id#3285, congestion_level#3286, lat#3287, lon#3288, road_id#3289, road_name#3290, cast(speed#3291 as double) AS speed#3303, timestamp#3292, vehicle_count#3293]
                                                         +- Relation [_id#3285,congestion_level#3286,lat#3287,lon#3288,road_id#3289,road_name#3290,speed#3291,timestamp#3292,vehicle_count#3293] MongoRelation(MongoRDD[195] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:23,536 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:28 +07)" executed successfully
2026-01-06 12:30:28,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:33 +07)" (scheduled at 2026-01-06 12:30:28.157382+07:00)
2026-01-06 12:30:28,164 - INFO -  Training Spark model...
2026-01-06 12:30:28,490 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_change#3664, vehicle_count_lag#3682, vehicle_count_change#3701, avg(speed#3522) windowspecdefinition(road_id#3508, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#3722]
+- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_change#3664, vehicle_count_lag#3682, CASE WHEN isnotnull(vehicle_count_lag#3682) THEN (vehicle_count#3532 - vehicle_count_lag#3682) ELSE 0.0 END AS vehicle_count_change#3701]
   +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_change#3664, vehicle_count_lag#3682]
      +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_change#3664, vehicle_count_lag#3682, vehicle_count_lag#3682]
         +- Window [lag(vehicle_count#3532, -1, null) windowspecdefinition(road_id#3508, timestamp#3511 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#3682], [road_id#3508], [timestamp#3511 ASC NULLS FIRST]
            +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_change#3664]
               +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, CASE WHEN isnotnull(speed_lag#3647) THEN (speed#3522 - speed_lag#3647) ELSE 0.0 END AS speed_change#3664]
                  +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647]
                     +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631, speed_lag#3647, speed_lag#3647]
                        +- Window [lag(speed#3522, -1, null) windowspecdefinition(road_id#3508, timestamp#3511 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#3647], [road_id#3508], [timestamp#3511 ASC NULLS FIRST]
                           +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, hour_cos#3631]
                              +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, hour_sin#3616, COS((0.2617993877991494 * cast(hour#3566 as double))) AS hour_cos#3631]
                                 +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, is_weekend#3602, SIN((0.2617993877991494 * cast(hour#3566 as double))) AS hour_sin#3616]
                                    +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, day_of_week#3589, CASE WHEN day_of_week#3589 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#3602]
                                       +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, is_peak#3577, dayofweek(cast(timestamp#3511 as date)) AS day_of_week#3589]
                                          +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour#3566, CASE WHEN hour#3566 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#3577]
                                             +- Project [_id#3504, congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532, hour(timestamp#3511, Some(Asia/Bangkok)) AS hour#3566]
                                                +- Project [_id#3504, cast(congestion_level#3505 as double) AS congestion_level#3542, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, vehicle_count#3532]
                                                   +- Project [_id#3504, congestion_level#3505, lat#3506, lon#3507, road_id#3508, road_name#3509, speed#3522, timestamp#3511, cast(vehicle_count#3512 as double) AS vehicle_count#3532]
                                                      +- Project [_id#3504, congestion_level#3505, lat#3506, lon#3507, road_id#3508, road_name#3509, cast(speed#3510 as double) AS speed#3522, timestamp#3511, vehicle_count#3512]
                                                         +- Relation [_id#3504,congestion_level#3505,lat#3506,lon#3507,road_id#3508,road_name#3509,speed#3510,timestamp#3511,vehicle_count#3512] MongoRelation(MongoRDD[208] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:28,490 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:33 +07)" executed successfully
2026-01-06 12:30:33,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:38 +07)" (scheduled at 2026-01-06 12:30:33.157382+07:00)
2026-01-06 12:30:33,160 - INFO -  Training Spark model...
2026-01-06 12:30:33,515 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_change#3883, vehicle_count_lag#3901, vehicle_count_change#3920, avg(speed#3741) windowspecdefinition(road_id#3727, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#3941]
+- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_change#3883, vehicle_count_lag#3901, CASE WHEN isnotnull(vehicle_count_lag#3901) THEN (vehicle_count#3751 - vehicle_count_lag#3901) ELSE 0.0 END AS vehicle_count_change#3920]
   +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_change#3883, vehicle_count_lag#3901]
      +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_change#3883, vehicle_count_lag#3901, vehicle_count_lag#3901]
         +- Window [lag(vehicle_count#3751, -1, null) windowspecdefinition(road_id#3727, timestamp#3730 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#3901], [road_id#3727], [timestamp#3730 ASC NULLS FIRST]
            +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_change#3883]
               +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, CASE WHEN isnotnull(speed_lag#3866) THEN (speed#3741 - speed_lag#3866) ELSE 0.0 END AS speed_change#3883]
                  +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866]
                     +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850, speed_lag#3866, speed_lag#3866]
                        +- Window [lag(speed#3741, -1, null) windowspecdefinition(road_id#3727, timestamp#3730 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#3866], [road_id#3727], [timestamp#3730 ASC NULLS FIRST]
                           +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, hour_cos#3850]
                              +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, hour_sin#3835, COS((0.2617993877991494 * cast(hour#3785 as double))) AS hour_cos#3850]
                                 +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, is_weekend#3821, SIN((0.2617993877991494 * cast(hour#3785 as double))) AS hour_sin#3835]
                                    +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, day_of_week#3808, CASE WHEN day_of_week#3808 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#3821]
                                       +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, is_peak#3796, dayofweek(cast(timestamp#3730 as date)) AS day_of_week#3808]
                                          +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour#3785, CASE WHEN hour#3785 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#3796]
                                             +- Project [_id#3723, congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751, hour(timestamp#3730, Some(Asia/Bangkok)) AS hour#3785]
                                                +- Project [_id#3723, cast(congestion_level#3724 as double) AS congestion_level#3761, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, vehicle_count#3751]
                                                   +- Project [_id#3723, congestion_level#3724, lat#3725, lon#3726, road_id#3727, road_name#3728, speed#3741, timestamp#3730, cast(vehicle_count#3731 as double) AS vehicle_count#3751]
                                                      +- Project [_id#3723, congestion_level#3724, lat#3725, lon#3726, road_id#3727, road_name#3728, cast(speed#3729 as double) AS speed#3741, timestamp#3730, vehicle_count#3731]
                                                         +- Relation [_id#3723,congestion_level#3724,lat#3725,lon#3726,road_id#3727,road_name#3728,speed#3729,timestamp#3730,vehicle_count#3731] MongoRelation(MongoRDD[221] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:33,515 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:38 +07)" executed successfully
2026-01-06 12:30:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:43 +07)" (scheduled at 2026-01-06 12:30:38.157382+07:00)
2026-01-06 12:30:38,158 - INFO -  Training Spark model...
2026-01-06 12:30:38,485 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_change#4102, vehicle_count_lag#4120, vehicle_count_change#4139, avg(speed#3960) windowspecdefinition(road_id#3946, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#4160]
+- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_change#4102, vehicle_count_lag#4120, CASE WHEN isnotnull(vehicle_count_lag#4120) THEN (vehicle_count#3970 - vehicle_count_lag#4120) ELSE 0.0 END AS vehicle_count_change#4139]
   +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_change#4102, vehicle_count_lag#4120]
      +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_change#4102, vehicle_count_lag#4120, vehicle_count_lag#4120]
         +- Window [lag(vehicle_count#3970, -1, null) windowspecdefinition(road_id#3946, timestamp#3949 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#4120], [road_id#3946], [timestamp#3949 ASC NULLS FIRST]
            +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_change#4102]
               +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, CASE WHEN isnotnull(speed_lag#4085) THEN (speed#3960 - speed_lag#4085) ELSE 0.0 END AS speed_change#4102]
                  +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085]
                     +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069, speed_lag#4085, speed_lag#4085]
                        +- Window [lag(speed#3960, -1, null) windowspecdefinition(road_id#3946, timestamp#3949 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#4085], [road_id#3946], [timestamp#3949 ASC NULLS FIRST]
                           +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, hour_cos#4069]
                              +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, hour_sin#4054, COS((0.2617993877991494 * cast(hour#4004 as double))) AS hour_cos#4069]
                                 +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, is_weekend#4040, SIN((0.2617993877991494 * cast(hour#4004 as double))) AS hour_sin#4054]
                                    +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, day_of_week#4027, CASE WHEN day_of_week#4027 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#4040]
                                       +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, is_peak#4015, dayofweek(cast(timestamp#3949 as date)) AS day_of_week#4027]
                                          +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour#4004, CASE WHEN hour#4004 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#4015]
                                             +- Project [_id#3942, congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970, hour(timestamp#3949, Some(Asia/Bangkok)) AS hour#4004]
                                                +- Project [_id#3942, cast(congestion_level#3943 as double) AS congestion_level#3980, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, vehicle_count#3970]
                                                   +- Project [_id#3942, congestion_level#3943, lat#3944, lon#3945, road_id#3946, road_name#3947, speed#3960, timestamp#3949, cast(vehicle_count#3950 as double) AS vehicle_count#3970]
                                                      +- Project [_id#3942, congestion_level#3943, lat#3944, lon#3945, road_id#3946, road_name#3947, cast(speed#3948 as double) AS speed#3960, timestamp#3949, vehicle_count#3950]
                                                         +- Relation [_id#3942,congestion_level#3943,lat#3944,lon#3945,road_id#3946,road_name#3947,speed#3948,timestamp#3949,vehicle_count#3950] MongoRelation(MongoRDD[234] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:38,485 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:43 +07)" executed successfully
2026-01-06 12:30:43,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:48 +07)" (scheduled at 2026-01-06 12:30:43.157382+07:00)
2026-01-06 12:30:43,159 - INFO -  Training Spark model...
2026-01-06 12:30:43,490 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_change#4321, vehicle_count_lag#4339, vehicle_count_change#4358, avg(speed#4179) windowspecdefinition(road_id#4165, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#4379]
+- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_change#4321, vehicle_count_lag#4339, CASE WHEN isnotnull(vehicle_count_lag#4339) THEN (vehicle_count#4189 - vehicle_count_lag#4339) ELSE 0.0 END AS vehicle_count_change#4358]
   +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_change#4321, vehicle_count_lag#4339]
      +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_change#4321, vehicle_count_lag#4339, vehicle_count_lag#4339]
         +- Window [lag(vehicle_count#4189, -1, null) windowspecdefinition(road_id#4165, timestamp#4168 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#4339], [road_id#4165], [timestamp#4168 ASC NULLS FIRST]
            +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_change#4321]
               +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, CASE WHEN isnotnull(speed_lag#4304) THEN (speed#4179 - speed_lag#4304) ELSE 0.0 END AS speed_change#4321]
                  +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304]
                     +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288, speed_lag#4304, speed_lag#4304]
                        +- Window [lag(speed#4179, -1, null) windowspecdefinition(road_id#4165, timestamp#4168 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#4304], [road_id#4165], [timestamp#4168 ASC NULLS FIRST]
                           +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, hour_cos#4288]
                              +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, hour_sin#4273, COS((0.2617993877991494 * cast(hour#4223 as double))) AS hour_cos#4288]
                                 +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, is_weekend#4259, SIN((0.2617993877991494 * cast(hour#4223 as double))) AS hour_sin#4273]
                                    +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, day_of_week#4246, CASE WHEN day_of_week#4246 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#4259]
                                       +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, is_peak#4234, dayofweek(cast(timestamp#4168 as date)) AS day_of_week#4246]
                                          +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour#4223, CASE WHEN hour#4223 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#4234]
                                             +- Project [_id#4161, congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189, hour(timestamp#4168, Some(Asia/Bangkok)) AS hour#4223]
                                                +- Project [_id#4161, cast(congestion_level#4162 as double) AS congestion_level#4199, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, vehicle_count#4189]
                                                   +- Project [_id#4161, congestion_level#4162, lat#4163, lon#4164, road_id#4165, road_name#4166, speed#4179, timestamp#4168, cast(vehicle_count#4169 as double) AS vehicle_count#4189]
                                                      +- Project [_id#4161, congestion_level#4162, lat#4163, lon#4164, road_id#4165, road_name#4166, cast(speed#4167 as double) AS speed#4179, timestamp#4168, vehicle_count#4169]
                                                         +- Relation [_id#4161,congestion_level#4162,lat#4163,lon#4164,road_id#4165,road_name#4166,speed#4167,timestamp#4168,vehicle_count#4169] MongoRelation(MongoRDD[247] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:43,490 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:48 +07)" executed successfully
2026-01-06 12:30:48,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:53 +07)" (scheduled at 2026-01-06 12:30:48.157382+07:00)
2026-01-06 12:30:48,163 - INFO -  Training Spark model...
2026-01-06 12:30:48,526 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_change#4540, vehicle_count_lag#4558, vehicle_count_change#4577, avg(speed#4398) windowspecdefinition(road_id#4384, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#4598]
+- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_change#4540, vehicle_count_lag#4558, CASE WHEN isnotnull(vehicle_count_lag#4558) THEN (vehicle_count#4408 - vehicle_count_lag#4558) ELSE 0.0 END AS vehicle_count_change#4577]
   +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_change#4540, vehicle_count_lag#4558]
      +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_change#4540, vehicle_count_lag#4558, vehicle_count_lag#4558]
         +- Window [lag(vehicle_count#4408, -1, null) windowspecdefinition(road_id#4384, timestamp#4387 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#4558], [road_id#4384], [timestamp#4387 ASC NULLS FIRST]
            +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_change#4540]
               +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, CASE WHEN isnotnull(speed_lag#4523) THEN (speed#4398 - speed_lag#4523) ELSE 0.0 END AS speed_change#4540]
                  +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523]
                     +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507, speed_lag#4523, speed_lag#4523]
                        +- Window [lag(speed#4398, -1, null) windowspecdefinition(road_id#4384, timestamp#4387 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#4523], [road_id#4384], [timestamp#4387 ASC NULLS FIRST]
                           +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, hour_cos#4507]
                              +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, hour_sin#4492, COS((0.2617993877991494 * cast(hour#4442 as double))) AS hour_cos#4507]
                                 +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, is_weekend#4478, SIN((0.2617993877991494 * cast(hour#4442 as double))) AS hour_sin#4492]
                                    +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, day_of_week#4465, CASE WHEN day_of_week#4465 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#4478]
                                       +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, is_peak#4453, dayofweek(cast(timestamp#4387 as date)) AS day_of_week#4465]
                                          +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour#4442, CASE WHEN hour#4442 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#4453]
                                             +- Project [_id#4380, congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408, hour(timestamp#4387, Some(Asia/Bangkok)) AS hour#4442]
                                                +- Project [_id#4380, cast(congestion_level#4381 as double) AS congestion_level#4418, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, vehicle_count#4408]
                                                   +- Project [_id#4380, congestion_level#4381, lat#4382, lon#4383, road_id#4384, road_name#4385, speed#4398, timestamp#4387, cast(vehicle_count#4388 as double) AS vehicle_count#4408]
                                                      +- Project [_id#4380, congestion_level#4381, lat#4382, lon#4383, road_id#4384, road_name#4385, cast(speed#4386 as double) AS speed#4398, timestamp#4387, vehicle_count#4388]
                                                         +- Relation [_id#4380,congestion_level#4381,lat#4382,lon#4383,road_id#4384,road_name#4385,speed#4386,timestamp#4387,vehicle_count#4388] MongoRelation(MongoRDD[260] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:48,526 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:53 +07)" executed successfully
2026-01-06 12:30:53,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:58 +07)" (scheduled at 2026-01-06 12:30:53.157382+07:00)
2026-01-06 12:30:53,165 - INFO -  Training Spark model...
2026-01-06 12:30:53,495 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_change#4759, vehicle_count_lag#4777, vehicle_count_change#4796, avg(speed#4617) windowspecdefinition(road_id#4603, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#4817]
+- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_change#4759, vehicle_count_lag#4777, CASE WHEN isnotnull(vehicle_count_lag#4777) THEN (vehicle_count#4627 - vehicle_count_lag#4777) ELSE 0.0 END AS vehicle_count_change#4796]
   +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_change#4759, vehicle_count_lag#4777]
      +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_change#4759, vehicle_count_lag#4777, vehicle_count_lag#4777]
         +- Window [lag(vehicle_count#4627, -1, null) windowspecdefinition(road_id#4603, timestamp#4606 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#4777], [road_id#4603], [timestamp#4606 ASC NULLS FIRST]
            +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_change#4759]
               +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, CASE WHEN isnotnull(speed_lag#4742) THEN (speed#4617 - speed_lag#4742) ELSE 0.0 END AS speed_change#4759]
                  +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742]
                     +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726, speed_lag#4742, speed_lag#4742]
                        +- Window [lag(speed#4617, -1, null) windowspecdefinition(road_id#4603, timestamp#4606 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#4742], [road_id#4603], [timestamp#4606 ASC NULLS FIRST]
                           +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, hour_cos#4726]
                              +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, hour_sin#4711, COS((0.2617993877991494 * cast(hour#4661 as double))) AS hour_cos#4726]
                                 +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, is_weekend#4697, SIN((0.2617993877991494 * cast(hour#4661 as double))) AS hour_sin#4711]
                                    +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, day_of_week#4684, CASE WHEN day_of_week#4684 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#4697]
                                       +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, is_peak#4672, dayofweek(cast(timestamp#4606 as date)) AS day_of_week#4684]
                                          +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour#4661, CASE WHEN hour#4661 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#4672]
                                             +- Project [_id#4599, congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627, hour(timestamp#4606, Some(Asia/Bangkok)) AS hour#4661]
                                                +- Project [_id#4599, cast(congestion_level#4600 as double) AS congestion_level#4637, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, vehicle_count#4627]
                                                   +- Project [_id#4599, congestion_level#4600, lat#4601, lon#4602, road_id#4603, road_name#4604, speed#4617, timestamp#4606, cast(vehicle_count#4607 as double) AS vehicle_count#4627]
                                                      +- Project [_id#4599, congestion_level#4600, lat#4601, lon#4602, road_id#4603, road_name#4604, cast(speed#4605 as double) AS speed#4617, timestamp#4606, vehicle_count#4607]
                                                         +- Relation [_id#4599,congestion_level#4600,lat#4601,lon#4602,road_id#4603,road_name#4604,speed#4605,timestamp#4606,vehicle_count#4607] MongoRelation(MongoRDD[273] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:53,495 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:30:58 +07)" executed successfully
2026-01-06 12:30:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:03 +07)" (scheduled at 2026-01-06 12:30:58.157382+07:00)
2026-01-06 12:30:58,158 - INFO -  Training Spark model...
2026-01-06 12:30:58,590 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_change#4978, vehicle_count_lag#4996, vehicle_count_change#5015, avg(speed#4836) windowspecdefinition(road_id#4822, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#5036]
+- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_change#4978, vehicle_count_lag#4996, CASE WHEN isnotnull(vehicle_count_lag#4996) THEN (vehicle_count#4846 - vehicle_count_lag#4996) ELSE 0.0 END AS vehicle_count_change#5015]
   +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_change#4978, vehicle_count_lag#4996]
      +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_change#4978, vehicle_count_lag#4996, vehicle_count_lag#4996]
         +- Window [lag(vehicle_count#4846, -1, null) windowspecdefinition(road_id#4822, timestamp#4825 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#4996], [road_id#4822], [timestamp#4825 ASC NULLS FIRST]
            +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_change#4978]
               +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, CASE WHEN isnotnull(speed_lag#4961) THEN (speed#4836 - speed_lag#4961) ELSE 0.0 END AS speed_change#4978]
                  +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961]
                     +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945, speed_lag#4961, speed_lag#4961]
                        +- Window [lag(speed#4836, -1, null) windowspecdefinition(road_id#4822, timestamp#4825 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#4961], [road_id#4822], [timestamp#4825 ASC NULLS FIRST]
                           +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, hour_cos#4945]
                              +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, hour_sin#4930, COS((0.2617993877991494 * cast(hour#4880 as double))) AS hour_cos#4945]
                                 +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, is_weekend#4916, SIN((0.2617993877991494 * cast(hour#4880 as double))) AS hour_sin#4930]
                                    +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, day_of_week#4903, CASE WHEN day_of_week#4903 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#4916]
                                       +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, is_peak#4891, dayofweek(cast(timestamp#4825 as date)) AS day_of_week#4903]
                                          +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour#4880, CASE WHEN hour#4880 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#4891]
                                             +- Project [_id#4818, congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846, hour(timestamp#4825, Some(Asia/Bangkok)) AS hour#4880]
                                                +- Project [_id#4818, cast(congestion_level#4819 as double) AS congestion_level#4856, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, vehicle_count#4846]
                                                   +- Project [_id#4818, congestion_level#4819, lat#4820, lon#4821, road_id#4822, road_name#4823, speed#4836, timestamp#4825, cast(vehicle_count#4826 as double) AS vehicle_count#4846]
                                                      +- Project [_id#4818, congestion_level#4819, lat#4820, lon#4821, road_id#4822, road_name#4823, cast(speed#4824 as double) AS speed#4836, timestamp#4825, vehicle_count#4826]
                                                         +- Relation [_id#4818,congestion_level#4819,lat#4820,lon#4821,road_id#4822,road_name#4823,speed#4824,timestamp#4825,vehicle_count#4826] MongoRelation(MongoRDD[286] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:30:58,590 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:03 +07)" executed successfully
2026-01-06 12:31:03,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:08 +07)" (scheduled at 2026-01-06 12:31:03.157382+07:00)
2026-01-06 12:31:03,159 - INFO -  Training Spark model...
2026-01-06 12:31:03,542 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_change#5197, vehicle_count_lag#5215, vehicle_count_change#5234, avg(speed#5055) windowspecdefinition(road_id#5041, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#5255]
+- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_change#5197, vehicle_count_lag#5215, CASE WHEN isnotnull(vehicle_count_lag#5215) THEN (vehicle_count#5065 - vehicle_count_lag#5215) ELSE 0.0 END AS vehicle_count_change#5234]
   +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_change#5197, vehicle_count_lag#5215]
      +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_change#5197, vehicle_count_lag#5215, vehicle_count_lag#5215]
         +- Window [lag(vehicle_count#5065, -1, null) windowspecdefinition(road_id#5041, timestamp#5044 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#5215], [road_id#5041], [timestamp#5044 ASC NULLS FIRST]
            +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_change#5197]
               +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, CASE WHEN isnotnull(speed_lag#5180) THEN (speed#5055 - speed_lag#5180) ELSE 0.0 END AS speed_change#5197]
                  +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180]
                     +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164, speed_lag#5180, speed_lag#5180]
                        +- Window [lag(speed#5055, -1, null) windowspecdefinition(road_id#5041, timestamp#5044 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#5180], [road_id#5041], [timestamp#5044 ASC NULLS FIRST]
                           +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, hour_cos#5164]
                              +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, hour_sin#5149, COS((0.2617993877991494 * cast(hour#5099 as double))) AS hour_cos#5164]
                                 +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, is_weekend#5135, SIN((0.2617993877991494 * cast(hour#5099 as double))) AS hour_sin#5149]
                                    +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, day_of_week#5122, CASE WHEN day_of_week#5122 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#5135]
                                       +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, is_peak#5110, dayofweek(cast(timestamp#5044 as date)) AS day_of_week#5122]
                                          +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour#5099, CASE WHEN hour#5099 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#5110]
                                             +- Project [_id#5037, congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065, hour(timestamp#5044, Some(Asia/Bangkok)) AS hour#5099]
                                                +- Project [_id#5037, cast(congestion_level#5038 as double) AS congestion_level#5075, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, vehicle_count#5065]
                                                   +- Project [_id#5037, congestion_level#5038, lat#5039, lon#5040, road_id#5041, road_name#5042, speed#5055, timestamp#5044, cast(vehicle_count#5045 as double) AS vehicle_count#5065]
                                                      +- Project [_id#5037, congestion_level#5038, lat#5039, lon#5040, road_id#5041, road_name#5042, cast(speed#5043 as double) AS speed#5055, timestamp#5044, vehicle_count#5045]
                                                         +- Relation [_id#5037,congestion_level#5038,lat#5039,lon#5040,road_id#5041,road_name#5042,speed#5043,timestamp#5044,vehicle_count#5045] MongoRelation(MongoRDD[299] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:03,542 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:08 +07)" executed successfully
2026-01-06 12:31:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:13 +07)" (scheduled at 2026-01-06 12:31:08.157382+07:00)
2026-01-06 12:31:08,159 - INFO -  Training Spark model...
2026-01-06 12:31:08,159 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:32:08 +07)" (scheduled at 2026-01-06 12:31:08.157779+07:00)
2026-01-06 12:31:08,159 - INFO -  Training Spark model...
2026-01-06 12:31:08,702 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_change#5559, vehicle_count_lag#5594, vehicle_count_change#5614, avg(speed#5302) windowspecdefinition(road_id#5269, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#5653]
+- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_change#5559, vehicle_count_lag#5594, CASE WHEN isnotnull(vehicle_count_lag#5594) THEN (vehicle_count#5322 - vehicle_count_lag#5594) ELSE 0.0 END AS vehicle_count_change#5614]
   +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_change#5559, vehicle_count_lag#5594]
      +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_change#5559, vehicle_count_lag#5594, vehicle_count_lag#5594]
         +- Window [lag(vehicle_count#5322, -1, null) windowspecdefinition(road_id#5269, timestamp#5272 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#5594], [road_id#5269], [timestamp#5272 ASC NULLS FIRST]
            +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_change#5559]
               +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, CASE WHEN isnotnull(speed_lag#5542) THEN (speed#5302 - speed_lag#5542) ELSE 0.0 END AS speed_change#5559]
                  +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542]
                     +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496, speed_lag#5542, speed_lag#5542]
                        +- Window [lag(speed#5302, -1, null) windowspecdefinition(road_id#5269, timestamp#5272 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#5542], [road_id#5269], [timestamp#5272 ASC NULLS FIRST]
                           +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, hour_cos#5496]
                              +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, hour_sin#5467, COS((0.2617993877991494 * cast(hour#5380 as double))) AS hour_cos#5496]
                                 +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, is_weekend#5452, SIN((0.2617993877991494 * cast(hour#5380 as double))) AS hour_sin#5467]
                                    +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, day_of_week#5426, CASE WHEN day_of_week#5426 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#5452]
                                       +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, is_peak#5402, dayofweek(cast(timestamp#5272 as date)) AS day_of_week#5426]
                                          +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour#5380, CASE WHEN hour#5380 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#5402]
                                             +- Project [_id#5265, congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322, hour(timestamp#5272, Some(Asia/Bangkok)) AS hour#5380]
                                                +- Project [_id#5265, cast(congestion_level#5266 as double) AS congestion_level#5354, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, vehicle_count#5322]
                                                   +- Project [_id#5265, congestion_level#5266, lat#5267, lon#5268, road_id#5269, road_name#5270, speed#5302, timestamp#5272, cast(vehicle_count#5273 as double) AS vehicle_count#5322]
                                                      +- Project [_id#5265, congestion_level#5266, lat#5267, lon#5268, road_id#5269, road_name#5270, cast(speed#5271 as double) AS speed#5302, timestamp#5272, vehicle_count#5273]
                                                         +- Relation [_id#5265,congestion_level#5266,lat#5267,lon#5268,road_id#5269,road_name#5270,speed#5271,timestamp#5272,vehicle_count#5273] MongoRelation(MongoRDD[314] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:08,703 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:13 +07)" executed successfully
2026-01-06 12:31:08,742 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_change#5613, vehicle_count_lag#5651, vehicle_count_change#5672, avg(speed#5292) windowspecdefinition(road_id#5260, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#5693]
+- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_change#5613, vehicle_count_lag#5651, CASE WHEN isnotnull(vehicle_count_lag#5651) THEN (vehicle_count#5312 - vehicle_count_lag#5651) ELSE 0.0 END AS vehicle_count_change#5672]
   +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_change#5613, vehicle_count_lag#5651]
      +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_change#5613, vehicle_count_lag#5651, vehicle_count_lag#5651]
         +- Window [lag(vehicle_count#5312, -1, null) windowspecdefinition(road_id#5260, timestamp#5263 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#5651], [road_id#5260], [timestamp#5263 ASC NULLS FIRST]
            +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_change#5613]
               +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, CASE WHEN isnotnull(speed_lag#5560) THEN (speed#5292 - speed_lag#5560) ELSE 0.0 END AS speed_change#5613]
                  +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560]
                     +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526, speed_lag#5560, speed_lag#5560]
                        +- Window [lag(speed#5292, -1, null) windowspecdefinition(road_id#5260, timestamp#5263 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#5560], [road_id#5260], [timestamp#5263 ASC NULLS FIRST]
                           +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, hour_cos#5526]
                              +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, hour_sin#5495, COS((0.2617993877991494 * cast(hour#5391 as double))) AS hour_cos#5526]
                                 +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, is_weekend#5466, SIN((0.2617993877991494 * cast(hour#5391 as double))) AS hour_sin#5495]
                                    +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, day_of_week#5439, CASE WHEN day_of_week#5439 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#5466]
                                       +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, is_peak#5414, dayofweek(cast(timestamp#5263 as date)) AS day_of_week#5439]
                                          +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour#5391, CASE WHEN hour#5391 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#5414]
                                             +- Project [_id#5256, congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312, hour(timestamp#5263, Some(Asia/Bangkok)) AS hour#5391]
                                                +- Project [_id#5256, cast(congestion_level#5257 as double) AS congestion_level#5323, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, vehicle_count#5312]
                                                   +- Project [_id#5256, congestion_level#5257, lat#5258, lon#5259, road_id#5260, road_name#5261, speed#5292, timestamp#5263, cast(vehicle_count#5264 as double) AS vehicle_count#5312]
                                                      +- Project [_id#5256, congestion_level#5257, lat#5258, lon#5259, road_id#5260, road_name#5261, cast(speed#5262 as double) AS speed#5292, timestamp#5263, vehicle_count#5264]
                                                         +- Relation [_id#5256,congestion_level#5257,lat#5258,lon#5259,road_id#5260,road_name#5261,speed#5262,timestamp#5263,vehicle_count#5264] MongoRelation(MongoRDD[312] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:08,742 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:32:08 +07)" executed successfully
2026-01-06 12:31:13,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:18 +07)" (scheduled at 2026-01-06 12:31:13.157382+07:00)
2026-01-06 12:31:13,160 - INFO -  Training Spark model...
2026-01-06 12:31:13,502 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_change#5854, vehicle_count_lag#5872, vehicle_count_change#5891, avg(speed#5712) windowspecdefinition(road_id#5698, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#5912]
+- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_change#5854, vehicle_count_lag#5872, CASE WHEN isnotnull(vehicle_count_lag#5872) THEN (vehicle_count#5722 - vehicle_count_lag#5872) ELSE 0.0 END AS vehicle_count_change#5891]
   +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_change#5854, vehicle_count_lag#5872]
      +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_change#5854, vehicle_count_lag#5872, vehicle_count_lag#5872]
         +- Window [lag(vehicle_count#5722, -1, null) windowspecdefinition(road_id#5698, timestamp#5701 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#5872], [road_id#5698], [timestamp#5701 ASC NULLS FIRST]
            +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_change#5854]
               +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, CASE WHEN isnotnull(speed_lag#5837) THEN (speed#5712 - speed_lag#5837) ELSE 0.0 END AS speed_change#5854]
                  +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837]
                     +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821, speed_lag#5837, speed_lag#5837]
                        +- Window [lag(speed#5712, -1, null) windowspecdefinition(road_id#5698, timestamp#5701 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#5837], [road_id#5698], [timestamp#5701 ASC NULLS FIRST]
                           +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, hour_cos#5821]
                              +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, hour_sin#5806, COS((0.2617993877991494 * cast(hour#5756 as double))) AS hour_cos#5821]
                                 +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, is_weekend#5792, SIN((0.2617993877991494 * cast(hour#5756 as double))) AS hour_sin#5806]
                                    +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, day_of_week#5779, CASE WHEN day_of_week#5779 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#5792]
                                       +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, is_peak#5767, dayofweek(cast(timestamp#5701 as date)) AS day_of_week#5779]
                                          +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour#5756, CASE WHEN hour#5756 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#5767]
                                             +- Project [_id#5694, congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722, hour(timestamp#5701, Some(Asia/Bangkok)) AS hour#5756]
                                                +- Project [_id#5694, cast(congestion_level#5695 as double) AS congestion_level#5732, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, vehicle_count#5722]
                                                   +- Project [_id#5694, congestion_level#5695, lat#5696, lon#5697, road_id#5698, road_name#5699, speed#5712, timestamp#5701, cast(vehicle_count#5702 as double) AS vehicle_count#5722]
                                                      +- Project [_id#5694, congestion_level#5695, lat#5696, lon#5697, road_id#5698, road_name#5699, cast(speed#5700 as double) AS speed#5712, timestamp#5701, vehicle_count#5702]
                                                         +- Relation [_id#5694,congestion_level#5695,lat#5696,lon#5697,road_id#5698,road_name#5699,speed#5700,timestamp#5701,vehicle_count#5702] MongoRelation(MongoRDD[338] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:13,502 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:18 +07)" executed successfully
2026-01-06 12:31:18,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:23 +07)" (scheduled at 2026-01-06 12:31:18.157382+07:00)
2026-01-06 12:31:18,158 - INFO -  Training Spark model...
2026-01-06 12:31:18,550 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_change#6073, vehicle_count_lag#6091, vehicle_count_change#6110, avg(speed#5931) windowspecdefinition(road_id#5917, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#6131]
+- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_change#6073, vehicle_count_lag#6091, CASE WHEN isnotnull(vehicle_count_lag#6091) THEN (vehicle_count#5941 - vehicle_count_lag#6091) ELSE 0.0 END AS vehicle_count_change#6110]
   +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_change#6073, vehicle_count_lag#6091]
      +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_change#6073, vehicle_count_lag#6091, vehicle_count_lag#6091]
         +- Window [lag(vehicle_count#5941, -1, null) windowspecdefinition(road_id#5917, timestamp#5920 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#6091], [road_id#5917], [timestamp#5920 ASC NULLS FIRST]
            +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_change#6073]
               +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, CASE WHEN isnotnull(speed_lag#6056) THEN (speed#5931 - speed_lag#6056) ELSE 0.0 END AS speed_change#6073]
                  +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056]
                     +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040, speed_lag#6056, speed_lag#6056]
                        +- Window [lag(speed#5931, -1, null) windowspecdefinition(road_id#5917, timestamp#5920 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#6056], [road_id#5917], [timestamp#5920 ASC NULLS FIRST]
                           +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, hour_cos#6040]
                              +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, hour_sin#6025, COS((0.2617993877991494 * cast(hour#5975 as double))) AS hour_cos#6040]
                                 +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, is_weekend#6011, SIN((0.2617993877991494 * cast(hour#5975 as double))) AS hour_sin#6025]
                                    +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, day_of_week#5998, CASE WHEN day_of_week#5998 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#6011]
                                       +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, is_peak#5986, dayofweek(cast(timestamp#5920 as date)) AS day_of_week#5998]
                                          +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour#5975, CASE WHEN hour#5975 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#5986]
                                             +- Project [_id#5913, congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941, hour(timestamp#5920, Some(Asia/Bangkok)) AS hour#5975]
                                                +- Project [_id#5913, cast(congestion_level#5914 as double) AS congestion_level#5951, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, vehicle_count#5941]
                                                   +- Project [_id#5913, congestion_level#5914, lat#5915, lon#5916, road_id#5917, road_name#5918, speed#5931, timestamp#5920, cast(vehicle_count#5921 as double) AS vehicle_count#5941]
                                                      +- Project [_id#5913, congestion_level#5914, lat#5915, lon#5916, road_id#5917, road_name#5918, cast(speed#5919 as double) AS speed#5931, timestamp#5920, vehicle_count#5921]
                                                         +- Relation [_id#5913,congestion_level#5914,lat#5915,lon#5916,road_id#5917,road_name#5918,speed#5919,timestamp#5920,vehicle_count#5921] MongoRelation(MongoRDD[351] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:18,550 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:23 +07)" executed successfully
2026-01-06 12:31:23,166 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:28 +07)" (scheduled at 2026-01-06 12:31:23.157382+07:00)
2026-01-06 12:31:23,167 - INFO -  Training Spark model...
2026-01-06 12:31:23,519 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_change#6292, vehicle_count_lag#6310, vehicle_count_change#6329, avg(speed#6150) windowspecdefinition(road_id#6136, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#6350]
+- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_change#6292, vehicle_count_lag#6310, CASE WHEN isnotnull(vehicle_count_lag#6310) THEN (vehicle_count#6160 - vehicle_count_lag#6310) ELSE 0.0 END AS vehicle_count_change#6329]
   +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_change#6292, vehicle_count_lag#6310]
      +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_change#6292, vehicle_count_lag#6310, vehicle_count_lag#6310]
         +- Window [lag(vehicle_count#6160, -1, null) windowspecdefinition(road_id#6136, timestamp#6139 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#6310], [road_id#6136], [timestamp#6139 ASC NULLS FIRST]
            +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_change#6292]
               +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, CASE WHEN isnotnull(speed_lag#6275) THEN (speed#6150 - speed_lag#6275) ELSE 0.0 END AS speed_change#6292]
                  +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275]
                     +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259, speed_lag#6275, speed_lag#6275]
                        +- Window [lag(speed#6150, -1, null) windowspecdefinition(road_id#6136, timestamp#6139 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#6275], [road_id#6136], [timestamp#6139 ASC NULLS FIRST]
                           +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, hour_cos#6259]
                              +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, hour_sin#6244, COS((0.2617993877991494 * cast(hour#6194 as double))) AS hour_cos#6259]
                                 +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, is_weekend#6230, SIN((0.2617993877991494 * cast(hour#6194 as double))) AS hour_sin#6244]
                                    +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, day_of_week#6217, CASE WHEN day_of_week#6217 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#6230]
                                       +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, is_peak#6205, dayofweek(cast(timestamp#6139 as date)) AS day_of_week#6217]
                                          +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour#6194, CASE WHEN hour#6194 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#6205]
                                             +- Project [_id#6132, congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160, hour(timestamp#6139, Some(Asia/Bangkok)) AS hour#6194]
                                                +- Project [_id#6132, cast(congestion_level#6133 as double) AS congestion_level#6170, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, vehicle_count#6160]
                                                   +- Project [_id#6132, congestion_level#6133, lat#6134, lon#6135, road_id#6136, road_name#6137, speed#6150, timestamp#6139, cast(vehicle_count#6140 as double) AS vehicle_count#6160]
                                                      +- Project [_id#6132, congestion_level#6133, lat#6134, lon#6135, road_id#6136, road_name#6137, cast(speed#6138 as double) AS speed#6150, timestamp#6139, vehicle_count#6140]
                                                         +- Relation [_id#6132,congestion_level#6133,lat#6134,lon#6135,road_id#6136,road_name#6137,speed#6138,timestamp#6139,vehicle_count#6140] MongoRelation(MongoRDD[364] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:23,519 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:28 +07)" executed successfully
2026-01-06 12:31:28,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:33 +07)" (scheduled at 2026-01-06 12:31:28.157382+07:00)
2026-01-06 12:31:28,158 - INFO -  Training Spark model...
2026-01-06 12:31:28,525 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_change#6511, vehicle_count_lag#6529, vehicle_count_change#6548, avg(speed#6369) windowspecdefinition(road_id#6355, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#6569]
+- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_change#6511, vehicle_count_lag#6529, CASE WHEN isnotnull(vehicle_count_lag#6529) THEN (vehicle_count#6379 - vehicle_count_lag#6529) ELSE 0.0 END AS vehicle_count_change#6548]
   +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_change#6511, vehicle_count_lag#6529]
      +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_change#6511, vehicle_count_lag#6529, vehicle_count_lag#6529]
         +- Window [lag(vehicle_count#6379, -1, null) windowspecdefinition(road_id#6355, timestamp#6358 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#6529], [road_id#6355], [timestamp#6358 ASC NULLS FIRST]
            +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_change#6511]
               +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, CASE WHEN isnotnull(speed_lag#6494) THEN (speed#6369 - speed_lag#6494) ELSE 0.0 END AS speed_change#6511]
                  +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494]
                     +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478, speed_lag#6494, speed_lag#6494]
                        +- Window [lag(speed#6369, -1, null) windowspecdefinition(road_id#6355, timestamp#6358 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#6494], [road_id#6355], [timestamp#6358 ASC NULLS FIRST]
                           +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, hour_cos#6478]
                              +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, hour_sin#6463, COS((0.2617993877991494 * cast(hour#6413 as double))) AS hour_cos#6478]
                                 +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, is_weekend#6449, SIN((0.2617993877991494 * cast(hour#6413 as double))) AS hour_sin#6463]
                                    +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, day_of_week#6436, CASE WHEN day_of_week#6436 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#6449]
                                       +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, is_peak#6424, dayofweek(cast(timestamp#6358 as date)) AS day_of_week#6436]
                                          +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour#6413, CASE WHEN hour#6413 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#6424]
                                             +- Project [_id#6351, congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379, hour(timestamp#6358, Some(Asia/Bangkok)) AS hour#6413]
                                                +- Project [_id#6351, cast(congestion_level#6352 as double) AS congestion_level#6389, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, vehicle_count#6379]
                                                   +- Project [_id#6351, congestion_level#6352, lat#6353, lon#6354, road_id#6355, road_name#6356, speed#6369, timestamp#6358, cast(vehicle_count#6359 as double) AS vehicle_count#6379]
                                                      +- Project [_id#6351, congestion_level#6352, lat#6353, lon#6354, road_id#6355, road_name#6356, cast(speed#6357 as double) AS speed#6369, timestamp#6358, vehicle_count#6359]
                                                         +- Relation [_id#6351,congestion_level#6352,lat#6353,lon#6354,road_id#6355,road_name#6356,speed#6357,timestamp#6358,vehicle_count#6359] MongoRelation(MongoRDD[377] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:28,525 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:33 +07)" executed successfully
2026-01-06 12:31:33,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:38 +07)" (scheduled at 2026-01-06 12:31:33.157382+07:00)
2026-01-06 12:31:33,162 - INFO -  Training Spark model...
2026-01-06 12:31:33,506 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_change#6730, vehicle_count_lag#6748, vehicle_count_change#6767, avg(speed#6588) windowspecdefinition(road_id#6574, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#6788]
+- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_change#6730, vehicle_count_lag#6748, CASE WHEN isnotnull(vehicle_count_lag#6748) THEN (vehicle_count#6598 - vehicle_count_lag#6748) ELSE 0.0 END AS vehicle_count_change#6767]
   +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_change#6730, vehicle_count_lag#6748]
      +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_change#6730, vehicle_count_lag#6748, vehicle_count_lag#6748]
         +- Window [lag(vehicle_count#6598, -1, null) windowspecdefinition(road_id#6574, timestamp#6577 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#6748], [road_id#6574], [timestamp#6577 ASC NULLS FIRST]
            +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_change#6730]
               +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, CASE WHEN isnotnull(speed_lag#6713) THEN (speed#6588 - speed_lag#6713) ELSE 0.0 END AS speed_change#6730]
                  +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713]
                     +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697, speed_lag#6713, speed_lag#6713]
                        +- Window [lag(speed#6588, -1, null) windowspecdefinition(road_id#6574, timestamp#6577 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#6713], [road_id#6574], [timestamp#6577 ASC NULLS FIRST]
                           +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, hour_cos#6697]
                              +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, hour_sin#6682, COS((0.2617993877991494 * cast(hour#6632 as double))) AS hour_cos#6697]
                                 +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, is_weekend#6668, SIN((0.2617993877991494 * cast(hour#6632 as double))) AS hour_sin#6682]
                                    +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, day_of_week#6655, CASE WHEN day_of_week#6655 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#6668]
                                       +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, is_peak#6643, dayofweek(cast(timestamp#6577 as date)) AS day_of_week#6655]
                                          +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour#6632, CASE WHEN hour#6632 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#6643]
                                             +- Project [_id#6570, congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598, hour(timestamp#6577, Some(Asia/Bangkok)) AS hour#6632]
                                                +- Project [_id#6570, cast(congestion_level#6571 as double) AS congestion_level#6608, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, vehicle_count#6598]
                                                   +- Project [_id#6570, congestion_level#6571, lat#6572, lon#6573, road_id#6574, road_name#6575, speed#6588, timestamp#6577, cast(vehicle_count#6578 as double) AS vehicle_count#6598]
                                                      +- Project [_id#6570, congestion_level#6571, lat#6572, lon#6573, road_id#6574, road_name#6575, cast(speed#6576 as double) AS speed#6588, timestamp#6577, vehicle_count#6578]
                                                         +- Relation [_id#6570,congestion_level#6571,lat#6572,lon#6573,road_id#6574,road_name#6575,speed#6576,timestamp#6577,vehicle_count#6578] MongoRelation(MongoRDD[390] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:33,506 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:38 +07)" executed successfully
2026-01-06 12:31:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:43 +07)" (scheduled at 2026-01-06 12:31:38.157382+07:00)
2026-01-06 12:31:38,158 - INFO -  Training Spark model...
2026-01-06 12:31:38,558 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_change#6949, vehicle_count_lag#6967, vehicle_count_change#6986, avg(speed#6807) windowspecdefinition(road_id#6793, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#7007]
+- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_change#6949, vehicle_count_lag#6967, CASE WHEN isnotnull(vehicle_count_lag#6967) THEN (vehicle_count#6817 - vehicle_count_lag#6967) ELSE 0.0 END AS vehicle_count_change#6986]
   +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_change#6949, vehicle_count_lag#6967]
      +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_change#6949, vehicle_count_lag#6967, vehicle_count_lag#6967]
         +- Window [lag(vehicle_count#6817, -1, null) windowspecdefinition(road_id#6793, timestamp#6796 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#6967], [road_id#6793], [timestamp#6796 ASC NULLS FIRST]
            +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_change#6949]
               +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, CASE WHEN isnotnull(speed_lag#6932) THEN (speed#6807 - speed_lag#6932) ELSE 0.0 END AS speed_change#6949]
                  +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932]
                     +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916, speed_lag#6932, speed_lag#6932]
                        +- Window [lag(speed#6807, -1, null) windowspecdefinition(road_id#6793, timestamp#6796 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#6932], [road_id#6793], [timestamp#6796 ASC NULLS FIRST]
                           +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, hour_cos#6916]
                              +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, hour_sin#6901, COS((0.2617993877991494 * cast(hour#6851 as double))) AS hour_cos#6916]
                                 +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, is_weekend#6887, SIN((0.2617993877991494 * cast(hour#6851 as double))) AS hour_sin#6901]
                                    +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, day_of_week#6874, CASE WHEN day_of_week#6874 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#6887]
                                       +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, is_peak#6862, dayofweek(cast(timestamp#6796 as date)) AS day_of_week#6874]
                                          +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour#6851, CASE WHEN hour#6851 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#6862]
                                             +- Project [_id#6789, congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817, hour(timestamp#6796, Some(Asia/Bangkok)) AS hour#6851]
                                                +- Project [_id#6789, cast(congestion_level#6790 as double) AS congestion_level#6827, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, vehicle_count#6817]
                                                   +- Project [_id#6789, congestion_level#6790, lat#6791, lon#6792, road_id#6793, road_name#6794, speed#6807, timestamp#6796, cast(vehicle_count#6797 as double) AS vehicle_count#6817]
                                                      +- Project [_id#6789, congestion_level#6790, lat#6791, lon#6792, road_id#6793, road_name#6794, cast(speed#6795 as double) AS speed#6807, timestamp#6796, vehicle_count#6797]
                                                         +- Relation [_id#6789,congestion_level#6790,lat#6791,lon#6792,road_id#6793,road_name#6794,speed#6795,timestamp#6796,vehicle_count#6797] MongoRelation(MongoRDD[403] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:38,558 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:43 +07)" executed successfully
2026-01-06 12:31:43,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:48 +07)" (scheduled at 2026-01-06 12:31:43.157382+07:00)
2026-01-06 12:31:43,158 - INFO -  Training Spark model...
2026-01-06 12:31:43,561 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_change#7168, vehicle_count_lag#7186, vehicle_count_change#7205, avg(speed#7026) windowspecdefinition(road_id#7012, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#7226]
+- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_change#7168, vehicle_count_lag#7186, CASE WHEN isnotnull(vehicle_count_lag#7186) THEN (vehicle_count#7036 - vehicle_count_lag#7186) ELSE 0.0 END AS vehicle_count_change#7205]
   +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_change#7168, vehicle_count_lag#7186]
      +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_change#7168, vehicle_count_lag#7186, vehicle_count_lag#7186]
         +- Window [lag(vehicle_count#7036, -1, null) windowspecdefinition(road_id#7012, timestamp#7015 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#7186], [road_id#7012], [timestamp#7015 ASC NULLS FIRST]
            +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_change#7168]
               +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, CASE WHEN isnotnull(speed_lag#7151) THEN (speed#7026 - speed_lag#7151) ELSE 0.0 END AS speed_change#7168]
                  +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151]
                     +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135, speed_lag#7151, speed_lag#7151]
                        +- Window [lag(speed#7026, -1, null) windowspecdefinition(road_id#7012, timestamp#7015 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#7151], [road_id#7012], [timestamp#7015 ASC NULLS FIRST]
                           +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, hour_cos#7135]
                              +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, hour_sin#7120, COS((0.2617993877991494 * cast(hour#7070 as double))) AS hour_cos#7135]
                                 +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, is_weekend#7106, SIN((0.2617993877991494 * cast(hour#7070 as double))) AS hour_sin#7120]
                                    +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, day_of_week#7093, CASE WHEN day_of_week#7093 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#7106]
                                       +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, is_peak#7081, dayofweek(cast(timestamp#7015 as date)) AS day_of_week#7093]
                                          +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour#7070, CASE WHEN hour#7070 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#7081]
                                             +- Project [_id#7008, congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036, hour(timestamp#7015, Some(Asia/Bangkok)) AS hour#7070]
                                                +- Project [_id#7008, cast(congestion_level#7009 as double) AS congestion_level#7046, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, vehicle_count#7036]
                                                   +- Project [_id#7008, congestion_level#7009, lat#7010, lon#7011, road_id#7012, road_name#7013, speed#7026, timestamp#7015, cast(vehicle_count#7016 as double) AS vehicle_count#7036]
                                                      +- Project [_id#7008, congestion_level#7009, lat#7010, lon#7011, road_id#7012, road_name#7013, cast(speed#7014 as double) AS speed#7026, timestamp#7015, vehicle_count#7016]
                                                         +- Relation [_id#7008,congestion_level#7009,lat#7010,lon#7011,road_id#7012,road_name#7013,speed#7014,timestamp#7015,vehicle_count#7016] MongoRelation(MongoRDD[416] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:43,561 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:48 +07)" executed successfully
2026-01-06 12:31:48,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:53 +07)" (scheduled at 2026-01-06 12:31:48.157382+07:00)
2026-01-06 12:31:48,163 - INFO -  Training Spark model...
2026-01-06 12:31:48,509 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_change#7387, vehicle_count_lag#7405, vehicle_count_change#7424, avg(speed#7245) windowspecdefinition(road_id#7231, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#7445]
+- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_change#7387, vehicle_count_lag#7405, CASE WHEN isnotnull(vehicle_count_lag#7405) THEN (vehicle_count#7255 - vehicle_count_lag#7405) ELSE 0.0 END AS vehicle_count_change#7424]
   +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_change#7387, vehicle_count_lag#7405]
      +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_change#7387, vehicle_count_lag#7405, vehicle_count_lag#7405]
         +- Window [lag(vehicle_count#7255, -1, null) windowspecdefinition(road_id#7231, timestamp#7234 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#7405], [road_id#7231], [timestamp#7234 ASC NULLS FIRST]
            +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_change#7387]
               +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, CASE WHEN isnotnull(speed_lag#7370) THEN (speed#7245 - speed_lag#7370) ELSE 0.0 END AS speed_change#7387]
                  +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370]
                     +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354, speed_lag#7370, speed_lag#7370]
                        +- Window [lag(speed#7245, -1, null) windowspecdefinition(road_id#7231, timestamp#7234 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#7370], [road_id#7231], [timestamp#7234 ASC NULLS FIRST]
                           +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, hour_cos#7354]
                              +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, hour_sin#7339, COS((0.2617993877991494 * cast(hour#7289 as double))) AS hour_cos#7354]
                                 +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, is_weekend#7325, SIN((0.2617993877991494 * cast(hour#7289 as double))) AS hour_sin#7339]
                                    +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, day_of_week#7312, CASE WHEN day_of_week#7312 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#7325]
                                       +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, is_peak#7300, dayofweek(cast(timestamp#7234 as date)) AS day_of_week#7312]
                                          +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour#7289, CASE WHEN hour#7289 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#7300]
                                             +- Project [_id#7227, congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255, hour(timestamp#7234, Some(Asia/Bangkok)) AS hour#7289]
                                                +- Project [_id#7227, cast(congestion_level#7228 as double) AS congestion_level#7265, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, vehicle_count#7255]
                                                   +- Project [_id#7227, congestion_level#7228, lat#7229, lon#7230, road_id#7231, road_name#7232, speed#7245, timestamp#7234, cast(vehicle_count#7235 as double) AS vehicle_count#7255]
                                                      +- Project [_id#7227, congestion_level#7228, lat#7229, lon#7230, road_id#7231, road_name#7232, cast(speed#7233 as double) AS speed#7245, timestamp#7234, vehicle_count#7235]
                                                         +- Relation [_id#7227,congestion_level#7228,lat#7229,lon#7230,road_id#7231,road_name#7232,speed#7233,timestamp#7234,vehicle_count#7235] MongoRelation(MongoRDD[429] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:48,509 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:53 +07)" executed successfully
2026-01-06 12:31:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:58 +07)" (scheduled at 2026-01-06 12:31:53.157382+07:00)
2026-01-06 12:31:53,160 - INFO -  Training Spark model...
2026-01-06 12:31:53,552 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_change#7606, vehicle_count_lag#7624, vehicle_count_change#7643, avg(speed#7464) windowspecdefinition(road_id#7450, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#7664]
+- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_change#7606, vehicle_count_lag#7624, CASE WHEN isnotnull(vehicle_count_lag#7624) THEN (vehicle_count#7474 - vehicle_count_lag#7624) ELSE 0.0 END AS vehicle_count_change#7643]
   +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_change#7606, vehicle_count_lag#7624]
      +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_change#7606, vehicle_count_lag#7624, vehicle_count_lag#7624]
         +- Window [lag(vehicle_count#7474, -1, null) windowspecdefinition(road_id#7450, timestamp#7453 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#7624], [road_id#7450], [timestamp#7453 ASC NULLS FIRST]
            +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_change#7606]
               +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, CASE WHEN isnotnull(speed_lag#7589) THEN (speed#7464 - speed_lag#7589) ELSE 0.0 END AS speed_change#7606]
                  +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589]
                     +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573, speed_lag#7589, speed_lag#7589]
                        +- Window [lag(speed#7464, -1, null) windowspecdefinition(road_id#7450, timestamp#7453 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#7589], [road_id#7450], [timestamp#7453 ASC NULLS FIRST]
                           +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, hour_cos#7573]
                              +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, hour_sin#7558, COS((0.2617993877991494 * cast(hour#7508 as double))) AS hour_cos#7573]
                                 +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, is_weekend#7544, SIN((0.2617993877991494 * cast(hour#7508 as double))) AS hour_sin#7558]
                                    +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, day_of_week#7531, CASE WHEN day_of_week#7531 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#7544]
                                       +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, is_peak#7519, dayofweek(cast(timestamp#7453 as date)) AS day_of_week#7531]
                                          +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour#7508, CASE WHEN hour#7508 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#7519]
                                             +- Project [_id#7446, congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474, hour(timestamp#7453, Some(Asia/Bangkok)) AS hour#7508]
                                                +- Project [_id#7446, cast(congestion_level#7447 as double) AS congestion_level#7484, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, vehicle_count#7474]
                                                   +- Project [_id#7446, congestion_level#7447, lat#7448, lon#7449, road_id#7450, road_name#7451, speed#7464, timestamp#7453, cast(vehicle_count#7454 as double) AS vehicle_count#7474]
                                                      +- Project [_id#7446, congestion_level#7447, lat#7448, lon#7449, road_id#7450, road_name#7451, cast(speed#7452 as double) AS speed#7464, timestamp#7453, vehicle_count#7454]
                                                         +- Relation [_id#7446,congestion_level#7447,lat#7448,lon#7449,road_id#7450,road_name#7451,speed#7452,timestamp#7453,vehicle_count#7454] MongoRelation(MongoRDD[442] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:53,552 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:31:58 +07)" executed successfully
2026-01-06 12:31:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:03 +07)" (scheduled at 2026-01-06 12:31:58.157382+07:00)
2026-01-06 12:31:58,158 - INFO -  Training Spark model...
2026-01-06 12:31:58,621 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_change#7825, vehicle_count_lag#7843, vehicle_count_change#7862, avg(speed#7683) windowspecdefinition(road_id#7669, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#7883]
+- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_change#7825, vehicle_count_lag#7843, CASE WHEN isnotnull(vehicle_count_lag#7843) THEN (vehicle_count#7693 - vehicle_count_lag#7843) ELSE 0.0 END AS vehicle_count_change#7862]
   +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_change#7825, vehicle_count_lag#7843]
      +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_change#7825, vehicle_count_lag#7843, vehicle_count_lag#7843]
         +- Window [lag(vehicle_count#7693, -1, null) windowspecdefinition(road_id#7669, timestamp#7672 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#7843], [road_id#7669], [timestamp#7672 ASC NULLS FIRST]
            +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_change#7825]
               +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, CASE WHEN isnotnull(speed_lag#7808) THEN (speed#7683 - speed_lag#7808) ELSE 0.0 END AS speed_change#7825]
                  +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808]
                     +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792, speed_lag#7808, speed_lag#7808]
                        +- Window [lag(speed#7683, -1, null) windowspecdefinition(road_id#7669, timestamp#7672 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#7808], [road_id#7669], [timestamp#7672 ASC NULLS FIRST]
                           +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, hour_cos#7792]
                              +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, hour_sin#7777, COS((0.2617993877991494 * cast(hour#7727 as double))) AS hour_cos#7792]
                                 +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, is_weekend#7763, SIN((0.2617993877991494 * cast(hour#7727 as double))) AS hour_sin#7777]
                                    +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, day_of_week#7750, CASE WHEN day_of_week#7750 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#7763]
                                       +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, is_peak#7738, dayofweek(cast(timestamp#7672 as date)) AS day_of_week#7750]
                                          +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour#7727, CASE WHEN hour#7727 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#7738]
                                             +- Project [_id#7665, congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693, hour(timestamp#7672, Some(Asia/Bangkok)) AS hour#7727]
                                                +- Project [_id#7665, cast(congestion_level#7666 as double) AS congestion_level#7703, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, vehicle_count#7693]
                                                   +- Project [_id#7665, congestion_level#7666, lat#7667, lon#7668, road_id#7669, road_name#7670, speed#7683, timestamp#7672, cast(vehicle_count#7673 as double) AS vehicle_count#7693]
                                                      +- Project [_id#7665, congestion_level#7666, lat#7667, lon#7668, road_id#7669, road_name#7670, cast(speed#7671 as double) AS speed#7683, timestamp#7672, vehicle_count#7673]
                                                         +- Relation [_id#7665,congestion_level#7666,lat#7667,lon#7668,road_id#7669,road_name#7670,speed#7671,timestamp#7672,vehicle_count#7673] MongoRelation(MongoRDD[455] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:31:58,621 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:03 +07)" executed successfully
2026-01-06 12:32:03,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:08 +07)" (scheduled at 2026-01-06 12:32:03.157382+07:00)
2026-01-06 12:32:03,158 - INFO -  Training Spark model...
2026-01-06 12:32:03,527 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_change#8044, vehicle_count_lag#8062, vehicle_count_change#8081, avg(speed#7902) windowspecdefinition(road_id#7888, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#8102]
+- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_change#8044, vehicle_count_lag#8062, CASE WHEN isnotnull(vehicle_count_lag#8062) THEN (vehicle_count#7912 - vehicle_count_lag#8062) ELSE 0.0 END AS vehicle_count_change#8081]
   +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_change#8044, vehicle_count_lag#8062]
      +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_change#8044, vehicle_count_lag#8062, vehicle_count_lag#8062]
         +- Window [lag(vehicle_count#7912, -1, null) windowspecdefinition(road_id#7888, timestamp#7891 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#8062], [road_id#7888], [timestamp#7891 ASC NULLS FIRST]
            +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_change#8044]
               +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, CASE WHEN isnotnull(speed_lag#8027) THEN (speed#7902 - speed_lag#8027) ELSE 0.0 END AS speed_change#8044]
                  +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027]
                     +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011, speed_lag#8027, speed_lag#8027]
                        +- Window [lag(speed#7902, -1, null) windowspecdefinition(road_id#7888, timestamp#7891 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#8027], [road_id#7888], [timestamp#7891 ASC NULLS FIRST]
                           +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, hour_cos#8011]
                              +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, hour_sin#7996, COS((0.2617993877991494 * cast(hour#7946 as double))) AS hour_cos#8011]
                                 +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, is_weekend#7982, SIN((0.2617993877991494 * cast(hour#7946 as double))) AS hour_sin#7996]
                                    +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, day_of_week#7969, CASE WHEN day_of_week#7969 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#7982]
                                       +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, is_peak#7957, dayofweek(cast(timestamp#7891 as date)) AS day_of_week#7969]
                                          +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour#7946, CASE WHEN hour#7946 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#7957]
                                             +- Project [_id#7884, congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912, hour(timestamp#7891, Some(Asia/Bangkok)) AS hour#7946]
                                                +- Project [_id#7884, cast(congestion_level#7885 as double) AS congestion_level#7922, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, vehicle_count#7912]
                                                   +- Project [_id#7884, congestion_level#7885, lat#7886, lon#7887, road_id#7888, road_name#7889, speed#7902, timestamp#7891, cast(vehicle_count#7892 as double) AS vehicle_count#7912]
                                                      +- Project [_id#7884, congestion_level#7885, lat#7886, lon#7887, road_id#7888, road_name#7889, cast(speed#7890 as double) AS speed#7902, timestamp#7891, vehicle_count#7892]
                                                         +- Relation [_id#7884,congestion_level#7885,lat#7886,lon#7887,road_id#7888,road_name#7889,speed#7890,timestamp#7891,vehicle_count#7892] MongoRelation(MongoRDD[468] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:03,528 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:08 +07)" executed successfully
2026-01-06 12:32:08,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:13 +07)" (scheduled at 2026-01-06 12:32:08.157382+07:00)
2026-01-06 12:32:08,165 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:33:08 +07)" (scheduled at 2026-01-06 12:32:08.157779+07:00)
2026-01-06 12:32:08,165 - INFO -  Training Spark model...
2026-01-06 12:32:08,165 - INFO -  Training Spark model...
2026-01-06 12:32:08,626 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_change#8442, vehicle_count_lag#8478, vehicle_count_change#8498, avg(speed#8149) windowspecdefinition(road_id#8125, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#8538]
+- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_change#8442, vehicle_count_lag#8478, CASE WHEN isnotnull(vehicle_count_lag#8478) THEN (vehicle_count#8169 - vehicle_count_lag#8478) ELSE 0.0 END AS vehicle_count_change#8498]
   +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_change#8442, vehicle_count_lag#8478]
      +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_change#8442, vehicle_count_lag#8478, vehicle_count_lag#8478]
         +- Window [lag(vehicle_count#8169, -1, null) windowspecdefinition(road_id#8125, timestamp#8128 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#8478], [road_id#8125], [timestamp#8128 ASC NULLS FIRST]
            +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_change#8442]
               +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, CASE WHEN isnotnull(speed_lag#8407) THEN (speed#8149 - speed_lag#8407) ELSE 0.0 END AS speed_change#8442]
                  +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407]
                     +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374, speed_lag#8407, speed_lag#8407]
                        +- Window [lag(speed#8149, -1, null) windowspecdefinition(road_id#8125, timestamp#8128 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#8407], [road_id#8125], [timestamp#8128 ASC NULLS FIRST]
                           +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, hour_cos#8374]
                              +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, hour_sin#8358, COS((0.2617993877991494 * cast(hour#8238 as double))) AS hour_cos#8374]
                                 +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, is_weekend#8328, SIN((0.2617993877991494 * cast(hour#8238 as double))) AS hour_sin#8358]
                                    +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, day_of_week#8287, CASE WHEN day_of_week#8287 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#8328]
                                       +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, is_peak#8274, dayofweek(cast(timestamp#8128 as date)) AS day_of_week#8287]
                                          +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour#8238, CASE WHEN hour#8238 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#8274]
                                             +- Project [_id#8121, congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169, hour(timestamp#8128, Some(Asia/Bangkok)) AS hour#8238]
                                                +- Project [_id#8121, cast(congestion_level#8122 as double) AS congestion_level#8189, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, vehicle_count#8169]
                                                   +- Project [_id#8121, congestion_level#8122, lat#8123, lon#8124, road_id#8125, road_name#8126, speed#8149, timestamp#8128, cast(vehicle_count#8129 as double) AS vehicle_count#8169]
                                                      +- Project [_id#8121, congestion_level#8122, lat#8123, lon#8124, road_id#8125, road_name#8126, cast(speed#8127 as double) AS speed#8149, timestamp#8128, vehicle_count#8129]
                                                         +- Relation [_id#8121,congestion_level#8122,lat#8123,lon#8124,road_id#8125,road_name#8126,speed#8127,timestamp#8128,vehicle_count#8129] MongoRelation(MongoRDD[481] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:08,626 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:33:08 +07)" executed successfully
2026-01-06 12:32:08,627 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_change#8406, vehicle_count_lag#8441, vehicle_count_change#8497, avg(speed#8139) windowspecdefinition(road_id#8107, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#8540]
+- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_change#8406, vehicle_count_lag#8441, CASE WHEN isnotnull(vehicle_count_lag#8441) THEN (vehicle_count#8159 - vehicle_count_lag#8441) ELSE 0.0 END AS vehicle_count_change#8497]
   +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_change#8406, vehicle_count_lag#8441]
      +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_change#8406, vehicle_count_lag#8441, vehicle_count_lag#8441]
         +- Window [lag(vehicle_count#8159, -1, null) windowspecdefinition(road_id#8107, timestamp#8110 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#8441], [road_id#8107], [timestamp#8110 ASC NULLS FIRST]
            +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_change#8406]
               +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, CASE WHEN isnotnull(speed_lag#8373) THEN (speed#8139 - speed_lag#8373) ELSE 0.0 END AS speed_change#8406]
                  +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373]
                     +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342, speed_lag#8373, speed_lag#8373]
                        +- Window [lag(speed#8139, -1, null) windowspecdefinition(road_id#8107, timestamp#8110 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#8373], [road_id#8107], [timestamp#8110 ASC NULLS FIRST]
                           +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, hour_cos#8342]
                              +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, hour_sin#8313, COS((0.2617993877991494 * cast(hour#8227 as double))) AS hour_cos#8342]
                                 +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, is_weekend#8286, SIN((0.2617993877991494 * cast(hour#8227 as double))) AS hour_sin#8313]
                                    +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, day_of_week#8261, CASE WHEN day_of_week#8261 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#8286]
                                       +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, is_peak#8249, dayofweek(cast(timestamp#8110 as date)) AS day_of_week#8261]
                                          +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour#8227, CASE WHEN hour#8227 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#8249]
                                             +- Project [_id#8103, congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159, hour(timestamp#8110, Some(Asia/Bangkok)) AS hour#8227]
                                                +- Project [_id#8103, cast(congestion_level#8104 as double) AS congestion_level#8179, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, vehicle_count#8159]
                                                   +- Project [_id#8103, congestion_level#8104, lat#8105, lon#8106, road_id#8107, road_name#8108, speed#8139, timestamp#8110, cast(vehicle_count#8111 as double) AS vehicle_count#8159]
                                                      +- Project [_id#8103, congestion_level#8104, lat#8105, lon#8106, road_id#8107, road_name#8108, cast(speed#8109 as double) AS speed#8139, timestamp#8110, vehicle_count#8111]
                                                         +- Relation [_id#8103,congestion_level#8104,lat#8105,lon#8106,road_id#8107,road_name#8108,speed#8109,timestamp#8110,vehicle_count#8111] MongoRelation(MongoRDD[483] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:08,628 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:13 +07)" executed successfully
2026-01-06 12:32:13,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:18 +07)" (scheduled at 2026-01-06 12:32:13.157382+07:00)
2026-01-06 12:32:13,164 - INFO -  Training Spark model...
2026-01-06 12:32:13,531 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_change#8701, vehicle_count_lag#8719, vehicle_count_change#8738, avg(speed#8559) windowspecdefinition(road_id#8545, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#8759]
+- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_change#8701, vehicle_count_lag#8719, CASE WHEN isnotnull(vehicle_count_lag#8719) THEN (vehicle_count#8569 - vehicle_count_lag#8719) ELSE 0.0 END AS vehicle_count_change#8738]
   +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_change#8701, vehicle_count_lag#8719]
      +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_change#8701, vehicle_count_lag#8719, vehicle_count_lag#8719]
         +- Window [lag(vehicle_count#8569, -1, null) windowspecdefinition(road_id#8545, timestamp#8548 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#8719], [road_id#8545], [timestamp#8548 ASC NULLS FIRST]
            +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_change#8701]
               +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, CASE WHEN isnotnull(speed_lag#8684) THEN (speed#8559 - speed_lag#8684) ELSE 0.0 END AS speed_change#8701]
                  +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684]
                     +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668, speed_lag#8684, speed_lag#8684]
                        +- Window [lag(speed#8559, -1, null) windowspecdefinition(road_id#8545, timestamp#8548 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#8684], [road_id#8545], [timestamp#8548 ASC NULLS FIRST]
                           +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, hour_cos#8668]
                              +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, hour_sin#8653, COS((0.2617993877991494 * cast(hour#8603 as double))) AS hour_cos#8668]
                                 +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, is_weekend#8639, SIN((0.2617993877991494 * cast(hour#8603 as double))) AS hour_sin#8653]
                                    +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, day_of_week#8626, CASE WHEN day_of_week#8626 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#8639]
                                       +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, is_peak#8614, dayofweek(cast(timestamp#8548 as date)) AS day_of_week#8626]
                                          +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour#8603, CASE WHEN hour#8603 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#8614]
                                             +- Project [_id#8541, congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569, hour(timestamp#8548, Some(Asia/Bangkok)) AS hour#8603]
                                                +- Project [_id#8541, cast(congestion_level#8542 as double) AS congestion_level#8579, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, vehicle_count#8569]
                                                   +- Project [_id#8541, congestion_level#8542, lat#8543, lon#8544, road_id#8545, road_name#8546, speed#8559, timestamp#8548, cast(vehicle_count#8549 as double) AS vehicle_count#8569]
                                                      +- Project [_id#8541, congestion_level#8542, lat#8543, lon#8544, road_id#8545, road_name#8546, cast(speed#8547 as double) AS speed#8559, timestamp#8548, vehicle_count#8549]
                                                         +- Relation [_id#8541,congestion_level#8542,lat#8543,lon#8544,road_id#8545,road_name#8546,speed#8547,timestamp#8548,vehicle_count#8549] MongoRelation(MongoRDD[507] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:13,531 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:18 +07)" executed successfully
2026-01-06 12:32:18,157 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:23 +07)" (scheduled at 2026-01-06 12:32:18.157382+07:00)
2026-01-06 12:32:18,158 - INFO -  Training Spark model...
2026-01-06 12:32:18,473 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_change#8920, vehicle_count_lag#8938, vehicle_count_change#8957, avg(speed#8778) windowspecdefinition(road_id#8764, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#8978]
+- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_change#8920, vehicle_count_lag#8938, CASE WHEN isnotnull(vehicle_count_lag#8938) THEN (vehicle_count#8788 - vehicle_count_lag#8938) ELSE 0.0 END AS vehicle_count_change#8957]
   +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_change#8920, vehicle_count_lag#8938]
      +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_change#8920, vehicle_count_lag#8938, vehicle_count_lag#8938]
         +- Window [lag(vehicle_count#8788, -1, null) windowspecdefinition(road_id#8764, timestamp#8767 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#8938], [road_id#8764], [timestamp#8767 ASC NULLS FIRST]
            +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_change#8920]
               +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, CASE WHEN isnotnull(speed_lag#8903) THEN (speed#8778 - speed_lag#8903) ELSE 0.0 END AS speed_change#8920]
                  +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903]
                     +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887, speed_lag#8903, speed_lag#8903]
                        +- Window [lag(speed#8778, -1, null) windowspecdefinition(road_id#8764, timestamp#8767 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#8903], [road_id#8764], [timestamp#8767 ASC NULLS FIRST]
                           +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, hour_cos#8887]
                              +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, hour_sin#8872, COS((0.2617993877991494 * cast(hour#8822 as double))) AS hour_cos#8887]
                                 +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, is_weekend#8858, SIN((0.2617993877991494 * cast(hour#8822 as double))) AS hour_sin#8872]
                                    +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, day_of_week#8845, CASE WHEN day_of_week#8845 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#8858]
                                       +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, is_peak#8833, dayofweek(cast(timestamp#8767 as date)) AS day_of_week#8845]
                                          +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour#8822, CASE WHEN hour#8822 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#8833]
                                             +- Project [_id#8760, congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788, hour(timestamp#8767, Some(Asia/Bangkok)) AS hour#8822]
                                                +- Project [_id#8760, cast(congestion_level#8761 as double) AS congestion_level#8798, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, vehicle_count#8788]
                                                   +- Project [_id#8760, congestion_level#8761, lat#8762, lon#8763, road_id#8764, road_name#8765, speed#8778, timestamp#8767, cast(vehicle_count#8768 as double) AS vehicle_count#8788]
                                                      +- Project [_id#8760, congestion_level#8761, lat#8762, lon#8763, road_id#8764, road_name#8765, cast(speed#8766 as double) AS speed#8778, timestamp#8767, vehicle_count#8768]
                                                         +- Relation [_id#8760,congestion_level#8761,lat#8762,lon#8763,road_id#8764,road_name#8765,speed#8766,timestamp#8767,vehicle_count#8768] MongoRelation(MongoRDD[520] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:18,473 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:23 +07)" executed successfully
2026-01-06 12:32:23,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:28 +07)" (scheduled at 2026-01-06 12:32:23.157382+07:00)
2026-01-06 12:32:23,158 - INFO -  Training Spark model...
2026-01-06 12:32:23,528 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_change#9139, vehicle_count_lag#9157, vehicle_count_change#9176, avg(speed#8997) windowspecdefinition(road_id#8983, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#9197]
+- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_change#9139, vehicle_count_lag#9157, CASE WHEN isnotnull(vehicle_count_lag#9157) THEN (vehicle_count#9007 - vehicle_count_lag#9157) ELSE 0.0 END AS vehicle_count_change#9176]
   +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_change#9139, vehicle_count_lag#9157]
      +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_change#9139, vehicle_count_lag#9157, vehicle_count_lag#9157]
         +- Window [lag(vehicle_count#9007, -1, null) windowspecdefinition(road_id#8983, timestamp#8986 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#9157], [road_id#8983], [timestamp#8986 ASC NULLS FIRST]
            +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_change#9139]
               +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, CASE WHEN isnotnull(speed_lag#9122) THEN (speed#8997 - speed_lag#9122) ELSE 0.0 END AS speed_change#9139]
                  +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122]
                     +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106, speed_lag#9122, speed_lag#9122]
                        +- Window [lag(speed#8997, -1, null) windowspecdefinition(road_id#8983, timestamp#8986 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#9122], [road_id#8983], [timestamp#8986 ASC NULLS FIRST]
                           +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, hour_cos#9106]
                              +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, hour_sin#9091, COS((0.2617993877991494 * cast(hour#9041 as double))) AS hour_cos#9106]
                                 +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, is_weekend#9077, SIN((0.2617993877991494 * cast(hour#9041 as double))) AS hour_sin#9091]
                                    +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, day_of_week#9064, CASE WHEN day_of_week#9064 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#9077]
                                       +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, is_peak#9052, dayofweek(cast(timestamp#8986 as date)) AS day_of_week#9064]
                                          +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour#9041, CASE WHEN hour#9041 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#9052]
                                             +- Project [_id#8979, congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007, hour(timestamp#8986, Some(Asia/Bangkok)) AS hour#9041]
                                                +- Project [_id#8979, cast(congestion_level#8980 as double) AS congestion_level#9017, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, vehicle_count#9007]
                                                   +- Project [_id#8979, congestion_level#8980, lat#8981, lon#8982, road_id#8983, road_name#8984, speed#8997, timestamp#8986, cast(vehicle_count#8987 as double) AS vehicle_count#9007]
                                                      +- Project [_id#8979, congestion_level#8980, lat#8981, lon#8982, road_id#8983, road_name#8984, cast(speed#8985 as double) AS speed#8997, timestamp#8986, vehicle_count#8987]
                                                         +- Relation [_id#8979,congestion_level#8980,lat#8981,lon#8982,road_id#8983,road_name#8984,speed#8985,timestamp#8986,vehicle_count#8987] MongoRelation(MongoRDD[533] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:23,529 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:28 +07)" executed successfully
2026-01-06 12:32:28,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:33 +07)" (scheduled at 2026-01-06 12:32:28.157382+07:00)
2026-01-06 12:32:28,159 - INFO -  Training Spark model...
2026-01-06 12:32:28,502 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_change#9358, vehicle_count_lag#9376, vehicle_count_change#9395, avg(speed#9216) windowspecdefinition(road_id#9202, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#9416]
+- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_change#9358, vehicle_count_lag#9376, CASE WHEN isnotnull(vehicle_count_lag#9376) THEN (vehicle_count#9226 - vehicle_count_lag#9376) ELSE 0.0 END AS vehicle_count_change#9395]
   +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_change#9358, vehicle_count_lag#9376]
      +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_change#9358, vehicle_count_lag#9376, vehicle_count_lag#9376]
         +- Window [lag(vehicle_count#9226, -1, null) windowspecdefinition(road_id#9202, timestamp#9205 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#9376], [road_id#9202], [timestamp#9205 ASC NULLS FIRST]
            +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_change#9358]
               +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, CASE WHEN isnotnull(speed_lag#9341) THEN (speed#9216 - speed_lag#9341) ELSE 0.0 END AS speed_change#9358]
                  +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341]
                     +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325, speed_lag#9341, speed_lag#9341]
                        +- Window [lag(speed#9216, -1, null) windowspecdefinition(road_id#9202, timestamp#9205 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#9341], [road_id#9202], [timestamp#9205 ASC NULLS FIRST]
                           +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, hour_cos#9325]
                              +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, hour_sin#9310, COS((0.2617993877991494 * cast(hour#9260 as double))) AS hour_cos#9325]
                                 +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, is_weekend#9296, SIN((0.2617993877991494 * cast(hour#9260 as double))) AS hour_sin#9310]
                                    +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, day_of_week#9283, CASE WHEN day_of_week#9283 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#9296]
                                       +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, is_peak#9271, dayofweek(cast(timestamp#9205 as date)) AS day_of_week#9283]
                                          +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour#9260, CASE WHEN hour#9260 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#9271]
                                             +- Project [_id#9198, congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226, hour(timestamp#9205, Some(Asia/Bangkok)) AS hour#9260]
                                                +- Project [_id#9198, cast(congestion_level#9199 as double) AS congestion_level#9236, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, vehicle_count#9226]
                                                   +- Project [_id#9198, congestion_level#9199, lat#9200, lon#9201, road_id#9202, road_name#9203, speed#9216, timestamp#9205, cast(vehicle_count#9206 as double) AS vehicle_count#9226]
                                                      +- Project [_id#9198, congestion_level#9199, lat#9200, lon#9201, road_id#9202, road_name#9203, cast(speed#9204 as double) AS speed#9216, timestamp#9205, vehicle_count#9206]
                                                         +- Relation [_id#9198,congestion_level#9199,lat#9200,lon#9201,road_id#9202,road_name#9203,speed#9204,timestamp#9205,vehicle_count#9206] MongoRelation(MongoRDD[546] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:28,503 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:33 +07)" executed successfully
2026-01-06 12:32:33,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:38 +07)" (scheduled at 2026-01-06 12:32:33.157382+07:00)
2026-01-06 12:32:33,164 - INFO -  Training Spark model...
2026-01-06 12:32:33,516 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_change#9577, vehicle_count_lag#9595, vehicle_count_change#9614, avg(speed#9435) windowspecdefinition(road_id#9421, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#9635]
+- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_change#9577, vehicle_count_lag#9595, CASE WHEN isnotnull(vehicle_count_lag#9595) THEN (vehicle_count#9445 - vehicle_count_lag#9595) ELSE 0.0 END AS vehicle_count_change#9614]
   +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_change#9577, vehicle_count_lag#9595]
      +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_change#9577, vehicle_count_lag#9595, vehicle_count_lag#9595]
         +- Window [lag(vehicle_count#9445, -1, null) windowspecdefinition(road_id#9421, timestamp#9424 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#9595], [road_id#9421], [timestamp#9424 ASC NULLS FIRST]
            +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_change#9577]
               +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, CASE WHEN isnotnull(speed_lag#9560) THEN (speed#9435 - speed_lag#9560) ELSE 0.0 END AS speed_change#9577]
                  +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560]
                     +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544, speed_lag#9560, speed_lag#9560]
                        +- Window [lag(speed#9435, -1, null) windowspecdefinition(road_id#9421, timestamp#9424 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#9560], [road_id#9421], [timestamp#9424 ASC NULLS FIRST]
                           +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, hour_cos#9544]
                              +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, hour_sin#9529, COS((0.2617993877991494 * cast(hour#9479 as double))) AS hour_cos#9544]
                                 +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, is_weekend#9515, SIN((0.2617993877991494 * cast(hour#9479 as double))) AS hour_sin#9529]
                                    +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, day_of_week#9502, CASE WHEN day_of_week#9502 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#9515]
                                       +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, is_peak#9490, dayofweek(cast(timestamp#9424 as date)) AS day_of_week#9502]
                                          +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour#9479, CASE WHEN hour#9479 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#9490]
                                             +- Project [_id#9417, congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445, hour(timestamp#9424, Some(Asia/Bangkok)) AS hour#9479]
                                                +- Project [_id#9417, cast(congestion_level#9418 as double) AS congestion_level#9455, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, vehicle_count#9445]
                                                   +- Project [_id#9417, congestion_level#9418, lat#9419, lon#9420, road_id#9421, road_name#9422, speed#9435, timestamp#9424, cast(vehicle_count#9425 as double) AS vehicle_count#9445]
                                                      +- Project [_id#9417, congestion_level#9418, lat#9419, lon#9420, road_id#9421, road_name#9422, cast(speed#9423 as double) AS speed#9435, timestamp#9424, vehicle_count#9425]
                                                         +- Relation [_id#9417,congestion_level#9418,lat#9419,lon#9420,road_id#9421,road_name#9422,speed#9423,timestamp#9424,vehicle_count#9425] MongoRelation(MongoRDD[559] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:33,516 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:38 +07)" executed successfully
2026-01-06 12:32:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:43 +07)" (scheduled at 2026-01-06 12:32:38.157382+07:00)
2026-01-06 12:32:38,158 - INFO -  Training Spark model...
2026-01-06 12:32:38,508 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_change#9796, vehicle_count_lag#9814, vehicle_count_change#9833, avg(speed#9654) windowspecdefinition(road_id#9640, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#9854]
+- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_change#9796, vehicle_count_lag#9814, CASE WHEN isnotnull(vehicle_count_lag#9814) THEN (vehicle_count#9664 - vehicle_count_lag#9814) ELSE 0.0 END AS vehicle_count_change#9833]
   +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_change#9796, vehicle_count_lag#9814]
      +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_change#9796, vehicle_count_lag#9814, vehicle_count_lag#9814]
         +- Window [lag(vehicle_count#9664, -1, null) windowspecdefinition(road_id#9640, timestamp#9643 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#9814], [road_id#9640], [timestamp#9643 ASC NULLS FIRST]
            +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_change#9796]
               +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, CASE WHEN isnotnull(speed_lag#9779) THEN (speed#9654 - speed_lag#9779) ELSE 0.0 END AS speed_change#9796]
                  +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779]
                     +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763, speed_lag#9779, speed_lag#9779]
                        +- Window [lag(speed#9654, -1, null) windowspecdefinition(road_id#9640, timestamp#9643 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#9779], [road_id#9640], [timestamp#9643 ASC NULLS FIRST]
                           +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, hour_cos#9763]
                              +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, hour_sin#9748, COS((0.2617993877991494 * cast(hour#9698 as double))) AS hour_cos#9763]
                                 +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, is_weekend#9734, SIN((0.2617993877991494 * cast(hour#9698 as double))) AS hour_sin#9748]
                                    +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, day_of_week#9721, CASE WHEN day_of_week#9721 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#9734]
                                       +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, is_peak#9709, dayofweek(cast(timestamp#9643 as date)) AS day_of_week#9721]
                                          +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour#9698, CASE WHEN hour#9698 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#9709]
                                             +- Project [_id#9636, congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664, hour(timestamp#9643, Some(Asia/Bangkok)) AS hour#9698]
                                                +- Project [_id#9636, cast(congestion_level#9637 as double) AS congestion_level#9674, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, vehicle_count#9664]
                                                   +- Project [_id#9636, congestion_level#9637, lat#9638, lon#9639, road_id#9640, road_name#9641, speed#9654, timestamp#9643, cast(vehicle_count#9644 as double) AS vehicle_count#9664]
                                                      +- Project [_id#9636, congestion_level#9637, lat#9638, lon#9639, road_id#9640, road_name#9641, cast(speed#9642 as double) AS speed#9654, timestamp#9643, vehicle_count#9644]
                                                         +- Relation [_id#9636,congestion_level#9637,lat#9638,lon#9639,road_id#9640,road_name#9641,speed#9642,timestamp#9643,vehicle_count#9644] MongoRelation(MongoRDD[572] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:38,509 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:43 +07)" executed successfully
2026-01-06 12:32:43,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:48 +07)" (scheduled at 2026-01-06 12:32:43.157382+07:00)
2026-01-06 12:32:43,158 - INFO -  Training Spark model...
2026-01-06 12:32:43,707 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_change#10015, vehicle_count_lag#10033, vehicle_count_change#10052, avg(speed#9873) windowspecdefinition(road_id#9859, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#10073]
+- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_change#10015, vehicle_count_lag#10033, CASE WHEN isnotnull(vehicle_count_lag#10033) THEN (vehicle_count#9883 - vehicle_count_lag#10033) ELSE 0.0 END AS vehicle_count_change#10052]
   +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_change#10015, vehicle_count_lag#10033]
      +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_change#10015, vehicle_count_lag#10033, vehicle_count_lag#10033]
         +- Window [lag(vehicle_count#9883, -1, null) windowspecdefinition(road_id#9859, timestamp#9862 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#10033], [road_id#9859], [timestamp#9862 ASC NULLS FIRST]
            +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_change#10015]
               +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, CASE WHEN isnotnull(speed_lag#9998) THEN (speed#9873 - speed_lag#9998) ELSE 0.0 END AS speed_change#10015]
                  +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998]
                     +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982, speed_lag#9998, speed_lag#9998]
                        +- Window [lag(speed#9873, -1, null) windowspecdefinition(road_id#9859, timestamp#9862 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#9998], [road_id#9859], [timestamp#9862 ASC NULLS FIRST]
                           +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, hour_cos#9982]
                              +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, hour_sin#9967, COS((0.2617993877991494 * cast(hour#9917 as double))) AS hour_cos#9982]
                                 +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, is_weekend#9953, SIN((0.2617993877991494 * cast(hour#9917 as double))) AS hour_sin#9967]
                                    +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, day_of_week#9940, CASE WHEN day_of_week#9940 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#9953]
                                       +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, is_peak#9928, dayofweek(cast(timestamp#9862 as date)) AS day_of_week#9940]
                                          +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour#9917, CASE WHEN hour#9917 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#9928]
                                             +- Project [_id#9855, congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883, hour(timestamp#9862, Some(Asia/Bangkok)) AS hour#9917]
                                                +- Project [_id#9855, cast(congestion_level#9856 as double) AS congestion_level#9893, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, vehicle_count#9883]
                                                   +- Project [_id#9855, congestion_level#9856, lat#9857, lon#9858, road_id#9859, road_name#9860, speed#9873, timestamp#9862, cast(vehicle_count#9863 as double) AS vehicle_count#9883]
                                                      +- Project [_id#9855, congestion_level#9856, lat#9857, lon#9858, road_id#9859, road_name#9860, cast(speed#9861 as double) AS speed#9873, timestamp#9862, vehicle_count#9863]
                                                         +- Relation [_id#9855,congestion_level#9856,lat#9857,lon#9858,road_id#9859,road_name#9860,speed#9861,timestamp#9862,vehicle_count#9863] MongoRelation(MongoRDD[585] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:43,708 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:48 +07)" executed successfully
2026-01-06 12:32:48,157 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:53 +07)" (scheduled at 2026-01-06 12:32:48.157382+07:00)
2026-01-06 12:32:48,158 - INFO -  Training Spark model...
2026-01-06 12:32:48,560 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_change#10234, vehicle_count_lag#10252, vehicle_count_change#10271, avg(speed#10092) windowspecdefinition(road_id#10078, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#10292]
+- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_change#10234, vehicle_count_lag#10252, CASE WHEN isnotnull(vehicle_count_lag#10252) THEN (vehicle_count#10102 - vehicle_count_lag#10252) ELSE 0.0 END AS vehicle_count_change#10271]
   +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_change#10234, vehicle_count_lag#10252]
      +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_change#10234, vehicle_count_lag#10252, vehicle_count_lag#10252]
         +- Window [lag(vehicle_count#10102, -1, null) windowspecdefinition(road_id#10078, timestamp#10081 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#10252], [road_id#10078], [timestamp#10081 ASC NULLS FIRST]
            +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_change#10234]
               +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, CASE WHEN isnotnull(speed_lag#10217) THEN (speed#10092 - speed_lag#10217) ELSE 0.0 END AS speed_change#10234]
                  +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217]
                     +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201, speed_lag#10217, speed_lag#10217]
                        +- Window [lag(speed#10092, -1, null) windowspecdefinition(road_id#10078, timestamp#10081 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#10217], [road_id#10078], [timestamp#10081 ASC NULLS FIRST]
                           +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, hour_cos#10201]
                              +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, hour_sin#10186, COS((0.2617993877991494 * cast(hour#10136 as double))) AS hour_cos#10201]
                                 +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, is_weekend#10172, SIN((0.2617993877991494 * cast(hour#10136 as double))) AS hour_sin#10186]
                                    +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, day_of_week#10159, CASE WHEN day_of_week#10159 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#10172]
                                       +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, is_peak#10147, dayofweek(cast(timestamp#10081 as date)) AS day_of_week#10159]
                                          +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour#10136, CASE WHEN hour#10136 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#10147]
                                             +- Project [_id#10074, congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102, hour(timestamp#10081, Some(Asia/Bangkok)) AS hour#10136]
                                                +- Project [_id#10074, cast(congestion_level#10075 as double) AS congestion_level#10112, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, vehicle_count#10102]
                                                   +- Project [_id#10074, congestion_level#10075, lat#10076, lon#10077, road_id#10078, road_name#10079, speed#10092, timestamp#10081, cast(vehicle_count#10082 as double) AS vehicle_count#10102]
                                                      +- Project [_id#10074, congestion_level#10075, lat#10076, lon#10077, road_id#10078, road_name#10079, cast(speed#10080 as double) AS speed#10092, timestamp#10081, vehicle_count#10082]
                                                         +- Relation [_id#10074,congestion_level#10075,lat#10076,lon#10077,road_id#10078,road_name#10079,speed#10080,timestamp#10081,vehicle_count#10082] MongoRelation(MongoRDD[598] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:48,560 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:53 +07)" executed successfully
2026-01-06 12:32:53,166 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:58 +07)" (scheduled at 2026-01-06 12:32:53.157382+07:00)
2026-01-06 12:32:53,167 - INFO -  Training Spark model...
2026-01-06 12:32:53,442 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_change#10453, vehicle_count_lag#10471, vehicle_count_change#10490, avg(speed#10311) windowspecdefinition(road_id#10297, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#10511]
+- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_change#10453, vehicle_count_lag#10471, CASE WHEN isnotnull(vehicle_count_lag#10471) THEN (vehicle_count#10321 - vehicle_count_lag#10471) ELSE 0.0 END AS vehicle_count_change#10490]
   +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_change#10453, vehicle_count_lag#10471]
      +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_change#10453, vehicle_count_lag#10471, vehicle_count_lag#10471]
         +- Window [lag(vehicle_count#10321, -1, null) windowspecdefinition(road_id#10297, timestamp#10300 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#10471], [road_id#10297], [timestamp#10300 ASC NULLS FIRST]
            +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_change#10453]
               +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, CASE WHEN isnotnull(speed_lag#10436) THEN (speed#10311 - speed_lag#10436) ELSE 0.0 END AS speed_change#10453]
                  +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436]
                     +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420, speed_lag#10436, speed_lag#10436]
                        +- Window [lag(speed#10311, -1, null) windowspecdefinition(road_id#10297, timestamp#10300 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#10436], [road_id#10297], [timestamp#10300 ASC NULLS FIRST]
                           +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, hour_cos#10420]
                              +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, hour_sin#10405, COS((0.2617993877991494 * cast(hour#10355 as double))) AS hour_cos#10420]
                                 +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, is_weekend#10391, SIN((0.2617993877991494 * cast(hour#10355 as double))) AS hour_sin#10405]
                                    +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, day_of_week#10378, CASE WHEN day_of_week#10378 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#10391]
                                       +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, is_peak#10366, dayofweek(cast(timestamp#10300 as date)) AS day_of_week#10378]
                                          +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour#10355, CASE WHEN hour#10355 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#10366]
                                             +- Project [_id#10293, congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321, hour(timestamp#10300, Some(Asia/Bangkok)) AS hour#10355]
                                                +- Project [_id#10293, cast(congestion_level#10294 as double) AS congestion_level#10331, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, vehicle_count#10321]
                                                   +- Project [_id#10293, congestion_level#10294, lat#10295, lon#10296, road_id#10297, road_name#10298, speed#10311, timestamp#10300, cast(vehicle_count#10301 as double) AS vehicle_count#10321]
                                                      +- Project [_id#10293, congestion_level#10294, lat#10295, lon#10296, road_id#10297, road_name#10298, cast(speed#10299 as double) AS speed#10311, timestamp#10300, vehicle_count#10301]
                                                         +- Relation [_id#10293,congestion_level#10294,lat#10295,lon#10296,road_id#10297,road_name#10298,speed#10299,timestamp#10300,vehicle_count#10301] MongoRelation(MongoRDD[611] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:53,442 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:32:58 +07)" executed successfully
2026-01-06 12:32:58,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:03 +07)" (scheduled at 2026-01-06 12:32:58.157382+07:00)
2026-01-06 12:32:58,159 - INFO -  Training Spark model...
2026-01-06 12:32:58,443 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_change#10672, vehicle_count_lag#10690, vehicle_count_change#10709, avg(speed#10530) windowspecdefinition(road_id#10516, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#10730]
+- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_change#10672, vehicle_count_lag#10690, CASE WHEN isnotnull(vehicle_count_lag#10690) THEN (vehicle_count#10540 - vehicle_count_lag#10690) ELSE 0.0 END AS vehicle_count_change#10709]
   +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_change#10672, vehicle_count_lag#10690]
      +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_change#10672, vehicle_count_lag#10690, vehicle_count_lag#10690]
         +- Window [lag(vehicle_count#10540, -1, null) windowspecdefinition(road_id#10516, timestamp#10519 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#10690], [road_id#10516], [timestamp#10519 ASC NULLS FIRST]
            +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_change#10672]
               +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, CASE WHEN isnotnull(speed_lag#10655) THEN (speed#10530 - speed_lag#10655) ELSE 0.0 END AS speed_change#10672]
                  +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655]
                     +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639, speed_lag#10655, speed_lag#10655]
                        +- Window [lag(speed#10530, -1, null) windowspecdefinition(road_id#10516, timestamp#10519 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#10655], [road_id#10516], [timestamp#10519 ASC NULLS FIRST]
                           +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, hour_cos#10639]
                              +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, hour_sin#10624, COS((0.2617993877991494 * cast(hour#10574 as double))) AS hour_cos#10639]
                                 +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, is_weekend#10610, SIN((0.2617993877991494 * cast(hour#10574 as double))) AS hour_sin#10624]
                                    +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, day_of_week#10597, CASE WHEN day_of_week#10597 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#10610]
                                       +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, is_peak#10585, dayofweek(cast(timestamp#10519 as date)) AS day_of_week#10597]
                                          +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour#10574, CASE WHEN hour#10574 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#10585]
                                             +- Project [_id#10512, congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540, hour(timestamp#10519, Some(Asia/Bangkok)) AS hour#10574]
                                                +- Project [_id#10512, cast(congestion_level#10513 as double) AS congestion_level#10550, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, vehicle_count#10540]
                                                   +- Project [_id#10512, congestion_level#10513, lat#10514, lon#10515, road_id#10516, road_name#10517, speed#10530, timestamp#10519, cast(vehicle_count#10520 as double) AS vehicle_count#10540]
                                                      +- Project [_id#10512, congestion_level#10513, lat#10514, lon#10515, road_id#10516, road_name#10517, cast(speed#10518 as double) AS speed#10530, timestamp#10519, vehicle_count#10520]
                                                         +- Relation [_id#10512,congestion_level#10513,lat#10514,lon#10515,road_id#10516,road_name#10517,speed#10518,timestamp#10519,vehicle_count#10520] MongoRelation(MongoRDD[624] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:32:58,443 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:03 +07)" executed successfully
2026-01-06 12:33:03,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:08 +07)" (scheduled at 2026-01-06 12:33:03.157382+07:00)
2026-01-06 12:33:03,159 - INFO -  Training Spark model...
2026-01-06 12:33:03,427 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_change#10891, vehicle_count_lag#10909, vehicle_count_change#10928, avg(speed#10749) windowspecdefinition(road_id#10735, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#10949]
+- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_change#10891, vehicle_count_lag#10909, CASE WHEN isnotnull(vehicle_count_lag#10909) THEN (vehicle_count#10759 - vehicle_count_lag#10909) ELSE 0.0 END AS vehicle_count_change#10928]
   +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_change#10891, vehicle_count_lag#10909]
      +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_change#10891, vehicle_count_lag#10909, vehicle_count_lag#10909]
         +- Window [lag(vehicle_count#10759, -1, null) windowspecdefinition(road_id#10735, timestamp#10738 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#10909], [road_id#10735], [timestamp#10738 ASC NULLS FIRST]
            +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_change#10891]
               +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, CASE WHEN isnotnull(speed_lag#10874) THEN (speed#10749 - speed_lag#10874) ELSE 0.0 END AS speed_change#10891]
                  +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874]
                     +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858, speed_lag#10874, speed_lag#10874]
                        +- Window [lag(speed#10749, -1, null) windowspecdefinition(road_id#10735, timestamp#10738 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#10874], [road_id#10735], [timestamp#10738 ASC NULLS FIRST]
                           +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, hour_cos#10858]
                              +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, hour_sin#10843, COS((0.2617993877991494 * cast(hour#10793 as double))) AS hour_cos#10858]
                                 +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, is_weekend#10829, SIN((0.2617993877991494 * cast(hour#10793 as double))) AS hour_sin#10843]
                                    +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, day_of_week#10816, CASE WHEN day_of_week#10816 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#10829]
                                       +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, is_peak#10804, dayofweek(cast(timestamp#10738 as date)) AS day_of_week#10816]
                                          +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour#10793, CASE WHEN hour#10793 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#10804]
                                             +- Project [_id#10731, congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759, hour(timestamp#10738, Some(Asia/Bangkok)) AS hour#10793]
                                                +- Project [_id#10731, cast(congestion_level#10732 as double) AS congestion_level#10769, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, vehicle_count#10759]
                                                   +- Project [_id#10731, congestion_level#10732, lat#10733, lon#10734, road_id#10735, road_name#10736, speed#10749, timestamp#10738, cast(vehicle_count#10739 as double) AS vehicle_count#10759]
                                                      +- Project [_id#10731, congestion_level#10732, lat#10733, lon#10734, road_id#10735, road_name#10736, cast(speed#10737 as double) AS speed#10749, timestamp#10738, vehicle_count#10739]
                                                         +- Relation [_id#10731,congestion_level#10732,lat#10733,lon#10734,road_id#10735,road_name#10736,speed#10737,timestamp#10738,vehicle_count#10739] MongoRelation(MongoRDD[637] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:03,427 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:08 +07)" executed successfully
2026-01-06 12:33:08,167 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:13 +07)" (scheduled at 2026-01-06 12:33:08.157382+07:00)
2026-01-06 12:33:08,167 - INFO -  Training Spark model...
2026-01-06 12:33:08,167 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:34:08 +07)" (scheduled at 2026-01-06 12:33:08.157779+07:00)
2026-01-06 12:33:08,168 - INFO -  Training Spark model...
2026-01-06 12:33:08,524 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_change#11271, vehicle_count_lag#11307, vehicle_count_change#11344, avg(speed#10986) windowspecdefinition(road_id#10972, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#11386]
+- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_change#11271, vehicle_count_lag#11307, CASE WHEN isnotnull(vehicle_count_lag#11307) THEN (vehicle_count#11006 - vehicle_count_lag#11307) ELSE 0.0 END AS vehicle_count_change#11344]
   +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_change#11271, vehicle_count_lag#11307]
      +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_change#11271, vehicle_count_lag#11307, vehicle_count_lag#11307]
         +- Window [lag(vehicle_count#11006, -1, null) windowspecdefinition(road_id#10972, timestamp#10975 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#11307], [road_id#10972], [timestamp#10975 ASC NULLS FIRST]
            +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_change#11271]
               +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, CASE WHEN isnotnull(speed_lag#11237) THEN (speed#10986 - speed_lag#11237) ELSE 0.0 END AS speed_change#11271]
                  +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237]
                     +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204, speed_lag#11237, speed_lag#11237]
                        +- Window [lag(speed#10986, -1, null) windowspecdefinition(road_id#10972, timestamp#10975 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#11237], [road_id#10972], [timestamp#10975 ASC NULLS FIRST]
                           +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, hour_cos#11204]
                              +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, hour_sin#11174, COS((0.2617993877991494 * cast(hour#11085 as double))) AS hour_cos#11204]
                                 +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, is_weekend#11146, SIN((0.2617993877991494 * cast(hour#11085 as double))) AS hour_sin#11174]
                                    +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, day_of_week#11120, CASE WHEN day_of_week#11120 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#11146]
                                       +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, is_peak#11096, dayofweek(cast(timestamp#10975 as date)) AS day_of_week#11120]
                                          +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour#11085, CASE WHEN hour#11085 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#11096]
                                             +- Project [_id#10968, congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006, hour(timestamp#10975, Some(Asia/Bangkok)) AS hour#11085]
                                                +- Project [_id#10968, cast(congestion_level#10969 as double) AS congestion_level#11017, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, vehicle_count#11006]
                                                   +- Project [_id#10968, congestion_level#10969, lat#10970, lon#10971, road_id#10972, road_name#10973, speed#10986, timestamp#10975, cast(vehicle_count#10976 as double) AS vehicle_count#11006]
                                                      +- Project [_id#10968, congestion_level#10969, lat#10970, lon#10971, road_id#10972, road_name#10973, cast(speed#10974 as double) AS speed#10986, timestamp#10975, vehicle_count#10976]
                                                         +- Relation [_id#10968,congestion_level#10969,lat#10970,lon#10971,road_id#10972,road_name#10973,speed#10974,timestamp#10975,vehicle_count#10976] MongoRelation(MongoRDD[652] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:08,524 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_change#11270, vehicle_count_lag#11306, vehicle_count_change#11345, avg(speed#10987) windowspecdefinition(road_id#10954, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#11387]
+- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_change#11270, vehicle_count_lag#11306, CASE WHEN isnotnull(vehicle_count_lag#11306) THEN (vehicle_count#11016 - vehicle_count_lag#11306) ELSE 0.0 END AS vehicle_count_change#11345]
   +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_change#11270, vehicle_count_lag#11306]
      +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_change#11270, vehicle_count_lag#11306, vehicle_count_lag#11306]
         +- Window [lag(vehicle_count#11016, -1, null) windowspecdefinition(road_id#10954, timestamp#10957 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#11306], [road_id#10954], [timestamp#10957 ASC NULLS FIRST]
            +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_change#11270]
               +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, CASE WHEN isnotnull(speed_lag#11236) THEN (speed#10987 - speed_lag#11236) ELSE 0.0 END AS speed_change#11270]
                  +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236]
                     +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205, speed_lag#11236, speed_lag#11236]
                        +- Window [lag(speed#10987, -1, null) windowspecdefinition(road_id#10954, timestamp#10957 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#11236], [road_id#10954], [timestamp#10957 ASC NULLS FIRST]
                           +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, hour_cos#11205]
                              +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, hour_sin#11175, COS((0.2617993877991494 * cast(hour#11074 as double))) AS hour_cos#11205]
                                 +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, is_weekend#11147, SIN((0.2617993877991494 * cast(hour#11074 as double))) AS hour_sin#11175]
                                    +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, day_of_week#11121, CASE WHEN day_of_week#11121 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#11147]
                                       +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, is_peak#11108, dayofweek(cast(timestamp#10957 as date)) AS day_of_week#11121]
                                          +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour#11074, CASE WHEN hour#11074 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#11108]
                                             +- Project [_id#10950, congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016, hour(timestamp#10957, Some(Asia/Bangkok)) AS hour#11074]
                                                +- Project [_id#10950, cast(congestion_level#10951 as double) AS congestion_level#11048, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, vehicle_count#11016]
                                                   +- Project [_id#10950, congestion_level#10951, lat#10952, lon#10953, road_id#10954, road_name#10955, speed#10987, timestamp#10957, cast(vehicle_count#10958 as double) AS vehicle_count#11016]
                                                      +- Project [_id#10950, congestion_level#10951, lat#10952, lon#10953, road_id#10954, road_name#10955, cast(speed#10956 as double) AS speed#10987, timestamp#10957, vehicle_count#10958]
                                                         +- Relation [_id#10950,congestion_level#10951,lat#10952,lon#10953,road_id#10954,road_name#10955,speed#10956,timestamp#10957,vehicle_count#10958] MongoRelation(MongoRDD[650] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:08,525 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:34:08 +07)" executed successfully
2026-01-06 12:33:08,525 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:13 +07)" executed successfully
2026-01-06 12:33:13,174 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:18 +07)" (scheduled at 2026-01-06 12:33:13.157382+07:00)
2026-01-06 12:33:13,175 - INFO -  Training Spark model...
2026-01-06 12:33:13,455 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_change#11548, vehicle_count_lag#11566, vehicle_count_change#11585, avg(speed#11406) windowspecdefinition(road_id#11392, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#11606]
+- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_change#11548, vehicle_count_lag#11566, CASE WHEN isnotnull(vehicle_count_lag#11566) THEN (vehicle_count#11416 - vehicle_count_lag#11566) ELSE 0.0 END AS vehicle_count_change#11585]
   +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_change#11548, vehicle_count_lag#11566]
      +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_change#11548, vehicle_count_lag#11566, vehicle_count_lag#11566]
         +- Window [lag(vehicle_count#11416, -1, null) windowspecdefinition(road_id#11392, timestamp#11395 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#11566], [road_id#11392], [timestamp#11395 ASC NULLS FIRST]
            +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_change#11548]
               +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, CASE WHEN isnotnull(speed_lag#11531) THEN (speed#11406 - speed_lag#11531) ELSE 0.0 END AS speed_change#11548]
                  +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531]
                     +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515, speed_lag#11531, speed_lag#11531]
                        +- Window [lag(speed#11406, -1, null) windowspecdefinition(road_id#11392, timestamp#11395 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#11531], [road_id#11392], [timestamp#11395 ASC NULLS FIRST]
                           +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, hour_cos#11515]
                              +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, hour_sin#11500, COS((0.2617993877991494 * cast(hour#11450 as double))) AS hour_cos#11515]
                                 +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, is_weekend#11486, SIN((0.2617993877991494 * cast(hour#11450 as double))) AS hour_sin#11500]
                                    +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, day_of_week#11473, CASE WHEN day_of_week#11473 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#11486]
                                       +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, is_peak#11461, dayofweek(cast(timestamp#11395 as date)) AS day_of_week#11473]
                                          +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour#11450, CASE WHEN hour#11450 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#11461]
                                             +- Project [_id#11388, congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416, hour(timestamp#11395, Some(Asia/Bangkok)) AS hour#11450]
                                                +- Project [_id#11388, cast(congestion_level#11389 as double) AS congestion_level#11426, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, vehicle_count#11416]
                                                   +- Project [_id#11388, congestion_level#11389, lat#11390, lon#11391, road_id#11392, road_name#11393, speed#11406, timestamp#11395, cast(vehicle_count#11396 as double) AS vehicle_count#11416]
                                                      +- Project [_id#11388, congestion_level#11389, lat#11390, lon#11391, road_id#11392, road_name#11393, cast(speed#11394 as double) AS speed#11406, timestamp#11395, vehicle_count#11396]
                                                         +- Relation [_id#11388,congestion_level#11389,lat#11390,lon#11391,road_id#11392,road_name#11393,speed#11394,timestamp#11395,vehicle_count#11396] MongoRelation(MongoRDD[676] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:13,455 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:18 +07)" executed successfully
2026-01-06 12:33:18,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:23 +07)" (scheduled at 2026-01-06 12:33:18.157382+07:00)
2026-01-06 12:33:18,160 - INFO -  Training Spark model...
2026-01-06 12:33:18,436 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_change#11767, vehicle_count_lag#11785, vehicle_count_change#11804, avg(speed#11625) windowspecdefinition(road_id#11611, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#11825]
+- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_change#11767, vehicle_count_lag#11785, CASE WHEN isnotnull(vehicle_count_lag#11785) THEN (vehicle_count#11635 - vehicle_count_lag#11785) ELSE 0.0 END AS vehicle_count_change#11804]
   +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_change#11767, vehicle_count_lag#11785]
      +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_change#11767, vehicle_count_lag#11785, vehicle_count_lag#11785]
         +- Window [lag(vehicle_count#11635, -1, null) windowspecdefinition(road_id#11611, timestamp#11614 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#11785], [road_id#11611], [timestamp#11614 ASC NULLS FIRST]
            +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_change#11767]
               +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, CASE WHEN isnotnull(speed_lag#11750) THEN (speed#11625 - speed_lag#11750) ELSE 0.0 END AS speed_change#11767]
                  +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750]
                     +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734, speed_lag#11750, speed_lag#11750]
                        +- Window [lag(speed#11625, -1, null) windowspecdefinition(road_id#11611, timestamp#11614 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#11750], [road_id#11611], [timestamp#11614 ASC NULLS FIRST]
                           +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, hour_cos#11734]
                              +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, hour_sin#11719, COS((0.2617993877991494 * cast(hour#11669 as double))) AS hour_cos#11734]
                                 +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, is_weekend#11705, SIN((0.2617993877991494 * cast(hour#11669 as double))) AS hour_sin#11719]
                                    +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, day_of_week#11692, CASE WHEN day_of_week#11692 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#11705]
                                       +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, is_peak#11680, dayofweek(cast(timestamp#11614 as date)) AS day_of_week#11692]
                                          +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour#11669, CASE WHEN hour#11669 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#11680]
                                             +- Project [_id#11607, congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635, hour(timestamp#11614, Some(Asia/Bangkok)) AS hour#11669]
                                                +- Project [_id#11607, cast(congestion_level#11608 as double) AS congestion_level#11645, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, vehicle_count#11635]
                                                   +- Project [_id#11607, congestion_level#11608, lat#11609, lon#11610, road_id#11611, road_name#11612, speed#11625, timestamp#11614, cast(vehicle_count#11615 as double) AS vehicle_count#11635]
                                                      +- Project [_id#11607, congestion_level#11608, lat#11609, lon#11610, road_id#11611, road_name#11612, cast(speed#11613 as double) AS speed#11625, timestamp#11614, vehicle_count#11615]
                                                         +- Relation [_id#11607,congestion_level#11608,lat#11609,lon#11610,road_id#11611,road_name#11612,speed#11613,timestamp#11614,vehicle_count#11615] MongoRelation(MongoRDD[689] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:18,436 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:23 +07)" executed successfully
2026-01-06 12:33:23,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:28 +07)" (scheduled at 2026-01-06 12:33:23.157382+07:00)
2026-01-06 12:33:23,159 - INFO -  Training Spark model...
2026-01-06 12:33:23,465 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_change#11986, vehicle_count_lag#12004, vehicle_count_change#12023, avg(speed#11844) windowspecdefinition(road_id#11830, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#12044]
+- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_change#11986, vehicle_count_lag#12004, CASE WHEN isnotnull(vehicle_count_lag#12004) THEN (vehicle_count#11854 - vehicle_count_lag#12004) ELSE 0.0 END AS vehicle_count_change#12023]
   +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_change#11986, vehicle_count_lag#12004]
      +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_change#11986, vehicle_count_lag#12004, vehicle_count_lag#12004]
         +- Window [lag(vehicle_count#11854, -1, null) windowspecdefinition(road_id#11830, timestamp#11833 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#12004], [road_id#11830], [timestamp#11833 ASC NULLS FIRST]
            +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_change#11986]
               +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, CASE WHEN isnotnull(speed_lag#11969) THEN (speed#11844 - speed_lag#11969) ELSE 0.0 END AS speed_change#11986]
                  +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969]
                     +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953, speed_lag#11969, speed_lag#11969]
                        +- Window [lag(speed#11844, -1, null) windowspecdefinition(road_id#11830, timestamp#11833 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#11969], [road_id#11830], [timestamp#11833 ASC NULLS FIRST]
                           +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, hour_cos#11953]
                              +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, hour_sin#11938, COS((0.2617993877991494 * cast(hour#11888 as double))) AS hour_cos#11953]
                                 +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, is_weekend#11924, SIN((0.2617993877991494 * cast(hour#11888 as double))) AS hour_sin#11938]
                                    +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, day_of_week#11911, CASE WHEN day_of_week#11911 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#11924]
                                       +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, is_peak#11899, dayofweek(cast(timestamp#11833 as date)) AS day_of_week#11911]
                                          +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour#11888, CASE WHEN hour#11888 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#11899]
                                             +- Project [_id#11826, congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854, hour(timestamp#11833, Some(Asia/Bangkok)) AS hour#11888]
                                                +- Project [_id#11826, cast(congestion_level#11827 as double) AS congestion_level#11864, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, vehicle_count#11854]
                                                   +- Project [_id#11826, congestion_level#11827, lat#11828, lon#11829, road_id#11830, road_name#11831, speed#11844, timestamp#11833, cast(vehicle_count#11834 as double) AS vehicle_count#11854]
                                                      +- Project [_id#11826, congestion_level#11827, lat#11828, lon#11829, road_id#11830, road_name#11831, cast(speed#11832 as double) AS speed#11844, timestamp#11833, vehicle_count#11834]
                                                         +- Relation [_id#11826,congestion_level#11827,lat#11828,lon#11829,road_id#11830,road_name#11831,speed#11832,timestamp#11833,vehicle_count#11834] MongoRelation(MongoRDD[702] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:23,466 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:28 +07)" executed successfully
2026-01-06 12:33:28,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:33 +07)" (scheduled at 2026-01-06 12:33:28.157382+07:00)
2026-01-06 12:33:28,161 - INFO -  Training Spark model...
2026-01-06 12:33:28,438 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_change#12205, vehicle_count_lag#12223, vehicle_count_change#12242, avg(speed#12063) windowspecdefinition(road_id#12049, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#12263]
+- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_change#12205, vehicle_count_lag#12223, CASE WHEN isnotnull(vehicle_count_lag#12223) THEN (vehicle_count#12073 - vehicle_count_lag#12223) ELSE 0.0 END AS vehicle_count_change#12242]
   +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_change#12205, vehicle_count_lag#12223]
      +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_change#12205, vehicle_count_lag#12223, vehicle_count_lag#12223]
         +- Window [lag(vehicle_count#12073, -1, null) windowspecdefinition(road_id#12049, timestamp#12052 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#12223], [road_id#12049], [timestamp#12052 ASC NULLS FIRST]
            +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_change#12205]
               +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, CASE WHEN isnotnull(speed_lag#12188) THEN (speed#12063 - speed_lag#12188) ELSE 0.0 END AS speed_change#12205]
                  +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188]
                     +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172, speed_lag#12188, speed_lag#12188]
                        +- Window [lag(speed#12063, -1, null) windowspecdefinition(road_id#12049, timestamp#12052 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#12188], [road_id#12049], [timestamp#12052 ASC NULLS FIRST]
                           +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, hour_cos#12172]
                              +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, hour_sin#12157, COS((0.2617993877991494 * cast(hour#12107 as double))) AS hour_cos#12172]
                                 +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, is_weekend#12143, SIN((0.2617993877991494 * cast(hour#12107 as double))) AS hour_sin#12157]
                                    +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, day_of_week#12130, CASE WHEN day_of_week#12130 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#12143]
                                       +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, is_peak#12118, dayofweek(cast(timestamp#12052 as date)) AS day_of_week#12130]
                                          +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour#12107, CASE WHEN hour#12107 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#12118]
                                             +- Project [_id#12045, congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073, hour(timestamp#12052, Some(Asia/Bangkok)) AS hour#12107]
                                                +- Project [_id#12045, cast(congestion_level#12046 as double) AS congestion_level#12083, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, vehicle_count#12073]
                                                   +- Project [_id#12045, congestion_level#12046, lat#12047, lon#12048, road_id#12049, road_name#12050, speed#12063, timestamp#12052, cast(vehicle_count#12053 as double) AS vehicle_count#12073]
                                                      +- Project [_id#12045, congestion_level#12046, lat#12047, lon#12048, road_id#12049, road_name#12050, cast(speed#12051 as double) AS speed#12063, timestamp#12052, vehicle_count#12053]
                                                         +- Relation [_id#12045,congestion_level#12046,lat#12047,lon#12048,road_id#12049,road_name#12050,speed#12051,timestamp#12052,vehicle_count#12053] MongoRelation(MongoRDD[715] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:28,439 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:33 +07)" executed successfully
2026-01-06 12:33:33,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:38 +07)" (scheduled at 2026-01-06 12:33:33.157382+07:00)
2026-01-06 12:33:33,161 - INFO -  Training Spark model...
2026-01-06 12:33:33,421 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_change#12424, vehicle_count_lag#12442, vehicle_count_change#12461, avg(speed#12282) windowspecdefinition(road_id#12268, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#12482]
+- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_change#12424, vehicle_count_lag#12442, CASE WHEN isnotnull(vehicle_count_lag#12442) THEN (vehicle_count#12292 - vehicle_count_lag#12442) ELSE 0.0 END AS vehicle_count_change#12461]
   +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_change#12424, vehicle_count_lag#12442]
      +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_change#12424, vehicle_count_lag#12442, vehicle_count_lag#12442]
         +- Window [lag(vehicle_count#12292, -1, null) windowspecdefinition(road_id#12268, timestamp#12271 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#12442], [road_id#12268], [timestamp#12271 ASC NULLS FIRST]
            +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_change#12424]
               +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, CASE WHEN isnotnull(speed_lag#12407) THEN (speed#12282 - speed_lag#12407) ELSE 0.0 END AS speed_change#12424]
                  +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407]
                     +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391, speed_lag#12407, speed_lag#12407]
                        +- Window [lag(speed#12282, -1, null) windowspecdefinition(road_id#12268, timestamp#12271 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#12407], [road_id#12268], [timestamp#12271 ASC NULLS FIRST]
                           +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, hour_cos#12391]
                              +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, hour_sin#12376, COS((0.2617993877991494 * cast(hour#12326 as double))) AS hour_cos#12391]
                                 +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, is_weekend#12362, SIN((0.2617993877991494 * cast(hour#12326 as double))) AS hour_sin#12376]
                                    +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, day_of_week#12349, CASE WHEN day_of_week#12349 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#12362]
                                       +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, is_peak#12337, dayofweek(cast(timestamp#12271 as date)) AS day_of_week#12349]
                                          +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour#12326, CASE WHEN hour#12326 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#12337]
                                             +- Project [_id#12264, congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292, hour(timestamp#12271, Some(Asia/Bangkok)) AS hour#12326]
                                                +- Project [_id#12264, cast(congestion_level#12265 as double) AS congestion_level#12302, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, vehicle_count#12292]
                                                   +- Project [_id#12264, congestion_level#12265, lat#12266, lon#12267, road_id#12268, road_name#12269, speed#12282, timestamp#12271, cast(vehicle_count#12272 as double) AS vehicle_count#12292]
                                                      +- Project [_id#12264, congestion_level#12265, lat#12266, lon#12267, road_id#12268, road_name#12269, cast(speed#12270 as double) AS speed#12282, timestamp#12271, vehicle_count#12272]
                                                         +- Relation [_id#12264,congestion_level#12265,lat#12266,lon#12267,road_id#12268,road_name#12269,speed#12270,timestamp#12271,vehicle_count#12272] MongoRelation(MongoRDD[728] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:33,421 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:38 +07)" executed successfully
2026-01-06 12:33:37,316 - INFO -  Initializing PySpark Session...
2026-01-06 12:33:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:43 +07)" (scheduled at 2026-01-06 12:33:38.157382+07:00)
2026-01-06 12:33:38,158 - INFO -  Training Spark model...
2026-01-06 12:33:38,551 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_change#12643, vehicle_count_lag#12661, vehicle_count_change#12680, avg(speed#12501) windowspecdefinition(road_id#12487, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#12701]
+- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_change#12643, vehicle_count_lag#12661, CASE WHEN isnotnull(vehicle_count_lag#12661) THEN (vehicle_count#12511 - vehicle_count_lag#12661) ELSE 0.0 END AS vehicle_count_change#12680]
   +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_change#12643, vehicle_count_lag#12661]
      +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_change#12643, vehicle_count_lag#12661, vehicle_count_lag#12661]
         +- Window [lag(vehicle_count#12511, -1, null) windowspecdefinition(road_id#12487, timestamp#12490 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#12661], [road_id#12487], [timestamp#12490 ASC NULLS FIRST]
            +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_change#12643]
               +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, CASE WHEN isnotnull(speed_lag#12626) THEN (speed#12501 - speed_lag#12626) ELSE 0.0 END AS speed_change#12643]
                  +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626]
                     +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610, speed_lag#12626, speed_lag#12626]
                        +- Window [lag(speed#12501, -1, null) windowspecdefinition(road_id#12487, timestamp#12490 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#12626], [road_id#12487], [timestamp#12490 ASC NULLS FIRST]
                           +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, hour_cos#12610]
                              +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, hour_sin#12595, COS((0.2617993877991494 * cast(hour#12545 as double))) AS hour_cos#12610]
                                 +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, is_weekend#12581, SIN((0.2617993877991494 * cast(hour#12545 as double))) AS hour_sin#12595]
                                    +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, day_of_week#12568, CASE WHEN day_of_week#12568 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#12581]
                                       +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, is_peak#12556, dayofweek(cast(timestamp#12490 as date)) AS day_of_week#12568]
                                          +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour#12545, CASE WHEN hour#12545 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#12556]
                                             +- Project [_id#12483, congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511, hour(timestamp#12490, Some(Asia/Bangkok)) AS hour#12545]
                                                +- Project [_id#12483, cast(congestion_level#12484 as double) AS congestion_level#12521, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, vehicle_count#12511]
                                                   +- Project [_id#12483, congestion_level#12484, lat#12485, lon#12486, road_id#12487, road_name#12488, speed#12501, timestamp#12490, cast(vehicle_count#12491 as double) AS vehicle_count#12511]
                                                      +- Project [_id#12483, congestion_level#12484, lat#12485, lon#12486, road_id#12487, road_name#12488, cast(speed#12489 as double) AS speed#12501, timestamp#12490, vehicle_count#12491]
                                                         +- Relation [_id#12483,congestion_level#12484,lat#12485,lon#12486,road_id#12487,road_name#12488,speed#12489,timestamp#12490,vehicle_count#12491] MongoRelation(MongoRDD[741] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:38,551 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:43 +07)" executed successfully
2026-01-06 12:33:40,590 - INFO - ‚úì Spark Session Created!
2026-01-06 12:33:40,591 - INFO - Starting Spark Prediction Service (predictions interval: 5s, training interval: 60s)...
2026-01-06 12:33:40,617 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:33:40,618 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 12:33:40,618 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 12:33:40,618 - INFO - Added job "SparkPredictionService.train_model" to job store "default"
2026-01-06 12:33:40,618 - INFO - Scheduler started
2026-01-06 12:33:43,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:48 +07)" (scheduled at 2026-01-06 12:33:43.157382+07:00)
2026-01-06 12:33:43,158 - INFO -  Training Spark model...
2026-01-06 12:33:43,574 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_change#12862, vehicle_count_lag#12880, vehicle_count_change#12899, avg(speed#12720) windowspecdefinition(road_id#12706, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#12920]
+- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_change#12862, vehicle_count_lag#12880, CASE WHEN isnotnull(vehicle_count_lag#12880) THEN (vehicle_count#12730 - vehicle_count_lag#12880) ELSE 0.0 END AS vehicle_count_change#12899]
   +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_change#12862, vehicle_count_lag#12880]
      +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_change#12862, vehicle_count_lag#12880, vehicle_count_lag#12880]
         +- Window [lag(vehicle_count#12730, -1, null) windowspecdefinition(road_id#12706, timestamp#12709 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#12880], [road_id#12706], [timestamp#12709 ASC NULLS FIRST]
            +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_change#12862]
               +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, CASE WHEN isnotnull(speed_lag#12845) THEN (speed#12720 - speed_lag#12845) ELSE 0.0 END AS speed_change#12862]
                  +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845]
                     +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829, speed_lag#12845, speed_lag#12845]
                        +- Window [lag(speed#12720, -1, null) windowspecdefinition(road_id#12706, timestamp#12709 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#12845], [road_id#12706], [timestamp#12709 ASC NULLS FIRST]
                           +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, hour_cos#12829]
                              +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, hour_sin#12814, COS((0.2617993877991494 * cast(hour#12764 as double))) AS hour_cos#12829]
                                 +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, is_weekend#12800, SIN((0.2617993877991494 * cast(hour#12764 as double))) AS hour_sin#12814]
                                    +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, day_of_week#12787, CASE WHEN day_of_week#12787 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#12800]
                                       +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, is_peak#12775, dayofweek(cast(timestamp#12709 as date)) AS day_of_week#12787]
                                          +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour#12764, CASE WHEN hour#12764 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#12775]
                                             +- Project [_id#12702, congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730, hour(timestamp#12709, Some(Asia/Bangkok)) AS hour#12764]
                                                +- Project [_id#12702, cast(congestion_level#12703 as double) AS congestion_level#12740, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, vehicle_count#12730]
                                                   +- Project [_id#12702, congestion_level#12703, lat#12704, lon#12705, road_id#12706, road_name#12707, speed#12720, timestamp#12709, cast(vehicle_count#12710 as double) AS vehicle_count#12730]
                                                      +- Project [_id#12702, congestion_level#12703, lat#12704, lon#12705, road_id#12706, road_name#12707, cast(speed#12708 as double) AS speed#12720, timestamp#12709, vehicle_count#12710]
                                                         +- Relation [_id#12702,congestion_level#12703,lat#12704,lon#12705,road_id#12706,road_name#12707,speed#12708,timestamp#12709,vehicle_count#12710] MongoRelation(MongoRDD[754] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:43,574 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:48 +07)" executed successfully
2026-01-06 12:33:45,618 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:45 +07)" (scheduled at 2026-01-06 12:33:45.617576+07:00)
2026-01-06 12:33:45,619 - INFO -  Training Spark model...
2026-01-06 12:33:48,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:53 +07)" (scheduled at 2026-01-06 12:33:48.157382+07:00)
2026-01-06 12:33:48,159 - INFO -  Training Spark model...
2026-01-06 12:33:48,546 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_change#13081, vehicle_count_lag#13099, vehicle_count_change#13118, avg(speed#12939) windowspecdefinition(road_id#12925, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#13139]
+- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_change#13081, vehicle_count_lag#13099, CASE WHEN isnotnull(vehicle_count_lag#13099) THEN (vehicle_count#12949 - vehicle_count_lag#13099) ELSE 0.0 END AS vehicle_count_change#13118]
   +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_change#13081, vehicle_count_lag#13099]
      +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_change#13081, vehicle_count_lag#13099, vehicle_count_lag#13099]
         +- Window [lag(vehicle_count#12949, -1, null) windowspecdefinition(road_id#12925, timestamp#12928 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#13099], [road_id#12925], [timestamp#12928 ASC NULLS FIRST]
            +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_change#13081]
               +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, CASE WHEN isnotnull(speed_lag#13064) THEN (speed#12939 - speed_lag#13064) ELSE 0.0 END AS speed_change#13081]
                  +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064]
                     +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048, speed_lag#13064, speed_lag#13064]
                        +- Window [lag(speed#12939, -1, null) windowspecdefinition(road_id#12925, timestamp#12928 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#13064], [road_id#12925], [timestamp#12928 ASC NULLS FIRST]
                           +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, hour_cos#13048]
                              +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, hour_sin#13033, COS((0.2617993877991494 * cast(hour#12983 as double))) AS hour_cos#13048]
                                 +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, is_weekend#13019, SIN((0.2617993877991494 * cast(hour#12983 as double))) AS hour_sin#13033]
                                    +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, day_of_week#13006, CASE WHEN day_of_week#13006 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13019]
                                       +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, is_peak#12994, dayofweek(cast(timestamp#12928 as date)) AS day_of_week#13006]
                                          +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour#12983, CASE WHEN hour#12983 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#12994]
                                             +- Project [_id#12921, congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949, hour(timestamp#12928, Some(Asia/Bangkok)) AS hour#12983]
                                                +- Project [_id#12921, cast(congestion_level#12922 as double) AS congestion_level#12959, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, vehicle_count#12949]
                                                   +- Project [_id#12921, congestion_level#12922, lat#12923, lon#12924, road_id#12925, road_name#12926, speed#12939, timestamp#12928, cast(vehicle_count#12929 as double) AS vehicle_count#12949]
                                                      +- Project [_id#12921, congestion_level#12922, lat#12923, lon#12924, road_id#12925, road_name#12926, cast(speed#12927 as double) AS speed#12939, timestamp#12928, vehicle_count#12929]
                                                         +- Relation [_id#12921,congestion_level#12922,lat#12923,lon#12924,road_id#12925,road_name#12926,speed#12927,timestamp#12928,vehicle_count#12929] MongoRelation(MongoRDD[767] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:48,546 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:53 +07)" executed successfully
2026-01-06 12:33:50,618 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:50 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 12:33:53,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:58 +07)" (scheduled at 2026-01-06 12:33:53.157382+07:00)
2026-01-06 12:33:53,161 - INFO -  Training Spark model...
2026-01-06 12:33:53,595 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_change#13300, vehicle_count_lag#13318, vehicle_count_change#13337, avg(speed#13158) windowspecdefinition(road_id#13144, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#13358]
+- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_change#13300, vehicle_count_lag#13318, CASE WHEN isnotnull(vehicle_count_lag#13318) THEN (vehicle_count#13168 - vehicle_count_lag#13318) ELSE 0.0 END AS vehicle_count_change#13337]
   +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_change#13300, vehicle_count_lag#13318]
      +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_change#13300, vehicle_count_lag#13318, vehicle_count_lag#13318]
         +- Window [lag(vehicle_count#13168, -1, null) windowspecdefinition(road_id#13144, timestamp#13147 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#13318], [road_id#13144], [timestamp#13147 ASC NULLS FIRST]
            +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_change#13300]
               +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, CASE WHEN isnotnull(speed_lag#13283) THEN (speed#13158 - speed_lag#13283) ELSE 0.0 END AS speed_change#13300]
                  +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283]
                     +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267, speed_lag#13283, speed_lag#13283]
                        +- Window [lag(speed#13158, -1, null) windowspecdefinition(road_id#13144, timestamp#13147 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#13283], [road_id#13144], [timestamp#13147 ASC NULLS FIRST]
                           +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, hour_cos#13267]
                              +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, hour_sin#13252, COS((0.2617993877991494 * cast(hour#13202 as double))) AS hour_cos#13267]
                                 +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, is_weekend#13238, SIN((0.2617993877991494 * cast(hour#13202 as double))) AS hour_sin#13252]
                                    +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, day_of_week#13225, CASE WHEN day_of_week#13225 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13238]
                                       +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, is_peak#13213, dayofweek(cast(timestamp#13147 as date)) AS day_of_week#13225]
                                          +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour#13202, CASE WHEN hour#13202 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#13213]
                                             +- Project [_id#13140, congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168, hour(timestamp#13147, Some(Asia/Bangkok)) AS hour#13202]
                                                +- Project [_id#13140, cast(congestion_level#13141 as double) AS congestion_level#13178, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, vehicle_count#13168]
                                                   +- Project [_id#13140, congestion_level#13141, lat#13142, lon#13143, road_id#13144, road_name#13145, speed#13158, timestamp#13147, cast(vehicle_count#13148 as double) AS vehicle_count#13168]
                                                      +- Project [_id#13140, congestion_level#13141, lat#13142, lon#13143, road_id#13144, road_name#13145, cast(speed#13146 as double) AS speed#13158, timestamp#13147, vehicle_count#13148]
                                                         +- Relation [_id#13140,congestion_level#13141,lat#13142,lon#13143,road_id#13144,road_name#13145,speed#13146,timestamp#13147,vehicle_count#13148] MongoRelation(MongoRDD[780] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:53,595 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:58 +07)" executed successfully
2026-01-06 12:33:55,622 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:33:55 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 12:33:58,157 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:03 +07)" (scheduled at 2026-01-06 12:33:58.157382+07:00)
2026-01-06 12:33:58,158 - INFO -  Training Spark model...
2026-01-06 12:33:58,464 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_change#13519, vehicle_count_lag#13537, vehicle_count_change#13556, avg(speed#13377) windowspecdefinition(road_id#13363, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#13577]
+- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_change#13519, vehicle_count_lag#13537, CASE WHEN isnotnull(vehicle_count_lag#13537) THEN (vehicle_count#13387 - vehicle_count_lag#13537) ELSE 0.0 END AS vehicle_count_change#13556]
   +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_change#13519, vehicle_count_lag#13537]
      +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_change#13519, vehicle_count_lag#13537, vehicle_count_lag#13537]
         +- Window [lag(vehicle_count#13387, -1, null) windowspecdefinition(road_id#13363, timestamp#13366 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#13537], [road_id#13363], [timestamp#13366 ASC NULLS FIRST]
            +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_change#13519]
               +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, CASE WHEN isnotnull(speed_lag#13502) THEN (speed#13377 - speed_lag#13502) ELSE 0.0 END AS speed_change#13519]
                  +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502]
                     +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486, speed_lag#13502, speed_lag#13502]
                        +- Window [lag(speed#13377, -1, null) windowspecdefinition(road_id#13363, timestamp#13366 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#13502], [road_id#13363], [timestamp#13366 ASC NULLS FIRST]
                           +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, hour_cos#13486]
                              +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, hour_sin#13471, COS((0.2617993877991494 * cast(hour#13421 as double))) AS hour_cos#13486]
                                 +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, is_weekend#13457, SIN((0.2617993877991494 * cast(hour#13421 as double))) AS hour_sin#13471]
                                    +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, day_of_week#13444, CASE WHEN day_of_week#13444 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13457]
                                       +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, is_peak#13432, dayofweek(cast(timestamp#13366 as date)) AS day_of_week#13444]
                                          +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour#13421, CASE WHEN hour#13421 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#13432]
                                             +- Project [_id#13359, congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387, hour(timestamp#13366, Some(Asia/Bangkok)) AS hour#13421]
                                                +- Project [_id#13359, cast(congestion_level#13360 as double) AS congestion_level#13397, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, vehicle_count#13387]
                                                   +- Project [_id#13359, congestion_level#13360, lat#13361, lon#13362, road_id#13363, road_name#13364, speed#13377, timestamp#13366, cast(vehicle_count#13367 as double) AS vehicle_count#13387]
                                                      +- Project [_id#13359, congestion_level#13360, lat#13361, lon#13362, road_id#13363, road_name#13364, cast(speed#13365 as double) AS speed#13377, timestamp#13366, vehicle_count#13367]
                                                         +- Relation [_id#13359,congestion_level#13360,lat#13361,lon#13362,road_id#13363,road_name#13364,speed#13365,timestamp#13366,vehicle_count#13367] MongoRelation(MongoRDD[793] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:33:58,464 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:03 +07)" executed successfully
2026-01-06 12:33:58,840 - INFO - ‚úì Model trained successfully!
2026-01-06 12:34:00,618 - WARNING - Execution of job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:00 +07)" skipped: maximum number of running instances reached (1)
2026-01-06 12:34:00,997 - INFO - ‚úì Pipeline model saved to models/traffic_pipeline
2026-01-06 12:34:00,997 - INFO -  Running predictions...
2026-01-06 12:34:03,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:08 +07)" (scheduled at 2026-01-06 12:34:03.157382+07:00)
2026-01-06 12:34:03,160 - INFO -  Training Spark model...
2026-01-06 12:34:03,589 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:03,589 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:05 +07)" executed successfully
2026-01-06 12:34:03,657 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_change#13738, vehicle_count_lag#13756, vehicle_count_change#13775, avg(speed#13596) windowspecdefinition(road_id#13582, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#13796]
+- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_change#13738, vehicle_count_lag#13756, CASE WHEN isnotnull(vehicle_count_lag#13756) THEN (vehicle_count#13606 - vehicle_count_lag#13756) ELSE 0.0 END AS vehicle_count_change#13775]
   +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_change#13738, vehicle_count_lag#13756]
      +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_change#13738, vehicle_count_lag#13756, vehicle_count_lag#13756]
         +- Window [lag(vehicle_count#13606, -1, null) windowspecdefinition(road_id#13582, timestamp#13585 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#13756], [road_id#13582], [timestamp#13585 ASC NULLS FIRST]
            +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_change#13738]
               +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, CASE WHEN isnotnull(speed_lag#13721) THEN (speed#13596 - speed_lag#13721) ELSE 0.0 END AS speed_change#13738]
                  +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721]
                     +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705, speed_lag#13721, speed_lag#13721]
                        +- Window [lag(speed#13596, -1, null) windowspecdefinition(road_id#13582, timestamp#13585 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#13721], [road_id#13582], [timestamp#13585 ASC NULLS FIRST]
                           +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, hour_cos#13705]
                              +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, hour_sin#13690, COS((0.2617993877991494 * cast(hour#13640 as double))) AS hour_cos#13705]
                                 +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, is_weekend#13676, SIN((0.2617993877991494 * cast(hour#13640 as double))) AS hour_sin#13690]
                                    +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, day_of_week#13663, CASE WHEN day_of_week#13663 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13676]
                                       +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, is_peak#13651, dayofweek(cast(timestamp#13585 as date)) AS day_of_week#13663]
                                          +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour#13640, CASE WHEN hour#13640 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#13651]
                                             +- Project [_id#13578, congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606, hour(timestamp#13585, Some(Asia/Bangkok)) AS hour#13640]
                                                +- Project [_id#13578, cast(congestion_level#13579 as double) AS congestion_level#13616, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, vehicle_count#13606]
                                                   +- Project [_id#13578, congestion_level#13579, lat#13580, lon#13581, road_id#13582, road_name#13583, speed#13596, timestamp#13585, cast(vehicle_count#13586 as double) AS vehicle_count#13606]
                                                      +- Project [_id#13578, congestion_level#13579, lat#13580, lon#13581, road_id#13582, road_name#13583, cast(speed#13584 as double) AS speed#13596, timestamp#13585, vehicle_count#13586]
                                                         +- Relation [_id#13578,congestion_level#13579,lat#13580,lon#13581,road_id#13582,road_name#13583,speed#13584,timestamp#13585,vehicle_count#13586] MongoRelation(MongoRDD[806] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:03,657 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:08 +07)" executed successfully
2026-01-06 12:34:05,619 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:10 +07)" (scheduled at 2026-01-06 12:34:05.617576+07:00)
2026-01-06 12:34:05,619 - INFO -  Running predictions...
2026-01-06 12:34:06,646 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:06,646 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:10 +07)" executed successfully
2026-01-06 12:34:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:13 +07)" (scheduled at 2026-01-06 12:34:08.157382+07:00)
2026-01-06 12:34:08,158 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:35:08 +07)" (scheduled at 2026-01-06 12:34:08.157779+07:00)
2026-01-06 12:34:08,158 - INFO -  Training Spark model...
2026-01-06 12:34:08,159 - INFO -  Training Spark model...
2026-01-06 12:34:08,528 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_change#14118, vehicle_count_lag#14153, vehicle_count_change#14192, avg(speed#13833) windowspecdefinition(road_id#13819, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#14234]
+- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_change#14118, vehicle_count_lag#14153, CASE WHEN isnotnull(vehicle_count_lag#14153) THEN (vehicle_count#13853 - vehicle_count_lag#14153) ELSE 0.0 END AS vehicle_count_change#14192]
   +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_change#14118, vehicle_count_lag#14153]
      +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_change#14118, vehicle_count_lag#14153, vehicle_count_lag#14153]
         +- Window [lag(vehicle_count#13853, -1, null) windowspecdefinition(road_id#13819, timestamp#13822 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#14153], [road_id#13819], [timestamp#13822 ASC NULLS FIRST]
            +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_change#14118]
               +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, CASE WHEN isnotnull(speed_lag#14083) THEN (speed#13833 - speed_lag#14083) ELSE 0.0 END AS speed_change#14118]
                  +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083]
                     +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052, speed_lag#14083, speed_lag#14083]
                        +- Window [lag(speed#13833, -1, null) windowspecdefinition(road_id#13819, timestamp#13822 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#14083], [road_id#13819], [timestamp#13822 ASC NULLS FIRST]
                           +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, hour_cos#14052]
                              +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, hour_sin#14021, COS((0.2617993877991494 * cast(hour#13932 as double))) AS hour_cos#14052]
                                 +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, is_weekend#13993, SIN((0.2617993877991494 * cast(hour#13932 as double))) AS hour_sin#14021]
                                    +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, day_of_week#13968, CASE WHEN day_of_week#13968 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13993]
                                       +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, is_peak#13944, dayofweek(cast(timestamp#13822 as date)) AS day_of_week#13968]
                                          +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour#13932, CASE WHEN hour#13932 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#13944]
                                             +- Project [_id#13815, congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853, hour(timestamp#13822, Some(Asia/Bangkok)) AS hour#13932]
                                                +- Project [_id#13815, cast(congestion_level#13816 as double) AS congestion_level#13874, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, vehicle_count#13853]
                                                   +- Project [_id#13815, congestion_level#13816, lat#13817, lon#13818, road_id#13819, road_name#13820, speed#13833, timestamp#13822, cast(vehicle_count#13823 as double) AS vehicle_count#13853]
                                                      +- Project [_id#13815, congestion_level#13816, lat#13817, lon#13818, road_id#13819, road_name#13820, cast(speed#13821 as double) AS speed#13833, timestamp#13822, vehicle_count#13823]
                                                         +- Relation [_id#13815,congestion_level#13816,lat#13817,lon#13818,road_id#13819,road_name#13820,speed#13821,timestamp#13822,vehicle_count#13823] MongoRelation(MongoRDD[820] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:08,528 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_change#14117, vehicle_count_lag#14154, vehicle_count_change#14191, avg(speed#13834) windowspecdefinition(road_id#13801, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#14232]
+- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_change#14117, vehicle_count_lag#14154, CASE WHEN isnotnull(vehicle_count_lag#14154) THEN (vehicle_count#13854 - vehicle_count_lag#14154) ELSE 0.0 END AS vehicle_count_change#14191]
   +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_change#14117, vehicle_count_lag#14154]
      +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_change#14117, vehicle_count_lag#14154, vehicle_count_lag#14154]
         +- Window [lag(vehicle_count#13854, -1, null) windowspecdefinition(road_id#13801, timestamp#13804 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#14154], [road_id#13801], [timestamp#13804 ASC NULLS FIRST]
            +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_change#14117]
               +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, CASE WHEN isnotnull(speed_lag#14084) THEN (speed#13834 - speed_lag#14084) ELSE 0.0 END AS speed_change#14117]
                  +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084]
                     +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051, speed_lag#14084, speed_lag#14084]
                        +- Window [lag(speed#13834, -1, null) windowspecdefinition(road_id#13801, timestamp#13804 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#14084], [road_id#13801], [timestamp#13804 ASC NULLS FIRST]
                           +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, hour_cos#14051]
                              +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, hour_sin#14022, COS((0.2617993877991494 * cast(hour#13921 as double))) AS hour_cos#14051]
                                 +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, is_weekend#13994, SIN((0.2617993877991494 * cast(hour#13921 as double))) AS hour_sin#14022]
                                    +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, day_of_week#13967, CASE WHEN day_of_week#13967 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#13994]
                                       +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, is_peak#13943, dayofweek(cast(timestamp#13804 as date)) AS day_of_week#13967]
                                          +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour#13921, CASE WHEN hour#13921 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#13943]
                                             +- Project [_id#13797, congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854, hour(timestamp#13804, Some(Asia/Bangkok)) AS hour#13921]
                                                +- Project [_id#13797, cast(congestion_level#13798 as double) AS congestion_level#13873, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, vehicle_count#13854]
                                                   +- Project [_id#13797, congestion_level#13798, lat#13799, lon#13800, road_id#13801, road_name#13802, speed#13834, timestamp#13804, cast(vehicle_count#13805 as double) AS vehicle_count#13854]
                                                      +- Project [_id#13797, congestion_level#13798, lat#13799, lon#13800, road_id#13801, road_name#13802, cast(speed#13803 as double) AS speed#13834, timestamp#13804, vehicle_count#13805]
                                                         +- Relation [_id#13797,congestion_level#13798,lat#13799,lon#13800,road_id#13801,road_name#13802,speed#13803,timestamp#13804,vehicle_count#13805] MongoRelation(MongoRDD[819] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:08,528 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:13 +07)" executed successfully
2026-01-06 12:34:08,528 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:35:08 +07)" executed successfully
2026-01-06 12:34:10,618 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:15 +07)" (scheduled at 2026-01-06 12:34:10.617576+07:00)
2026-01-06 12:34:10,618 - INFO -  Running predictions...
2026-01-06 12:34:12,134 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:12,134 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:15 +07)" executed successfully
2026-01-06 12:34:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:18 +07)" (scheduled at 2026-01-06 12:34:13.157382+07:00)
2026-01-06 12:34:13,158 - INFO -  Training Spark model...
2026-01-06 12:34:13,597 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_change#14395, vehicle_count_lag#14413, vehicle_count_change#14432, avg(speed#14253) windowspecdefinition(road_id#14239, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#14453]
+- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_change#14395, vehicle_count_lag#14413, CASE WHEN isnotnull(vehicle_count_lag#14413) THEN (vehicle_count#14263 - vehicle_count_lag#14413) ELSE 0.0 END AS vehicle_count_change#14432]
   +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_change#14395, vehicle_count_lag#14413]
      +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_change#14395, vehicle_count_lag#14413, vehicle_count_lag#14413]
         +- Window [lag(vehicle_count#14263, -1, null) windowspecdefinition(road_id#14239, timestamp#14242 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#14413], [road_id#14239], [timestamp#14242 ASC NULLS FIRST]
            +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_change#14395]
               +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, CASE WHEN isnotnull(speed_lag#14378) THEN (speed#14253 - speed_lag#14378) ELSE 0.0 END AS speed_change#14395]
                  +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378]
                     +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362, speed_lag#14378, speed_lag#14378]
                        +- Window [lag(speed#14253, -1, null) windowspecdefinition(road_id#14239, timestamp#14242 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#14378], [road_id#14239], [timestamp#14242 ASC NULLS FIRST]
                           +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, hour_cos#14362]
                              +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, hour_sin#14347, COS((0.2617993877991494 * cast(hour#14297 as double))) AS hour_cos#14362]
                                 +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, is_weekend#14333, SIN((0.2617993877991494 * cast(hour#14297 as double))) AS hour_sin#14347]
                                    +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, day_of_week#14320, CASE WHEN day_of_week#14320 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#14333]
                                       +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, is_peak#14308, dayofweek(cast(timestamp#14242 as date)) AS day_of_week#14320]
                                          +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour#14297, CASE WHEN hour#14297 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#14308]
                                             +- Project [_id#14235, congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263, hour(timestamp#14242, Some(Asia/Bangkok)) AS hour#14297]
                                                +- Project [_id#14235, cast(congestion_level#14236 as double) AS congestion_level#14273, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, vehicle_count#14263]
                                                   +- Project [_id#14235, congestion_level#14236, lat#14237, lon#14238, road_id#14239, road_name#14240, speed#14253, timestamp#14242, cast(vehicle_count#14243 as double) AS vehicle_count#14263]
                                                      +- Project [_id#14235, congestion_level#14236, lat#14237, lon#14238, road_id#14239, road_name#14240, cast(speed#14241 as double) AS speed#14253, timestamp#14242, vehicle_count#14243]
                                                         +- Relation [_id#14235,congestion_level#14236,lat#14237,lon#14238,road_id#14239,road_name#14240,speed#14241,timestamp#14242,vehicle_count#14243] MongoRelation(MongoRDD[845] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:13,598 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:18 +07)" executed successfully
2026-01-06 12:34:15,618 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:20 +07)" (scheduled at 2026-01-06 12:34:15.617576+07:00)
2026-01-06 12:34:15,619 - INFO -  Running predictions...
2026-01-06 12:34:16,488 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:16,488 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:20 +07)" executed successfully
2026-01-06 12:34:18,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:23 +07)" (scheduled at 2026-01-06 12:34:18.157382+07:00)
2026-01-06 12:34:18,163 - INFO -  Training Spark model...
2026-01-06 12:34:18,433 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_change#14614, vehicle_count_lag#14632, vehicle_count_change#14651, avg(speed#14472) windowspecdefinition(road_id#14458, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#14672]
+- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_change#14614, vehicle_count_lag#14632, CASE WHEN isnotnull(vehicle_count_lag#14632) THEN (vehicle_count#14482 - vehicle_count_lag#14632) ELSE 0.0 END AS vehicle_count_change#14651]
   +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_change#14614, vehicle_count_lag#14632]
      +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_change#14614, vehicle_count_lag#14632, vehicle_count_lag#14632]
         +- Window [lag(vehicle_count#14482, -1, null) windowspecdefinition(road_id#14458, timestamp#14461 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#14632], [road_id#14458], [timestamp#14461 ASC NULLS FIRST]
            +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_change#14614]
               +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, CASE WHEN isnotnull(speed_lag#14597) THEN (speed#14472 - speed_lag#14597) ELSE 0.0 END AS speed_change#14614]
                  +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597]
                     +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581, speed_lag#14597, speed_lag#14597]
                        +- Window [lag(speed#14472, -1, null) windowspecdefinition(road_id#14458, timestamp#14461 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#14597], [road_id#14458], [timestamp#14461 ASC NULLS FIRST]
                           +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, hour_cos#14581]
                              +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, hour_sin#14566, COS((0.2617993877991494 * cast(hour#14516 as double))) AS hour_cos#14581]
                                 +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, is_weekend#14552, SIN((0.2617993877991494 * cast(hour#14516 as double))) AS hour_sin#14566]
                                    +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, day_of_week#14539, CASE WHEN day_of_week#14539 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#14552]
                                       +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, is_peak#14527, dayofweek(cast(timestamp#14461 as date)) AS day_of_week#14539]
                                          +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour#14516, CASE WHEN hour#14516 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#14527]
                                             +- Project [_id#14454, congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482, hour(timestamp#14461, Some(Asia/Bangkok)) AS hour#14516]
                                                +- Project [_id#14454, cast(congestion_level#14455 as double) AS congestion_level#14492, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, vehicle_count#14482]
                                                   +- Project [_id#14454, congestion_level#14455, lat#14456, lon#14457, road_id#14458, road_name#14459, speed#14472, timestamp#14461, cast(vehicle_count#14462 as double) AS vehicle_count#14482]
                                                      +- Project [_id#14454, congestion_level#14455, lat#14456, lon#14457, road_id#14458, road_name#14459, cast(speed#14460 as double) AS speed#14472, timestamp#14461, vehicle_count#14462]
                                                         +- Relation [_id#14454,congestion_level#14455,lat#14456,lon#14457,road_id#14458,road_name#14459,speed#14460,timestamp#14461,vehicle_count#14462] MongoRelation(MongoRDD[858] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:18,434 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:23 +07)" executed successfully
2026-01-06 12:34:20,622 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:25 +07)" (scheduled at 2026-01-06 12:34:20.617576+07:00)
2026-01-06 12:34:20,622 - INFO -  Running predictions...
2026-01-06 12:34:21,581 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:21,581 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:25 +07)" executed successfully
2026-01-06 12:34:23,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:28 +07)" (scheduled at 2026-01-06 12:34:23.157382+07:00)
2026-01-06 12:34:23,158 - INFO -  Training Spark model...
2026-01-06 12:34:23,565 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_change#14833, vehicle_count_lag#14851, vehicle_count_change#14870, avg(speed#14691) windowspecdefinition(road_id#14677, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#14891]
+- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_change#14833, vehicle_count_lag#14851, CASE WHEN isnotnull(vehicle_count_lag#14851) THEN (vehicle_count#14701 - vehicle_count_lag#14851) ELSE 0.0 END AS vehicle_count_change#14870]
   +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_change#14833, vehicle_count_lag#14851]
      +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_change#14833, vehicle_count_lag#14851, vehicle_count_lag#14851]
         +- Window [lag(vehicle_count#14701, -1, null) windowspecdefinition(road_id#14677, timestamp#14680 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#14851], [road_id#14677], [timestamp#14680 ASC NULLS FIRST]
            +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_change#14833]
               +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, CASE WHEN isnotnull(speed_lag#14816) THEN (speed#14691 - speed_lag#14816) ELSE 0.0 END AS speed_change#14833]
                  +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816]
                     +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800, speed_lag#14816, speed_lag#14816]
                        +- Window [lag(speed#14691, -1, null) windowspecdefinition(road_id#14677, timestamp#14680 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#14816], [road_id#14677], [timestamp#14680 ASC NULLS FIRST]
                           +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, hour_cos#14800]
                              +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, hour_sin#14785, COS((0.2617993877991494 * cast(hour#14735 as double))) AS hour_cos#14800]
                                 +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, is_weekend#14771, SIN((0.2617993877991494 * cast(hour#14735 as double))) AS hour_sin#14785]
                                    +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, day_of_week#14758, CASE WHEN day_of_week#14758 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#14771]
                                       +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, is_peak#14746, dayofweek(cast(timestamp#14680 as date)) AS day_of_week#14758]
                                          +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour#14735, CASE WHEN hour#14735 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#14746]
                                             +- Project [_id#14673, congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701, hour(timestamp#14680, Some(Asia/Bangkok)) AS hour#14735]
                                                +- Project [_id#14673, cast(congestion_level#14674 as double) AS congestion_level#14711, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, vehicle_count#14701]
                                                   +- Project [_id#14673, congestion_level#14674, lat#14675, lon#14676, road_id#14677, road_name#14678, speed#14691, timestamp#14680, cast(vehicle_count#14681 as double) AS vehicle_count#14701]
                                                      +- Project [_id#14673, congestion_level#14674, lat#14675, lon#14676, road_id#14677, road_name#14678, cast(speed#14679 as double) AS speed#14691, timestamp#14680, vehicle_count#14681]
                                                         +- Relation [_id#14673,congestion_level#14674,lat#14675,lon#14676,road_id#14677,road_name#14678,speed#14679,timestamp#14680,vehicle_count#14681] MongoRelation(MongoRDD[871] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:23,565 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:28 +07)" executed successfully
2026-01-06 12:34:25,621 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:30 +07)" (scheduled at 2026-01-06 12:34:25.617576+07:00)
2026-01-06 12:34:25,621 - INFO -  Running predictions...
2026-01-06 12:34:26,489 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:26,489 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:30 +07)" executed successfully
2026-01-06 12:34:28,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:33 +07)" (scheduled at 2026-01-06 12:34:28.157382+07:00)
2026-01-06 12:34:28,158 - INFO -  Training Spark model...
2026-01-06 12:34:28,599 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_change#15052, vehicle_count_lag#15070, vehicle_count_change#15089, avg(speed#14910) windowspecdefinition(road_id#14896, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#15110]
+- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_change#15052, vehicle_count_lag#15070, CASE WHEN isnotnull(vehicle_count_lag#15070) THEN (vehicle_count#14920 - vehicle_count_lag#15070) ELSE 0.0 END AS vehicle_count_change#15089]
   +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_change#15052, vehicle_count_lag#15070]
      +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_change#15052, vehicle_count_lag#15070, vehicle_count_lag#15070]
         +- Window [lag(vehicle_count#14920, -1, null) windowspecdefinition(road_id#14896, timestamp#14899 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#15070], [road_id#14896], [timestamp#14899 ASC NULLS FIRST]
            +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_change#15052]
               +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, CASE WHEN isnotnull(speed_lag#15035) THEN (speed#14910 - speed_lag#15035) ELSE 0.0 END AS speed_change#15052]
                  +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035]
                     +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019, speed_lag#15035, speed_lag#15035]
                        +- Window [lag(speed#14910, -1, null) windowspecdefinition(road_id#14896, timestamp#14899 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#15035], [road_id#14896], [timestamp#14899 ASC NULLS FIRST]
                           +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, hour_cos#15019]
                              +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, hour_sin#15004, COS((0.2617993877991494 * cast(hour#14954 as double))) AS hour_cos#15019]
                                 +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, is_weekend#14990, SIN((0.2617993877991494 * cast(hour#14954 as double))) AS hour_sin#15004]
                                    +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, day_of_week#14977, CASE WHEN day_of_week#14977 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#14990]
                                       +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, is_peak#14965, dayofweek(cast(timestamp#14899 as date)) AS day_of_week#14977]
                                          +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour#14954, CASE WHEN hour#14954 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#14965]
                                             +- Project [_id#14892, congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920, hour(timestamp#14899, Some(Asia/Bangkok)) AS hour#14954]
                                                +- Project [_id#14892, cast(congestion_level#14893 as double) AS congestion_level#14930, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, vehicle_count#14920]
                                                   +- Project [_id#14892, congestion_level#14893, lat#14894, lon#14895, road_id#14896, road_name#14897, speed#14910, timestamp#14899, cast(vehicle_count#14900 as double) AS vehicle_count#14920]
                                                      +- Project [_id#14892, congestion_level#14893, lat#14894, lon#14895, road_id#14896, road_name#14897, cast(speed#14898 as double) AS speed#14910, timestamp#14899, vehicle_count#14900]
                                                         +- Relation [_id#14892,congestion_level#14893,lat#14894,lon#14895,road_id#14896,road_name#14897,speed#14898,timestamp#14899,vehicle_count#14900] MongoRelation(MongoRDD[884] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:28,602 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:33 +07)" executed successfully
2026-01-06 12:34:30,621 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:35 +07)" (scheduled at 2026-01-06 12:34:30.617576+07:00)
2026-01-06 12:34:30,622 - INFO -  Running predictions...
2026-01-06 12:34:31,500 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 12:34:31,500 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:35 +07)" executed successfully
2026-01-06 12:34:32,149 - INFO - Stopping Spark Session...
2026-01-06 12:34:32,390 - INFO - Closing down clientserver connection
2026-01-06 12:34:32,390 - INFO - Scheduler has been shut down
2026-01-06 12:34:32,391 - INFO - Closing down clientserver connection
2026-01-06 12:34:33,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:38 +07)" (scheduled at 2026-01-06 12:34:33.157382+07:00)
2026-01-06 12:34:33,158 - INFO -  Training Spark model...
2026-01-06 12:34:33,433 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_change#15271, vehicle_count_lag#15289, vehicle_count_change#15308, avg(speed#15129) windowspecdefinition(road_id#15115, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#15329]
+- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_change#15271, vehicle_count_lag#15289, CASE WHEN isnotnull(vehicle_count_lag#15289) THEN (vehicle_count#15139 - vehicle_count_lag#15289) ELSE 0.0 END AS vehicle_count_change#15308]
   +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_change#15271, vehicle_count_lag#15289]
      +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_change#15271, vehicle_count_lag#15289, vehicle_count_lag#15289]
         +- Window [lag(vehicle_count#15139, -1, null) windowspecdefinition(road_id#15115, timestamp#15118 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#15289], [road_id#15115], [timestamp#15118 ASC NULLS FIRST]
            +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_change#15271]
               +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, CASE WHEN isnotnull(speed_lag#15254) THEN (speed#15129 - speed_lag#15254) ELSE 0.0 END AS speed_change#15271]
                  +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254]
                     +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238, speed_lag#15254, speed_lag#15254]
                        +- Window [lag(speed#15129, -1, null) windowspecdefinition(road_id#15115, timestamp#15118 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#15254], [road_id#15115], [timestamp#15118 ASC NULLS FIRST]
                           +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, hour_cos#15238]
                              +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, hour_sin#15223, COS((0.2617993877991494 * cast(hour#15173 as double))) AS hour_cos#15238]
                                 +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, is_weekend#15209, SIN((0.2617993877991494 * cast(hour#15173 as double))) AS hour_sin#15223]
                                    +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, day_of_week#15196, CASE WHEN day_of_week#15196 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#15209]
                                       +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, is_peak#15184, dayofweek(cast(timestamp#15118 as date)) AS day_of_week#15196]
                                          +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour#15173, CASE WHEN hour#15173 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#15184]
                                             +- Project [_id#15111, congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139, hour(timestamp#15118, Some(Asia/Bangkok)) AS hour#15173]
                                                +- Project [_id#15111, cast(congestion_level#15112 as double) AS congestion_level#15149, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, vehicle_count#15139]
                                                   +- Project [_id#15111, congestion_level#15112, lat#15113, lon#15114, road_id#15115, road_name#15116, speed#15129, timestamp#15118, cast(vehicle_count#15119 as double) AS vehicle_count#15139]
                                                      +- Project [_id#15111, congestion_level#15112, lat#15113, lon#15114, road_id#15115, road_name#15116, cast(speed#15117 as double) AS speed#15129, timestamp#15118, vehicle_count#15119]
                                                         +- Relation [_id#15111,congestion_level#15112,lat#15113,lon#15114,road_id#15115,road_name#15116,speed#15117,timestamp#15118,vehicle_count#15119] MongoRelation(MongoRDD[897] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:33,433 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:38 +07)" executed successfully
2026-01-06 12:34:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:43 +07)" (scheduled at 2026-01-06 12:34:38.157382+07:00)
2026-01-06 12:34:38,158 - INFO -  Training Spark model...
2026-01-06 12:34:38,431 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_change#15490, vehicle_count_lag#15508, vehicle_count_change#15527, avg(speed#15348) windowspecdefinition(road_id#15334, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#15548]
+- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_change#15490, vehicle_count_lag#15508, CASE WHEN isnotnull(vehicle_count_lag#15508) THEN (vehicle_count#15358 - vehicle_count_lag#15508) ELSE 0.0 END AS vehicle_count_change#15527]
   +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_change#15490, vehicle_count_lag#15508]
      +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_change#15490, vehicle_count_lag#15508, vehicle_count_lag#15508]
         +- Window [lag(vehicle_count#15358, -1, null) windowspecdefinition(road_id#15334, timestamp#15337 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#15508], [road_id#15334], [timestamp#15337 ASC NULLS FIRST]
            +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_change#15490]
               +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, CASE WHEN isnotnull(speed_lag#15473) THEN (speed#15348 - speed_lag#15473) ELSE 0.0 END AS speed_change#15490]
                  +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473]
                     +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457, speed_lag#15473, speed_lag#15473]
                        +- Window [lag(speed#15348, -1, null) windowspecdefinition(road_id#15334, timestamp#15337 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#15473], [road_id#15334], [timestamp#15337 ASC NULLS FIRST]
                           +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, hour_cos#15457]
                              +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, hour_sin#15442, COS((0.2617993877991494 * cast(hour#15392 as double))) AS hour_cos#15457]
                                 +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, is_weekend#15428, SIN((0.2617993877991494 * cast(hour#15392 as double))) AS hour_sin#15442]
                                    +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, day_of_week#15415, CASE WHEN day_of_week#15415 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#15428]
                                       +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, is_peak#15403, dayofweek(cast(timestamp#15337 as date)) AS day_of_week#15415]
                                          +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour#15392, CASE WHEN hour#15392 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#15403]
                                             +- Project [_id#15330, congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358, hour(timestamp#15337, Some(Asia/Bangkok)) AS hour#15392]
                                                +- Project [_id#15330, cast(congestion_level#15331 as double) AS congestion_level#15368, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, vehicle_count#15358]
                                                   +- Project [_id#15330, congestion_level#15331, lat#15332, lon#15333, road_id#15334, road_name#15335, speed#15348, timestamp#15337, cast(vehicle_count#15338 as double) AS vehicle_count#15358]
                                                      +- Project [_id#15330, congestion_level#15331, lat#15332, lon#15333, road_id#15334, road_name#15335, cast(speed#15336 as double) AS speed#15348, timestamp#15337, vehicle_count#15338]
                                                         +- Relation [_id#15330,congestion_level#15331,lat#15332,lon#15333,road_id#15334,road_name#15335,speed#15336,timestamp#15337,vehicle_count#15338] MongoRelation(MongoRDD[910] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:38,432 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:43 +07)" executed successfully
2026-01-06 12:34:43,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:48 +07)" (scheduled at 2026-01-06 12:34:43.157382+07:00)
2026-01-06 12:34:43,160 - INFO -  Training Spark model...
2026-01-06 12:34:43,464 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_change#15709, vehicle_count_lag#15727, vehicle_count_change#15746, avg(speed#15567) windowspecdefinition(road_id#15553, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#15767]
+- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_change#15709, vehicle_count_lag#15727, CASE WHEN isnotnull(vehicle_count_lag#15727) THEN (vehicle_count#15577 - vehicle_count_lag#15727) ELSE 0.0 END AS vehicle_count_change#15746]
   +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_change#15709, vehicle_count_lag#15727]
      +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_change#15709, vehicle_count_lag#15727, vehicle_count_lag#15727]
         +- Window [lag(vehicle_count#15577, -1, null) windowspecdefinition(road_id#15553, timestamp#15556 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#15727], [road_id#15553], [timestamp#15556 ASC NULLS FIRST]
            +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_change#15709]
               +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, CASE WHEN isnotnull(speed_lag#15692) THEN (speed#15567 - speed_lag#15692) ELSE 0.0 END AS speed_change#15709]
                  +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692]
                     +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676, speed_lag#15692, speed_lag#15692]
                        +- Window [lag(speed#15567, -1, null) windowspecdefinition(road_id#15553, timestamp#15556 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#15692], [road_id#15553], [timestamp#15556 ASC NULLS FIRST]
                           +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, hour_cos#15676]
                              +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, hour_sin#15661, COS((0.2617993877991494 * cast(hour#15611 as double))) AS hour_cos#15676]
                                 +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, is_weekend#15647, SIN((0.2617993877991494 * cast(hour#15611 as double))) AS hour_sin#15661]
                                    +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, day_of_week#15634, CASE WHEN day_of_week#15634 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#15647]
                                       +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, is_peak#15622, dayofweek(cast(timestamp#15556 as date)) AS day_of_week#15634]
                                          +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour#15611, CASE WHEN hour#15611 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#15622]
                                             +- Project [_id#15549, congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577, hour(timestamp#15556, Some(Asia/Bangkok)) AS hour#15611]
                                                +- Project [_id#15549, cast(congestion_level#15550 as double) AS congestion_level#15587, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, vehicle_count#15577]
                                                   +- Project [_id#15549, congestion_level#15550, lat#15551, lon#15552, road_id#15553, road_name#15554, speed#15567, timestamp#15556, cast(vehicle_count#15557 as double) AS vehicle_count#15577]
                                                      +- Project [_id#15549, congestion_level#15550, lat#15551, lon#15552, road_id#15553, road_name#15554, cast(speed#15555 as double) AS speed#15567, timestamp#15556, vehicle_count#15557]
                                                         +- Relation [_id#15549,congestion_level#15550,lat#15551,lon#15552,road_id#15553,road_name#15554,speed#15555,timestamp#15556,vehicle_count#15557] MongoRelation(MongoRDD[923] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:43,464 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:48 +07)" executed successfully
2026-01-06 12:34:48,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:53 +07)" (scheduled at 2026-01-06 12:34:48.157382+07:00)
2026-01-06 12:34:48,165 - INFO -  Training Spark model...
2026-01-06 12:34:48,439 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_change#15928, vehicle_count_lag#15946, vehicle_count_change#15965, avg(speed#15786) windowspecdefinition(road_id#15772, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#15986]
+- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_change#15928, vehicle_count_lag#15946, CASE WHEN isnotnull(vehicle_count_lag#15946) THEN (vehicle_count#15796 - vehicle_count_lag#15946) ELSE 0.0 END AS vehicle_count_change#15965]
   +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_change#15928, vehicle_count_lag#15946]
      +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_change#15928, vehicle_count_lag#15946, vehicle_count_lag#15946]
         +- Window [lag(vehicle_count#15796, -1, null) windowspecdefinition(road_id#15772, timestamp#15775 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#15946], [road_id#15772], [timestamp#15775 ASC NULLS FIRST]
            +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_change#15928]
               +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, CASE WHEN isnotnull(speed_lag#15911) THEN (speed#15786 - speed_lag#15911) ELSE 0.0 END AS speed_change#15928]
                  +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911]
                     +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895, speed_lag#15911, speed_lag#15911]
                        +- Window [lag(speed#15786, -1, null) windowspecdefinition(road_id#15772, timestamp#15775 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#15911], [road_id#15772], [timestamp#15775 ASC NULLS FIRST]
                           +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, hour_cos#15895]
                              +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, hour_sin#15880, COS((0.2617993877991494 * cast(hour#15830 as double))) AS hour_cos#15895]
                                 +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, is_weekend#15866, SIN((0.2617993877991494 * cast(hour#15830 as double))) AS hour_sin#15880]
                                    +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, day_of_week#15853, CASE WHEN day_of_week#15853 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#15866]
                                       +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, is_peak#15841, dayofweek(cast(timestamp#15775 as date)) AS day_of_week#15853]
                                          +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour#15830, CASE WHEN hour#15830 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#15841]
                                             +- Project [_id#15768, congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796, hour(timestamp#15775, Some(Asia/Bangkok)) AS hour#15830]
                                                +- Project [_id#15768, cast(congestion_level#15769 as double) AS congestion_level#15806, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, vehicle_count#15796]
                                                   +- Project [_id#15768, congestion_level#15769, lat#15770, lon#15771, road_id#15772, road_name#15773, speed#15786, timestamp#15775, cast(vehicle_count#15776 as double) AS vehicle_count#15796]
                                                      +- Project [_id#15768, congestion_level#15769, lat#15770, lon#15771, road_id#15772, road_name#15773, cast(speed#15774 as double) AS speed#15786, timestamp#15775, vehicle_count#15776]
                                                         +- Relation [_id#15768,congestion_level#15769,lat#15770,lon#15771,road_id#15772,road_name#15773,speed#15774,timestamp#15775,vehicle_count#15776] MongoRelation(MongoRDD[936] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:48,440 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:53 +07)" executed successfully
2026-01-06 12:34:53,170 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:58 +07)" (scheduled at 2026-01-06 12:34:53.157382+07:00)
2026-01-06 12:34:53,170 - INFO -  Training Spark model...
2026-01-06 12:34:53,443 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_change#16147, vehicle_count_lag#16165, vehicle_count_change#16184, avg(speed#16005) windowspecdefinition(road_id#15991, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#16205]
+- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_change#16147, vehicle_count_lag#16165, CASE WHEN isnotnull(vehicle_count_lag#16165) THEN (vehicle_count#16015 - vehicle_count_lag#16165) ELSE 0.0 END AS vehicle_count_change#16184]
   +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_change#16147, vehicle_count_lag#16165]
      +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_change#16147, vehicle_count_lag#16165, vehicle_count_lag#16165]
         +- Window [lag(vehicle_count#16015, -1, null) windowspecdefinition(road_id#15991, timestamp#15994 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#16165], [road_id#15991], [timestamp#15994 ASC NULLS FIRST]
            +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_change#16147]
               +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, CASE WHEN isnotnull(speed_lag#16130) THEN (speed#16005 - speed_lag#16130) ELSE 0.0 END AS speed_change#16147]
                  +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130]
                     +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114, speed_lag#16130, speed_lag#16130]
                        +- Window [lag(speed#16005, -1, null) windowspecdefinition(road_id#15991, timestamp#15994 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#16130], [road_id#15991], [timestamp#15994 ASC NULLS FIRST]
                           +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, hour_cos#16114]
                              +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, hour_sin#16099, COS((0.2617993877991494 * cast(hour#16049 as double))) AS hour_cos#16114]
                                 +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, is_weekend#16085, SIN((0.2617993877991494 * cast(hour#16049 as double))) AS hour_sin#16099]
                                    +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, day_of_week#16072, CASE WHEN day_of_week#16072 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#16085]
                                       +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, is_peak#16060, dayofweek(cast(timestamp#15994 as date)) AS day_of_week#16072]
                                          +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour#16049, CASE WHEN hour#16049 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#16060]
                                             +- Project [_id#15987, congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015, hour(timestamp#15994, Some(Asia/Bangkok)) AS hour#16049]
                                                +- Project [_id#15987, cast(congestion_level#15988 as double) AS congestion_level#16025, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, vehicle_count#16015]
                                                   +- Project [_id#15987, congestion_level#15988, lat#15989, lon#15990, road_id#15991, road_name#15992, speed#16005, timestamp#15994, cast(vehicle_count#15995 as double) AS vehicle_count#16015]
                                                      +- Project [_id#15987, congestion_level#15988, lat#15989, lon#15990, road_id#15991, road_name#15992, cast(speed#15993 as double) AS speed#16005, timestamp#15994, vehicle_count#15995]
                                                         +- Relation [_id#15987,congestion_level#15988,lat#15989,lon#15990,road_id#15991,road_name#15992,speed#15993,timestamp#15994,vehicle_count#15995] MongoRelation(MongoRDD[949] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:53,444 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:34:58 +07)" executed successfully
2026-01-06 12:34:58,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:03 +07)" (scheduled at 2026-01-06 12:34:58.157382+07:00)
2026-01-06 12:34:58,162 - INFO -  Training Spark model...
2026-01-06 12:34:58,471 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_change#16366, vehicle_count_lag#16384, vehicle_count_change#16403, avg(speed#16224) windowspecdefinition(road_id#16210, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#16424]
+- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_change#16366, vehicle_count_lag#16384, CASE WHEN isnotnull(vehicle_count_lag#16384) THEN (vehicle_count#16234 - vehicle_count_lag#16384) ELSE 0.0 END AS vehicle_count_change#16403]
   +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_change#16366, vehicle_count_lag#16384]
      +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_change#16366, vehicle_count_lag#16384, vehicle_count_lag#16384]
         +- Window [lag(vehicle_count#16234, -1, null) windowspecdefinition(road_id#16210, timestamp#16213 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#16384], [road_id#16210], [timestamp#16213 ASC NULLS FIRST]
            +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_change#16366]
               +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, CASE WHEN isnotnull(speed_lag#16349) THEN (speed#16224 - speed_lag#16349) ELSE 0.0 END AS speed_change#16366]
                  +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349]
                     +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333, speed_lag#16349, speed_lag#16349]
                        +- Window [lag(speed#16224, -1, null) windowspecdefinition(road_id#16210, timestamp#16213 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#16349], [road_id#16210], [timestamp#16213 ASC NULLS FIRST]
                           +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, hour_cos#16333]
                              +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, hour_sin#16318, COS((0.2617993877991494 * cast(hour#16268 as double))) AS hour_cos#16333]
                                 +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, is_weekend#16304, SIN((0.2617993877991494 * cast(hour#16268 as double))) AS hour_sin#16318]
                                    +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, day_of_week#16291, CASE WHEN day_of_week#16291 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#16304]
                                       +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, is_peak#16279, dayofweek(cast(timestamp#16213 as date)) AS day_of_week#16291]
                                          +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour#16268, CASE WHEN hour#16268 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#16279]
                                             +- Project [_id#16206, congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234, hour(timestamp#16213, Some(Asia/Bangkok)) AS hour#16268]
                                                +- Project [_id#16206, cast(congestion_level#16207 as double) AS congestion_level#16244, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, vehicle_count#16234]
                                                   +- Project [_id#16206, congestion_level#16207, lat#16208, lon#16209, road_id#16210, road_name#16211, speed#16224, timestamp#16213, cast(vehicle_count#16214 as double) AS vehicle_count#16234]
                                                      +- Project [_id#16206, congestion_level#16207, lat#16208, lon#16209, road_id#16210, road_name#16211, cast(speed#16212 as double) AS speed#16224, timestamp#16213, vehicle_count#16214]
                                                         +- Relation [_id#16206,congestion_level#16207,lat#16208,lon#16209,road_id#16210,road_name#16211,speed#16212,timestamp#16213,vehicle_count#16214] MongoRelation(MongoRDD[962] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:34:58,472 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:03 +07)" executed successfully
2026-01-06 12:35:03,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:08 +07)" (scheduled at 2026-01-06 12:35:03.157382+07:00)
2026-01-06 12:35:03,160 - INFO -  Training Spark model...
2026-01-06 12:35:03,450 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_change#16585, vehicle_count_lag#16603, vehicle_count_change#16622, avg(speed#16443) windowspecdefinition(road_id#16429, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#16643]
+- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_change#16585, vehicle_count_lag#16603, CASE WHEN isnotnull(vehicle_count_lag#16603) THEN (vehicle_count#16453 - vehicle_count_lag#16603) ELSE 0.0 END AS vehicle_count_change#16622]
   +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_change#16585, vehicle_count_lag#16603]
      +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_change#16585, vehicle_count_lag#16603, vehicle_count_lag#16603]
         +- Window [lag(vehicle_count#16453, -1, null) windowspecdefinition(road_id#16429, timestamp#16432 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#16603], [road_id#16429], [timestamp#16432 ASC NULLS FIRST]
            +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_change#16585]
               +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, CASE WHEN isnotnull(speed_lag#16568) THEN (speed#16443 - speed_lag#16568) ELSE 0.0 END AS speed_change#16585]
                  +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568]
                     +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552, speed_lag#16568, speed_lag#16568]
                        +- Window [lag(speed#16443, -1, null) windowspecdefinition(road_id#16429, timestamp#16432 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#16568], [road_id#16429], [timestamp#16432 ASC NULLS FIRST]
                           +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, hour_cos#16552]
                              +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, hour_sin#16537, COS((0.2617993877991494 * cast(hour#16487 as double))) AS hour_cos#16552]
                                 +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, is_weekend#16523, SIN((0.2617993877991494 * cast(hour#16487 as double))) AS hour_sin#16537]
                                    +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, day_of_week#16510, CASE WHEN day_of_week#16510 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#16523]
                                       +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, is_peak#16498, dayofweek(cast(timestamp#16432 as date)) AS day_of_week#16510]
                                          +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour#16487, CASE WHEN hour#16487 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#16498]
                                             +- Project [_id#16425, congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453, hour(timestamp#16432, Some(Asia/Bangkok)) AS hour#16487]
                                                +- Project [_id#16425, cast(congestion_level#16426 as double) AS congestion_level#16463, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, vehicle_count#16453]
                                                   +- Project [_id#16425, congestion_level#16426, lat#16427, lon#16428, road_id#16429, road_name#16430, speed#16443, timestamp#16432, cast(vehicle_count#16433 as double) AS vehicle_count#16453]
                                                      +- Project [_id#16425, congestion_level#16426, lat#16427, lon#16428, road_id#16429, road_name#16430, cast(speed#16431 as double) AS speed#16443, timestamp#16432, vehicle_count#16433]
                                                         +- Relation [_id#16425,congestion_level#16426,lat#16427,lon#16428,road_id#16429,road_name#16430,speed#16431,timestamp#16432,vehicle_count#16433] MongoRelation(MongoRDD[975] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:03,450 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:08 +07)" executed successfully
2026-01-06 12:35:08,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:13 +07)" (scheduled at 2026-01-06 12:35:08.157382+07:00)
2026-01-06 12:35:08,163 - INFO -  Training Spark model...
2026-01-06 12:35:08,162 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:36:08 +07)" (scheduled at 2026-01-06 12:35:08.157779+07:00)
2026-01-06 12:35:08,163 - INFO -  Training Spark model...
2026-01-06 12:35:08,613 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_change#16948, vehicle_count_lag#16982, vehicle_count_change#17020, avg(speed#16671) windowspecdefinition(road_id#16648, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17060]
+- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_change#16948, vehicle_count_lag#16982, CASE WHEN isnotnull(vehicle_count_lag#16982) THEN (vehicle_count#16700 - vehicle_count_lag#16982) ELSE 0.0 END AS vehicle_count_change#17020]
   +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_change#16948, vehicle_count_lag#16982]
      +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_change#16948, vehicle_count_lag#16982, vehicle_count_lag#16982]
         +- Window [lag(vehicle_count#16700, -1, null) windowspecdefinition(road_id#16648, timestamp#16651 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#16982], [road_id#16648], [timestamp#16651 ASC NULLS FIRST]
            +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_change#16948]
               +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, CASE WHEN isnotnull(speed_lag#16930) THEN (speed#16671 - speed_lag#16930) ELSE 0.0 END AS speed_change#16948]
                  +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930]
                     +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884, speed_lag#16930, speed_lag#16930]
                        +- Window [lag(speed#16671, -1, null) windowspecdefinition(road_id#16648, timestamp#16651 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#16930], [road_id#16648], [timestamp#16651 ASC NULLS FIRST]
                           +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, hour_cos#16884]
                              +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, hour_sin#16855, COS((0.2617993877991494 * cast(hour#16768 as double))) AS hour_cos#16884]
                                 +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, is_weekend#16840, SIN((0.2617993877991494 * cast(hour#16768 as double))) AS hour_sin#16855]
                                    +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, day_of_week#16814, CASE WHEN day_of_week#16814 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#16840]
                                       +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, is_peak#16790, dayofweek(cast(timestamp#16651 as date)) AS day_of_week#16814]
                                          +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour#16768, CASE WHEN hour#16768 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#16790]
                                             +- Project [_id#16644, congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700, hour(timestamp#16651, Some(Asia/Bangkok)) AS hour#16768]
                                                +- Project [_id#16644, cast(congestion_level#16645 as double) AS congestion_level#16720, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, vehicle_count#16700]
                                                   +- Project [_id#16644, congestion_level#16645, lat#16646, lon#16647, road_id#16648, road_name#16649, speed#16671, timestamp#16651, cast(vehicle_count#16652 as double) AS vehicle_count#16700]
                                                      +- Project [_id#16644, congestion_level#16645, lat#16646, lon#16647, road_id#16648, road_name#16649, cast(speed#16650 as double) AS speed#16671, timestamp#16651, vehicle_count#16652]
                                                         +- Relation [_id#16644,congestion_level#16645,lat#16646,lon#16647,road_id#16648,road_name#16649,speed#16650,timestamp#16651,vehicle_count#16652] MongoRelation(MongoRDD[988] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:08,613 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:13 +07)" executed successfully
2026-01-06 12:35:08,614 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_change#16983, vehicle_count_lag#17019, vehicle_count_change#17058, avg(speed#16690) windowspecdefinition(road_id#16666, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17081]
+- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_change#16983, vehicle_count_lag#17019, CASE WHEN isnotnull(vehicle_count_lag#17019) THEN (vehicle_count#16710 - vehicle_count_lag#17019) ELSE 0.0 END AS vehicle_count_change#17058]
   +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_change#16983, vehicle_count_lag#17019]
      +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_change#16983, vehicle_count_lag#17019, vehicle_count_lag#17019]
         +- Window [lag(vehicle_count#16710, -1, null) windowspecdefinition(road_id#16666, timestamp#16669 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#17019], [road_id#16666], [timestamp#16669 ASC NULLS FIRST]
            +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_change#16983]
               +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, CASE WHEN isnotnull(speed_lag#16947) THEN (speed#16690 - speed_lag#16947) ELSE 0.0 END AS speed_change#16983]
                  +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947]
                     +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914, speed_lag#16947, speed_lag#16947]
                        +- Window [lag(speed#16690, -1, null) windowspecdefinition(road_id#16666, timestamp#16669 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#16947], [road_id#16666], [timestamp#16669 ASC NULLS FIRST]
                           +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, hour_cos#16914]
                              +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, hour_sin#16883, COS((0.2617993877991494 * cast(hour#16779 as double))) AS hour_cos#16914]
                                 +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, is_weekend#16854, SIN((0.2617993877991494 * cast(hour#16779 as double))) AS hour_sin#16883]
                                    +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, day_of_week#16827, CASE WHEN day_of_week#16827 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#16854]
                                       +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, is_peak#16802, dayofweek(cast(timestamp#16669 as date)) AS day_of_week#16827]
                                          +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour#16779, CASE WHEN hour#16779 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#16802]
                                             +- Project [_id#16662, congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710, hour(timestamp#16669, Some(Asia/Bangkok)) AS hour#16779]
                                                +- Project [_id#16662, cast(congestion_level#16663 as double) AS congestion_level#16730, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, vehicle_count#16710]
                                                   +- Project [_id#16662, congestion_level#16663, lat#16664, lon#16665, road_id#16666, road_name#16667, speed#16690, timestamp#16669, cast(vehicle_count#16670 as double) AS vehicle_count#16710]
                                                      +- Project [_id#16662, congestion_level#16663, lat#16664, lon#16665, road_id#16666, road_name#16667, cast(speed#16668 as double) AS speed#16690, timestamp#16669, vehicle_count#16670]
                                                         +- Relation [_id#16662,congestion_level#16663,lat#16664,lon#16665,road_id#16666,road_name#16667,speed#16668,timestamp#16669,vehicle_count#16670] MongoRelation(MongoRDD[990] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:08,614 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:36:08 +07)" executed successfully
2026-01-06 12:35:13,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:18 +07)" (scheduled at 2026-01-06 12:35:13.157382+07:00)
2026-01-06 12:35:13,160 - INFO -  Training Spark model...
2026-01-06 12:35:13,404 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_change#17242, vehicle_count_lag#17260, vehicle_count_change#17279, avg(speed#17100) windowspecdefinition(road_id#17086, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17300]
+- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_change#17242, vehicle_count_lag#17260, CASE WHEN isnotnull(vehicle_count_lag#17260) THEN (vehicle_count#17110 - vehicle_count_lag#17260) ELSE 0.0 END AS vehicle_count_change#17279]
   +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_change#17242, vehicle_count_lag#17260]
      +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_change#17242, vehicle_count_lag#17260, vehicle_count_lag#17260]
         +- Window [lag(vehicle_count#17110, -1, null) windowspecdefinition(road_id#17086, timestamp#17089 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#17260], [road_id#17086], [timestamp#17089 ASC NULLS FIRST]
            +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_change#17242]
               +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, CASE WHEN isnotnull(speed_lag#17225) THEN (speed#17100 - speed_lag#17225) ELSE 0.0 END AS speed_change#17242]
                  +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225]
                     +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209, speed_lag#17225, speed_lag#17225]
                        +- Window [lag(speed#17100, -1, null) windowspecdefinition(road_id#17086, timestamp#17089 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#17225], [road_id#17086], [timestamp#17089 ASC NULLS FIRST]
                           +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, hour_cos#17209]
                              +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, hour_sin#17194, COS((0.2617993877991494 * cast(hour#17144 as double))) AS hour_cos#17209]
                                 +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, is_weekend#17180, SIN((0.2617993877991494 * cast(hour#17144 as double))) AS hour_sin#17194]
                                    +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, day_of_week#17167, CASE WHEN day_of_week#17167 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#17180]
                                       +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, is_peak#17155, dayofweek(cast(timestamp#17089 as date)) AS day_of_week#17167]
                                          +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour#17144, CASE WHEN hour#17144 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#17155]
                                             +- Project [_id#17082, congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110, hour(timestamp#17089, Some(Asia/Bangkok)) AS hour#17144]
                                                +- Project [_id#17082, cast(congestion_level#17083 as double) AS congestion_level#17120, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, vehicle_count#17110]
                                                   +- Project [_id#17082, congestion_level#17083, lat#17084, lon#17085, road_id#17086, road_name#17087, speed#17100, timestamp#17089, cast(vehicle_count#17090 as double) AS vehicle_count#17110]
                                                      +- Project [_id#17082, congestion_level#17083, lat#17084, lon#17085, road_id#17086, road_name#17087, cast(speed#17088 as double) AS speed#17100, timestamp#17089, vehicle_count#17090]
                                                         +- Relation [_id#17082,congestion_level#17083,lat#17084,lon#17085,road_id#17086,road_name#17087,speed#17088,timestamp#17089,vehicle_count#17090] MongoRelation(MongoRDD[1014] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:13,404 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:18 +07)" executed successfully
2026-01-06 12:35:18,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:23 +07)" (scheduled at 2026-01-06 12:35:18.157382+07:00)
2026-01-06 12:35:18,158 - INFO -  Training Spark model...
2026-01-06 12:35:18,416 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_change#17461, vehicle_count_lag#17479, vehicle_count_change#17498, avg(speed#17319) windowspecdefinition(road_id#17305, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17519]
+- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_change#17461, vehicle_count_lag#17479, CASE WHEN isnotnull(vehicle_count_lag#17479) THEN (vehicle_count#17329 - vehicle_count_lag#17479) ELSE 0.0 END AS vehicle_count_change#17498]
   +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_change#17461, vehicle_count_lag#17479]
      +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_change#17461, vehicle_count_lag#17479, vehicle_count_lag#17479]
         +- Window [lag(vehicle_count#17329, -1, null) windowspecdefinition(road_id#17305, timestamp#17308 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#17479], [road_id#17305], [timestamp#17308 ASC NULLS FIRST]
            +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_change#17461]
               +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, CASE WHEN isnotnull(speed_lag#17444) THEN (speed#17319 - speed_lag#17444) ELSE 0.0 END AS speed_change#17461]
                  +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444]
                     +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428, speed_lag#17444, speed_lag#17444]
                        +- Window [lag(speed#17319, -1, null) windowspecdefinition(road_id#17305, timestamp#17308 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#17444], [road_id#17305], [timestamp#17308 ASC NULLS FIRST]
                           +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, hour_cos#17428]
                              +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, hour_sin#17413, COS((0.2617993877991494 * cast(hour#17363 as double))) AS hour_cos#17428]
                                 +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, is_weekend#17399, SIN((0.2617993877991494 * cast(hour#17363 as double))) AS hour_sin#17413]
                                    +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, day_of_week#17386, CASE WHEN day_of_week#17386 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#17399]
                                       +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, is_peak#17374, dayofweek(cast(timestamp#17308 as date)) AS day_of_week#17386]
                                          +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour#17363, CASE WHEN hour#17363 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#17374]
                                             +- Project [_id#17301, congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329, hour(timestamp#17308, Some(Asia/Bangkok)) AS hour#17363]
                                                +- Project [_id#17301, cast(congestion_level#17302 as double) AS congestion_level#17339, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, vehicle_count#17329]
                                                   +- Project [_id#17301, congestion_level#17302, lat#17303, lon#17304, road_id#17305, road_name#17306, speed#17319, timestamp#17308, cast(vehicle_count#17309 as double) AS vehicle_count#17329]
                                                      +- Project [_id#17301, congestion_level#17302, lat#17303, lon#17304, road_id#17305, road_name#17306, cast(speed#17307 as double) AS speed#17319, timestamp#17308, vehicle_count#17309]
                                                         +- Relation [_id#17301,congestion_level#17302,lat#17303,lon#17304,road_id#17305,road_name#17306,speed#17307,timestamp#17308,vehicle_count#17309] MongoRelation(MongoRDD[1027] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:18,417 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:23 +07)" executed successfully
2026-01-06 12:35:23,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:28 +07)" (scheduled at 2026-01-06 12:35:23.157382+07:00)
2026-01-06 12:35:23,160 - INFO -  Training Spark model...
2026-01-06 12:35:23,457 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_change#17680, vehicle_count_lag#17698, vehicle_count_change#17717, avg(speed#17538) windowspecdefinition(road_id#17524, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17738]
+- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_change#17680, vehicle_count_lag#17698, CASE WHEN isnotnull(vehicle_count_lag#17698) THEN (vehicle_count#17548 - vehicle_count_lag#17698) ELSE 0.0 END AS vehicle_count_change#17717]
   +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_change#17680, vehicle_count_lag#17698]
      +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_change#17680, vehicle_count_lag#17698, vehicle_count_lag#17698]
         +- Window [lag(vehicle_count#17548, -1, null) windowspecdefinition(road_id#17524, timestamp#17527 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#17698], [road_id#17524], [timestamp#17527 ASC NULLS FIRST]
            +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_change#17680]
               +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, CASE WHEN isnotnull(speed_lag#17663) THEN (speed#17538 - speed_lag#17663) ELSE 0.0 END AS speed_change#17680]
                  +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663]
                     +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647, speed_lag#17663, speed_lag#17663]
                        +- Window [lag(speed#17538, -1, null) windowspecdefinition(road_id#17524, timestamp#17527 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#17663], [road_id#17524], [timestamp#17527 ASC NULLS FIRST]
                           +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, hour_cos#17647]
                              +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, hour_sin#17632, COS((0.2617993877991494 * cast(hour#17582 as double))) AS hour_cos#17647]
                                 +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, is_weekend#17618, SIN((0.2617993877991494 * cast(hour#17582 as double))) AS hour_sin#17632]
                                    +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, day_of_week#17605, CASE WHEN day_of_week#17605 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#17618]
                                       +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, is_peak#17593, dayofweek(cast(timestamp#17527 as date)) AS day_of_week#17605]
                                          +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour#17582, CASE WHEN hour#17582 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#17593]
                                             +- Project [_id#17520, congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548, hour(timestamp#17527, Some(Asia/Bangkok)) AS hour#17582]
                                                +- Project [_id#17520, cast(congestion_level#17521 as double) AS congestion_level#17558, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, vehicle_count#17548]
                                                   +- Project [_id#17520, congestion_level#17521, lat#17522, lon#17523, road_id#17524, road_name#17525, speed#17538, timestamp#17527, cast(vehicle_count#17528 as double) AS vehicle_count#17548]
                                                      +- Project [_id#17520, congestion_level#17521, lat#17522, lon#17523, road_id#17524, road_name#17525, cast(speed#17526 as double) AS speed#17538, timestamp#17527, vehicle_count#17528]
                                                         +- Relation [_id#17520,congestion_level#17521,lat#17522,lon#17523,road_id#17524,road_name#17525,speed#17526,timestamp#17527,vehicle_count#17528] MongoRelation(MongoRDD[1040] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:23,457 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:28 +07)" executed successfully
2026-01-06 12:35:28,166 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:33 +07)" (scheduled at 2026-01-06 12:35:28.157382+07:00)
2026-01-06 12:35:28,166 - INFO -  Training Spark model...
2026-01-06 12:35:28,426 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_change#17899, vehicle_count_lag#17917, vehicle_count_change#17936, avg(speed#17757) windowspecdefinition(road_id#17743, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#17957]
+- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_change#17899, vehicle_count_lag#17917, CASE WHEN isnotnull(vehicle_count_lag#17917) THEN (vehicle_count#17767 - vehicle_count_lag#17917) ELSE 0.0 END AS vehicle_count_change#17936]
   +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_change#17899, vehicle_count_lag#17917]
      +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_change#17899, vehicle_count_lag#17917, vehicle_count_lag#17917]
         +- Window [lag(vehicle_count#17767, -1, null) windowspecdefinition(road_id#17743, timestamp#17746 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#17917], [road_id#17743], [timestamp#17746 ASC NULLS FIRST]
            +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_change#17899]
               +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, CASE WHEN isnotnull(speed_lag#17882) THEN (speed#17757 - speed_lag#17882) ELSE 0.0 END AS speed_change#17899]
                  +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882]
                     +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866, speed_lag#17882, speed_lag#17882]
                        +- Window [lag(speed#17757, -1, null) windowspecdefinition(road_id#17743, timestamp#17746 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#17882], [road_id#17743], [timestamp#17746 ASC NULLS FIRST]
                           +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, hour_cos#17866]
                              +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, hour_sin#17851, COS((0.2617993877991494 * cast(hour#17801 as double))) AS hour_cos#17866]
                                 +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, is_weekend#17837, SIN((0.2617993877991494 * cast(hour#17801 as double))) AS hour_sin#17851]
                                    +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, day_of_week#17824, CASE WHEN day_of_week#17824 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#17837]
                                       +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, is_peak#17812, dayofweek(cast(timestamp#17746 as date)) AS day_of_week#17824]
                                          +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour#17801, CASE WHEN hour#17801 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#17812]
                                             +- Project [_id#17739, congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767, hour(timestamp#17746, Some(Asia/Bangkok)) AS hour#17801]
                                                +- Project [_id#17739, cast(congestion_level#17740 as double) AS congestion_level#17777, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, vehicle_count#17767]
                                                   +- Project [_id#17739, congestion_level#17740, lat#17741, lon#17742, road_id#17743, road_name#17744, speed#17757, timestamp#17746, cast(vehicle_count#17747 as double) AS vehicle_count#17767]
                                                      +- Project [_id#17739, congestion_level#17740, lat#17741, lon#17742, road_id#17743, road_name#17744, cast(speed#17745 as double) AS speed#17757, timestamp#17746, vehicle_count#17747]
                                                         +- Relation [_id#17739,congestion_level#17740,lat#17741,lon#17742,road_id#17743,road_name#17744,speed#17745,timestamp#17746,vehicle_count#17747] MongoRelation(MongoRDD[1053] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:28,426 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:33 +07)" executed successfully
2026-01-06 12:35:33,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:38 +07)" (scheduled at 2026-01-06 12:35:33.157382+07:00)
2026-01-06 12:35:33,164 - INFO -  Training Spark model...
2026-01-06 12:35:33,436 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_change#18118, vehicle_count_lag#18136, vehicle_count_change#18155, avg(speed#17976) windowspecdefinition(road_id#17962, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#18176]
+- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_change#18118, vehicle_count_lag#18136, CASE WHEN isnotnull(vehicle_count_lag#18136) THEN (vehicle_count#17986 - vehicle_count_lag#18136) ELSE 0.0 END AS vehicle_count_change#18155]
   +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_change#18118, vehicle_count_lag#18136]
      +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_change#18118, vehicle_count_lag#18136, vehicle_count_lag#18136]
         +- Window [lag(vehicle_count#17986, -1, null) windowspecdefinition(road_id#17962, timestamp#17965 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#18136], [road_id#17962], [timestamp#17965 ASC NULLS FIRST]
            +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_change#18118]
               +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, CASE WHEN isnotnull(speed_lag#18101) THEN (speed#17976 - speed_lag#18101) ELSE 0.0 END AS speed_change#18118]
                  +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101]
                     +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085, speed_lag#18101, speed_lag#18101]
                        +- Window [lag(speed#17976, -1, null) windowspecdefinition(road_id#17962, timestamp#17965 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#18101], [road_id#17962], [timestamp#17965 ASC NULLS FIRST]
                           +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, hour_cos#18085]
                              +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, hour_sin#18070, COS((0.2617993877991494 * cast(hour#18020 as double))) AS hour_cos#18085]
                                 +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, is_weekend#18056, SIN((0.2617993877991494 * cast(hour#18020 as double))) AS hour_sin#18070]
                                    +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, day_of_week#18043, CASE WHEN day_of_week#18043 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#18056]
                                       +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, is_peak#18031, dayofweek(cast(timestamp#17965 as date)) AS day_of_week#18043]
                                          +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour#18020, CASE WHEN hour#18020 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#18031]
                                             +- Project [_id#17958, congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986, hour(timestamp#17965, Some(Asia/Bangkok)) AS hour#18020]
                                                +- Project [_id#17958, cast(congestion_level#17959 as double) AS congestion_level#17996, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, vehicle_count#17986]
                                                   +- Project [_id#17958, congestion_level#17959, lat#17960, lon#17961, road_id#17962, road_name#17963, speed#17976, timestamp#17965, cast(vehicle_count#17966 as double) AS vehicle_count#17986]
                                                      +- Project [_id#17958, congestion_level#17959, lat#17960, lon#17961, road_id#17962, road_name#17963, cast(speed#17964 as double) AS speed#17976, timestamp#17965, vehicle_count#17966]
                                                         +- Relation [_id#17958,congestion_level#17959,lat#17960,lon#17961,road_id#17962,road_name#17963,speed#17964,timestamp#17965,vehicle_count#17966] MongoRelation(MongoRDD[1066] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:33,437 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:38 +07)" executed successfully
2026-01-06 12:35:38,170 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:43 +07)" (scheduled at 2026-01-06 12:35:38.157382+07:00)
2026-01-06 12:35:38,170 - INFO -  Training Spark model...
2026-01-06 12:35:38,449 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_change#18337, vehicle_count_lag#18355, vehicle_count_change#18374, avg(speed#18195) windowspecdefinition(road_id#18181, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#18395]
+- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_change#18337, vehicle_count_lag#18355, CASE WHEN isnotnull(vehicle_count_lag#18355) THEN (vehicle_count#18205 - vehicle_count_lag#18355) ELSE 0.0 END AS vehicle_count_change#18374]
   +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_change#18337, vehicle_count_lag#18355]
      +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_change#18337, vehicle_count_lag#18355, vehicle_count_lag#18355]
         +- Window [lag(vehicle_count#18205, -1, null) windowspecdefinition(road_id#18181, timestamp#18184 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#18355], [road_id#18181], [timestamp#18184 ASC NULLS FIRST]
            +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_change#18337]
               +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, CASE WHEN isnotnull(speed_lag#18320) THEN (speed#18195 - speed_lag#18320) ELSE 0.0 END AS speed_change#18337]
                  +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320]
                     +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304, speed_lag#18320, speed_lag#18320]
                        +- Window [lag(speed#18195, -1, null) windowspecdefinition(road_id#18181, timestamp#18184 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#18320], [road_id#18181], [timestamp#18184 ASC NULLS FIRST]
                           +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, hour_cos#18304]
                              +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, hour_sin#18289, COS((0.2617993877991494 * cast(hour#18239 as double))) AS hour_cos#18304]
                                 +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, is_weekend#18275, SIN((0.2617993877991494 * cast(hour#18239 as double))) AS hour_sin#18289]
                                    +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, day_of_week#18262, CASE WHEN day_of_week#18262 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#18275]
                                       +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, is_peak#18250, dayofweek(cast(timestamp#18184 as date)) AS day_of_week#18262]
                                          +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour#18239, CASE WHEN hour#18239 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#18250]
                                             +- Project [_id#18177, congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205, hour(timestamp#18184, Some(Asia/Bangkok)) AS hour#18239]
                                                +- Project [_id#18177, cast(congestion_level#18178 as double) AS congestion_level#18215, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, vehicle_count#18205]
                                                   +- Project [_id#18177, congestion_level#18178, lat#18179, lon#18180, road_id#18181, road_name#18182, speed#18195, timestamp#18184, cast(vehicle_count#18185 as double) AS vehicle_count#18205]
                                                      +- Project [_id#18177, congestion_level#18178, lat#18179, lon#18180, road_id#18181, road_name#18182, cast(speed#18183 as double) AS speed#18195, timestamp#18184, vehicle_count#18185]
                                                         +- Relation [_id#18177,congestion_level#18178,lat#18179,lon#18180,road_id#18181,road_name#18182,speed#18183,timestamp#18184,vehicle_count#18185] MongoRelation(MongoRDD[1079] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:38,449 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:43 +07)" executed successfully
2026-01-06 12:35:43,157 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:48 +07)" (scheduled at 2026-01-06 12:35:43.157382+07:00)
2026-01-06 12:35:43,158 - INFO -  Training Spark model...
2026-01-06 12:35:43,477 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_change#18556, vehicle_count_lag#18574, vehicle_count_change#18593, avg(speed#18414) windowspecdefinition(road_id#18400, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#18614]
+- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_change#18556, vehicle_count_lag#18574, CASE WHEN isnotnull(vehicle_count_lag#18574) THEN (vehicle_count#18424 - vehicle_count_lag#18574) ELSE 0.0 END AS vehicle_count_change#18593]
   +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_change#18556, vehicle_count_lag#18574]
      +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_change#18556, vehicle_count_lag#18574, vehicle_count_lag#18574]
         +- Window [lag(vehicle_count#18424, -1, null) windowspecdefinition(road_id#18400, timestamp#18403 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#18574], [road_id#18400], [timestamp#18403 ASC NULLS FIRST]
            +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_change#18556]
               +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, CASE WHEN isnotnull(speed_lag#18539) THEN (speed#18414 - speed_lag#18539) ELSE 0.0 END AS speed_change#18556]
                  +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539]
                     +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523, speed_lag#18539, speed_lag#18539]
                        +- Window [lag(speed#18414, -1, null) windowspecdefinition(road_id#18400, timestamp#18403 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#18539], [road_id#18400], [timestamp#18403 ASC NULLS FIRST]
                           +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, hour_cos#18523]
                              +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, hour_sin#18508, COS((0.2617993877991494 * cast(hour#18458 as double))) AS hour_cos#18523]
                                 +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, is_weekend#18494, SIN((0.2617993877991494 * cast(hour#18458 as double))) AS hour_sin#18508]
                                    +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, day_of_week#18481, CASE WHEN day_of_week#18481 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#18494]
                                       +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, is_peak#18469, dayofweek(cast(timestamp#18403 as date)) AS day_of_week#18481]
                                          +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour#18458, CASE WHEN hour#18458 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#18469]
                                             +- Project [_id#18396, congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424, hour(timestamp#18403, Some(Asia/Bangkok)) AS hour#18458]
                                                +- Project [_id#18396, cast(congestion_level#18397 as double) AS congestion_level#18434, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, vehicle_count#18424]
                                                   +- Project [_id#18396, congestion_level#18397, lat#18398, lon#18399, road_id#18400, road_name#18401, speed#18414, timestamp#18403, cast(vehicle_count#18404 as double) AS vehicle_count#18424]
                                                      +- Project [_id#18396, congestion_level#18397, lat#18398, lon#18399, road_id#18400, road_name#18401, cast(speed#18402 as double) AS speed#18414, timestamp#18403, vehicle_count#18404]
                                                         +- Relation [_id#18396,congestion_level#18397,lat#18398,lon#18399,road_id#18400,road_name#18401,speed#18402,timestamp#18403,vehicle_count#18404] MongoRelation(MongoRDD[1092] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:43,477 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:48 +07)" executed successfully
2026-01-06 12:35:48,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:53 +07)" (scheduled at 2026-01-06 12:35:48.157382+07:00)
2026-01-06 12:35:48,164 - INFO -  Training Spark model...
2026-01-06 12:35:48,422 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_change#18775, vehicle_count_lag#18793, vehicle_count_change#18812, avg(speed#18633) windowspecdefinition(road_id#18619, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#18833]
+- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_change#18775, vehicle_count_lag#18793, CASE WHEN isnotnull(vehicle_count_lag#18793) THEN (vehicle_count#18643 - vehicle_count_lag#18793) ELSE 0.0 END AS vehicle_count_change#18812]
   +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_change#18775, vehicle_count_lag#18793]
      +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_change#18775, vehicle_count_lag#18793, vehicle_count_lag#18793]
         +- Window [lag(vehicle_count#18643, -1, null) windowspecdefinition(road_id#18619, timestamp#18622 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#18793], [road_id#18619], [timestamp#18622 ASC NULLS FIRST]
            +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_change#18775]
               +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, CASE WHEN isnotnull(speed_lag#18758) THEN (speed#18633 - speed_lag#18758) ELSE 0.0 END AS speed_change#18775]
                  +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758]
                     +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742, speed_lag#18758, speed_lag#18758]
                        +- Window [lag(speed#18633, -1, null) windowspecdefinition(road_id#18619, timestamp#18622 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#18758], [road_id#18619], [timestamp#18622 ASC NULLS FIRST]
                           +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, hour_cos#18742]
                              +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, hour_sin#18727, COS((0.2617993877991494 * cast(hour#18677 as double))) AS hour_cos#18742]
                                 +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, is_weekend#18713, SIN((0.2617993877991494 * cast(hour#18677 as double))) AS hour_sin#18727]
                                    +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, day_of_week#18700, CASE WHEN day_of_week#18700 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#18713]
                                       +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, is_peak#18688, dayofweek(cast(timestamp#18622 as date)) AS day_of_week#18700]
                                          +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour#18677, CASE WHEN hour#18677 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#18688]
                                             +- Project [_id#18615, congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643, hour(timestamp#18622, Some(Asia/Bangkok)) AS hour#18677]
                                                +- Project [_id#18615, cast(congestion_level#18616 as double) AS congestion_level#18653, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, vehicle_count#18643]
                                                   +- Project [_id#18615, congestion_level#18616, lat#18617, lon#18618, road_id#18619, road_name#18620, speed#18633, timestamp#18622, cast(vehicle_count#18623 as double) AS vehicle_count#18643]
                                                      +- Project [_id#18615, congestion_level#18616, lat#18617, lon#18618, road_id#18619, road_name#18620, cast(speed#18621 as double) AS speed#18633, timestamp#18622, vehicle_count#18623]
                                                         +- Relation [_id#18615,congestion_level#18616,lat#18617,lon#18618,road_id#18619,road_name#18620,speed#18621,timestamp#18622,vehicle_count#18623] MongoRelation(MongoRDD[1105] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:48,423 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:53 +07)" executed successfully
2026-01-06 12:35:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:58 +07)" (scheduled at 2026-01-06 12:35:53.157382+07:00)
2026-01-06 12:35:53,159 - INFO -  Training Spark model...
2026-01-06 12:35:53,432 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_change#18994, vehicle_count_lag#19012, vehicle_count_change#19031, avg(speed#18852) windowspecdefinition(road_id#18838, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#19052]
+- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_change#18994, vehicle_count_lag#19012, CASE WHEN isnotnull(vehicle_count_lag#19012) THEN (vehicle_count#18862 - vehicle_count_lag#19012) ELSE 0.0 END AS vehicle_count_change#19031]
   +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_change#18994, vehicle_count_lag#19012]
      +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_change#18994, vehicle_count_lag#19012, vehicle_count_lag#19012]
         +- Window [lag(vehicle_count#18862, -1, null) windowspecdefinition(road_id#18838, timestamp#18841 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#19012], [road_id#18838], [timestamp#18841 ASC NULLS FIRST]
            +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_change#18994]
               +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, CASE WHEN isnotnull(speed_lag#18977) THEN (speed#18852 - speed_lag#18977) ELSE 0.0 END AS speed_change#18994]
                  +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977]
                     +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961, speed_lag#18977, speed_lag#18977]
                        +- Window [lag(speed#18852, -1, null) windowspecdefinition(road_id#18838, timestamp#18841 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#18977], [road_id#18838], [timestamp#18841 ASC NULLS FIRST]
                           +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, hour_cos#18961]
                              +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, hour_sin#18946, COS((0.2617993877991494 * cast(hour#18896 as double))) AS hour_cos#18961]
                                 +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, is_weekend#18932, SIN((0.2617993877991494 * cast(hour#18896 as double))) AS hour_sin#18946]
                                    +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, day_of_week#18919, CASE WHEN day_of_week#18919 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#18932]
                                       +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, is_peak#18907, dayofweek(cast(timestamp#18841 as date)) AS day_of_week#18919]
                                          +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour#18896, CASE WHEN hour#18896 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#18907]
                                             +- Project [_id#18834, congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862, hour(timestamp#18841, Some(Asia/Bangkok)) AS hour#18896]
                                                +- Project [_id#18834, cast(congestion_level#18835 as double) AS congestion_level#18872, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, vehicle_count#18862]
                                                   +- Project [_id#18834, congestion_level#18835, lat#18836, lon#18837, road_id#18838, road_name#18839, speed#18852, timestamp#18841, cast(vehicle_count#18842 as double) AS vehicle_count#18862]
                                                      +- Project [_id#18834, congestion_level#18835, lat#18836, lon#18837, road_id#18838, road_name#18839, cast(speed#18840 as double) AS speed#18852, timestamp#18841, vehicle_count#18842]
                                                         +- Relation [_id#18834,congestion_level#18835,lat#18836,lon#18837,road_id#18838,road_name#18839,speed#18840,timestamp#18841,vehicle_count#18842] MongoRelation(MongoRDD[1118] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:53,433 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:35:58 +07)" executed successfully
2026-01-06 12:35:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:03 +07)" (scheduled at 2026-01-06 12:35:58.157382+07:00)
2026-01-06 12:35:58,158 - INFO -  Training Spark model...
2026-01-06 12:35:58,421 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_change#19213, vehicle_count_lag#19231, vehicle_count_change#19250, avg(speed#19071) windowspecdefinition(road_id#19057, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#19271]
+- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_change#19213, vehicle_count_lag#19231, CASE WHEN isnotnull(vehicle_count_lag#19231) THEN (vehicle_count#19081 - vehicle_count_lag#19231) ELSE 0.0 END AS vehicle_count_change#19250]
   +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_change#19213, vehicle_count_lag#19231]
      +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_change#19213, vehicle_count_lag#19231, vehicle_count_lag#19231]
         +- Window [lag(vehicle_count#19081, -1, null) windowspecdefinition(road_id#19057, timestamp#19060 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#19231], [road_id#19057], [timestamp#19060 ASC NULLS FIRST]
            +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_change#19213]
               +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, CASE WHEN isnotnull(speed_lag#19196) THEN (speed#19071 - speed_lag#19196) ELSE 0.0 END AS speed_change#19213]
                  +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196]
                     +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180, speed_lag#19196, speed_lag#19196]
                        +- Window [lag(speed#19071, -1, null) windowspecdefinition(road_id#19057, timestamp#19060 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#19196], [road_id#19057], [timestamp#19060 ASC NULLS FIRST]
                           +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, hour_cos#19180]
                              +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, hour_sin#19165, COS((0.2617993877991494 * cast(hour#19115 as double))) AS hour_cos#19180]
                                 +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, is_weekend#19151, SIN((0.2617993877991494 * cast(hour#19115 as double))) AS hour_sin#19165]
                                    +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, day_of_week#19138, CASE WHEN day_of_week#19138 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#19151]
                                       +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, is_peak#19126, dayofweek(cast(timestamp#19060 as date)) AS day_of_week#19138]
                                          +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour#19115, CASE WHEN hour#19115 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#19126]
                                             +- Project [_id#19053, congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081, hour(timestamp#19060, Some(Asia/Bangkok)) AS hour#19115]
                                                +- Project [_id#19053, cast(congestion_level#19054 as double) AS congestion_level#19091, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, vehicle_count#19081]
                                                   +- Project [_id#19053, congestion_level#19054, lat#19055, lon#19056, road_id#19057, road_name#19058, speed#19071, timestamp#19060, cast(vehicle_count#19061 as double) AS vehicle_count#19081]
                                                      +- Project [_id#19053, congestion_level#19054, lat#19055, lon#19056, road_id#19057, road_name#19058, cast(speed#19059 as double) AS speed#19071, timestamp#19060, vehicle_count#19061]
                                                         +- Relation [_id#19053,congestion_level#19054,lat#19055,lon#19056,road_id#19057,road_name#19058,speed#19059,timestamp#19060,vehicle_count#19061] MongoRelation(MongoRDD[1131] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:35:58,421 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:03 +07)" executed successfully
2026-01-06 12:36:03,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:08 +07)" (scheduled at 2026-01-06 12:36:03.157382+07:00)
2026-01-06 12:36:03,159 - INFO -  Training Spark model...
2026-01-06 12:36:03,394 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_change#19432, vehicle_count_lag#19450, vehicle_count_change#19469, avg(speed#19290) windowspecdefinition(road_id#19276, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#19490]
+- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_change#19432, vehicle_count_lag#19450, CASE WHEN isnotnull(vehicle_count_lag#19450) THEN (vehicle_count#19300 - vehicle_count_lag#19450) ELSE 0.0 END AS vehicle_count_change#19469]
   +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_change#19432, vehicle_count_lag#19450]
      +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_change#19432, vehicle_count_lag#19450, vehicle_count_lag#19450]
         +- Window [lag(vehicle_count#19300, -1, null) windowspecdefinition(road_id#19276, timestamp#19279 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#19450], [road_id#19276], [timestamp#19279 ASC NULLS FIRST]
            +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_change#19432]
               +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, CASE WHEN isnotnull(speed_lag#19415) THEN (speed#19290 - speed_lag#19415) ELSE 0.0 END AS speed_change#19432]
                  +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415]
                     +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399, speed_lag#19415, speed_lag#19415]
                        +- Window [lag(speed#19290, -1, null) windowspecdefinition(road_id#19276, timestamp#19279 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#19415], [road_id#19276], [timestamp#19279 ASC NULLS FIRST]
                           +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, hour_cos#19399]
                              +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, hour_sin#19384, COS((0.2617993877991494 * cast(hour#19334 as double))) AS hour_cos#19399]
                                 +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, is_weekend#19370, SIN((0.2617993877991494 * cast(hour#19334 as double))) AS hour_sin#19384]
                                    +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, day_of_week#19357, CASE WHEN day_of_week#19357 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#19370]
                                       +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, is_peak#19345, dayofweek(cast(timestamp#19279 as date)) AS day_of_week#19357]
                                          +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour#19334, CASE WHEN hour#19334 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#19345]
                                             +- Project [_id#19272, congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300, hour(timestamp#19279, Some(Asia/Bangkok)) AS hour#19334]
                                                +- Project [_id#19272, cast(congestion_level#19273 as double) AS congestion_level#19310, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, vehicle_count#19300]
                                                   +- Project [_id#19272, congestion_level#19273, lat#19274, lon#19275, road_id#19276, road_name#19277, speed#19290, timestamp#19279, cast(vehicle_count#19280 as double) AS vehicle_count#19300]
                                                      +- Project [_id#19272, congestion_level#19273, lat#19274, lon#19275, road_id#19276, road_name#19277, cast(speed#19278 as double) AS speed#19290, timestamp#19279, vehicle_count#19280]
                                                         +- Relation [_id#19272,congestion_level#19273,lat#19274,lon#19275,road_id#19276,road_name#19277,speed#19278,timestamp#19279,vehicle_count#19280] MongoRelation(MongoRDD[1144] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:03,394 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:08 +07)" executed successfully
2026-01-06 12:36:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:13 +07)" (scheduled at 2026-01-06 12:36:08.157382+07:00)
2026-01-06 12:36:08,158 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:37:08 +07)" (scheduled at 2026-01-06 12:36:08.157779+07:00)
2026-01-06 12:36:08,158 - INFO -  Training Spark model...
2026-01-06 12:36:08,158 - INFO -  Training Spark model...
2026-01-06 12:36:08,697 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_change#19794, vehicle_count_lag#19812, vehicle_count_change#19832, avg(speed#19528) windowspecdefinition(road_id#19513, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#19906]
+- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_change#19794, vehicle_count_lag#19812, CASE WHEN isnotnull(vehicle_count_lag#19812) THEN (vehicle_count#19548 - vehicle_count_lag#19812) ELSE 0.0 END AS vehicle_count_change#19832]
   +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_change#19794, vehicle_count_lag#19812]
      +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_change#19794, vehicle_count_lag#19812, vehicle_count_lag#19812]
         +- Window [lag(vehicle_count#19548, -1, null) windowspecdefinition(road_id#19513, timestamp#19516 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#19812], [road_id#19513], [timestamp#19516 ASC NULLS FIRST]
            +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_change#19794]
               +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, CASE WHEN isnotnull(speed_lag#19762) THEN (speed#19528 - speed_lag#19762) ELSE 0.0 END AS speed_change#19794]
                  +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762]
                     +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731, speed_lag#19762, speed_lag#19762]
                        +- Window [lag(speed#19528, -1, null) windowspecdefinition(road_id#19513, timestamp#19516 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#19762], [road_id#19513], [timestamp#19516 ASC NULLS FIRST]
                           +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, hour_cos#19731]
                              +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, hour_sin#19715, COS((0.2617993877991494 * cast(hour#19626 as double))) AS hour_cos#19731]
                                 +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, is_weekend#19687, SIN((0.2617993877991494 * cast(hour#19626 as double))) AS hour_sin#19715]
                                    +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, day_of_week#19661, CASE WHEN day_of_week#19661 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#19687]
                                       +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, is_peak#19638, dayofweek(cast(timestamp#19516 as date)) AS day_of_week#19661]
                                          +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour#19626, CASE WHEN hour#19626 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#19638]
                                             +- Project [_id#19509, congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548, hour(timestamp#19516, Some(Asia/Bangkok)) AS hour#19626]
                                                +- Project [_id#19509, cast(congestion_level#19510 as double) AS congestion_level#19577, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, vehicle_count#19548]
                                                   +- Project [_id#19509, congestion_level#19510, lat#19511, lon#19512, road_id#19513, road_name#19514, speed#19528, timestamp#19516, cast(vehicle_count#19517 as double) AS vehicle_count#19548]
                                                      +- Project [_id#19509, congestion_level#19510, lat#19511, lon#19512, road_id#19513, road_name#19514, cast(speed#19515 as double) AS speed#19528, timestamp#19516, vehicle_count#19517]
                                                         +- Relation [_id#19509,congestion_level#19510,lat#19511,lon#19512,road_id#19513,road_name#19514,speed#19515,timestamp#19516,vehicle_count#19517] MongoRelation(MongoRDD[1158] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:08,697 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:13 +07)" executed successfully
2026-01-06 12:36:08,705 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_change#19868, vehicle_count_lag#19886, vehicle_count_change#19907, avg(speed#19527) windowspecdefinition(road_id#19495, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#19928]
+- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_change#19868, vehicle_count_lag#19886, CASE WHEN isnotnull(vehicle_count_lag#19886) THEN (vehicle_count#19547 - vehicle_count_lag#19886) ELSE 0.0 END AS vehicle_count_change#19907]
   +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_change#19868, vehicle_count_lag#19886]
      +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_change#19868, vehicle_count_lag#19886, vehicle_count_lag#19886]
         +- Window [lag(vehicle_count#19547, -1, null) windowspecdefinition(road_id#19495, timestamp#19498 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#19886], [road_id#19495], [timestamp#19498 ASC NULLS FIRST]
            +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_change#19868]
               +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, CASE WHEN isnotnull(speed_lag#19831) THEN (speed#19527 - speed_lag#19831) ELSE 0.0 END AS speed_change#19868]
                  +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831]
                     +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761, speed_lag#19831, speed_lag#19831]
                        +- Window [lag(speed#19527, -1, null) windowspecdefinition(road_id#19495, timestamp#19498 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#19831], [road_id#19495], [timestamp#19498 ASC NULLS FIRST]
                           +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, hour_cos#19761]
                              +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, hour_sin#19730, COS((0.2617993877991494 * cast(hour#19615 as double))) AS hour_cos#19761]
                                 +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, is_weekend#19701, SIN((0.2617993877991494 * cast(hour#19615 as double))) AS hour_sin#19730]
                                    +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, day_of_week#19674, CASE WHEN day_of_week#19674 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#19701]
                                       +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, is_peak#19637, dayofweek(cast(timestamp#19498 as date)) AS day_of_week#19674]
                                          +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour#19615, CASE WHEN hour#19615 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#19637]
                                             +- Project [_id#19491, congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547, hour(timestamp#19498, Some(Asia/Bangkok)) AS hour#19615]
                                                +- Project [_id#19491, cast(congestion_level#19492 as double) AS congestion_level#19567, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, vehicle_count#19547]
                                                   +- Project [_id#19491, congestion_level#19492, lat#19493, lon#19494, road_id#19495, road_name#19496, speed#19527, timestamp#19498, cast(vehicle_count#19499 as double) AS vehicle_count#19547]
                                                      +- Project [_id#19491, congestion_level#19492, lat#19493, lon#19494, road_id#19495, road_name#19496, cast(speed#19497 as double) AS speed#19527, timestamp#19498, vehicle_count#19499]
                                                         +- Relation [_id#19491,congestion_level#19492,lat#19493,lon#19494,road_id#19495,road_name#19496,speed#19497,timestamp#19498,vehicle_count#19499] MongoRelation(MongoRDD[1157] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:08,706 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:37:08 +07)" executed successfully
2026-01-06 12:36:13,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:18 +07)" (scheduled at 2026-01-06 12:36:13.157382+07:00)
2026-01-06 12:36:13,159 - INFO -  Training Spark model...
2026-01-06 12:36:13,439 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_change#20089, vehicle_count_lag#20107, vehicle_count_change#20126, avg(speed#19947) windowspecdefinition(road_id#19933, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#20147]
+- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_change#20089, vehicle_count_lag#20107, CASE WHEN isnotnull(vehicle_count_lag#20107) THEN (vehicle_count#19957 - vehicle_count_lag#20107) ELSE 0.0 END AS vehicle_count_change#20126]
   +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_change#20089, vehicle_count_lag#20107]
      +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_change#20089, vehicle_count_lag#20107, vehicle_count_lag#20107]
         +- Window [lag(vehicle_count#19957, -1, null) windowspecdefinition(road_id#19933, timestamp#19936 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#20107], [road_id#19933], [timestamp#19936 ASC NULLS FIRST]
            +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_change#20089]
               +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, CASE WHEN isnotnull(speed_lag#20072) THEN (speed#19947 - speed_lag#20072) ELSE 0.0 END AS speed_change#20089]
                  +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072]
                     +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056, speed_lag#20072, speed_lag#20072]
                        +- Window [lag(speed#19947, -1, null) windowspecdefinition(road_id#19933, timestamp#19936 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#20072], [road_id#19933], [timestamp#19936 ASC NULLS FIRST]
                           +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, hour_cos#20056]
                              +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, hour_sin#20041, COS((0.2617993877991494 * cast(hour#19991 as double))) AS hour_cos#20056]
                                 +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, is_weekend#20027, SIN((0.2617993877991494 * cast(hour#19991 as double))) AS hour_sin#20041]
                                    +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, day_of_week#20014, CASE WHEN day_of_week#20014 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#20027]
                                       +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, is_peak#20002, dayofweek(cast(timestamp#19936 as date)) AS day_of_week#20014]
                                          +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour#19991, CASE WHEN hour#19991 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#20002]
                                             +- Project [_id#19929, congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957, hour(timestamp#19936, Some(Asia/Bangkok)) AS hour#19991]
                                                +- Project [_id#19929, cast(congestion_level#19930 as double) AS congestion_level#19967, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, vehicle_count#19957]
                                                   +- Project [_id#19929, congestion_level#19930, lat#19931, lon#19932, road_id#19933, road_name#19934, speed#19947, timestamp#19936, cast(vehicle_count#19937 as double) AS vehicle_count#19957]
                                                      +- Project [_id#19929, congestion_level#19930, lat#19931, lon#19932, road_id#19933, road_name#19934, cast(speed#19935 as double) AS speed#19947, timestamp#19936, vehicle_count#19937]
                                                         +- Relation [_id#19929,congestion_level#19930,lat#19931,lon#19932,road_id#19933,road_name#19934,speed#19935,timestamp#19936,vehicle_count#19937] MongoRelation(MongoRDD[1183] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:13,439 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:18 +07)" executed successfully
2026-01-06 12:36:18,177 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:23 +07)" (scheduled at 2026-01-06 12:36:18.157382+07:00)
2026-01-06 12:36:18,177 - INFO -  Training Spark model...
2026-01-06 12:36:18,511 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_change#20308, vehicle_count_lag#20326, vehicle_count_change#20345, avg(speed#20166) windowspecdefinition(road_id#20152, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#20366]
+- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_change#20308, vehicle_count_lag#20326, CASE WHEN isnotnull(vehicle_count_lag#20326) THEN (vehicle_count#20176 - vehicle_count_lag#20326) ELSE 0.0 END AS vehicle_count_change#20345]
   +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_change#20308, vehicle_count_lag#20326]
      +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_change#20308, vehicle_count_lag#20326, vehicle_count_lag#20326]
         +- Window [lag(vehicle_count#20176, -1, null) windowspecdefinition(road_id#20152, timestamp#20155 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#20326], [road_id#20152], [timestamp#20155 ASC NULLS FIRST]
            +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_change#20308]
               +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, CASE WHEN isnotnull(speed_lag#20291) THEN (speed#20166 - speed_lag#20291) ELSE 0.0 END AS speed_change#20308]
                  +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291]
                     +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275, speed_lag#20291, speed_lag#20291]
                        +- Window [lag(speed#20166, -1, null) windowspecdefinition(road_id#20152, timestamp#20155 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#20291], [road_id#20152], [timestamp#20155 ASC NULLS FIRST]
                           +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, hour_cos#20275]
                              +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, hour_sin#20260, COS((0.2617993877991494 * cast(hour#20210 as double))) AS hour_cos#20275]
                                 +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, is_weekend#20246, SIN((0.2617993877991494 * cast(hour#20210 as double))) AS hour_sin#20260]
                                    +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, day_of_week#20233, CASE WHEN day_of_week#20233 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#20246]
                                       +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, is_peak#20221, dayofweek(cast(timestamp#20155 as date)) AS day_of_week#20233]
                                          +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour#20210, CASE WHEN hour#20210 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#20221]
                                             +- Project [_id#20148, congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176, hour(timestamp#20155, Some(Asia/Bangkok)) AS hour#20210]
                                                +- Project [_id#20148, cast(congestion_level#20149 as double) AS congestion_level#20186, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, vehicle_count#20176]
                                                   +- Project [_id#20148, congestion_level#20149, lat#20150, lon#20151, road_id#20152, road_name#20153, speed#20166, timestamp#20155, cast(vehicle_count#20156 as double) AS vehicle_count#20176]
                                                      +- Project [_id#20148, congestion_level#20149, lat#20150, lon#20151, road_id#20152, road_name#20153, cast(speed#20154 as double) AS speed#20166, timestamp#20155, vehicle_count#20156]
                                                         +- Relation [_id#20148,congestion_level#20149,lat#20150,lon#20151,road_id#20152,road_name#20153,speed#20154,timestamp#20155,vehicle_count#20156] MongoRelation(MongoRDD[1196] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:18,511 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:23 +07)" executed successfully
2026-01-06 12:36:23,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:28 +07)" (scheduled at 2026-01-06 12:36:23.157382+07:00)
2026-01-06 12:36:23,158 - INFO -  Training Spark model...
2026-01-06 12:36:23,447 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_change#20527, vehicle_count_lag#20545, vehicle_count_change#20564, avg(speed#20385) windowspecdefinition(road_id#20371, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#20585]
+- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_change#20527, vehicle_count_lag#20545, CASE WHEN isnotnull(vehicle_count_lag#20545) THEN (vehicle_count#20395 - vehicle_count_lag#20545) ELSE 0.0 END AS vehicle_count_change#20564]
   +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_change#20527, vehicle_count_lag#20545]
      +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_change#20527, vehicle_count_lag#20545, vehicle_count_lag#20545]
         +- Window [lag(vehicle_count#20395, -1, null) windowspecdefinition(road_id#20371, timestamp#20374 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#20545], [road_id#20371], [timestamp#20374 ASC NULLS FIRST]
            +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_change#20527]
               +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, CASE WHEN isnotnull(speed_lag#20510) THEN (speed#20385 - speed_lag#20510) ELSE 0.0 END AS speed_change#20527]
                  +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510]
                     +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494, speed_lag#20510, speed_lag#20510]
                        +- Window [lag(speed#20385, -1, null) windowspecdefinition(road_id#20371, timestamp#20374 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#20510], [road_id#20371], [timestamp#20374 ASC NULLS FIRST]
                           +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, hour_cos#20494]
                              +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, hour_sin#20479, COS((0.2617993877991494 * cast(hour#20429 as double))) AS hour_cos#20494]
                                 +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, is_weekend#20465, SIN((0.2617993877991494 * cast(hour#20429 as double))) AS hour_sin#20479]
                                    +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, day_of_week#20452, CASE WHEN day_of_week#20452 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#20465]
                                       +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, is_peak#20440, dayofweek(cast(timestamp#20374 as date)) AS day_of_week#20452]
                                          +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour#20429, CASE WHEN hour#20429 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#20440]
                                             +- Project [_id#20367, congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395, hour(timestamp#20374, Some(Asia/Bangkok)) AS hour#20429]
                                                +- Project [_id#20367, cast(congestion_level#20368 as double) AS congestion_level#20405, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, vehicle_count#20395]
                                                   +- Project [_id#20367, congestion_level#20368, lat#20369, lon#20370, road_id#20371, road_name#20372, speed#20385, timestamp#20374, cast(vehicle_count#20375 as double) AS vehicle_count#20395]
                                                      +- Project [_id#20367, congestion_level#20368, lat#20369, lon#20370, road_id#20371, road_name#20372, cast(speed#20373 as double) AS speed#20385, timestamp#20374, vehicle_count#20375]
                                                         +- Relation [_id#20367,congestion_level#20368,lat#20369,lon#20370,road_id#20371,road_name#20372,speed#20373,timestamp#20374,vehicle_count#20375] MongoRelation(MongoRDD[1209] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:23,447 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:28 +07)" executed successfully
2026-01-06 12:36:28,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:33 +07)" (scheduled at 2026-01-06 12:36:28.157382+07:00)
2026-01-06 12:36:28,158 - INFO -  Training Spark model...
2026-01-06 12:36:28,475 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_change#20746, vehicle_count_lag#20764, vehicle_count_change#20783, avg(speed#20604) windowspecdefinition(road_id#20590, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#20804]
+- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_change#20746, vehicle_count_lag#20764, CASE WHEN isnotnull(vehicle_count_lag#20764) THEN (vehicle_count#20614 - vehicle_count_lag#20764) ELSE 0.0 END AS vehicle_count_change#20783]
   +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_change#20746, vehicle_count_lag#20764]
      +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_change#20746, vehicle_count_lag#20764, vehicle_count_lag#20764]
         +- Window [lag(vehicle_count#20614, -1, null) windowspecdefinition(road_id#20590, timestamp#20593 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#20764], [road_id#20590], [timestamp#20593 ASC NULLS FIRST]
            +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_change#20746]
               +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, CASE WHEN isnotnull(speed_lag#20729) THEN (speed#20604 - speed_lag#20729) ELSE 0.0 END AS speed_change#20746]
                  +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729]
                     +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713, speed_lag#20729, speed_lag#20729]
                        +- Window [lag(speed#20604, -1, null) windowspecdefinition(road_id#20590, timestamp#20593 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#20729], [road_id#20590], [timestamp#20593 ASC NULLS FIRST]
                           +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, hour_cos#20713]
                              +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, hour_sin#20698, COS((0.2617993877991494 * cast(hour#20648 as double))) AS hour_cos#20713]
                                 +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, is_weekend#20684, SIN((0.2617993877991494 * cast(hour#20648 as double))) AS hour_sin#20698]
                                    +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, day_of_week#20671, CASE WHEN day_of_week#20671 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#20684]
                                       +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, is_peak#20659, dayofweek(cast(timestamp#20593 as date)) AS day_of_week#20671]
                                          +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour#20648, CASE WHEN hour#20648 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#20659]
                                             +- Project [_id#20586, congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614, hour(timestamp#20593, Some(Asia/Bangkok)) AS hour#20648]
                                                +- Project [_id#20586, cast(congestion_level#20587 as double) AS congestion_level#20624, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, vehicle_count#20614]
                                                   +- Project [_id#20586, congestion_level#20587, lat#20588, lon#20589, road_id#20590, road_name#20591, speed#20604, timestamp#20593, cast(vehicle_count#20594 as double) AS vehicle_count#20614]
                                                      +- Project [_id#20586, congestion_level#20587, lat#20588, lon#20589, road_id#20590, road_name#20591, cast(speed#20592 as double) AS speed#20604, timestamp#20593, vehicle_count#20594]
                                                         +- Relation [_id#20586,congestion_level#20587,lat#20588,lon#20589,road_id#20590,road_name#20591,speed#20592,timestamp#20593,vehicle_count#20594] MongoRelation(MongoRDD[1222] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:28,475 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:33 +07)" executed successfully
2026-01-06 12:36:33,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:38 +07)" (scheduled at 2026-01-06 12:36:33.157382+07:00)
2026-01-06 12:36:33,158 - INFO -  Training Spark model...
2026-01-06 12:36:33,626 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_change#20965, vehicle_count_lag#20983, vehicle_count_change#21002, avg(speed#20823) windowspecdefinition(road_id#20809, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#21023]
+- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_change#20965, vehicle_count_lag#20983, CASE WHEN isnotnull(vehicle_count_lag#20983) THEN (vehicle_count#20833 - vehicle_count_lag#20983) ELSE 0.0 END AS vehicle_count_change#21002]
   +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_change#20965, vehicle_count_lag#20983]
      +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_change#20965, vehicle_count_lag#20983, vehicle_count_lag#20983]
         +- Window [lag(vehicle_count#20833, -1, null) windowspecdefinition(road_id#20809, timestamp#20812 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#20983], [road_id#20809], [timestamp#20812 ASC NULLS FIRST]
            +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_change#20965]
               +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, CASE WHEN isnotnull(speed_lag#20948) THEN (speed#20823 - speed_lag#20948) ELSE 0.0 END AS speed_change#20965]
                  +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948]
                     +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932, speed_lag#20948, speed_lag#20948]
                        +- Window [lag(speed#20823, -1, null) windowspecdefinition(road_id#20809, timestamp#20812 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#20948], [road_id#20809], [timestamp#20812 ASC NULLS FIRST]
                           +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, hour_cos#20932]
                              +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, hour_sin#20917, COS((0.2617993877991494 * cast(hour#20867 as double))) AS hour_cos#20932]
                                 +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, is_weekend#20903, SIN((0.2617993877991494 * cast(hour#20867 as double))) AS hour_sin#20917]
                                    +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, day_of_week#20890, CASE WHEN day_of_week#20890 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#20903]
                                       +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, is_peak#20878, dayofweek(cast(timestamp#20812 as date)) AS day_of_week#20890]
                                          +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour#20867, CASE WHEN hour#20867 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#20878]
                                             +- Project [_id#20805, congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833, hour(timestamp#20812, Some(Asia/Bangkok)) AS hour#20867]
                                                +- Project [_id#20805, cast(congestion_level#20806 as double) AS congestion_level#20843, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, vehicle_count#20833]
                                                   +- Project [_id#20805, congestion_level#20806, lat#20807, lon#20808, road_id#20809, road_name#20810, speed#20823, timestamp#20812, cast(vehicle_count#20813 as double) AS vehicle_count#20833]
                                                      +- Project [_id#20805, congestion_level#20806, lat#20807, lon#20808, road_id#20809, road_name#20810, cast(speed#20811 as double) AS speed#20823, timestamp#20812, vehicle_count#20813]
                                                         +- Relation [_id#20805,congestion_level#20806,lat#20807,lon#20808,road_id#20809,road_name#20810,speed#20811,timestamp#20812,vehicle_count#20813] MongoRelation(MongoRDD[1235] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:33,627 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:38 +07)" executed successfully
2026-01-06 12:36:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:43 +07)" (scheduled at 2026-01-06 12:36:38.157382+07:00)
2026-01-06 12:36:38,158 - INFO -  Training Spark model...
2026-01-06 12:36:38,495 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_change#21184, vehicle_count_lag#21202, vehicle_count_change#21221, avg(speed#21042) windowspecdefinition(road_id#21028, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#21242]
+- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_change#21184, vehicle_count_lag#21202, CASE WHEN isnotnull(vehicle_count_lag#21202) THEN (vehicle_count#21052 - vehicle_count_lag#21202) ELSE 0.0 END AS vehicle_count_change#21221]
   +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_change#21184, vehicle_count_lag#21202]
      +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_change#21184, vehicle_count_lag#21202, vehicle_count_lag#21202]
         +- Window [lag(vehicle_count#21052, -1, null) windowspecdefinition(road_id#21028, timestamp#21031 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#21202], [road_id#21028], [timestamp#21031 ASC NULLS FIRST]
            +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_change#21184]
               +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, CASE WHEN isnotnull(speed_lag#21167) THEN (speed#21042 - speed_lag#21167) ELSE 0.0 END AS speed_change#21184]
                  +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167]
                     +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151, speed_lag#21167, speed_lag#21167]
                        +- Window [lag(speed#21042, -1, null) windowspecdefinition(road_id#21028, timestamp#21031 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#21167], [road_id#21028], [timestamp#21031 ASC NULLS FIRST]
                           +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, hour_cos#21151]
                              +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, hour_sin#21136, COS((0.2617993877991494 * cast(hour#21086 as double))) AS hour_cos#21151]
                                 +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, is_weekend#21122, SIN((0.2617993877991494 * cast(hour#21086 as double))) AS hour_sin#21136]
                                    +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, day_of_week#21109, CASE WHEN day_of_week#21109 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#21122]
                                       +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, is_peak#21097, dayofweek(cast(timestamp#21031 as date)) AS day_of_week#21109]
                                          +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour#21086, CASE WHEN hour#21086 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#21097]
                                             +- Project [_id#21024, congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052, hour(timestamp#21031, Some(Asia/Bangkok)) AS hour#21086]
                                                +- Project [_id#21024, cast(congestion_level#21025 as double) AS congestion_level#21062, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, vehicle_count#21052]
                                                   +- Project [_id#21024, congestion_level#21025, lat#21026, lon#21027, road_id#21028, road_name#21029, speed#21042, timestamp#21031, cast(vehicle_count#21032 as double) AS vehicle_count#21052]
                                                      +- Project [_id#21024, congestion_level#21025, lat#21026, lon#21027, road_id#21028, road_name#21029, cast(speed#21030 as double) AS speed#21042, timestamp#21031, vehicle_count#21032]
                                                         +- Relation [_id#21024,congestion_level#21025,lat#21026,lon#21027,road_id#21028,road_name#21029,speed#21030,timestamp#21031,vehicle_count#21032] MongoRelation(MongoRDD[1248] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:38,495 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:43 +07)" executed successfully
2026-01-06 12:36:43,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:48 +07)" (scheduled at 2026-01-06 12:36:43.157382+07:00)
2026-01-06 12:36:43,162 - INFO -  Training Spark model...
2026-01-06 12:36:43,405 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_change#21403, vehicle_count_lag#21421, vehicle_count_change#21440, avg(speed#21261) windowspecdefinition(road_id#21247, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#21461]
+- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_change#21403, vehicle_count_lag#21421, CASE WHEN isnotnull(vehicle_count_lag#21421) THEN (vehicle_count#21271 - vehicle_count_lag#21421) ELSE 0.0 END AS vehicle_count_change#21440]
   +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_change#21403, vehicle_count_lag#21421]
      +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_change#21403, vehicle_count_lag#21421, vehicle_count_lag#21421]
         +- Window [lag(vehicle_count#21271, -1, null) windowspecdefinition(road_id#21247, timestamp#21250 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#21421], [road_id#21247], [timestamp#21250 ASC NULLS FIRST]
            +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_change#21403]
               +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, CASE WHEN isnotnull(speed_lag#21386) THEN (speed#21261 - speed_lag#21386) ELSE 0.0 END AS speed_change#21403]
                  +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386]
                     +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370, speed_lag#21386, speed_lag#21386]
                        +- Window [lag(speed#21261, -1, null) windowspecdefinition(road_id#21247, timestamp#21250 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#21386], [road_id#21247], [timestamp#21250 ASC NULLS FIRST]
                           +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, hour_cos#21370]
                              +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, hour_sin#21355, COS((0.2617993877991494 * cast(hour#21305 as double))) AS hour_cos#21370]
                                 +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, is_weekend#21341, SIN((0.2617993877991494 * cast(hour#21305 as double))) AS hour_sin#21355]
                                    +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, day_of_week#21328, CASE WHEN day_of_week#21328 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#21341]
                                       +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, is_peak#21316, dayofweek(cast(timestamp#21250 as date)) AS day_of_week#21328]
                                          +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour#21305, CASE WHEN hour#21305 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#21316]
                                             +- Project [_id#21243, congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271, hour(timestamp#21250, Some(Asia/Bangkok)) AS hour#21305]
                                                +- Project [_id#21243, cast(congestion_level#21244 as double) AS congestion_level#21281, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, vehicle_count#21271]
                                                   +- Project [_id#21243, congestion_level#21244, lat#21245, lon#21246, road_id#21247, road_name#21248, speed#21261, timestamp#21250, cast(vehicle_count#21251 as double) AS vehicle_count#21271]
                                                      +- Project [_id#21243, congestion_level#21244, lat#21245, lon#21246, road_id#21247, road_name#21248, cast(speed#21249 as double) AS speed#21261, timestamp#21250, vehicle_count#21251]
                                                         +- Relation [_id#21243,congestion_level#21244,lat#21245,lon#21246,road_id#21247,road_name#21248,speed#21249,timestamp#21250,vehicle_count#21251] MongoRelation(MongoRDD[1261] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:43,406 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:48 +07)" executed successfully
2026-01-06 12:36:48,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:53 +07)" (scheduled at 2026-01-06 12:36:48.157382+07:00)
2026-01-06 12:36:48,165 - INFO -  Training Spark model...
2026-01-06 12:36:48,551 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_change#21622, vehicle_count_lag#21640, vehicle_count_change#21659, avg(speed#21480) windowspecdefinition(road_id#21466, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#21680]
+- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_change#21622, vehicle_count_lag#21640, CASE WHEN isnotnull(vehicle_count_lag#21640) THEN (vehicle_count#21490 - vehicle_count_lag#21640) ELSE 0.0 END AS vehicle_count_change#21659]
   +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_change#21622, vehicle_count_lag#21640]
      +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_change#21622, vehicle_count_lag#21640, vehicle_count_lag#21640]
         +- Window [lag(vehicle_count#21490, -1, null) windowspecdefinition(road_id#21466, timestamp#21469 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#21640], [road_id#21466], [timestamp#21469 ASC NULLS FIRST]
            +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_change#21622]
               +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, CASE WHEN isnotnull(speed_lag#21605) THEN (speed#21480 - speed_lag#21605) ELSE 0.0 END AS speed_change#21622]
                  +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605]
                     +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589, speed_lag#21605, speed_lag#21605]
                        +- Window [lag(speed#21480, -1, null) windowspecdefinition(road_id#21466, timestamp#21469 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#21605], [road_id#21466], [timestamp#21469 ASC NULLS FIRST]
                           +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, hour_cos#21589]
                              +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, hour_sin#21574, COS((0.2617993877991494 * cast(hour#21524 as double))) AS hour_cos#21589]
                                 +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, is_weekend#21560, SIN((0.2617993877991494 * cast(hour#21524 as double))) AS hour_sin#21574]
                                    +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, day_of_week#21547, CASE WHEN day_of_week#21547 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#21560]
                                       +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, is_peak#21535, dayofweek(cast(timestamp#21469 as date)) AS day_of_week#21547]
                                          +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour#21524, CASE WHEN hour#21524 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#21535]
                                             +- Project [_id#21462, congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490, hour(timestamp#21469, Some(Asia/Bangkok)) AS hour#21524]
                                                +- Project [_id#21462, cast(congestion_level#21463 as double) AS congestion_level#21500, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, vehicle_count#21490]
                                                   +- Project [_id#21462, congestion_level#21463, lat#21464, lon#21465, road_id#21466, road_name#21467, speed#21480, timestamp#21469, cast(vehicle_count#21470 as double) AS vehicle_count#21490]
                                                      +- Project [_id#21462, congestion_level#21463, lat#21464, lon#21465, road_id#21466, road_name#21467, cast(speed#21468 as double) AS speed#21480, timestamp#21469, vehicle_count#21470]
                                                         +- Relation [_id#21462,congestion_level#21463,lat#21464,lon#21465,road_id#21466,road_name#21467,speed#21468,timestamp#21469,vehicle_count#21470] MongoRelation(MongoRDD[1274] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:48,551 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:53 +07)" executed successfully
2026-01-06 12:36:53,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:58 +07)" (scheduled at 2026-01-06 12:36:53.157382+07:00)
2026-01-06 12:36:53,158 - INFO -  Training Spark model...
2026-01-06 12:36:53,492 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_change#21841, vehicle_count_lag#21859, vehicle_count_change#21878, avg(speed#21699) windowspecdefinition(road_id#21685, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#21899]
+- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_change#21841, vehicle_count_lag#21859, CASE WHEN isnotnull(vehicle_count_lag#21859) THEN (vehicle_count#21709 - vehicle_count_lag#21859) ELSE 0.0 END AS vehicle_count_change#21878]
   +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_change#21841, vehicle_count_lag#21859]
      +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_change#21841, vehicle_count_lag#21859, vehicle_count_lag#21859]
         +- Window [lag(vehicle_count#21709, -1, null) windowspecdefinition(road_id#21685, timestamp#21688 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#21859], [road_id#21685], [timestamp#21688 ASC NULLS FIRST]
            +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_change#21841]
               +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, CASE WHEN isnotnull(speed_lag#21824) THEN (speed#21699 - speed_lag#21824) ELSE 0.0 END AS speed_change#21841]
                  +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824]
                     +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808, speed_lag#21824, speed_lag#21824]
                        +- Window [lag(speed#21699, -1, null) windowspecdefinition(road_id#21685, timestamp#21688 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#21824], [road_id#21685], [timestamp#21688 ASC NULLS FIRST]
                           +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, hour_cos#21808]
                              +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, hour_sin#21793, COS((0.2617993877991494 * cast(hour#21743 as double))) AS hour_cos#21808]
                                 +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, is_weekend#21779, SIN((0.2617993877991494 * cast(hour#21743 as double))) AS hour_sin#21793]
                                    +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, day_of_week#21766, CASE WHEN day_of_week#21766 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#21779]
                                       +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, is_peak#21754, dayofweek(cast(timestamp#21688 as date)) AS day_of_week#21766]
                                          +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour#21743, CASE WHEN hour#21743 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#21754]
                                             +- Project [_id#21681, congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709, hour(timestamp#21688, Some(Asia/Bangkok)) AS hour#21743]
                                                +- Project [_id#21681, cast(congestion_level#21682 as double) AS congestion_level#21719, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, vehicle_count#21709]
                                                   +- Project [_id#21681, congestion_level#21682, lat#21683, lon#21684, road_id#21685, road_name#21686, speed#21699, timestamp#21688, cast(vehicle_count#21689 as double) AS vehicle_count#21709]
                                                      +- Project [_id#21681, congestion_level#21682, lat#21683, lon#21684, road_id#21685, road_name#21686, cast(speed#21687 as double) AS speed#21699, timestamp#21688, vehicle_count#21689]
                                                         +- Relation [_id#21681,congestion_level#21682,lat#21683,lon#21684,road_id#21685,road_name#21686,speed#21687,timestamp#21688,vehicle_count#21689] MongoRelation(MongoRDD[1287] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:53,492 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:36:58 +07)" executed successfully
2026-01-06 12:36:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:03 +07)" (scheduled at 2026-01-06 12:36:58.157382+07:00)
2026-01-06 12:36:58,158 - INFO -  Training Spark model...
2026-01-06 12:36:58,490 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_change#22060, vehicle_count_lag#22078, vehicle_count_change#22097, avg(speed#21918) windowspecdefinition(road_id#21904, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#22118]
+- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_change#22060, vehicle_count_lag#22078, CASE WHEN isnotnull(vehicle_count_lag#22078) THEN (vehicle_count#21928 - vehicle_count_lag#22078) ELSE 0.0 END AS vehicle_count_change#22097]
   +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_change#22060, vehicle_count_lag#22078]
      +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_change#22060, vehicle_count_lag#22078, vehicle_count_lag#22078]
         +- Window [lag(vehicle_count#21928, -1, null) windowspecdefinition(road_id#21904, timestamp#21907 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#22078], [road_id#21904], [timestamp#21907 ASC NULLS FIRST]
            +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_change#22060]
               +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, CASE WHEN isnotnull(speed_lag#22043) THEN (speed#21918 - speed_lag#22043) ELSE 0.0 END AS speed_change#22060]
                  +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043]
                     +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027, speed_lag#22043, speed_lag#22043]
                        +- Window [lag(speed#21918, -1, null) windowspecdefinition(road_id#21904, timestamp#21907 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#22043], [road_id#21904], [timestamp#21907 ASC NULLS FIRST]
                           +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, hour_cos#22027]
                              +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, hour_sin#22012, COS((0.2617993877991494 * cast(hour#21962 as double))) AS hour_cos#22027]
                                 +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, is_weekend#21998, SIN((0.2617993877991494 * cast(hour#21962 as double))) AS hour_sin#22012]
                                    +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, day_of_week#21985, CASE WHEN day_of_week#21985 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#21998]
                                       +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, is_peak#21973, dayofweek(cast(timestamp#21907 as date)) AS day_of_week#21985]
                                          +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour#21962, CASE WHEN hour#21962 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#21973]
                                             +- Project [_id#21900, congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928, hour(timestamp#21907, Some(Asia/Bangkok)) AS hour#21962]
                                                +- Project [_id#21900, cast(congestion_level#21901 as double) AS congestion_level#21938, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, vehicle_count#21928]
                                                   +- Project [_id#21900, congestion_level#21901, lat#21902, lon#21903, road_id#21904, road_name#21905, speed#21918, timestamp#21907, cast(vehicle_count#21908 as double) AS vehicle_count#21928]
                                                      +- Project [_id#21900, congestion_level#21901, lat#21902, lon#21903, road_id#21904, road_name#21905, cast(speed#21906 as double) AS speed#21918, timestamp#21907, vehicle_count#21908]
                                                         +- Relation [_id#21900,congestion_level#21901,lat#21902,lon#21903,road_id#21904,road_name#21905,speed#21906,timestamp#21907,vehicle_count#21908] MongoRelation(MongoRDD[1300] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:36:58,490 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:03 +07)" executed successfully
2026-01-06 12:37:03,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:08 +07)" (scheduled at 2026-01-06 12:37:03.157382+07:00)
2026-01-06 12:37:03,158 - INFO -  Training Spark model...
2026-01-06 12:37:03,454 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_change#22279, vehicle_count_lag#22297, vehicle_count_change#22316, avg(speed#22137) windowspecdefinition(road_id#22123, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#22337]
+- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_change#22279, vehicle_count_lag#22297, CASE WHEN isnotnull(vehicle_count_lag#22297) THEN (vehicle_count#22147 - vehicle_count_lag#22297) ELSE 0.0 END AS vehicle_count_change#22316]
   +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_change#22279, vehicle_count_lag#22297]
      +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_change#22279, vehicle_count_lag#22297, vehicle_count_lag#22297]
         +- Window [lag(vehicle_count#22147, -1, null) windowspecdefinition(road_id#22123, timestamp#22126 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#22297], [road_id#22123], [timestamp#22126 ASC NULLS FIRST]
            +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_change#22279]
               +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, CASE WHEN isnotnull(speed_lag#22262) THEN (speed#22137 - speed_lag#22262) ELSE 0.0 END AS speed_change#22279]
                  +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262]
                     +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246, speed_lag#22262, speed_lag#22262]
                        +- Window [lag(speed#22137, -1, null) windowspecdefinition(road_id#22123, timestamp#22126 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#22262], [road_id#22123], [timestamp#22126 ASC NULLS FIRST]
                           +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, hour_cos#22246]
                              +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, hour_sin#22231, COS((0.2617993877991494 * cast(hour#22181 as double))) AS hour_cos#22246]
                                 +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, is_weekend#22217, SIN((0.2617993877991494 * cast(hour#22181 as double))) AS hour_sin#22231]
                                    +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, day_of_week#22204, CASE WHEN day_of_week#22204 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#22217]
                                       +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, is_peak#22192, dayofweek(cast(timestamp#22126 as date)) AS day_of_week#22204]
                                          +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour#22181, CASE WHEN hour#22181 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#22192]
                                             +- Project [_id#22119, congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147, hour(timestamp#22126, Some(Asia/Bangkok)) AS hour#22181]
                                                +- Project [_id#22119, cast(congestion_level#22120 as double) AS congestion_level#22157, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, vehicle_count#22147]
                                                   +- Project [_id#22119, congestion_level#22120, lat#22121, lon#22122, road_id#22123, road_name#22124, speed#22137, timestamp#22126, cast(vehicle_count#22127 as double) AS vehicle_count#22147]
                                                      +- Project [_id#22119, congestion_level#22120, lat#22121, lon#22122, road_id#22123, road_name#22124, cast(speed#22125 as double) AS speed#22137, timestamp#22126, vehicle_count#22127]
                                                         +- Relation [_id#22119,congestion_level#22120,lat#22121,lon#22122,road_id#22123,road_name#22124,speed#22125,timestamp#22126,vehicle_count#22127] MongoRelation(MongoRDD[1313] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:03,454 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:08 +07)" executed successfully
2026-01-06 12:37:08,179 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:13 +07)" (scheduled at 2026-01-06 12:37:08.157382+07:00)
2026-01-06 12:37:08,179 - INFO -  Training Spark model...
2026-01-06 12:37:08,179 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:38:08 +07)" (scheduled at 2026-01-06 12:37:08.157779+07:00)
2026-01-06 12:37:08,179 - INFO -  Training Spark model...
2026-01-06 12:37:08,530 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_change#22658, vehicle_count_lag#22695, vehicle_count_change#22732, avg(speed#22374) windowspecdefinition(road_id#22342, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#22773]
+- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_change#22658, vehicle_count_lag#22695, CASE WHEN isnotnull(vehicle_count_lag#22695) THEN (vehicle_count#22385 - vehicle_count_lag#22695) ELSE 0.0 END AS vehicle_count_change#22732]
   +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_change#22658, vehicle_count_lag#22695]
      +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_change#22658, vehicle_count_lag#22695, vehicle_count_lag#22695]
         +- Window [lag(vehicle_count#22385, -1, null) windowspecdefinition(road_id#22342, timestamp#22345 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#22695], [road_id#22342], [timestamp#22345 ASC NULLS FIRST]
            +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_change#22658]
               +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, CASE WHEN isnotnull(speed_lag#22625) THEN (speed#22374 - speed_lag#22625) ELSE 0.0 END AS speed_change#22658]
                  +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625]
                     +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592, speed_lag#22625, speed_lag#22625]
                        +- Window [lag(speed#22374, -1, null) windowspecdefinition(road_id#22342, timestamp#22345 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#22625], [road_id#22342], [timestamp#22345 ASC NULLS FIRST]
                           +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, hour_cos#22592]
                              +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, hour_sin#22563, COS((0.2617993877991494 * cast(hour#22473 as double))) AS hour_cos#22592]
                                 +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, is_weekend#22548, SIN((0.2617993877991494 * cast(hour#22473 as double))) AS hour_sin#22563]
                                    +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, day_of_week#22509, CASE WHEN day_of_week#22509 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#22548]
                                       +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, is_peak#22485, dayofweek(cast(timestamp#22345 as date)) AS day_of_week#22509]
                                          +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour#22473, CASE WHEN hour#22473 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#22485]
                                             +- Project [_id#22338, congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385, hour(timestamp#22345, Some(Asia/Bangkok)) AS hour#22473]
                                                +- Project [_id#22338, cast(congestion_level#22339 as double) AS congestion_level#22404, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, vehicle_count#22385]
                                                   +- Project [_id#22338, congestion_level#22339, lat#22340, lon#22341, road_id#22342, road_name#22343, speed#22374, timestamp#22345, cast(vehicle_count#22346 as double) AS vehicle_count#22385]
                                                      +- Project [_id#22338, congestion_level#22339, lat#22340, lon#22341, road_id#22342, road_name#22343, cast(speed#22344 as double) AS speed#22374, timestamp#22345, vehicle_count#22346]
                                                         +- Relation [_id#22338,congestion_level#22339,lat#22340,lon#22341,road_id#22342,road_name#22343,speed#22344,timestamp#22345,vehicle_count#22346] MongoRelation(MongoRDD[1328] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:08,530 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_change#22659, vehicle_count_lag#22694, vehicle_count_change#22733, avg(speed#22384) windowspecdefinition(road_id#22360, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#22775]
+- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_change#22659, vehicle_count_lag#22694, CASE WHEN isnotnull(vehicle_count_lag#22694) THEN (vehicle_count#22405 - vehicle_count_lag#22694) ELSE 0.0 END AS vehicle_count_change#22733]
   +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_change#22659, vehicle_count_lag#22694]
      +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_change#22659, vehicle_count_lag#22694, vehicle_count_lag#22694]
         +- Window [lag(vehicle_count#22405, -1, null) windowspecdefinition(road_id#22360, timestamp#22363 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#22694], [road_id#22360], [timestamp#22363 ASC NULLS FIRST]
            +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_change#22659]
               +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, CASE WHEN isnotnull(speed_lag#22624) THEN (speed#22384 - speed_lag#22624) ELSE 0.0 END AS speed_change#22659]
                  +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624]
                     +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593, speed_lag#22624, speed_lag#22624]
                        +- Window [lag(speed#22384, -1, null) windowspecdefinition(road_id#22360, timestamp#22363 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#22624], [road_id#22360], [timestamp#22363 ASC NULLS FIRST]
                           +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, hour_cos#22593]
                              +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, hour_sin#22562, COS((0.2617993877991494 * cast(hour#22462 as double))) AS hour_cos#22593]
                                 +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, is_weekend#22534, SIN((0.2617993877991494 * cast(hour#22462 as double))) AS hour_sin#22562]
                                    +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, day_of_week#22508, CASE WHEN day_of_week#22508 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#22534]
                                       +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, is_peak#22484, dayofweek(cast(timestamp#22363 as date)) AS day_of_week#22508]
                                          +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour#22462, CASE WHEN hour#22462 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#22484]
                                             +- Project [_id#22356, congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405, hour(timestamp#22363, Some(Asia/Bangkok)) AS hour#22462]
                                                +- Project [_id#22356, cast(congestion_level#22357 as double) AS congestion_level#22436, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, vehicle_count#22405]
                                                   +- Project [_id#22356, congestion_level#22357, lat#22358, lon#22359, road_id#22360, road_name#22361, speed#22384, timestamp#22363, cast(vehicle_count#22364 as double) AS vehicle_count#22405]
                                                      +- Project [_id#22356, congestion_level#22357, lat#22358, lon#22359, road_id#22360, road_name#22361, cast(speed#22362 as double) AS speed#22384, timestamp#22363, vehicle_count#22364]
                                                         +- Relation [_id#22356,congestion_level#22357,lat#22358,lon#22359,road_id#22360,road_name#22361,speed#22362,timestamp#22363,vehicle_count#22364] MongoRelation(MongoRDD[1326] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:08,530 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:38:08 +07)" executed successfully
2026-01-06 12:37:08,530 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:13 +07)" executed successfully
2026-01-06 12:37:13,157 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:18 +07)" (scheduled at 2026-01-06 12:37:13.157382+07:00)
2026-01-06 12:37:13,158 - INFO -  Training Spark model...
2026-01-06 12:37:13,482 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_change#22936, vehicle_count_lag#22954, vehicle_count_change#22973, avg(speed#22794) windowspecdefinition(road_id#22780, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#22994]
+- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_change#22936, vehicle_count_lag#22954, CASE WHEN isnotnull(vehicle_count_lag#22954) THEN (vehicle_count#22804 - vehicle_count_lag#22954) ELSE 0.0 END AS vehicle_count_change#22973]
   +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_change#22936, vehicle_count_lag#22954]
      +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_change#22936, vehicle_count_lag#22954, vehicle_count_lag#22954]
         +- Window [lag(vehicle_count#22804, -1, null) windowspecdefinition(road_id#22780, timestamp#22783 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#22954], [road_id#22780], [timestamp#22783 ASC NULLS FIRST]
            +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_change#22936]
               +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, CASE WHEN isnotnull(speed_lag#22919) THEN (speed#22794 - speed_lag#22919) ELSE 0.0 END AS speed_change#22936]
                  +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919]
                     +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903, speed_lag#22919, speed_lag#22919]
                        +- Window [lag(speed#22794, -1, null) windowspecdefinition(road_id#22780, timestamp#22783 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#22919], [road_id#22780], [timestamp#22783 ASC NULLS FIRST]
                           +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, hour_cos#22903]
                              +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, hour_sin#22888, COS((0.2617993877991494 * cast(hour#22838 as double))) AS hour_cos#22903]
                                 +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, is_weekend#22874, SIN((0.2617993877991494 * cast(hour#22838 as double))) AS hour_sin#22888]
                                    +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, day_of_week#22861, CASE WHEN day_of_week#22861 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#22874]
                                       +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, is_peak#22849, dayofweek(cast(timestamp#22783 as date)) AS day_of_week#22861]
                                          +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour#22838, CASE WHEN hour#22838 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#22849]
                                             +- Project [_id#22776, congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804, hour(timestamp#22783, Some(Asia/Bangkok)) AS hour#22838]
                                                +- Project [_id#22776, cast(congestion_level#22777 as double) AS congestion_level#22814, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, vehicle_count#22804]
                                                   +- Project [_id#22776, congestion_level#22777, lat#22778, lon#22779, road_id#22780, road_name#22781, speed#22794, timestamp#22783, cast(vehicle_count#22784 as double) AS vehicle_count#22804]
                                                      +- Project [_id#22776, congestion_level#22777, lat#22778, lon#22779, road_id#22780, road_name#22781, cast(speed#22782 as double) AS speed#22794, timestamp#22783, vehicle_count#22784]
                                                         +- Relation [_id#22776,congestion_level#22777,lat#22778,lon#22779,road_id#22780,road_name#22781,speed#22782,timestamp#22783,vehicle_count#22784] MongoRelation(MongoRDD[1352] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:13,482 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:18 +07)" executed successfully
2026-01-06 12:37:18,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:23 +07)" (scheduled at 2026-01-06 12:37:18.157382+07:00)
2026-01-06 12:37:18,159 - INFO -  Training Spark model...
2026-01-06 12:37:18,510 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_change#23155, vehicle_count_lag#23173, vehicle_count_change#23192, avg(speed#23013) windowspecdefinition(road_id#22999, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#23213]
+- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_change#23155, vehicle_count_lag#23173, CASE WHEN isnotnull(vehicle_count_lag#23173) THEN (vehicle_count#23023 - vehicle_count_lag#23173) ELSE 0.0 END AS vehicle_count_change#23192]
   +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_change#23155, vehicle_count_lag#23173]
      +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_change#23155, vehicle_count_lag#23173, vehicle_count_lag#23173]
         +- Window [lag(vehicle_count#23023, -1, null) windowspecdefinition(road_id#22999, timestamp#23002 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#23173], [road_id#22999], [timestamp#23002 ASC NULLS FIRST]
            +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_change#23155]
               +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, CASE WHEN isnotnull(speed_lag#23138) THEN (speed#23013 - speed_lag#23138) ELSE 0.0 END AS speed_change#23155]
                  +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138]
                     +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122, speed_lag#23138, speed_lag#23138]
                        +- Window [lag(speed#23013, -1, null) windowspecdefinition(road_id#22999, timestamp#23002 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#23138], [road_id#22999], [timestamp#23002 ASC NULLS FIRST]
                           +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, hour_cos#23122]
                              +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, hour_sin#23107, COS((0.2617993877991494 * cast(hour#23057 as double))) AS hour_cos#23122]
                                 +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, is_weekend#23093, SIN((0.2617993877991494 * cast(hour#23057 as double))) AS hour_sin#23107]
                                    +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, day_of_week#23080, CASE WHEN day_of_week#23080 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#23093]
                                       +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, is_peak#23068, dayofweek(cast(timestamp#23002 as date)) AS day_of_week#23080]
                                          +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour#23057, CASE WHEN hour#23057 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#23068]
                                             +- Project [_id#22995, congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023, hour(timestamp#23002, Some(Asia/Bangkok)) AS hour#23057]
                                                +- Project [_id#22995, cast(congestion_level#22996 as double) AS congestion_level#23033, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, vehicle_count#23023]
                                                   +- Project [_id#22995, congestion_level#22996, lat#22997, lon#22998, road_id#22999, road_name#23000, speed#23013, timestamp#23002, cast(vehicle_count#23003 as double) AS vehicle_count#23023]
                                                      +- Project [_id#22995, congestion_level#22996, lat#22997, lon#22998, road_id#22999, road_name#23000, cast(speed#23001 as double) AS speed#23013, timestamp#23002, vehicle_count#23003]
                                                         +- Relation [_id#22995,congestion_level#22996,lat#22997,lon#22998,road_id#22999,road_name#23000,speed#23001,timestamp#23002,vehicle_count#23003] MongoRelation(MongoRDD[1365] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:18,511 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:23 +07)" executed successfully
2026-01-06 12:37:23,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:28 +07)" (scheduled at 2026-01-06 12:37:23.157382+07:00)
2026-01-06 12:37:23,161 - INFO -  Training Spark model...
2026-01-06 12:37:23,484 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_change#23374, vehicle_count_lag#23392, vehicle_count_change#23411, avg(speed#23232) windowspecdefinition(road_id#23218, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#23432]
+- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_change#23374, vehicle_count_lag#23392, CASE WHEN isnotnull(vehicle_count_lag#23392) THEN (vehicle_count#23242 - vehicle_count_lag#23392) ELSE 0.0 END AS vehicle_count_change#23411]
   +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_change#23374, vehicle_count_lag#23392]
      +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_change#23374, vehicle_count_lag#23392, vehicle_count_lag#23392]
         +- Window [lag(vehicle_count#23242, -1, null) windowspecdefinition(road_id#23218, timestamp#23221 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#23392], [road_id#23218], [timestamp#23221 ASC NULLS FIRST]
            +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_change#23374]
               +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, CASE WHEN isnotnull(speed_lag#23357) THEN (speed#23232 - speed_lag#23357) ELSE 0.0 END AS speed_change#23374]
                  +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357]
                     +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341, speed_lag#23357, speed_lag#23357]
                        +- Window [lag(speed#23232, -1, null) windowspecdefinition(road_id#23218, timestamp#23221 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#23357], [road_id#23218], [timestamp#23221 ASC NULLS FIRST]
                           +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, hour_cos#23341]
                              +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, hour_sin#23326, COS((0.2617993877991494 * cast(hour#23276 as double))) AS hour_cos#23341]
                                 +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, is_weekend#23312, SIN((0.2617993877991494 * cast(hour#23276 as double))) AS hour_sin#23326]
                                    +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, day_of_week#23299, CASE WHEN day_of_week#23299 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#23312]
                                       +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, is_peak#23287, dayofweek(cast(timestamp#23221 as date)) AS day_of_week#23299]
                                          +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour#23276, CASE WHEN hour#23276 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#23287]
                                             +- Project [_id#23214, congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242, hour(timestamp#23221, Some(Asia/Bangkok)) AS hour#23276]
                                                +- Project [_id#23214, cast(congestion_level#23215 as double) AS congestion_level#23252, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, vehicle_count#23242]
                                                   +- Project [_id#23214, congestion_level#23215, lat#23216, lon#23217, road_id#23218, road_name#23219, speed#23232, timestamp#23221, cast(vehicle_count#23222 as double) AS vehicle_count#23242]
                                                      +- Project [_id#23214, congestion_level#23215, lat#23216, lon#23217, road_id#23218, road_name#23219, cast(speed#23220 as double) AS speed#23232, timestamp#23221, vehicle_count#23222]
                                                         +- Relation [_id#23214,congestion_level#23215,lat#23216,lon#23217,road_id#23218,road_name#23219,speed#23220,timestamp#23221,vehicle_count#23222] MongoRelation(MongoRDD[1378] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:23,484 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:28 +07)" executed successfully
2026-01-06 12:37:28,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:33 +07)" (scheduled at 2026-01-06 12:37:28.157382+07:00)
2026-01-06 12:37:28,160 - INFO -  Training Spark model...
2026-01-06 12:37:28,429 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_change#23593, vehicle_count_lag#23611, vehicle_count_change#23630, avg(speed#23451) windowspecdefinition(road_id#23437, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#23651]
+- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_change#23593, vehicle_count_lag#23611, CASE WHEN isnotnull(vehicle_count_lag#23611) THEN (vehicle_count#23461 - vehicle_count_lag#23611) ELSE 0.0 END AS vehicle_count_change#23630]
   +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_change#23593, vehicle_count_lag#23611]
      +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_change#23593, vehicle_count_lag#23611, vehicle_count_lag#23611]
         +- Window [lag(vehicle_count#23461, -1, null) windowspecdefinition(road_id#23437, timestamp#23440 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#23611], [road_id#23437], [timestamp#23440 ASC NULLS FIRST]
            +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_change#23593]
               +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, CASE WHEN isnotnull(speed_lag#23576) THEN (speed#23451 - speed_lag#23576) ELSE 0.0 END AS speed_change#23593]
                  +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576]
                     +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560, speed_lag#23576, speed_lag#23576]
                        +- Window [lag(speed#23451, -1, null) windowspecdefinition(road_id#23437, timestamp#23440 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#23576], [road_id#23437], [timestamp#23440 ASC NULLS FIRST]
                           +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, hour_cos#23560]
                              +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, hour_sin#23545, COS((0.2617993877991494 * cast(hour#23495 as double))) AS hour_cos#23560]
                                 +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, is_weekend#23531, SIN((0.2617993877991494 * cast(hour#23495 as double))) AS hour_sin#23545]
                                    +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, day_of_week#23518, CASE WHEN day_of_week#23518 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#23531]
                                       +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, is_peak#23506, dayofweek(cast(timestamp#23440 as date)) AS day_of_week#23518]
                                          +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour#23495, CASE WHEN hour#23495 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#23506]
                                             +- Project [_id#23433, congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461, hour(timestamp#23440, Some(Asia/Bangkok)) AS hour#23495]
                                                +- Project [_id#23433, cast(congestion_level#23434 as double) AS congestion_level#23471, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, vehicle_count#23461]
                                                   +- Project [_id#23433, congestion_level#23434, lat#23435, lon#23436, road_id#23437, road_name#23438, speed#23451, timestamp#23440, cast(vehicle_count#23441 as double) AS vehicle_count#23461]
                                                      +- Project [_id#23433, congestion_level#23434, lat#23435, lon#23436, road_id#23437, road_name#23438, cast(speed#23439 as double) AS speed#23451, timestamp#23440, vehicle_count#23441]
                                                         +- Relation [_id#23433,congestion_level#23434,lat#23435,lon#23436,road_id#23437,road_name#23438,speed#23439,timestamp#23440,vehicle_count#23441] MongoRelation(MongoRDD[1391] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:28,430 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:33 +07)" executed successfully
2026-01-06 12:37:33,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:38 +07)" (scheduled at 2026-01-06 12:37:33.157382+07:00)
2026-01-06 12:37:33,158 - INFO -  Training Spark model...
2026-01-06 12:37:33,546 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_change#23812, vehicle_count_lag#23830, vehicle_count_change#23849, avg(speed#23670) windowspecdefinition(road_id#23656, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#23870]
+- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_change#23812, vehicle_count_lag#23830, CASE WHEN isnotnull(vehicle_count_lag#23830) THEN (vehicle_count#23680 - vehicle_count_lag#23830) ELSE 0.0 END AS vehicle_count_change#23849]
   +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_change#23812, vehicle_count_lag#23830]
      +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_change#23812, vehicle_count_lag#23830, vehicle_count_lag#23830]
         +- Window [lag(vehicle_count#23680, -1, null) windowspecdefinition(road_id#23656, timestamp#23659 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#23830], [road_id#23656], [timestamp#23659 ASC NULLS FIRST]
            +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_change#23812]
               +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, CASE WHEN isnotnull(speed_lag#23795) THEN (speed#23670 - speed_lag#23795) ELSE 0.0 END AS speed_change#23812]
                  +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795]
                     +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779, speed_lag#23795, speed_lag#23795]
                        +- Window [lag(speed#23670, -1, null) windowspecdefinition(road_id#23656, timestamp#23659 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#23795], [road_id#23656], [timestamp#23659 ASC NULLS FIRST]
                           +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, hour_cos#23779]
                              +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, hour_sin#23764, COS((0.2617993877991494 * cast(hour#23714 as double))) AS hour_cos#23779]
                                 +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, is_weekend#23750, SIN((0.2617993877991494 * cast(hour#23714 as double))) AS hour_sin#23764]
                                    +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, day_of_week#23737, CASE WHEN day_of_week#23737 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#23750]
                                       +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, is_peak#23725, dayofweek(cast(timestamp#23659 as date)) AS day_of_week#23737]
                                          +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour#23714, CASE WHEN hour#23714 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#23725]
                                             +- Project [_id#23652, congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680, hour(timestamp#23659, Some(Asia/Bangkok)) AS hour#23714]
                                                +- Project [_id#23652, cast(congestion_level#23653 as double) AS congestion_level#23690, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, vehicle_count#23680]
                                                   +- Project [_id#23652, congestion_level#23653, lat#23654, lon#23655, road_id#23656, road_name#23657, speed#23670, timestamp#23659, cast(vehicle_count#23660 as double) AS vehicle_count#23680]
                                                      +- Project [_id#23652, congestion_level#23653, lat#23654, lon#23655, road_id#23656, road_name#23657, cast(speed#23658 as double) AS speed#23670, timestamp#23659, vehicle_count#23660]
                                                         +- Relation [_id#23652,congestion_level#23653,lat#23654,lon#23655,road_id#23656,road_name#23657,speed#23658,timestamp#23659,vehicle_count#23660] MongoRelation(MongoRDD[1404] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:33,546 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:38 +07)" executed successfully
2026-01-06 12:37:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:43 +07)" (scheduled at 2026-01-06 12:37:38.157382+07:00)
2026-01-06 12:37:38,159 - INFO -  Training Spark model...
2026-01-06 12:37:38,442 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_change#24031, vehicle_count_lag#24049, vehicle_count_change#24068, avg(speed#23889) windowspecdefinition(road_id#23875, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#24089]
+- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_change#24031, vehicle_count_lag#24049, CASE WHEN isnotnull(vehicle_count_lag#24049) THEN (vehicle_count#23899 - vehicle_count_lag#24049) ELSE 0.0 END AS vehicle_count_change#24068]
   +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_change#24031, vehicle_count_lag#24049]
      +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_change#24031, vehicle_count_lag#24049, vehicle_count_lag#24049]
         +- Window [lag(vehicle_count#23899, -1, null) windowspecdefinition(road_id#23875, timestamp#23878 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#24049], [road_id#23875], [timestamp#23878 ASC NULLS FIRST]
            +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_change#24031]
               +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, CASE WHEN isnotnull(speed_lag#24014) THEN (speed#23889 - speed_lag#24014) ELSE 0.0 END AS speed_change#24031]
                  +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014]
                     +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998, speed_lag#24014, speed_lag#24014]
                        +- Window [lag(speed#23889, -1, null) windowspecdefinition(road_id#23875, timestamp#23878 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#24014], [road_id#23875], [timestamp#23878 ASC NULLS FIRST]
                           +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, hour_cos#23998]
                              +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, hour_sin#23983, COS((0.2617993877991494 * cast(hour#23933 as double))) AS hour_cos#23998]
                                 +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, is_weekend#23969, SIN((0.2617993877991494 * cast(hour#23933 as double))) AS hour_sin#23983]
                                    +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, day_of_week#23956, CASE WHEN day_of_week#23956 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#23969]
                                       +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, is_peak#23944, dayofweek(cast(timestamp#23878 as date)) AS day_of_week#23956]
                                          +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour#23933, CASE WHEN hour#23933 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#23944]
                                             +- Project [_id#23871, congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899, hour(timestamp#23878, Some(Asia/Bangkok)) AS hour#23933]
                                                +- Project [_id#23871, cast(congestion_level#23872 as double) AS congestion_level#23909, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, vehicle_count#23899]
                                                   +- Project [_id#23871, congestion_level#23872, lat#23873, lon#23874, road_id#23875, road_name#23876, speed#23889, timestamp#23878, cast(vehicle_count#23879 as double) AS vehicle_count#23899]
                                                      +- Project [_id#23871, congestion_level#23872, lat#23873, lon#23874, road_id#23875, road_name#23876, cast(speed#23877 as double) AS speed#23889, timestamp#23878, vehicle_count#23879]
                                                         +- Relation [_id#23871,congestion_level#23872,lat#23873,lon#23874,road_id#23875,road_name#23876,speed#23877,timestamp#23878,vehicle_count#23879] MongoRelation(MongoRDD[1417] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:38,442 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:43 +07)" executed successfully
2026-01-06 12:37:43,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:48 +07)" (scheduled at 2026-01-06 12:37:43.157382+07:00)
2026-01-06 12:37:43,159 - INFO -  Training Spark model...
2026-01-06 12:37:43,483 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_change#24250, vehicle_count_lag#24268, vehicle_count_change#24287, avg(speed#24108) windowspecdefinition(road_id#24094, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#24308]
+- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_change#24250, vehicle_count_lag#24268, CASE WHEN isnotnull(vehicle_count_lag#24268) THEN (vehicle_count#24118 - vehicle_count_lag#24268) ELSE 0.0 END AS vehicle_count_change#24287]
   +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_change#24250, vehicle_count_lag#24268]
      +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_change#24250, vehicle_count_lag#24268, vehicle_count_lag#24268]
         +- Window [lag(vehicle_count#24118, -1, null) windowspecdefinition(road_id#24094, timestamp#24097 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#24268], [road_id#24094], [timestamp#24097 ASC NULLS FIRST]
            +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_change#24250]
               +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, CASE WHEN isnotnull(speed_lag#24233) THEN (speed#24108 - speed_lag#24233) ELSE 0.0 END AS speed_change#24250]
                  +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233]
                     +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217, speed_lag#24233, speed_lag#24233]
                        +- Window [lag(speed#24108, -1, null) windowspecdefinition(road_id#24094, timestamp#24097 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#24233], [road_id#24094], [timestamp#24097 ASC NULLS FIRST]
                           +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, hour_cos#24217]
                              +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, hour_sin#24202, COS((0.2617993877991494 * cast(hour#24152 as double))) AS hour_cos#24217]
                                 +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, is_weekend#24188, SIN((0.2617993877991494 * cast(hour#24152 as double))) AS hour_sin#24202]
                                    +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, day_of_week#24175, CASE WHEN day_of_week#24175 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#24188]
                                       +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, is_peak#24163, dayofweek(cast(timestamp#24097 as date)) AS day_of_week#24175]
                                          +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour#24152, CASE WHEN hour#24152 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#24163]
                                             +- Project [_id#24090, congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118, hour(timestamp#24097, Some(Asia/Bangkok)) AS hour#24152]
                                                +- Project [_id#24090, cast(congestion_level#24091 as double) AS congestion_level#24128, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, vehicle_count#24118]
                                                   +- Project [_id#24090, congestion_level#24091, lat#24092, lon#24093, road_id#24094, road_name#24095, speed#24108, timestamp#24097, cast(vehicle_count#24098 as double) AS vehicle_count#24118]
                                                      +- Project [_id#24090, congestion_level#24091, lat#24092, lon#24093, road_id#24094, road_name#24095, cast(speed#24096 as double) AS speed#24108, timestamp#24097, vehicle_count#24098]
                                                         +- Relation [_id#24090,congestion_level#24091,lat#24092,lon#24093,road_id#24094,road_name#24095,speed#24096,timestamp#24097,vehicle_count#24098] MongoRelation(MongoRDD[1430] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:43,484 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:48 +07)" executed successfully
2026-01-06 12:37:48,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:53 +07)" (scheduled at 2026-01-06 12:37:48.157382+07:00)
2026-01-06 12:37:48,162 - INFO -  Training Spark model...
2026-01-06 12:37:48,409 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_change#24469, vehicle_count_lag#24487, vehicle_count_change#24506, avg(speed#24327) windowspecdefinition(road_id#24313, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#24527]
+- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_change#24469, vehicle_count_lag#24487, CASE WHEN isnotnull(vehicle_count_lag#24487) THEN (vehicle_count#24337 - vehicle_count_lag#24487) ELSE 0.0 END AS vehicle_count_change#24506]
   +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_change#24469, vehicle_count_lag#24487]
      +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_change#24469, vehicle_count_lag#24487, vehicle_count_lag#24487]
         +- Window [lag(vehicle_count#24337, -1, null) windowspecdefinition(road_id#24313, timestamp#24316 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#24487], [road_id#24313], [timestamp#24316 ASC NULLS FIRST]
            +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_change#24469]
               +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, CASE WHEN isnotnull(speed_lag#24452) THEN (speed#24327 - speed_lag#24452) ELSE 0.0 END AS speed_change#24469]
                  +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452]
                     +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436, speed_lag#24452, speed_lag#24452]
                        +- Window [lag(speed#24327, -1, null) windowspecdefinition(road_id#24313, timestamp#24316 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#24452], [road_id#24313], [timestamp#24316 ASC NULLS FIRST]
                           +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, hour_cos#24436]
                              +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, hour_sin#24421, COS((0.2617993877991494 * cast(hour#24371 as double))) AS hour_cos#24436]
                                 +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, is_weekend#24407, SIN((0.2617993877991494 * cast(hour#24371 as double))) AS hour_sin#24421]
                                    +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, day_of_week#24394, CASE WHEN day_of_week#24394 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#24407]
                                       +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, is_peak#24382, dayofweek(cast(timestamp#24316 as date)) AS day_of_week#24394]
                                          +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour#24371, CASE WHEN hour#24371 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#24382]
                                             +- Project [_id#24309, congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337, hour(timestamp#24316, Some(Asia/Bangkok)) AS hour#24371]
                                                +- Project [_id#24309, cast(congestion_level#24310 as double) AS congestion_level#24347, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, vehicle_count#24337]
                                                   +- Project [_id#24309, congestion_level#24310, lat#24311, lon#24312, road_id#24313, road_name#24314, speed#24327, timestamp#24316, cast(vehicle_count#24317 as double) AS vehicle_count#24337]
                                                      +- Project [_id#24309, congestion_level#24310, lat#24311, lon#24312, road_id#24313, road_name#24314, cast(speed#24315 as double) AS speed#24327, timestamp#24316, vehicle_count#24317]
                                                         +- Relation [_id#24309,congestion_level#24310,lat#24311,lon#24312,road_id#24313,road_name#24314,speed#24315,timestamp#24316,vehicle_count#24317] MongoRelation(MongoRDD[1443] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:48,409 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:53 +07)" executed successfully
2026-01-06 12:37:53,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:58 +07)" (scheduled at 2026-01-06 12:37:53.157382+07:00)
2026-01-06 12:37:53,158 - INFO -  Training Spark model...
2026-01-06 12:37:53,432 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_change#24688, vehicle_count_lag#24706, vehicle_count_change#24725, avg(speed#24546) windowspecdefinition(road_id#24532, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#24746]
+- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_change#24688, vehicle_count_lag#24706, CASE WHEN isnotnull(vehicle_count_lag#24706) THEN (vehicle_count#24556 - vehicle_count_lag#24706) ELSE 0.0 END AS vehicle_count_change#24725]
   +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_change#24688, vehicle_count_lag#24706]
      +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_change#24688, vehicle_count_lag#24706, vehicle_count_lag#24706]
         +- Window [lag(vehicle_count#24556, -1, null) windowspecdefinition(road_id#24532, timestamp#24535 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#24706], [road_id#24532], [timestamp#24535 ASC NULLS FIRST]
            +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_change#24688]
               +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, CASE WHEN isnotnull(speed_lag#24671) THEN (speed#24546 - speed_lag#24671) ELSE 0.0 END AS speed_change#24688]
                  +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671]
                     +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655, speed_lag#24671, speed_lag#24671]
                        +- Window [lag(speed#24546, -1, null) windowspecdefinition(road_id#24532, timestamp#24535 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#24671], [road_id#24532], [timestamp#24535 ASC NULLS FIRST]
                           +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, hour_cos#24655]
                              +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, hour_sin#24640, COS((0.2617993877991494 * cast(hour#24590 as double))) AS hour_cos#24655]
                                 +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, is_weekend#24626, SIN((0.2617993877991494 * cast(hour#24590 as double))) AS hour_sin#24640]
                                    +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, day_of_week#24613, CASE WHEN day_of_week#24613 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#24626]
                                       +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, is_peak#24601, dayofweek(cast(timestamp#24535 as date)) AS day_of_week#24613]
                                          +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour#24590, CASE WHEN hour#24590 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#24601]
                                             +- Project [_id#24528, congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556, hour(timestamp#24535, Some(Asia/Bangkok)) AS hour#24590]
                                                +- Project [_id#24528, cast(congestion_level#24529 as double) AS congestion_level#24566, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, vehicle_count#24556]
                                                   +- Project [_id#24528, congestion_level#24529, lat#24530, lon#24531, road_id#24532, road_name#24533, speed#24546, timestamp#24535, cast(vehicle_count#24536 as double) AS vehicle_count#24556]
                                                      +- Project [_id#24528, congestion_level#24529, lat#24530, lon#24531, road_id#24532, road_name#24533, cast(speed#24534 as double) AS speed#24546, timestamp#24535, vehicle_count#24536]
                                                         +- Relation [_id#24528,congestion_level#24529,lat#24530,lon#24531,road_id#24532,road_name#24533,speed#24534,timestamp#24535,vehicle_count#24536] MongoRelation(MongoRDD[1456] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:53,432 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:37:58 +07)" executed successfully
2026-01-06 12:37:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:03 +07)" (scheduled at 2026-01-06 12:37:58.157382+07:00)
2026-01-06 12:37:58,158 - INFO -  Training Spark model...
2026-01-06 12:37:58,372 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_change#24907, vehicle_count_lag#24925, vehicle_count_change#24944, avg(speed#24765) windowspecdefinition(road_id#24751, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#24965]
+- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_change#24907, vehicle_count_lag#24925, CASE WHEN isnotnull(vehicle_count_lag#24925) THEN (vehicle_count#24775 - vehicle_count_lag#24925) ELSE 0.0 END AS vehicle_count_change#24944]
   +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_change#24907, vehicle_count_lag#24925]
      +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_change#24907, vehicle_count_lag#24925, vehicle_count_lag#24925]
         +- Window [lag(vehicle_count#24775, -1, null) windowspecdefinition(road_id#24751, timestamp#24754 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#24925], [road_id#24751], [timestamp#24754 ASC NULLS FIRST]
            +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_change#24907]
               +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, CASE WHEN isnotnull(speed_lag#24890) THEN (speed#24765 - speed_lag#24890) ELSE 0.0 END AS speed_change#24907]
                  +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890]
                     +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874, speed_lag#24890, speed_lag#24890]
                        +- Window [lag(speed#24765, -1, null) windowspecdefinition(road_id#24751, timestamp#24754 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#24890], [road_id#24751], [timestamp#24754 ASC NULLS FIRST]
                           +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, hour_cos#24874]
                              +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, hour_sin#24859, COS((0.2617993877991494 * cast(hour#24809 as double))) AS hour_cos#24874]
                                 +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, is_weekend#24845, SIN((0.2617993877991494 * cast(hour#24809 as double))) AS hour_sin#24859]
                                    +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, day_of_week#24832, CASE WHEN day_of_week#24832 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#24845]
                                       +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, is_peak#24820, dayofweek(cast(timestamp#24754 as date)) AS day_of_week#24832]
                                          +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour#24809, CASE WHEN hour#24809 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#24820]
                                             +- Project [_id#24747, congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775, hour(timestamp#24754, Some(Asia/Bangkok)) AS hour#24809]
                                                +- Project [_id#24747, cast(congestion_level#24748 as double) AS congestion_level#24785, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, vehicle_count#24775]
                                                   +- Project [_id#24747, congestion_level#24748, lat#24749, lon#24750, road_id#24751, road_name#24752, speed#24765, timestamp#24754, cast(vehicle_count#24755 as double) AS vehicle_count#24775]
                                                      +- Project [_id#24747, congestion_level#24748, lat#24749, lon#24750, road_id#24751, road_name#24752, cast(speed#24753 as double) AS speed#24765, timestamp#24754, vehicle_count#24755]
                                                         +- Relation [_id#24747,congestion_level#24748,lat#24749,lon#24750,road_id#24751,road_name#24752,speed#24753,timestamp#24754,vehicle_count#24755] MongoRelation(MongoRDD[1469] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:37:58,372 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:03 +07)" executed successfully
2026-01-06 12:38:03,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:08 +07)" (scheduled at 2026-01-06 12:38:03.157382+07:00)
2026-01-06 12:38:03,163 - INFO -  Training Spark model...
2026-01-06 12:38:03,401 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_change#25126, vehicle_count_lag#25144, vehicle_count_change#25163, avg(speed#24984) windowspecdefinition(road_id#24970, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#25184]
+- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_change#25126, vehicle_count_lag#25144, CASE WHEN isnotnull(vehicle_count_lag#25144) THEN (vehicle_count#24994 - vehicle_count_lag#25144) ELSE 0.0 END AS vehicle_count_change#25163]
   +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_change#25126, vehicle_count_lag#25144]
      +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_change#25126, vehicle_count_lag#25144, vehicle_count_lag#25144]
         +- Window [lag(vehicle_count#24994, -1, null) windowspecdefinition(road_id#24970, timestamp#24973 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#25144], [road_id#24970], [timestamp#24973 ASC NULLS FIRST]
            +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_change#25126]
               +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, CASE WHEN isnotnull(speed_lag#25109) THEN (speed#24984 - speed_lag#25109) ELSE 0.0 END AS speed_change#25126]
                  +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109]
                     +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093, speed_lag#25109, speed_lag#25109]
                        +- Window [lag(speed#24984, -1, null) windowspecdefinition(road_id#24970, timestamp#24973 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#25109], [road_id#24970], [timestamp#24973 ASC NULLS FIRST]
                           +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, hour_cos#25093]
                              +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, hour_sin#25078, COS((0.2617993877991494 * cast(hour#25028 as double))) AS hour_cos#25093]
                                 +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, is_weekend#25064, SIN((0.2617993877991494 * cast(hour#25028 as double))) AS hour_sin#25078]
                                    +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, day_of_week#25051, CASE WHEN day_of_week#25051 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#25064]
                                       +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, is_peak#25039, dayofweek(cast(timestamp#24973 as date)) AS day_of_week#25051]
                                          +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour#25028, CASE WHEN hour#25028 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#25039]
                                             +- Project [_id#24966, congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994, hour(timestamp#24973, Some(Asia/Bangkok)) AS hour#25028]
                                                +- Project [_id#24966, cast(congestion_level#24967 as double) AS congestion_level#25004, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, vehicle_count#24994]
                                                   +- Project [_id#24966, congestion_level#24967, lat#24968, lon#24969, road_id#24970, road_name#24971, speed#24984, timestamp#24973, cast(vehicle_count#24974 as double) AS vehicle_count#24994]
                                                      +- Project [_id#24966, congestion_level#24967, lat#24968, lon#24969, road_id#24970, road_name#24971, cast(speed#24972 as double) AS speed#24984, timestamp#24973, vehicle_count#24974]
                                                         +- Relation [_id#24966,congestion_level#24967,lat#24968,lon#24969,road_id#24970,road_name#24971,speed#24972,timestamp#24973,vehicle_count#24974] MongoRelation(MongoRDD[1482] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:03,401 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:08 +07)" executed successfully
2026-01-06 12:38:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:13 +07)" (scheduled at 2026-01-06 12:38:08.157382+07:00)
2026-01-06 12:38:08,158 - INFO -  Training Spark model...
2026-01-06 12:38:08,158 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:39:08 +07)" (scheduled at 2026-01-06 12:38:08.157779+07:00)
2026-01-06 12:38:08,158 - INFO -  Training Spark model...
2026-01-06 12:38:08,616 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_change#25488, vehicle_count_lag#25523, vehicle_count_change#25560, avg(speed#25203) windowspecdefinition(road_id#25189, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#25582]
+- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_change#25488, vehicle_count_lag#25523, CASE WHEN isnotnull(vehicle_count_lag#25523) THEN (vehicle_count#25231 - vehicle_count_lag#25523) ELSE 0.0 END AS vehicle_count_change#25560]
   +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_change#25488, vehicle_count_lag#25523]
      +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_change#25488, vehicle_count_lag#25523, vehicle_count_lag#25523]
         +- Window [lag(vehicle_count#25231, -1, null) windowspecdefinition(road_id#25189, timestamp#25192 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#25523], [road_id#25189], [timestamp#25192 ASC NULLS FIRST]
            +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_change#25488]
               +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, CASE WHEN isnotnull(speed_lag#25456) THEN (speed#25203 - speed_lag#25456) ELSE 0.0 END AS speed_change#25488]
                  +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456]
                     +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424, speed_lag#25456, speed_lag#25456]
                        +- Window [lag(speed#25203, -1, null) windowspecdefinition(road_id#25189, timestamp#25192 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#25456], [road_id#25189], [timestamp#25192 ASC NULLS FIRST]
                           +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, hour_cos#25424]
                              +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, hour_sin#25395, COS((0.2617993877991494 * cast(hour#25309 as double))) AS hour_cos#25424]
                                 +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, is_weekend#25369, SIN((0.2617993877991494 * cast(hour#25309 as double))) AS hour_sin#25395]
                                    +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, day_of_week#25343, CASE WHEN day_of_week#25343 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#25369]
                                       +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, is_peak#25331, dayofweek(cast(timestamp#25192 as date)) AS day_of_week#25343]
                                          +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour#25309, CASE WHEN hour#25309 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#25331]
                                             +- Project [_id#25185, congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231, hour(timestamp#25192, Some(Asia/Bangkok)) AS hour#25309]
                                                +- Project [_id#25185, cast(congestion_level#25186 as double) AS congestion_level#25252, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, vehicle_count#25231]
                                                   +- Project [_id#25185, congestion_level#25186, lat#25187, lon#25188, road_id#25189, road_name#25190, speed#25203, timestamp#25192, cast(vehicle_count#25193 as double) AS vehicle_count#25231]
                                                      +- Project [_id#25185, congestion_level#25186, lat#25187, lon#25188, road_id#25189, road_name#25190, cast(speed#25191 as double) AS speed#25203, timestamp#25192, vehicle_count#25193]
                                                         +- Relation [_id#25185,congestion_level#25186,lat#25187,lon#25188,road_id#25189,road_name#25190,speed#25191,timestamp#25192,vehicle_count#25193] MongoRelation(MongoRDD[1495] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:08,617 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:39:08 +07)" executed successfully
2026-01-06 12:38:08,632 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_change#25524, vehicle_count_lag#25580, vehicle_count_change#25601, avg(speed#25232) windowspecdefinition(road_id#25208, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#25622]
+- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_change#25524, vehicle_count_lag#25580, CASE WHEN isnotnull(vehicle_count_lag#25580) THEN (vehicle_count#25251 - vehicle_count_lag#25580) ELSE 0.0 END AS vehicle_count_change#25601]
   +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_change#25524, vehicle_count_lag#25580]
      +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_change#25524, vehicle_count_lag#25580, vehicle_count_lag#25580]
         +- Window [lag(vehicle_count#25251, -1, null) windowspecdefinition(road_id#25208, timestamp#25211 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#25580], [road_id#25208], [timestamp#25211 ASC NULLS FIRST]
            +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_change#25524]
               +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, CASE WHEN isnotnull(speed_lag#25489) THEN (speed#25232 - speed_lag#25489) ELSE 0.0 END AS speed_change#25524]
                  +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489]
                     +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455, speed_lag#25489, speed_lag#25489]
                        +- Window [lag(speed#25232, -1, null) windowspecdefinition(road_id#25208, timestamp#25211 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#25489], [road_id#25208], [timestamp#25211 ASC NULLS FIRST]
                           +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, hour_cos#25455]
                              +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, hour_sin#25440, COS((0.2617993877991494 * cast(hour#25310 as double))) AS hour_cos#25455]
                                 +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, is_weekend#25396, SIN((0.2617993877991494 * cast(hour#25310 as double))) AS hour_sin#25440]
                                    +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, day_of_week#25368, CASE WHEN day_of_week#25368 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#25396]
                                       +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, is_peak#25344, dayofweek(cast(timestamp#25211 as date)) AS day_of_week#25368]
                                          +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour#25310, CASE WHEN hour#25310 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#25344]
                                             +- Project [_id#25204, congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251, hour(timestamp#25211, Some(Asia/Bangkok)) AS hour#25310]
                                                +- Project [_id#25204, cast(congestion_level#25205 as double) AS congestion_level#25280, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, vehicle_count#25251]
                                                   +- Project [_id#25204, congestion_level#25205, lat#25206, lon#25207, road_id#25208, road_name#25209, speed#25232, timestamp#25211, cast(vehicle_count#25212 as double) AS vehicle_count#25251]
                                                      +- Project [_id#25204, congestion_level#25205, lat#25206, lon#25207, road_id#25208, road_name#25209, cast(speed#25210 as double) AS speed#25232, timestamp#25211, vehicle_count#25212]
                                                         +- Relation [_id#25204,congestion_level#25205,lat#25206,lon#25207,road_id#25208,road_name#25209,speed#25210,timestamp#25211,vehicle_count#25212] MongoRelation(MongoRDD[1497] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:08,632 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:13 +07)" executed successfully
2026-01-06 12:38:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:18 +07)" (scheduled at 2026-01-06 12:38:13.157382+07:00)
2026-01-06 12:38:13,159 - INFO -  Training Spark model...
2026-01-06 12:38:13,421 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_change#25783, vehicle_count_lag#25801, vehicle_count_change#25820, avg(speed#25641) windowspecdefinition(road_id#25627, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#25841]
+- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_change#25783, vehicle_count_lag#25801, CASE WHEN isnotnull(vehicle_count_lag#25801) THEN (vehicle_count#25651 - vehicle_count_lag#25801) ELSE 0.0 END AS vehicle_count_change#25820]
   +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_change#25783, vehicle_count_lag#25801]
      +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_change#25783, vehicle_count_lag#25801, vehicle_count_lag#25801]
         +- Window [lag(vehicle_count#25651, -1, null) windowspecdefinition(road_id#25627, timestamp#25630 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#25801], [road_id#25627], [timestamp#25630 ASC NULLS FIRST]
            +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_change#25783]
               +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, CASE WHEN isnotnull(speed_lag#25766) THEN (speed#25641 - speed_lag#25766) ELSE 0.0 END AS speed_change#25783]
                  +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766]
                     +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750, speed_lag#25766, speed_lag#25766]
                        +- Window [lag(speed#25641, -1, null) windowspecdefinition(road_id#25627, timestamp#25630 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#25766], [road_id#25627], [timestamp#25630 ASC NULLS FIRST]
                           +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, hour_cos#25750]
                              +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, hour_sin#25735, COS((0.2617993877991494 * cast(hour#25685 as double))) AS hour_cos#25750]
                                 +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, is_weekend#25721, SIN((0.2617993877991494 * cast(hour#25685 as double))) AS hour_sin#25735]
                                    +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, day_of_week#25708, CASE WHEN day_of_week#25708 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#25721]
                                       +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, is_peak#25696, dayofweek(cast(timestamp#25630 as date)) AS day_of_week#25708]
                                          +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour#25685, CASE WHEN hour#25685 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#25696]
                                             +- Project [_id#25623, congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651, hour(timestamp#25630, Some(Asia/Bangkok)) AS hour#25685]
                                                +- Project [_id#25623, cast(congestion_level#25624 as double) AS congestion_level#25661, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, vehicle_count#25651]
                                                   +- Project [_id#25623, congestion_level#25624, lat#25625, lon#25626, road_id#25627, road_name#25628, speed#25641, timestamp#25630, cast(vehicle_count#25631 as double) AS vehicle_count#25651]
                                                      +- Project [_id#25623, congestion_level#25624, lat#25625, lon#25626, road_id#25627, road_name#25628, cast(speed#25629 as double) AS speed#25641, timestamp#25630, vehicle_count#25631]
                                                         +- Relation [_id#25623,congestion_level#25624,lat#25625,lon#25626,road_id#25627,road_name#25628,speed#25629,timestamp#25630,vehicle_count#25631] MongoRelation(MongoRDD[1521] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:13,421 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:18 +07)" executed successfully
2026-01-06 12:38:18,167 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:23 +07)" (scheduled at 2026-01-06 12:38:18.157382+07:00)
2026-01-06 12:38:18,167 - INFO -  Training Spark model...
2026-01-06 12:38:18,401 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_change#26002, vehicle_count_lag#26020, vehicle_count_change#26039, avg(speed#25860) windowspecdefinition(road_id#25846, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#26060]
+- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_change#26002, vehicle_count_lag#26020, CASE WHEN isnotnull(vehicle_count_lag#26020) THEN (vehicle_count#25870 - vehicle_count_lag#26020) ELSE 0.0 END AS vehicle_count_change#26039]
   +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_change#26002, vehicle_count_lag#26020]
      +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_change#26002, vehicle_count_lag#26020, vehicle_count_lag#26020]
         +- Window [lag(vehicle_count#25870, -1, null) windowspecdefinition(road_id#25846, timestamp#25849 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#26020], [road_id#25846], [timestamp#25849 ASC NULLS FIRST]
            +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_change#26002]
               +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, CASE WHEN isnotnull(speed_lag#25985) THEN (speed#25860 - speed_lag#25985) ELSE 0.0 END AS speed_change#26002]
                  +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985]
                     +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969, speed_lag#25985, speed_lag#25985]
                        +- Window [lag(speed#25860, -1, null) windowspecdefinition(road_id#25846, timestamp#25849 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#25985], [road_id#25846], [timestamp#25849 ASC NULLS FIRST]
                           +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, hour_cos#25969]
                              +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, hour_sin#25954, COS((0.2617993877991494 * cast(hour#25904 as double))) AS hour_cos#25969]
                                 +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, is_weekend#25940, SIN((0.2617993877991494 * cast(hour#25904 as double))) AS hour_sin#25954]
                                    +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, day_of_week#25927, CASE WHEN day_of_week#25927 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#25940]
                                       +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, is_peak#25915, dayofweek(cast(timestamp#25849 as date)) AS day_of_week#25927]
                                          +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour#25904, CASE WHEN hour#25904 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#25915]
                                             +- Project [_id#25842, congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870, hour(timestamp#25849, Some(Asia/Bangkok)) AS hour#25904]
                                                +- Project [_id#25842, cast(congestion_level#25843 as double) AS congestion_level#25880, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, vehicle_count#25870]
                                                   +- Project [_id#25842, congestion_level#25843, lat#25844, lon#25845, road_id#25846, road_name#25847, speed#25860, timestamp#25849, cast(vehicle_count#25850 as double) AS vehicle_count#25870]
                                                      +- Project [_id#25842, congestion_level#25843, lat#25844, lon#25845, road_id#25846, road_name#25847, cast(speed#25848 as double) AS speed#25860, timestamp#25849, vehicle_count#25850]
                                                         +- Relation [_id#25842,congestion_level#25843,lat#25844,lon#25845,road_id#25846,road_name#25847,speed#25848,timestamp#25849,vehicle_count#25850] MongoRelation(MongoRDD[1534] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:18,401 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:23 +07)" executed successfully
2026-01-06 12:38:23,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:28 +07)" (scheduled at 2026-01-06 12:38:23.157382+07:00)
2026-01-06 12:38:23,166 - INFO -  Training Spark model...
2026-01-06 12:38:23,473 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_change#26221, vehicle_count_lag#26239, vehicle_count_change#26258, avg(speed#26079) windowspecdefinition(road_id#26065, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#26279]
+- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_change#26221, vehicle_count_lag#26239, CASE WHEN isnotnull(vehicle_count_lag#26239) THEN (vehicle_count#26089 - vehicle_count_lag#26239) ELSE 0.0 END AS vehicle_count_change#26258]
   +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_change#26221, vehicle_count_lag#26239]
      +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_change#26221, vehicle_count_lag#26239, vehicle_count_lag#26239]
         +- Window [lag(vehicle_count#26089, -1, null) windowspecdefinition(road_id#26065, timestamp#26068 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#26239], [road_id#26065], [timestamp#26068 ASC NULLS FIRST]
            +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_change#26221]
               +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, CASE WHEN isnotnull(speed_lag#26204) THEN (speed#26079 - speed_lag#26204) ELSE 0.0 END AS speed_change#26221]
                  +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204]
                     +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188, speed_lag#26204, speed_lag#26204]
                        +- Window [lag(speed#26079, -1, null) windowspecdefinition(road_id#26065, timestamp#26068 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#26204], [road_id#26065], [timestamp#26068 ASC NULLS FIRST]
                           +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, hour_cos#26188]
                              +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, hour_sin#26173, COS((0.2617993877991494 * cast(hour#26123 as double))) AS hour_cos#26188]
                                 +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, is_weekend#26159, SIN((0.2617993877991494 * cast(hour#26123 as double))) AS hour_sin#26173]
                                    +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, day_of_week#26146, CASE WHEN day_of_week#26146 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#26159]
                                       +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, is_peak#26134, dayofweek(cast(timestamp#26068 as date)) AS day_of_week#26146]
                                          +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour#26123, CASE WHEN hour#26123 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#26134]
                                             +- Project [_id#26061, congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089, hour(timestamp#26068, Some(Asia/Bangkok)) AS hour#26123]
                                                +- Project [_id#26061, cast(congestion_level#26062 as double) AS congestion_level#26099, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, vehicle_count#26089]
                                                   +- Project [_id#26061, congestion_level#26062, lat#26063, lon#26064, road_id#26065, road_name#26066, speed#26079, timestamp#26068, cast(vehicle_count#26069 as double) AS vehicle_count#26089]
                                                      +- Project [_id#26061, congestion_level#26062, lat#26063, lon#26064, road_id#26065, road_name#26066, cast(speed#26067 as double) AS speed#26079, timestamp#26068, vehicle_count#26069]
                                                         +- Relation [_id#26061,congestion_level#26062,lat#26063,lon#26064,road_id#26065,road_name#26066,speed#26067,timestamp#26068,vehicle_count#26069] MongoRelation(MongoRDD[1547] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:23,473 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:28 +07)" executed successfully
2026-01-06 12:38:28,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:33 +07)" (scheduled at 2026-01-06 12:38:28.157382+07:00)
2026-01-06 12:38:28,161 - INFO -  Training Spark model...
2026-01-06 12:38:28,768 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_change#26440, vehicle_count_lag#26458, vehicle_count_change#26477, avg(speed#26298) windowspecdefinition(road_id#26284, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#26498]
+- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_change#26440, vehicle_count_lag#26458, CASE WHEN isnotnull(vehicle_count_lag#26458) THEN (vehicle_count#26308 - vehicle_count_lag#26458) ELSE 0.0 END AS vehicle_count_change#26477]
   +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_change#26440, vehicle_count_lag#26458]
      +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_change#26440, vehicle_count_lag#26458, vehicle_count_lag#26458]
         +- Window [lag(vehicle_count#26308, -1, null) windowspecdefinition(road_id#26284, timestamp#26287 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#26458], [road_id#26284], [timestamp#26287 ASC NULLS FIRST]
            +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_change#26440]
               +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, CASE WHEN isnotnull(speed_lag#26423) THEN (speed#26298 - speed_lag#26423) ELSE 0.0 END AS speed_change#26440]
                  +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423]
                     +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407, speed_lag#26423, speed_lag#26423]
                        +- Window [lag(speed#26298, -1, null) windowspecdefinition(road_id#26284, timestamp#26287 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#26423], [road_id#26284], [timestamp#26287 ASC NULLS FIRST]
                           +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, hour_cos#26407]
                              +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, hour_sin#26392, COS((0.2617993877991494 * cast(hour#26342 as double))) AS hour_cos#26407]
                                 +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, is_weekend#26378, SIN((0.2617993877991494 * cast(hour#26342 as double))) AS hour_sin#26392]
                                    +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, day_of_week#26365, CASE WHEN day_of_week#26365 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#26378]
                                       +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, is_peak#26353, dayofweek(cast(timestamp#26287 as date)) AS day_of_week#26365]
                                          +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour#26342, CASE WHEN hour#26342 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#26353]
                                             +- Project [_id#26280, congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308, hour(timestamp#26287, Some(Asia/Bangkok)) AS hour#26342]
                                                +- Project [_id#26280, cast(congestion_level#26281 as double) AS congestion_level#26318, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, vehicle_count#26308]
                                                   +- Project [_id#26280, congestion_level#26281, lat#26282, lon#26283, road_id#26284, road_name#26285, speed#26298, timestamp#26287, cast(vehicle_count#26288 as double) AS vehicle_count#26308]
                                                      +- Project [_id#26280, congestion_level#26281, lat#26282, lon#26283, road_id#26284, road_name#26285, cast(speed#26286 as double) AS speed#26298, timestamp#26287, vehicle_count#26288]
                                                         +- Relation [_id#26280,congestion_level#26281,lat#26282,lon#26283,road_id#26284,road_name#26285,speed#26286,timestamp#26287,vehicle_count#26288] MongoRelation(MongoRDD[1560] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:28,768 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:33 +07)" executed successfully
2026-01-06 12:38:33,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:38 +07)" (scheduled at 2026-01-06 12:38:33.157382+07:00)
2026-01-06 12:38:33,161 - INFO -  Training Spark model...
2026-01-06 12:38:33,554 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_change#26659, vehicle_count_lag#26677, vehicle_count_change#26696, avg(speed#26517) windowspecdefinition(road_id#26503, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#26717]
+- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_change#26659, vehicle_count_lag#26677, CASE WHEN isnotnull(vehicle_count_lag#26677) THEN (vehicle_count#26527 - vehicle_count_lag#26677) ELSE 0.0 END AS vehicle_count_change#26696]
   +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_change#26659, vehicle_count_lag#26677]
      +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_change#26659, vehicle_count_lag#26677, vehicle_count_lag#26677]
         +- Window [lag(vehicle_count#26527, -1, null) windowspecdefinition(road_id#26503, timestamp#26506 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#26677], [road_id#26503], [timestamp#26506 ASC NULLS FIRST]
            +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_change#26659]
               +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, CASE WHEN isnotnull(speed_lag#26642) THEN (speed#26517 - speed_lag#26642) ELSE 0.0 END AS speed_change#26659]
                  +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642]
                     +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626, speed_lag#26642, speed_lag#26642]
                        +- Window [lag(speed#26517, -1, null) windowspecdefinition(road_id#26503, timestamp#26506 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#26642], [road_id#26503], [timestamp#26506 ASC NULLS FIRST]
                           +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, hour_cos#26626]
                              +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, hour_sin#26611, COS((0.2617993877991494 * cast(hour#26561 as double))) AS hour_cos#26626]
                                 +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, is_weekend#26597, SIN((0.2617993877991494 * cast(hour#26561 as double))) AS hour_sin#26611]
                                    +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, day_of_week#26584, CASE WHEN day_of_week#26584 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#26597]
                                       +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, is_peak#26572, dayofweek(cast(timestamp#26506 as date)) AS day_of_week#26584]
                                          +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour#26561, CASE WHEN hour#26561 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#26572]
                                             +- Project [_id#26499, congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527, hour(timestamp#26506, Some(Asia/Bangkok)) AS hour#26561]
                                                +- Project [_id#26499, cast(congestion_level#26500 as double) AS congestion_level#26537, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, vehicle_count#26527]
                                                   +- Project [_id#26499, congestion_level#26500, lat#26501, lon#26502, road_id#26503, road_name#26504, speed#26517, timestamp#26506, cast(vehicle_count#26507 as double) AS vehicle_count#26527]
                                                      +- Project [_id#26499, congestion_level#26500, lat#26501, lon#26502, road_id#26503, road_name#26504, cast(speed#26505 as double) AS speed#26517, timestamp#26506, vehicle_count#26507]
                                                         +- Relation [_id#26499,congestion_level#26500,lat#26501,lon#26502,road_id#26503,road_name#26504,speed#26505,timestamp#26506,vehicle_count#26507] MongoRelation(MongoRDD[1573] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:33,554 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:38 +07)" executed successfully
2026-01-06 12:38:38,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:43 +07)" (scheduled at 2026-01-06 12:38:38.157382+07:00)
2026-01-06 12:38:38,160 - INFO -  Training Spark model...
2026-01-06 12:38:38,430 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_change#26878, vehicle_count_lag#26896, vehicle_count_change#26915, avg(speed#26736) windowspecdefinition(road_id#26722, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#26936]
+- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_change#26878, vehicle_count_lag#26896, CASE WHEN isnotnull(vehicle_count_lag#26896) THEN (vehicle_count#26746 - vehicle_count_lag#26896) ELSE 0.0 END AS vehicle_count_change#26915]
   +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_change#26878, vehicle_count_lag#26896]
      +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_change#26878, vehicle_count_lag#26896, vehicle_count_lag#26896]
         +- Window [lag(vehicle_count#26746, -1, null) windowspecdefinition(road_id#26722, timestamp#26725 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#26896], [road_id#26722], [timestamp#26725 ASC NULLS FIRST]
            +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_change#26878]
               +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, CASE WHEN isnotnull(speed_lag#26861) THEN (speed#26736 - speed_lag#26861) ELSE 0.0 END AS speed_change#26878]
                  +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861]
                     +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845, speed_lag#26861, speed_lag#26861]
                        +- Window [lag(speed#26736, -1, null) windowspecdefinition(road_id#26722, timestamp#26725 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#26861], [road_id#26722], [timestamp#26725 ASC NULLS FIRST]
                           +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, hour_cos#26845]
                              +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, hour_sin#26830, COS((0.2617993877991494 * cast(hour#26780 as double))) AS hour_cos#26845]
                                 +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, is_weekend#26816, SIN((0.2617993877991494 * cast(hour#26780 as double))) AS hour_sin#26830]
                                    +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, day_of_week#26803, CASE WHEN day_of_week#26803 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#26816]
                                       +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, is_peak#26791, dayofweek(cast(timestamp#26725 as date)) AS day_of_week#26803]
                                          +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour#26780, CASE WHEN hour#26780 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#26791]
                                             +- Project [_id#26718, congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746, hour(timestamp#26725, Some(Asia/Bangkok)) AS hour#26780]
                                                +- Project [_id#26718, cast(congestion_level#26719 as double) AS congestion_level#26756, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, vehicle_count#26746]
                                                   +- Project [_id#26718, congestion_level#26719, lat#26720, lon#26721, road_id#26722, road_name#26723, speed#26736, timestamp#26725, cast(vehicle_count#26726 as double) AS vehicle_count#26746]
                                                      +- Project [_id#26718, congestion_level#26719, lat#26720, lon#26721, road_id#26722, road_name#26723, cast(speed#26724 as double) AS speed#26736, timestamp#26725, vehicle_count#26726]
                                                         +- Relation [_id#26718,congestion_level#26719,lat#26720,lon#26721,road_id#26722,road_name#26723,speed#26724,timestamp#26725,vehicle_count#26726] MongoRelation(MongoRDD[1586] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:38,430 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:43 +07)" executed successfully
2026-01-06 12:38:43,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:48 +07)" (scheduled at 2026-01-06 12:38:43.157382+07:00)
2026-01-06 12:38:43,158 - INFO -  Training Spark model...
2026-01-06 12:38:43,461 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_change#27097, vehicle_count_lag#27115, vehicle_count_change#27134, avg(speed#26955) windowspecdefinition(road_id#26941, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#27155]
+- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_change#27097, vehicle_count_lag#27115, CASE WHEN isnotnull(vehicle_count_lag#27115) THEN (vehicle_count#26965 - vehicle_count_lag#27115) ELSE 0.0 END AS vehicle_count_change#27134]
   +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_change#27097, vehicle_count_lag#27115]
      +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_change#27097, vehicle_count_lag#27115, vehicle_count_lag#27115]
         +- Window [lag(vehicle_count#26965, -1, null) windowspecdefinition(road_id#26941, timestamp#26944 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#27115], [road_id#26941], [timestamp#26944 ASC NULLS FIRST]
            +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_change#27097]
               +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, CASE WHEN isnotnull(speed_lag#27080) THEN (speed#26955 - speed_lag#27080) ELSE 0.0 END AS speed_change#27097]
                  +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080]
                     +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064, speed_lag#27080, speed_lag#27080]
                        +- Window [lag(speed#26955, -1, null) windowspecdefinition(road_id#26941, timestamp#26944 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#27080], [road_id#26941], [timestamp#26944 ASC NULLS FIRST]
                           +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, hour_cos#27064]
                              +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, hour_sin#27049, COS((0.2617993877991494 * cast(hour#26999 as double))) AS hour_cos#27064]
                                 +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, is_weekend#27035, SIN((0.2617993877991494 * cast(hour#26999 as double))) AS hour_sin#27049]
                                    +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, day_of_week#27022, CASE WHEN day_of_week#27022 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#27035]
                                       +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, is_peak#27010, dayofweek(cast(timestamp#26944 as date)) AS day_of_week#27022]
                                          +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour#26999, CASE WHEN hour#26999 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#27010]
                                             +- Project [_id#26937, congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965, hour(timestamp#26944, Some(Asia/Bangkok)) AS hour#26999]
                                                +- Project [_id#26937, cast(congestion_level#26938 as double) AS congestion_level#26975, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, vehicle_count#26965]
                                                   +- Project [_id#26937, congestion_level#26938, lat#26939, lon#26940, road_id#26941, road_name#26942, speed#26955, timestamp#26944, cast(vehicle_count#26945 as double) AS vehicle_count#26965]
                                                      +- Project [_id#26937, congestion_level#26938, lat#26939, lon#26940, road_id#26941, road_name#26942, cast(speed#26943 as double) AS speed#26955, timestamp#26944, vehicle_count#26945]
                                                         +- Relation [_id#26937,congestion_level#26938,lat#26939,lon#26940,road_id#26941,road_name#26942,speed#26943,timestamp#26944,vehicle_count#26945] MongoRelation(MongoRDD[1599] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:43,461 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:48 +07)" executed successfully
2026-01-06 12:38:48,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:53 +07)" (scheduled at 2026-01-06 12:38:48.157382+07:00)
2026-01-06 12:38:48,158 - INFO -  Training Spark model...
2026-01-06 12:38:48,463 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_change#27316, vehicle_count_lag#27334, vehicle_count_change#27353, avg(speed#27174) windowspecdefinition(road_id#27160, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#27374]
+- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_change#27316, vehicle_count_lag#27334, CASE WHEN isnotnull(vehicle_count_lag#27334) THEN (vehicle_count#27184 - vehicle_count_lag#27334) ELSE 0.0 END AS vehicle_count_change#27353]
   +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_change#27316, vehicle_count_lag#27334]
      +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_change#27316, vehicle_count_lag#27334, vehicle_count_lag#27334]
         +- Window [lag(vehicle_count#27184, -1, null) windowspecdefinition(road_id#27160, timestamp#27163 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#27334], [road_id#27160], [timestamp#27163 ASC NULLS FIRST]
            +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_change#27316]
               +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, CASE WHEN isnotnull(speed_lag#27299) THEN (speed#27174 - speed_lag#27299) ELSE 0.0 END AS speed_change#27316]
                  +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299]
                     +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283, speed_lag#27299, speed_lag#27299]
                        +- Window [lag(speed#27174, -1, null) windowspecdefinition(road_id#27160, timestamp#27163 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#27299], [road_id#27160], [timestamp#27163 ASC NULLS FIRST]
                           +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, hour_cos#27283]
                              +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, hour_sin#27268, COS((0.2617993877991494 * cast(hour#27218 as double))) AS hour_cos#27283]
                                 +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, is_weekend#27254, SIN((0.2617993877991494 * cast(hour#27218 as double))) AS hour_sin#27268]
                                    +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, day_of_week#27241, CASE WHEN day_of_week#27241 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#27254]
                                       +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, is_peak#27229, dayofweek(cast(timestamp#27163 as date)) AS day_of_week#27241]
                                          +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour#27218, CASE WHEN hour#27218 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#27229]
                                             +- Project [_id#27156, congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184, hour(timestamp#27163, Some(Asia/Bangkok)) AS hour#27218]
                                                +- Project [_id#27156, cast(congestion_level#27157 as double) AS congestion_level#27194, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, vehicle_count#27184]
                                                   +- Project [_id#27156, congestion_level#27157, lat#27158, lon#27159, road_id#27160, road_name#27161, speed#27174, timestamp#27163, cast(vehicle_count#27164 as double) AS vehicle_count#27184]
                                                      +- Project [_id#27156, congestion_level#27157, lat#27158, lon#27159, road_id#27160, road_name#27161, cast(speed#27162 as double) AS speed#27174, timestamp#27163, vehicle_count#27164]
                                                         +- Relation [_id#27156,congestion_level#27157,lat#27158,lon#27159,road_id#27160,road_name#27161,speed#27162,timestamp#27163,vehicle_count#27164] MongoRelation(MongoRDD[1612] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:48,464 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:53 +07)" executed successfully
2026-01-06 12:38:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:58 +07)" (scheduled at 2026-01-06 12:38:53.157382+07:00)
2026-01-06 12:38:53,160 - INFO -  Training Spark model...
2026-01-06 12:38:53,418 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_change#27535, vehicle_count_lag#27553, vehicle_count_change#27572, avg(speed#27393) windowspecdefinition(road_id#27379, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#27593]
+- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_change#27535, vehicle_count_lag#27553, CASE WHEN isnotnull(vehicle_count_lag#27553) THEN (vehicle_count#27403 - vehicle_count_lag#27553) ELSE 0.0 END AS vehicle_count_change#27572]
   +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_change#27535, vehicle_count_lag#27553]
      +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_change#27535, vehicle_count_lag#27553, vehicle_count_lag#27553]
         +- Window [lag(vehicle_count#27403, -1, null) windowspecdefinition(road_id#27379, timestamp#27382 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#27553], [road_id#27379], [timestamp#27382 ASC NULLS FIRST]
            +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_change#27535]
               +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, CASE WHEN isnotnull(speed_lag#27518) THEN (speed#27393 - speed_lag#27518) ELSE 0.0 END AS speed_change#27535]
                  +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518]
                     +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502, speed_lag#27518, speed_lag#27518]
                        +- Window [lag(speed#27393, -1, null) windowspecdefinition(road_id#27379, timestamp#27382 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#27518], [road_id#27379], [timestamp#27382 ASC NULLS FIRST]
                           +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, hour_cos#27502]
                              +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, hour_sin#27487, COS((0.2617993877991494 * cast(hour#27437 as double))) AS hour_cos#27502]
                                 +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, is_weekend#27473, SIN((0.2617993877991494 * cast(hour#27437 as double))) AS hour_sin#27487]
                                    +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, day_of_week#27460, CASE WHEN day_of_week#27460 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#27473]
                                       +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, is_peak#27448, dayofweek(cast(timestamp#27382 as date)) AS day_of_week#27460]
                                          +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour#27437, CASE WHEN hour#27437 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#27448]
                                             +- Project [_id#27375, congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403, hour(timestamp#27382, Some(Asia/Bangkok)) AS hour#27437]
                                                +- Project [_id#27375, cast(congestion_level#27376 as double) AS congestion_level#27413, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, vehicle_count#27403]
                                                   +- Project [_id#27375, congestion_level#27376, lat#27377, lon#27378, road_id#27379, road_name#27380, speed#27393, timestamp#27382, cast(vehicle_count#27383 as double) AS vehicle_count#27403]
                                                      +- Project [_id#27375, congestion_level#27376, lat#27377, lon#27378, road_id#27379, road_name#27380, cast(speed#27381 as double) AS speed#27393, timestamp#27382, vehicle_count#27383]
                                                         +- Relation [_id#27375,congestion_level#27376,lat#27377,lon#27378,road_id#27379,road_name#27380,speed#27381,timestamp#27382,vehicle_count#27383] MongoRelation(MongoRDD[1625] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:53,418 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:38:58 +07)" executed successfully
2026-01-06 12:38:58,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:03 +07)" (scheduled at 2026-01-06 12:38:58.157382+07:00)
2026-01-06 12:38:58,158 - INFO -  Training Spark model...
2026-01-06 12:38:58,471 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_change#27754, vehicle_count_lag#27772, vehicle_count_change#27791, avg(speed#27612) windowspecdefinition(road_id#27598, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#27812]
+- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_change#27754, vehicle_count_lag#27772, CASE WHEN isnotnull(vehicle_count_lag#27772) THEN (vehicle_count#27622 - vehicle_count_lag#27772) ELSE 0.0 END AS vehicle_count_change#27791]
   +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_change#27754, vehicle_count_lag#27772]
      +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_change#27754, vehicle_count_lag#27772, vehicle_count_lag#27772]
         +- Window [lag(vehicle_count#27622, -1, null) windowspecdefinition(road_id#27598, timestamp#27601 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#27772], [road_id#27598], [timestamp#27601 ASC NULLS FIRST]
            +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_change#27754]
               +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, CASE WHEN isnotnull(speed_lag#27737) THEN (speed#27612 - speed_lag#27737) ELSE 0.0 END AS speed_change#27754]
                  +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737]
                     +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721, speed_lag#27737, speed_lag#27737]
                        +- Window [lag(speed#27612, -1, null) windowspecdefinition(road_id#27598, timestamp#27601 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#27737], [road_id#27598], [timestamp#27601 ASC NULLS FIRST]
                           +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, hour_cos#27721]
                              +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, hour_sin#27706, COS((0.2617993877991494 * cast(hour#27656 as double))) AS hour_cos#27721]
                                 +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, is_weekend#27692, SIN((0.2617993877991494 * cast(hour#27656 as double))) AS hour_sin#27706]
                                    +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, day_of_week#27679, CASE WHEN day_of_week#27679 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#27692]
                                       +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, is_peak#27667, dayofweek(cast(timestamp#27601 as date)) AS day_of_week#27679]
                                          +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour#27656, CASE WHEN hour#27656 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#27667]
                                             +- Project [_id#27594, congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622, hour(timestamp#27601, Some(Asia/Bangkok)) AS hour#27656]
                                                +- Project [_id#27594, cast(congestion_level#27595 as double) AS congestion_level#27632, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, vehicle_count#27622]
                                                   +- Project [_id#27594, congestion_level#27595, lat#27596, lon#27597, road_id#27598, road_name#27599, speed#27612, timestamp#27601, cast(vehicle_count#27602 as double) AS vehicle_count#27622]
                                                      +- Project [_id#27594, congestion_level#27595, lat#27596, lon#27597, road_id#27598, road_name#27599, cast(speed#27600 as double) AS speed#27612, timestamp#27601, vehicle_count#27602]
                                                         +- Relation [_id#27594,congestion_level#27595,lat#27596,lon#27597,road_id#27598,road_name#27599,speed#27600,timestamp#27601,vehicle_count#27602] MongoRelation(MongoRDD[1638] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:38:58,473 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:03 +07)" executed successfully
2026-01-06 12:39:03,167 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:08 +07)" (scheduled at 2026-01-06 12:39:03.157382+07:00)
2026-01-06 12:39:03,167 - INFO -  Training Spark model...
2026-01-06 12:39:03,466 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_change#27973, vehicle_count_lag#27991, vehicle_count_change#28010, avg(speed#27831) windowspecdefinition(road_id#27817, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#28031]
+- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_change#27973, vehicle_count_lag#27991, CASE WHEN isnotnull(vehicle_count_lag#27991) THEN (vehicle_count#27841 - vehicle_count_lag#27991) ELSE 0.0 END AS vehicle_count_change#28010]
   +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_change#27973, vehicle_count_lag#27991]
      +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_change#27973, vehicle_count_lag#27991, vehicle_count_lag#27991]
         +- Window [lag(vehicle_count#27841, -1, null) windowspecdefinition(road_id#27817, timestamp#27820 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#27991], [road_id#27817], [timestamp#27820 ASC NULLS FIRST]
            +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_change#27973]
               +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, CASE WHEN isnotnull(speed_lag#27956) THEN (speed#27831 - speed_lag#27956) ELSE 0.0 END AS speed_change#27973]
                  +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956]
                     +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940, speed_lag#27956, speed_lag#27956]
                        +- Window [lag(speed#27831, -1, null) windowspecdefinition(road_id#27817, timestamp#27820 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#27956], [road_id#27817], [timestamp#27820 ASC NULLS FIRST]
                           +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, hour_cos#27940]
                              +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, hour_sin#27925, COS((0.2617993877991494 * cast(hour#27875 as double))) AS hour_cos#27940]
                                 +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, is_weekend#27911, SIN((0.2617993877991494 * cast(hour#27875 as double))) AS hour_sin#27925]
                                    +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, day_of_week#27898, CASE WHEN day_of_week#27898 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#27911]
                                       +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, is_peak#27886, dayofweek(cast(timestamp#27820 as date)) AS day_of_week#27898]
                                          +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour#27875, CASE WHEN hour#27875 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#27886]
                                             +- Project [_id#27813, congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841, hour(timestamp#27820, Some(Asia/Bangkok)) AS hour#27875]
                                                +- Project [_id#27813, cast(congestion_level#27814 as double) AS congestion_level#27851, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, vehicle_count#27841]
                                                   +- Project [_id#27813, congestion_level#27814, lat#27815, lon#27816, road_id#27817, road_name#27818, speed#27831, timestamp#27820, cast(vehicle_count#27821 as double) AS vehicle_count#27841]
                                                      +- Project [_id#27813, congestion_level#27814, lat#27815, lon#27816, road_id#27817, road_name#27818, cast(speed#27819 as double) AS speed#27831, timestamp#27820, vehicle_count#27821]
                                                         +- Relation [_id#27813,congestion_level#27814,lat#27815,lon#27816,road_id#27817,road_name#27818,speed#27819,timestamp#27820,vehicle_count#27821] MongoRelation(MongoRDD[1651] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:03,466 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:08 +07)" executed successfully
2026-01-06 12:39:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:13 +07)" (scheduled at 2026-01-06 12:39:08.157382+07:00)
2026-01-06 12:39:08,158 - INFO -  Training Spark model...
2026-01-06 12:39:08,159 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:40:08 +07)" (scheduled at 2026-01-06 12:39:08.157779+07:00)
2026-01-06 12:39:08,159 - INFO -  Training Spark model...
2026-01-06 12:39:08,783 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_change#28336, vehicle_count_lag#28370, vehicle_count_change#28426, avg(speed#28068) windowspecdefinition(road_id#28036, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#28467]
+- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_change#28336, vehicle_count_lag#28370, CASE WHEN isnotnull(vehicle_count_lag#28370) THEN (vehicle_count#28088 - vehicle_count_lag#28370) ELSE 0.0 END AS vehicle_count_change#28426]
   +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_change#28336, vehicle_count_lag#28370]
      +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_change#28336, vehicle_count_lag#28370, vehicle_count_lag#28370]
         +- Window [lag(vehicle_count#28088, -1, null) windowspecdefinition(road_id#28036, timestamp#28039 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#28370], [road_id#28036], [timestamp#28039 ASC NULLS FIRST]
            +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_change#28336]
               +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, CASE WHEN isnotnull(speed_lag#28318) THEN (speed#28068 - speed_lag#28318) ELSE 0.0 END AS speed_change#28336]
                  +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318]
                     +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272, speed_lag#28318, speed_lag#28318]
                        +- Window [lag(speed#28068, -1, null) windowspecdefinition(road_id#28036, timestamp#28039 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#28318], [road_id#28036], [timestamp#28039 ASC NULLS FIRST]
                           +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, hour_cos#28272]
                              +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, hour_sin#28243, COS((0.2617993877991494 * cast(hour#28157 as double))) AS hour_cos#28272]
                                 +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, is_weekend#28228, SIN((0.2617993877991494 * cast(hour#28157 as double))) AS hour_sin#28243]
                                    +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, day_of_week#28190, CASE WHEN day_of_week#28190 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#28228]
                                       +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, is_peak#28178, dayofweek(cast(timestamp#28039 as date)) AS day_of_week#28190]
                                          +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour#28157, CASE WHEN hour#28157 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#28178]
                                             +- Project [_id#28032, congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088, hour(timestamp#28039, Some(Asia/Bangkok)) AS hour#28157]
                                                +- Project [_id#28032, cast(congestion_level#28033 as double) AS congestion_level#28108, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, vehicle_count#28088]
                                                   +- Project [_id#28032, congestion_level#28033, lat#28034, lon#28035, road_id#28036, road_name#28037, speed#28068, timestamp#28039, cast(vehicle_count#28040 as double) AS vehicle_count#28088]
                                                      +- Project [_id#28032, congestion_level#28033, lat#28034, lon#28035, road_id#28036, road_name#28037, cast(speed#28038 as double) AS speed#28068, timestamp#28039, vehicle_count#28040]
                                                         +- Relation [_id#28032,congestion_level#28033,lat#28034,lon#28035,road_id#28036,road_name#28037,speed#28038,timestamp#28039,vehicle_count#28040] MongoRelation(MongoRDD[1666] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:08,783 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:40:08 +07)" executed successfully
2026-01-06 12:39:08,814 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_change#28371, vehicle_count_lag#28389, vehicle_count_change#28446, avg(speed#28078) windowspecdefinition(road_id#28054, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#28469]
+- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_change#28371, vehicle_count_lag#28389, CASE WHEN isnotnull(vehicle_count_lag#28389) THEN (vehicle_count#28089 - vehicle_count_lag#28389) ELSE 0.0 END AS vehicle_count_change#28446]
   +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_change#28371, vehicle_count_lag#28389]
      +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_change#28371, vehicle_count_lag#28389, vehicle_count_lag#28389]
         +- Window [lag(vehicle_count#28089, -1, null) windowspecdefinition(road_id#28054, timestamp#28057 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#28389], [road_id#28054], [timestamp#28057 ASC NULLS FIRST]
            +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_change#28371]
               +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, CASE WHEN isnotnull(speed_lag#28335) THEN (speed#28078 - speed_lag#28335) ELSE 0.0 END AS speed_change#28371]
                  +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335]
                     +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302, speed_lag#28335, speed_lag#28335]
                        +- Window [lag(speed#28078, -1, null) windowspecdefinition(road_id#28054, timestamp#28057 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#28335], [road_id#28054], [timestamp#28057 ASC NULLS FIRST]
                           +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, hour_cos#28302]
                              +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, hour_sin#28271, COS((0.2617993877991494 * cast(hour#28156 as double))) AS hour_cos#28302]
                                 +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, is_weekend#28242, SIN((0.2617993877991494 * cast(hour#28156 as double))) AS hour_sin#28271]
                                    +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, day_of_week#28215, CASE WHEN day_of_week#28215 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#28242]
                                       +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, is_peak#28203, dayofweek(cast(timestamp#28057 as date)) AS day_of_week#28215]
                                          +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour#28156, CASE WHEN hour#28156 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#28203]
                                             +- Project [_id#28050, congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089, hour(timestamp#28057, Some(Asia/Bangkok)) AS hour#28156]
                                                +- Project [_id#28050, cast(congestion_level#28051 as double) AS congestion_level#28130, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, vehicle_count#28089]
                                                   +- Project [_id#28050, congestion_level#28051, lat#28052, lon#28053, road_id#28054, road_name#28055, speed#28078, timestamp#28057, cast(vehicle_count#28058 as double) AS vehicle_count#28089]
                                                      +- Project [_id#28050, congestion_level#28051, lat#28052, lon#28053, road_id#28054, road_name#28055, cast(speed#28056 as double) AS speed#28078, timestamp#28057, vehicle_count#28058]
                                                         +- Relation [_id#28050,congestion_level#28051,lat#28052,lon#28053,road_id#28054,road_name#28055,speed#28056,timestamp#28057,vehicle_count#28058] MongoRelation(MongoRDD[1664] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:08,814 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:13 +07)" executed successfully
2026-01-06 12:39:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:18 +07)" (scheduled at 2026-01-06 12:39:13.157382+07:00)
2026-01-06 12:39:13,158 - INFO -  Training Spark model...
2026-01-06 12:39:13,469 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_change#28630, vehicle_count_lag#28648, vehicle_count_change#28667, avg(speed#28488) windowspecdefinition(road_id#28474, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#28688]
+- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_change#28630, vehicle_count_lag#28648, CASE WHEN isnotnull(vehicle_count_lag#28648) THEN (vehicle_count#28498 - vehicle_count_lag#28648) ELSE 0.0 END AS vehicle_count_change#28667]
   +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_change#28630, vehicle_count_lag#28648]
      +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_change#28630, vehicle_count_lag#28648, vehicle_count_lag#28648]
         +- Window [lag(vehicle_count#28498, -1, null) windowspecdefinition(road_id#28474, timestamp#28477 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#28648], [road_id#28474], [timestamp#28477 ASC NULLS FIRST]
            +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_change#28630]
               +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, CASE WHEN isnotnull(speed_lag#28613) THEN (speed#28488 - speed_lag#28613) ELSE 0.0 END AS speed_change#28630]
                  +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613]
                     +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597, speed_lag#28613, speed_lag#28613]
                        +- Window [lag(speed#28488, -1, null) windowspecdefinition(road_id#28474, timestamp#28477 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#28613], [road_id#28474], [timestamp#28477 ASC NULLS FIRST]
                           +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, hour_cos#28597]
                              +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, hour_sin#28582, COS((0.2617993877991494 * cast(hour#28532 as double))) AS hour_cos#28597]
                                 +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, is_weekend#28568, SIN((0.2617993877991494 * cast(hour#28532 as double))) AS hour_sin#28582]
                                    +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, day_of_week#28555, CASE WHEN day_of_week#28555 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#28568]
                                       +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, is_peak#28543, dayofweek(cast(timestamp#28477 as date)) AS day_of_week#28555]
                                          +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour#28532, CASE WHEN hour#28532 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#28543]
                                             +- Project [_id#28470, congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498, hour(timestamp#28477, Some(Asia/Bangkok)) AS hour#28532]
                                                +- Project [_id#28470, cast(congestion_level#28471 as double) AS congestion_level#28508, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, vehicle_count#28498]
                                                   +- Project [_id#28470, congestion_level#28471, lat#28472, lon#28473, road_id#28474, road_name#28475, speed#28488, timestamp#28477, cast(vehicle_count#28478 as double) AS vehicle_count#28498]
                                                      +- Project [_id#28470, congestion_level#28471, lat#28472, lon#28473, road_id#28474, road_name#28475, cast(speed#28476 as double) AS speed#28488, timestamp#28477, vehicle_count#28478]
                                                         +- Relation [_id#28470,congestion_level#28471,lat#28472,lon#28473,road_id#28474,road_name#28475,speed#28476,timestamp#28477,vehicle_count#28478] MongoRelation(MongoRDD[1690] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:13,470 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:18 +07)" executed successfully
2026-01-06 12:39:18,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:23 +07)" (scheduled at 2026-01-06 12:39:18.157382+07:00)
2026-01-06 12:39:18,158 - INFO -  Training Spark model...
2026-01-06 12:39:18,419 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_change#28849, vehicle_count_lag#28867, vehicle_count_change#28886, avg(speed#28707) windowspecdefinition(road_id#28693, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#28907]
+- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_change#28849, vehicle_count_lag#28867, CASE WHEN isnotnull(vehicle_count_lag#28867) THEN (vehicle_count#28717 - vehicle_count_lag#28867) ELSE 0.0 END AS vehicle_count_change#28886]
   +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_change#28849, vehicle_count_lag#28867]
      +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_change#28849, vehicle_count_lag#28867, vehicle_count_lag#28867]
         +- Window [lag(vehicle_count#28717, -1, null) windowspecdefinition(road_id#28693, timestamp#28696 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#28867], [road_id#28693], [timestamp#28696 ASC NULLS FIRST]
            +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_change#28849]
               +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, CASE WHEN isnotnull(speed_lag#28832) THEN (speed#28707 - speed_lag#28832) ELSE 0.0 END AS speed_change#28849]
                  +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832]
                     +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816, speed_lag#28832, speed_lag#28832]
                        +- Window [lag(speed#28707, -1, null) windowspecdefinition(road_id#28693, timestamp#28696 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#28832], [road_id#28693], [timestamp#28696 ASC NULLS FIRST]
                           +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, hour_cos#28816]
                              +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, hour_sin#28801, COS((0.2617993877991494 * cast(hour#28751 as double))) AS hour_cos#28816]
                                 +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, is_weekend#28787, SIN((0.2617993877991494 * cast(hour#28751 as double))) AS hour_sin#28801]
                                    +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, day_of_week#28774, CASE WHEN day_of_week#28774 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#28787]
                                       +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, is_peak#28762, dayofweek(cast(timestamp#28696 as date)) AS day_of_week#28774]
                                          +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour#28751, CASE WHEN hour#28751 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#28762]
                                             +- Project [_id#28689, congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717, hour(timestamp#28696, Some(Asia/Bangkok)) AS hour#28751]
                                                +- Project [_id#28689, cast(congestion_level#28690 as double) AS congestion_level#28727, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, vehicle_count#28717]
                                                   +- Project [_id#28689, congestion_level#28690, lat#28691, lon#28692, road_id#28693, road_name#28694, speed#28707, timestamp#28696, cast(vehicle_count#28697 as double) AS vehicle_count#28717]
                                                      +- Project [_id#28689, congestion_level#28690, lat#28691, lon#28692, road_id#28693, road_name#28694, cast(speed#28695 as double) AS speed#28707, timestamp#28696, vehicle_count#28697]
                                                         +- Relation [_id#28689,congestion_level#28690,lat#28691,lon#28692,road_id#28693,road_name#28694,speed#28695,timestamp#28696,vehicle_count#28697] MongoRelation(MongoRDD[1703] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:18,419 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:23 +07)" executed successfully
2026-01-06 12:39:23,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:28 +07)" (scheduled at 2026-01-06 12:39:23.157382+07:00)
2026-01-06 12:39:23,158 - INFO -  Training Spark model...
2026-01-06 12:39:23,510 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_change#29068, vehicle_count_lag#29086, vehicle_count_change#29105, avg(speed#28926) windowspecdefinition(road_id#28912, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#29126]
+- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_change#29068, vehicle_count_lag#29086, CASE WHEN isnotnull(vehicle_count_lag#29086) THEN (vehicle_count#28936 - vehicle_count_lag#29086) ELSE 0.0 END AS vehicle_count_change#29105]
   +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_change#29068, vehicle_count_lag#29086]
      +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_change#29068, vehicle_count_lag#29086, vehicle_count_lag#29086]
         +- Window [lag(vehicle_count#28936, -1, null) windowspecdefinition(road_id#28912, timestamp#28915 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#29086], [road_id#28912], [timestamp#28915 ASC NULLS FIRST]
            +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_change#29068]
               +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, CASE WHEN isnotnull(speed_lag#29051) THEN (speed#28926 - speed_lag#29051) ELSE 0.0 END AS speed_change#29068]
                  +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051]
                     +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035, speed_lag#29051, speed_lag#29051]
                        +- Window [lag(speed#28926, -1, null) windowspecdefinition(road_id#28912, timestamp#28915 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#29051], [road_id#28912], [timestamp#28915 ASC NULLS FIRST]
                           +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, hour_cos#29035]
                              +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, hour_sin#29020, COS((0.2617993877991494 * cast(hour#28970 as double))) AS hour_cos#29035]
                                 +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, is_weekend#29006, SIN((0.2617993877991494 * cast(hour#28970 as double))) AS hour_sin#29020]
                                    +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, day_of_week#28993, CASE WHEN day_of_week#28993 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#29006]
                                       +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, is_peak#28981, dayofweek(cast(timestamp#28915 as date)) AS day_of_week#28993]
                                          +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour#28970, CASE WHEN hour#28970 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#28981]
                                             +- Project [_id#28908, congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936, hour(timestamp#28915, Some(Asia/Bangkok)) AS hour#28970]
                                                +- Project [_id#28908, cast(congestion_level#28909 as double) AS congestion_level#28946, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, vehicle_count#28936]
                                                   +- Project [_id#28908, congestion_level#28909, lat#28910, lon#28911, road_id#28912, road_name#28913, speed#28926, timestamp#28915, cast(vehicle_count#28916 as double) AS vehicle_count#28936]
                                                      +- Project [_id#28908, congestion_level#28909, lat#28910, lon#28911, road_id#28912, road_name#28913, cast(speed#28914 as double) AS speed#28926, timestamp#28915, vehicle_count#28916]
                                                         +- Relation [_id#28908,congestion_level#28909,lat#28910,lon#28911,road_id#28912,road_name#28913,speed#28914,timestamp#28915,vehicle_count#28916] MongoRelation(MongoRDD[1716] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:23,510 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:28 +07)" executed successfully
2026-01-06 12:39:28,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:33 +07)" (scheduled at 2026-01-06 12:39:28.157382+07:00)
2026-01-06 12:39:28,159 - INFO -  Training Spark model...
2026-01-06 12:39:28,413 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_change#29287, vehicle_count_lag#29305, vehicle_count_change#29324, avg(speed#29145) windowspecdefinition(road_id#29131, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#29345]
+- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_change#29287, vehicle_count_lag#29305, CASE WHEN isnotnull(vehicle_count_lag#29305) THEN (vehicle_count#29155 - vehicle_count_lag#29305) ELSE 0.0 END AS vehicle_count_change#29324]
   +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_change#29287, vehicle_count_lag#29305]
      +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_change#29287, vehicle_count_lag#29305, vehicle_count_lag#29305]
         +- Window [lag(vehicle_count#29155, -1, null) windowspecdefinition(road_id#29131, timestamp#29134 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#29305], [road_id#29131], [timestamp#29134 ASC NULLS FIRST]
            +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_change#29287]
               +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, CASE WHEN isnotnull(speed_lag#29270) THEN (speed#29145 - speed_lag#29270) ELSE 0.0 END AS speed_change#29287]
                  +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270]
                     +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254, speed_lag#29270, speed_lag#29270]
                        +- Window [lag(speed#29145, -1, null) windowspecdefinition(road_id#29131, timestamp#29134 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#29270], [road_id#29131], [timestamp#29134 ASC NULLS FIRST]
                           +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, hour_cos#29254]
                              +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, hour_sin#29239, COS((0.2617993877991494 * cast(hour#29189 as double))) AS hour_cos#29254]
                                 +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, is_weekend#29225, SIN((0.2617993877991494 * cast(hour#29189 as double))) AS hour_sin#29239]
                                    +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, day_of_week#29212, CASE WHEN day_of_week#29212 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#29225]
                                       +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, is_peak#29200, dayofweek(cast(timestamp#29134 as date)) AS day_of_week#29212]
                                          +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour#29189, CASE WHEN hour#29189 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#29200]
                                             +- Project [_id#29127, congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155, hour(timestamp#29134, Some(Asia/Bangkok)) AS hour#29189]
                                                +- Project [_id#29127, cast(congestion_level#29128 as double) AS congestion_level#29165, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, vehicle_count#29155]
                                                   +- Project [_id#29127, congestion_level#29128, lat#29129, lon#29130, road_id#29131, road_name#29132, speed#29145, timestamp#29134, cast(vehicle_count#29135 as double) AS vehicle_count#29155]
                                                      +- Project [_id#29127, congestion_level#29128, lat#29129, lon#29130, road_id#29131, road_name#29132, cast(speed#29133 as double) AS speed#29145, timestamp#29134, vehicle_count#29135]
                                                         +- Relation [_id#29127,congestion_level#29128,lat#29129,lon#29130,road_id#29131,road_name#29132,speed#29133,timestamp#29134,vehicle_count#29135] MongoRelation(MongoRDD[1729] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:28,414 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:33 +07)" executed successfully
2026-01-06 12:39:33,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:38 +07)" (scheduled at 2026-01-06 12:39:33.157382+07:00)
2026-01-06 12:39:33,158 - INFO -  Training Spark model...
2026-01-06 12:39:33,787 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_change#29506, vehicle_count_lag#29524, vehicle_count_change#29543, avg(speed#29364) windowspecdefinition(road_id#29350, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#29564]
+- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_change#29506, vehicle_count_lag#29524, CASE WHEN isnotnull(vehicle_count_lag#29524) THEN (vehicle_count#29374 - vehicle_count_lag#29524) ELSE 0.0 END AS vehicle_count_change#29543]
   +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_change#29506, vehicle_count_lag#29524]
      +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_change#29506, vehicle_count_lag#29524, vehicle_count_lag#29524]
         +- Window [lag(vehicle_count#29374, -1, null) windowspecdefinition(road_id#29350, timestamp#29353 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#29524], [road_id#29350], [timestamp#29353 ASC NULLS FIRST]
            +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_change#29506]
               +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, CASE WHEN isnotnull(speed_lag#29489) THEN (speed#29364 - speed_lag#29489) ELSE 0.0 END AS speed_change#29506]
                  +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489]
                     +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473, speed_lag#29489, speed_lag#29489]
                        +- Window [lag(speed#29364, -1, null) windowspecdefinition(road_id#29350, timestamp#29353 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#29489], [road_id#29350], [timestamp#29353 ASC NULLS FIRST]
                           +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, hour_cos#29473]
                              +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, hour_sin#29458, COS((0.2617993877991494 * cast(hour#29408 as double))) AS hour_cos#29473]
                                 +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, is_weekend#29444, SIN((0.2617993877991494 * cast(hour#29408 as double))) AS hour_sin#29458]
                                    +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, day_of_week#29431, CASE WHEN day_of_week#29431 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#29444]
                                       +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, is_peak#29419, dayofweek(cast(timestamp#29353 as date)) AS day_of_week#29431]
                                          +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour#29408, CASE WHEN hour#29408 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#29419]
                                             +- Project [_id#29346, congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374, hour(timestamp#29353, Some(Asia/Bangkok)) AS hour#29408]
                                                +- Project [_id#29346, cast(congestion_level#29347 as double) AS congestion_level#29384, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, vehicle_count#29374]
                                                   +- Project [_id#29346, congestion_level#29347, lat#29348, lon#29349, road_id#29350, road_name#29351, speed#29364, timestamp#29353, cast(vehicle_count#29354 as double) AS vehicle_count#29374]
                                                      +- Project [_id#29346, congestion_level#29347, lat#29348, lon#29349, road_id#29350, road_name#29351, cast(speed#29352 as double) AS speed#29364, timestamp#29353, vehicle_count#29354]
                                                         +- Relation [_id#29346,congestion_level#29347,lat#29348,lon#29349,road_id#29350,road_name#29351,speed#29352,timestamp#29353,vehicle_count#29354] MongoRelation(MongoRDD[1742] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:33,787 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:38 +07)" executed successfully
2026-01-06 12:39:38,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:43 +07)" (scheduled at 2026-01-06 12:39:38.157382+07:00)
2026-01-06 12:39:38,159 - INFO -  Training Spark model...
2026-01-06 12:39:38,465 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_change#29725, vehicle_count_lag#29743, vehicle_count_change#29762, avg(speed#29583) windowspecdefinition(road_id#29569, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#29783]
+- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_change#29725, vehicle_count_lag#29743, CASE WHEN isnotnull(vehicle_count_lag#29743) THEN (vehicle_count#29593 - vehicle_count_lag#29743) ELSE 0.0 END AS vehicle_count_change#29762]
   +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_change#29725, vehicle_count_lag#29743]
      +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_change#29725, vehicle_count_lag#29743, vehicle_count_lag#29743]
         +- Window [lag(vehicle_count#29593, -1, null) windowspecdefinition(road_id#29569, timestamp#29572 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#29743], [road_id#29569], [timestamp#29572 ASC NULLS FIRST]
            +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_change#29725]
               +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, CASE WHEN isnotnull(speed_lag#29708) THEN (speed#29583 - speed_lag#29708) ELSE 0.0 END AS speed_change#29725]
                  +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708]
                     +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692, speed_lag#29708, speed_lag#29708]
                        +- Window [lag(speed#29583, -1, null) windowspecdefinition(road_id#29569, timestamp#29572 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#29708], [road_id#29569], [timestamp#29572 ASC NULLS FIRST]
                           +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, hour_cos#29692]
                              +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, hour_sin#29677, COS((0.2617993877991494 * cast(hour#29627 as double))) AS hour_cos#29692]
                                 +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, is_weekend#29663, SIN((0.2617993877991494 * cast(hour#29627 as double))) AS hour_sin#29677]
                                    +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, day_of_week#29650, CASE WHEN day_of_week#29650 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#29663]
                                       +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, is_peak#29638, dayofweek(cast(timestamp#29572 as date)) AS day_of_week#29650]
                                          +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour#29627, CASE WHEN hour#29627 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#29638]
                                             +- Project [_id#29565, congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593, hour(timestamp#29572, Some(Asia/Bangkok)) AS hour#29627]
                                                +- Project [_id#29565, cast(congestion_level#29566 as double) AS congestion_level#29603, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, vehicle_count#29593]
                                                   +- Project [_id#29565, congestion_level#29566, lat#29567, lon#29568, road_id#29569, road_name#29570, speed#29583, timestamp#29572, cast(vehicle_count#29573 as double) AS vehicle_count#29593]
                                                      +- Project [_id#29565, congestion_level#29566, lat#29567, lon#29568, road_id#29569, road_name#29570, cast(speed#29571 as double) AS speed#29583, timestamp#29572, vehicle_count#29573]
                                                         +- Relation [_id#29565,congestion_level#29566,lat#29567,lon#29568,road_id#29569,road_name#29570,speed#29571,timestamp#29572,vehicle_count#29573] MongoRelation(MongoRDD[1755] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:38,465 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:43 +07)" executed successfully
2026-01-06 12:39:43,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:48 +07)" (scheduled at 2026-01-06 12:39:43.157382+07:00)
2026-01-06 12:39:43,159 - INFO -  Training Spark model...
2026-01-06 12:39:43,407 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_change#29944, vehicle_count_lag#29962, vehicle_count_change#29981, avg(speed#29802) windowspecdefinition(road_id#29788, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#30002]
+- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_change#29944, vehicle_count_lag#29962, CASE WHEN isnotnull(vehicle_count_lag#29962) THEN (vehicle_count#29812 - vehicle_count_lag#29962) ELSE 0.0 END AS vehicle_count_change#29981]
   +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_change#29944, vehicle_count_lag#29962]
      +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_change#29944, vehicle_count_lag#29962, vehicle_count_lag#29962]
         +- Window [lag(vehicle_count#29812, -1, null) windowspecdefinition(road_id#29788, timestamp#29791 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#29962], [road_id#29788], [timestamp#29791 ASC NULLS FIRST]
            +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_change#29944]
               +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, CASE WHEN isnotnull(speed_lag#29927) THEN (speed#29802 - speed_lag#29927) ELSE 0.0 END AS speed_change#29944]
                  +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927]
                     +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911, speed_lag#29927, speed_lag#29927]
                        +- Window [lag(speed#29802, -1, null) windowspecdefinition(road_id#29788, timestamp#29791 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#29927], [road_id#29788], [timestamp#29791 ASC NULLS FIRST]
                           +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, hour_cos#29911]
                              +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, hour_sin#29896, COS((0.2617993877991494 * cast(hour#29846 as double))) AS hour_cos#29911]
                                 +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, is_weekend#29882, SIN((0.2617993877991494 * cast(hour#29846 as double))) AS hour_sin#29896]
                                    +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, day_of_week#29869, CASE WHEN day_of_week#29869 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#29882]
                                       +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, is_peak#29857, dayofweek(cast(timestamp#29791 as date)) AS day_of_week#29869]
                                          +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour#29846, CASE WHEN hour#29846 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#29857]
                                             +- Project [_id#29784, congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812, hour(timestamp#29791, Some(Asia/Bangkok)) AS hour#29846]
                                                +- Project [_id#29784, cast(congestion_level#29785 as double) AS congestion_level#29822, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, vehicle_count#29812]
                                                   +- Project [_id#29784, congestion_level#29785, lat#29786, lon#29787, road_id#29788, road_name#29789, speed#29802, timestamp#29791, cast(vehicle_count#29792 as double) AS vehicle_count#29812]
                                                      +- Project [_id#29784, congestion_level#29785, lat#29786, lon#29787, road_id#29788, road_name#29789, cast(speed#29790 as double) AS speed#29802, timestamp#29791, vehicle_count#29792]
                                                         +- Relation [_id#29784,congestion_level#29785,lat#29786,lon#29787,road_id#29788,road_name#29789,speed#29790,timestamp#29791,vehicle_count#29792] MongoRelation(MongoRDD[1768] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:43,407 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:48 +07)" executed successfully
2026-01-06 12:39:48,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:53 +07)" (scheduled at 2026-01-06 12:39:48.157382+07:00)
2026-01-06 12:39:48,163 - INFO -  Training Spark model...
2026-01-06 12:39:48,417 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_change#30163, vehicle_count_lag#30181, vehicle_count_change#30200, avg(speed#30021) windowspecdefinition(road_id#30007, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#30221]
+- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_change#30163, vehicle_count_lag#30181, CASE WHEN isnotnull(vehicle_count_lag#30181) THEN (vehicle_count#30031 - vehicle_count_lag#30181) ELSE 0.0 END AS vehicle_count_change#30200]
   +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_change#30163, vehicle_count_lag#30181]
      +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_change#30163, vehicle_count_lag#30181, vehicle_count_lag#30181]
         +- Window [lag(vehicle_count#30031, -1, null) windowspecdefinition(road_id#30007, timestamp#30010 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#30181], [road_id#30007], [timestamp#30010 ASC NULLS FIRST]
            +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_change#30163]
               +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, CASE WHEN isnotnull(speed_lag#30146) THEN (speed#30021 - speed_lag#30146) ELSE 0.0 END AS speed_change#30163]
                  +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146]
                     +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130, speed_lag#30146, speed_lag#30146]
                        +- Window [lag(speed#30021, -1, null) windowspecdefinition(road_id#30007, timestamp#30010 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#30146], [road_id#30007], [timestamp#30010 ASC NULLS FIRST]
                           +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, hour_cos#30130]
                              +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, hour_sin#30115, COS((0.2617993877991494 * cast(hour#30065 as double))) AS hour_cos#30130]
                                 +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, is_weekend#30101, SIN((0.2617993877991494 * cast(hour#30065 as double))) AS hour_sin#30115]
                                    +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, day_of_week#30088, CASE WHEN day_of_week#30088 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#30101]
                                       +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, is_peak#30076, dayofweek(cast(timestamp#30010 as date)) AS day_of_week#30088]
                                          +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour#30065, CASE WHEN hour#30065 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#30076]
                                             +- Project [_id#30003, congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031, hour(timestamp#30010, Some(Asia/Bangkok)) AS hour#30065]
                                                +- Project [_id#30003, cast(congestion_level#30004 as double) AS congestion_level#30041, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, vehicle_count#30031]
                                                   +- Project [_id#30003, congestion_level#30004, lat#30005, lon#30006, road_id#30007, road_name#30008, speed#30021, timestamp#30010, cast(vehicle_count#30011 as double) AS vehicle_count#30031]
                                                      +- Project [_id#30003, congestion_level#30004, lat#30005, lon#30006, road_id#30007, road_name#30008, cast(speed#30009 as double) AS speed#30021, timestamp#30010, vehicle_count#30011]
                                                         +- Relation [_id#30003,congestion_level#30004,lat#30005,lon#30006,road_id#30007,road_name#30008,speed#30009,timestamp#30010,vehicle_count#30011] MongoRelation(MongoRDD[1781] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:48,417 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:53 +07)" executed successfully
2026-01-06 12:39:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:58 +07)" (scheduled at 2026-01-06 12:39:53.157382+07:00)
2026-01-06 12:39:53,159 - INFO -  Training Spark model...
2026-01-06 12:39:53,428 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_change#30382, vehicle_count_lag#30400, vehicle_count_change#30419, avg(speed#30240) windowspecdefinition(road_id#30226, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#30440]
+- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_change#30382, vehicle_count_lag#30400, CASE WHEN isnotnull(vehicle_count_lag#30400) THEN (vehicle_count#30250 - vehicle_count_lag#30400) ELSE 0.0 END AS vehicle_count_change#30419]
   +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_change#30382, vehicle_count_lag#30400]
      +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_change#30382, vehicle_count_lag#30400, vehicle_count_lag#30400]
         +- Window [lag(vehicle_count#30250, -1, null) windowspecdefinition(road_id#30226, timestamp#30229 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#30400], [road_id#30226], [timestamp#30229 ASC NULLS FIRST]
            +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_change#30382]
               +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, CASE WHEN isnotnull(speed_lag#30365) THEN (speed#30240 - speed_lag#30365) ELSE 0.0 END AS speed_change#30382]
                  +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365]
                     +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349, speed_lag#30365, speed_lag#30365]
                        +- Window [lag(speed#30240, -1, null) windowspecdefinition(road_id#30226, timestamp#30229 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#30365], [road_id#30226], [timestamp#30229 ASC NULLS FIRST]
                           +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, hour_cos#30349]
                              +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, hour_sin#30334, COS((0.2617993877991494 * cast(hour#30284 as double))) AS hour_cos#30349]
                                 +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, is_weekend#30320, SIN((0.2617993877991494 * cast(hour#30284 as double))) AS hour_sin#30334]
                                    +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, day_of_week#30307, CASE WHEN day_of_week#30307 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#30320]
                                       +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, is_peak#30295, dayofweek(cast(timestamp#30229 as date)) AS day_of_week#30307]
                                          +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour#30284, CASE WHEN hour#30284 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#30295]
                                             +- Project [_id#30222, congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250, hour(timestamp#30229, Some(Asia/Bangkok)) AS hour#30284]
                                                +- Project [_id#30222, cast(congestion_level#30223 as double) AS congestion_level#30260, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, vehicle_count#30250]
                                                   +- Project [_id#30222, congestion_level#30223, lat#30224, lon#30225, road_id#30226, road_name#30227, speed#30240, timestamp#30229, cast(vehicle_count#30230 as double) AS vehicle_count#30250]
                                                      +- Project [_id#30222, congestion_level#30223, lat#30224, lon#30225, road_id#30226, road_name#30227, cast(speed#30228 as double) AS speed#30240, timestamp#30229, vehicle_count#30230]
                                                         +- Relation [_id#30222,congestion_level#30223,lat#30224,lon#30225,road_id#30226,road_name#30227,speed#30228,timestamp#30229,vehicle_count#30230] MongoRelation(MongoRDD[1794] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:53,428 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:39:58 +07)" executed successfully
2026-01-06 12:39:58,167 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:03 +07)" (scheduled at 2026-01-06 12:39:58.157382+07:00)
2026-01-06 12:39:58,168 - INFO -  Training Spark model...
2026-01-06 12:39:58,400 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_change#30601, vehicle_count_lag#30619, vehicle_count_change#30638, avg(speed#30459) windowspecdefinition(road_id#30445, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#30659]
+- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_change#30601, vehicle_count_lag#30619, CASE WHEN isnotnull(vehicle_count_lag#30619) THEN (vehicle_count#30469 - vehicle_count_lag#30619) ELSE 0.0 END AS vehicle_count_change#30638]
   +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_change#30601, vehicle_count_lag#30619]
      +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_change#30601, vehicle_count_lag#30619, vehicle_count_lag#30619]
         +- Window [lag(vehicle_count#30469, -1, null) windowspecdefinition(road_id#30445, timestamp#30448 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#30619], [road_id#30445], [timestamp#30448 ASC NULLS FIRST]
            +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_change#30601]
               +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, CASE WHEN isnotnull(speed_lag#30584) THEN (speed#30459 - speed_lag#30584) ELSE 0.0 END AS speed_change#30601]
                  +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584]
                     +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568, speed_lag#30584, speed_lag#30584]
                        +- Window [lag(speed#30459, -1, null) windowspecdefinition(road_id#30445, timestamp#30448 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#30584], [road_id#30445], [timestamp#30448 ASC NULLS FIRST]
                           +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, hour_cos#30568]
                              +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, hour_sin#30553, COS((0.2617993877991494 * cast(hour#30503 as double))) AS hour_cos#30568]
                                 +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, is_weekend#30539, SIN((0.2617993877991494 * cast(hour#30503 as double))) AS hour_sin#30553]
                                    +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, day_of_week#30526, CASE WHEN day_of_week#30526 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#30539]
                                       +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, is_peak#30514, dayofweek(cast(timestamp#30448 as date)) AS day_of_week#30526]
                                          +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour#30503, CASE WHEN hour#30503 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#30514]
                                             +- Project [_id#30441, congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469, hour(timestamp#30448, Some(Asia/Bangkok)) AS hour#30503]
                                                +- Project [_id#30441, cast(congestion_level#30442 as double) AS congestion_level#30479, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, vehicle_count#30469]
                                                   +- Project [_id#30441, congestion_level#30442, lat#30443, lon#30444, road_id#30445, road_name#30446, speed#30459, timestamp#30448, cast(vehicle_count#30449 as double) AS vehicle_count#30469]
                                                      +- Project [_id#30441, congestion_level#30442, lat#30443, lon#30444, road_id#30445, road_name#30446, cast(speed#30447 as double) AS speed#30459, timestamp#30448, vehicle_count#30449]
                                                         +- Relation [_id#30441,congestion_level#30442,lat#30443,lon#30444,road_id#30445,road_name#30446,speed#30447,timestamp#30448,vehicle_count#30449] MongoRelation(MongoRDD[1807] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:39:58,400 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:03 +07)" executed successfully
2026-01-06 12:40:03,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:08 +07)" (scheduled at 2026-01-06 12:40:03.157382+07:00)
2026-01-06 12:40:03,165 - INFO -  Training Spark model...
2026-01-06 12:40:03,392 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_change#30820, vehicle_count_lag#30838, vehicle_count_change#30857, avg(speed#30678) windowspecdefinition(road_id#30664, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#30878]
+- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_change#30820, vehicle_count_lag#30838, CASE WHEN isnotnull(vehicle_count_lag#30838) THEN (vehicle_count#30688 - vehicle_count_lag#30838) ELSE 0.0 END AS vehicle_count_change#30857]
   +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_change#30820, vehicle_count_lag#30838]
      +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_change#30820, vehicle_count_lag#30838, vehicle_count_lag#30838]
         +- Window [lag(vehicle_count#30688, -1, null) windowspecdefinition(road_id#30664, timestamp#30667 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#30838], [road_id#30664], [timestamp#30667 ASC NULLS FIRST]
            +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_change#30820]
               +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, CASE WHEN isnotnull(speed_lag#30803) THEN (speed#30678 - speed_lag#30803) ELSE 0.0 END AS speed_change#30820]
                  +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803]
                     +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787, speed_lag#30803, speed_lag#30803]
                        +- Window [lag(speed#30678, -1, null) windowspecdefinition(road_id#30664, timestamp#30667 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#30803], [road_id#30664], [timestamp#30667 ASC NULLS FIRST]
                           +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, hour_cos#30787]
                              +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, hour_sin#30772, COS((0.2617993877991494 * cast(hour#30722 as double))) AS hour_cos#30787]
                                 +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, is_weekend#30758, SIN((0.2617993877991494 * cast(hour#30722 as double))) AS hour_sin#30772]
                                    +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, day_of_week#30745, CASE WHEN day_of_week#30745 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#30758]
                                       +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, is_peak#30733, dayofweek(cast(timestamp#30667 as date)) AS day_of_week#30745]
                                          +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour#30722, CASE WHEN hour#30722 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#30733]
                                             +- Project [_id#30660, congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688, hour(timestamp#30667, Some(Asia/Bangkok)) AS hour#30722]
                                                +- Project [_id#30660, cast(congestion_level#30661 as double) AS congestion_level#30698, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, vehicle_count#30688]
                                                   +- Project [_id#30660, congestion_level#30661, lat#30662, lon#30663, road_id#30664, road_name#30665, speed#30678, timestamp#30667, cast(vehicle_count#30668 as double) AS vehicle_count#30688]
                                                      +- Project [_id#30660, congestion_level#30661, lat#30662, lon#30663, road_id#30664, road_name#30665, cast(speed#30666 as double) AS speed#30678, timestamp#30667, vehicle_count#30668]
                                                         +- Relation [_id#30660,congestion_level#30661,lat#30662,lon#30663,road_id#30664,road_name#30665,speed#30666,timestamp#30667,vehicle_count#30668] MongoRelation(MongoRDD[1820] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:03,392 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:08 +07)" executed successfully
2026-01-06 12:40:08,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:13 +07)" (scheduled at 2026-01-06 12:40:08.157382+07:00)
2026-01-06 12:40:08,160 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:41:08 +07)" (scheduled at 2026-01-06 12:40:08.157779+07:00)
2026-01-06 12:40:08,160 - INFO -  Training Spark model...
2026-01-06 12:40:08,161 - INFO -  Training Spark model...
2026-01-06 12:40:08,451 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_change#31199, vehicle_count_lag#31235, vehicle_count_change#31274, avg(speed#30915) windowspecdefinition(road_id#30883, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#31316]
+- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_change#31199, vehicle_count_lag#31235, CASE WHEN isnotnull(vehicle_count_lag#31235) THEN (vehicle_count#30926 - vehicle_count_lag#31235) ELSE 0.0 END AS vehicle_count_change#31274]
   +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_change#31199, vehicle_count_lag#31235]
      +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_change#31199, vehicle_count_lag#31235, vehicle_count_lag#31235]
         +- Window [lag(vehicle_count#30926, -1, null) windowspecdefinition(road_id#30883, timestamp#30886 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#31235], [road_id#30883], [timestamp#30886 ASC NULLS FIRST]
            +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_change#31199]
               +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, CASE WHEN isnotnull(speed_lag#31165) THEN (speed#30915 - speed_lag#31165) ELSE 0.0 END AS speed_change#31199]
                  +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165]
                     +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133, speed_lag#31165, speed_lag#31165]
                        +- Window [lag(speed#30915, -1, null) windowspecdefinition(road_id#30883, timestamp#30886 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#31165], [road_id#30883], [timestamp#30886 ASC NULLS FIRST]
                           +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, hour_cos#31133]
                              +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, hour_sin#31104, COS((0.2617993877991494 * cast(hour#31004 as double))) AS hour_cos#31133]
                                 +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, is_weekend#31076, SIN((0.2617993877991494 * cast(hour#31004 as double))) AS hour_sin#31104]
                                    +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, day_of_week#31050, CASE WHEN day_of_week#31050 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#31076]
                                       +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, is_peak#31026, dayofweek(cast(timestamp#30886 as date)) AS day_of_week#31050]
                                          +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour#31004, CASE WHEN hour#31004 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#31026]
                                             +- Project [_id#30879, congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926, hour(timestamp#30886, Some(Asia/Bangkok)) AS hour#31004]
                                                +- Project [_id#30879, cast(congestion_level#30880 as double) AS congestion_level#30945, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, vehicle_count#30926]
                                                   +- Project [_id#30879, congestion_level#30880, lat#30881, lon#30882, road_id#30883, road_name#30884, speed#30915, timestamp#30886, cast(vehicle_count#30887 as double) AS vehicle_count#30926]
                                                      +- Project [_id#30879, congestion_level#30880, lat#30881, lon#30882, road_id#30883, road_name#30884, cast(speed#30885 as double) AS speed#30915, timestamp#30886, vehicle_count#30887]
                                                         +- Relation [_id#30879,congestion_level#30880,lat#30881,lon#30882,road_id#30883,road_name#30884,speed#30885,timestamp#30886,vehicle_count#30887] MongoRelation(MongoRDD[1834] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:08,451 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:41:08 +07)" executed successfully
2026-01-06 12:40:08,451 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_change#31200, vehicle_count_lag#31236, vehicle_count_change#31273, avg(speed#30925) windowspecdefinition(road_id#30901, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#31315]
+- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_change#31200, vehicle_count_lag#31236, CASE WHEN isnotnull(vehicle_count_lag#31236) THEN (vehicle_count#30946 - vehicle_count_lag#31236) ELSE 0.0 END AS vehicle_count_change#31273]
   +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_change#31200, vehicle_count_lag#31236]
      +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_change#31200, vehicle_count_lag#31236, vehicle_count_lag#31236]
         +- Window [lag(vehicle_count#30946, -1, null) windowspecdefinition(road_id#30901, timestamp#30904 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#31236], [road_id#30901], [timestamp#30904 ASC NULLS FIRST]
            +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_change#31200]
               +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, CASE WHEN isnotnull(speed_lag#31166) THEN (speed#30925 - speed_lag#31166) ELSE 0.0 END AS speed_change#31200]
                  +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166]
                     +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134, speed_lag#31166, speed_lag#31166]
                        +- Window [lag(speed#30925, -1, null) windowspecdefinition(road_id#30901, timestamp#30904 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#31166], [road_id#30901], [timestamp#30904 ASC NULLS FIRST]
                           +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, hour_cos#31134]
                              +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, hour_sin#31103, COS((0.2617993877991494 * cast(hour#31003 as double))) AS hour_cos#31134]
                                 +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, is_weekend#31075, SIN((0.2617993877991494 * cast(hour#31003 as double))) AS hour_sin#31103]
                                    +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, day_of_week#31049, CASE WHEN day_of_week#31049 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#31075]
                                       +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, is_peak#31025, dayofweek(cast(timestamp#30904 as date)) AS day_of_week#31049]
                                          +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour#31003, CASE WHEN hour#31003 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#31025]
                                             +- Project [_id#30897, congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946, hour(timestamp#30904, Some(Asia/Bangkok)) AS hour#31003]
                                                +- Project [_id#30897, cast(congestion_level#30898 as double) AS congestion_level#30976, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, vehicle_count#30946]
                                                   +- Project [_id#30897, congestion_level#30898, lat#30899, lon#30900, road_id#30901, road_name#30902, speed#30925, timestamp#30904, cast(vehicle_count#30905 as double) AS vehicle_count#30946]
                                                      +- Project [_id#30897, congestion_level#30898, lat#30899, lon#30900, road_id#30901, road_name#30902, cast(speed#30903 as double) AS speed#30925, timestamp#30904, vehicle_count#30905]
                                                         +- Relation [_id#30897,congestion_level#30898,lat#30899,lon#30900,road_id#30901,road_name#30902,speed#30903,timestamp#30904,vehicle_count#30905] MongoRelation(MongoRDD[1833] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:08,452 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:13 +07)" executed successfully
2026-01-06 12:40:13,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:18 +07)" (scheduled at 2026-01-06 12:40:13.157382+07:00)
2026-01-06 12:40:13,159 - INFO -  Training Spark model...
2026-01-06 12:40:13,372 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_change#31477, vehicle_count_lag#31495, vehicle_count_change#31514, avg(speed#31335) windowspecdefinition(road_id#31321, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#31535]
+- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_change#31477, vehicle_count_lag#31495, CASE WHEN isnotnull(vehicle_count_lag#31495) THEN (vehicle_count#31345 - vehicle_count_lag#31495) ELSE 0.0 END AS vehicle_count_change#31514]
   +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_change#31477, vehicle_count_lag#31495]
      +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_change#31477, vehicle_count_lag#31495, vehicle_count_lag#31495]
         +- Window [lag(vehicle_count#31345, -1, null) windowspecdefinition(road_id#31321, timestamp#31324 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#31495], [road_id#31321], [timestamp#31324 ASC NULLS FIRST]
            +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_change#31477]
               +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, CASE WHEN isnotnull(speed_lag#31460) THEN (speed#31335 - speed_lag#31460) ELSE 0.0 END AS speed_change#31477]
                  +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460]
                     +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444, speed_lag#31460, speed_lag#31460]
                        +- Window [lag(speed#31335, -1, null) windowspecdefinition(road_id#31321, timestamp#31324 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#31460], [road_id#31321], [timestamp#31324 ASC NULLS FIRST]
                           +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, hour_cos#31444]
                              +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, hour_sin#31429, COS((0.2617993877991494 * cast(hour#31379 as double))) AS hour_cos#31444]
                                 +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, is_weekend#31415, SIN((0.2617993877991494 * cast(hour#31379 as double))) AS hour_sin#31429]
                                    +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, day_of_week#31402, CASE WHEN day_of_week#31402 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#31415]
                                       +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, is_peak#31390, dayofweek(cast(timestamp#31324 as date)) AS day_of_week#31402]
                                          +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour#31379, CASE WHEN hour#31379 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#31390]
                                             +- Project [_id#31317, congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345, hour(timestamp#31324, Some(Asia/Bangkok)) AS hour#31379]
                                                +- Project [_id#31317, cast(congestion_level#31318 as double) AS congestion_level#31355, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, vehicle_count#31345]
                                                   +- Project [_id#31317, congestion_level#31318, lat#31319, lon#31320, road_id#31321, road_name#31322, speed#31335, timestamp#31324, cast(vehicle_count#31325 as double) AS vehicle_count#31345]
                                                      +- Project [_id#31317, congestion_level#31318, lat#31319, lon#31320, road_id#31321, road_name#31322, cast(speed#31323 as double) AS speed#31335, timestamp#31324, vehicle_count#31325]
                                                         +- Relation [_id#31317,congestion_level#31318,lat#31319,lon#31320,road_id#31321,road_name#31322,speed#31323,timestamp#31324,vehicle_count#31325] MongoRelation(MongoRDD[1859] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:13,373 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:18 +07)" executed successfully
2026-01-06 12:40:18,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:23 +07)" (scheduled at 2026-01-06 12:40:18.157382+07:00)
2026-01-06 12:40:18,165 - INFO -  Training Spark model...
2026-01-06 12:40:18,389 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_change#31696, vehicle_count_lag#31714, vehicle_count_change#31733, avg(speed#31554) windowspecdefinition(road_id#31540, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#31754]
+- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_change#31696, vehicle_count_lag#31714, CASE WHEN isnotnull(vehicle_count_lag#31714) THEN (vehicle_count#31564 - vehicle_count_lag#31714) ELSE 0.0 END AS vehicle_count_change#31733]
   +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_change#31696, vehicle_count_lag#31714]
      +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_change#31696, vehicle_count_lag#31714, vehicle_count_lag#31714]
         +- Window [lag(vehicle_count#31564, -1, null) windowspecdefinition(road_id#31540, timestamp#31543 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#31714], [road_id#31540], [timestamp#31543 ASC NULLS FIRST]
            +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_change#31696]
               +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, CASE WHEN isnotnull(speed_lag#31679) THEN (speed#31554 - speed_lag#31679) ELSE 0.0 END AS speed_change#31696]
                  +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679]
                     +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663, speed_lag#31679, speed_lag#31679]
                        +- Window [lag(speed#31554, -1, null) windowspecdefinition(road_id#31540, timestamp#31543 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#31679], [road_id#31540], [timestamp#31543 ASC NULLS FIRST]
                           +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, hour_cos#31663]
                              +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, hour_sin#31648, COS((0.2617993877991494 * cast(hour#31598 as double))) AS hour_cos#31663]
                                 +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, is_weekend#31634, SIN((0.2617993877991494 * cast(hour#31598 as double))) AS hour_sin#31648]
                                    +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, day_of_week#31621, CASE WHEN day_of_week#31621 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#31634]
                                       +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, is_peak#31609, dayofweek(cast(timestamp#31543 as date)) AS day_of_week#31621]
                                          +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour#31598, CASE WHEN hour#31598 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#31609]
                                             +- Project [_id#31536, congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564, hour(timestamp#31543, Some(Asia/Bangkok)) AS hour#31598]
                                                +- Project [_id#31536, cast(congestion_level#31537 as double) AS congestion_level#31574, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, vehicle_count#31564]
                                                   +- Project [_id#31536, congestion_level#31537, lat#31538, lon#31539, road_id#31540, road_name#31541, speed#31554, timestamp#31543, cast(vehicle_count#31544 as double) AS vehicle_count#31564]
                                                      +- Project [_id#31536, congestion_level#31537, lat#31538, lon#31539, road_id#31540, road_name#31541, cast(speed#31542 as double) AS speed#31554, timestamp#31543, vehicle_count#31544]
                                                         +- Relation [_id#31536,congestion_level#31537,lat#31538,lon#31539,road_id#31540,road_name#31541,speed#31542,timestamp#31543,vehicle_count#31544] MongoRelation(MongoRDD[1872] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:18,389 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:23 +07)" executed successfully
2026-01-06 12:40:23,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:28 +07)" (scheduled at 2026-01-06 12:40:23.157382+07:00)
2026-01-06 12:40:23,158 - INFO -  Training Spark model...
2026-01-06 12:40:23,548 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_change#31915, vehicle_count_lag#31933, vehicle_count_change#31952, avg(speed#31773) windowspecdefinition(road_id#31759, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#31973]
+- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_change#31915, vehicle_count_lag#31933, CASE WHEN isnotnull(vehicle_count_lag#31933) THEN (vehicle_count#31783 - vehicle_count_lag#31933) ELSE 0.0 END AS vehicle_count_change#31952]
   +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_change#31915, vehicle_count_lag#31933]
      +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_change#31915, vehicle_count_lag#31933, vehicle_count_lag#31933]
         +- Window [lag(vehicle_count#31783, -1, null) windowspecdefinition(road_id#31759, timestamp#31762 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#31933], [road_id#31759], [timestamp#31762 ASC NULLS FIRST]
            +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_change#31915]
               +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, CASE WHEN isnotnull(speed_lag#31898) THEN (speed#31773 - speed_lag#31898) ELSE 0.0 END AS speed_change#31915]
                  +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898]
                     +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882, speed_lag#31898, speed_lag#31898]
                        +- Window [lag(speed#31773, -1, null) windowspecdefinition(road_id#31759, timestamp#31762 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#31898], [road_id#31759], [timestamp#31762 ASC NULLS FIRST]
                           +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, hour_cos#31882]
                              +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, hour_sin#31867, COS((0.2617993877991494 * cast(hour#31817 as double))) AS hour_cos#31882]
                                 +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, is_weekend#31853, SIN((0.2617993877991494 * cast(hour#31817 as double))) AS hour_sin#31867]
                                    +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, day_of_week#31840, CASE WHEN day_of_week#31840 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#31853]
                                       +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, is_peak#31828, dayofweek(cast(timestamp#31762 as date)) AS day_of_week#31840]
                                          +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour#31817, CASE WHEN hour#31817 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#31828]
                                             +- Project [_id#31755, congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783, hour(timestamp#31762, Some(Asia/Bangkok)) AS hour#31817]
                                                +- Project [_id#31755, cast(congestion_level#31756 as double) AS congestion_level#31793, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, vehicle_count#31783]
                                                   +- Project [_id#31755, congestion_level#31756, lat#31757, lon#31758, road_id#31759, road_name#31760, speed#31773, timestamp#31762, cast(vehicle_count#31763 as double) AS vehicle_count#31783]
                                                      +- Project [_id#31755, congestion_level#31756, lat#31757, lon#31758, road_id#31759, road_name#31760, cast(speed#31761 as double) AS speed#31773, timestamp#31762, vehicle_count#31763]
                                                         +- Relation [_id#31755,congestion_level#31756,lat#31757,lon#31758,road_id#31759,road_name#31760,speed#31761,timestamp#31762,vehicle_count#31763] MongoRelation(MongoRDD[1885] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:23,548 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:28 +07)" executed successfully
2026-01-06 12:40:28,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:33 +07)" (scheduled at 2026-01-06 12:40:28.157382+07:00)
2026-01-06 12:40:28,158 - INFO -  Training Spark model...
2026-01-06 12:40:28,412 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_change#32134, vehicle_count_lag#32152, vehicle_count_change#32171, avg(speed#31992) windowspecdefinition(road_id#31978, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#32192]
+- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_change#32134, vehicle_count_lag#32152, CASE WHEN isnotnull(vehicle_count_lag#32152) THEN (vehicle_count#32002 - vehicle_count_lag#32152) ELSE 0.0 END AS vehicle_count_change#32171]
   +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_change#32134, vehicle_count_lag#32152]
      +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_change#32134, vehicle_count_lag#32152, vehicle_count_lag#32152]
         +- Window [lag(vehicle_count#32002, -1, null) windowspecdefinition(road_id#31978, timestamp#31981 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#32152], [road_id#31978], [timestamp#31981 ASC NULLS FIRST]
            +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_change#32134]
               +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, CASE WHEN isnotnull(speed_lag#32117) THEN (speed#31992 - speed_lag#32117) ELSE 0.0 END AS speed_change#32134]
                  +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117]
                     +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101, speed_lag#32117, speed_lag#32117]
                        +- Window [lag(speed#31992, -1, null) windowspecdefinition(road_id#31978, timestamp#31981 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#32117], [road_id#31978], [timestamp#31981 ASC NULLS FIRST]
                           +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, hour_cos#32101]
                              +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, hour_sin#32086, COS((0.2617993877991494 * cast(hour#32036 as double))) AS hour_cos#32101]
                                 +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, is_weekend#32072, SIN((0.2617993877991494 * cast(hour#32036 as double))) AS hour_sin#32086]
                                    +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, day_of_week#32059, CASE WHEN day_of_week#32059 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#32072]
                                       +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, is_peak#32047, dayofweek(cast(timestamp#31981 as date)) AS day_of_week#32059]
                                          +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour#32036, CASE WHEN hour#32036 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#32047]
                                             +- Project [_id#31974, congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002, hour(timestamp#31981, Some(Asia/Bangkok)) AS hour#32036]
                                                +- Project [_id#31974, cast(congestion_level#31975 as double) AS congestion_level#32012, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, vehicle_count#32002]
                                                   +- Project [_id#31974, congestion_level#31975, lat#31976, lon#31977, road_id#31978, road_name#31979, speed#31992, timestamp#31981, cast(vehicle_count#31982 as double) AS vehicle_count#32002]
                                                      +- Project [_id#31974, congestion_level#31975, lat#31976, lon#31977, road_id#31978, road_name#31979, cast(speed#31980 as double) AS speed#31992, timestamp#31981, vehicle_count#31982]
                                                         +- Relation [_id#31974,congestion_level#31975,lat#31976,lon#31977,road_id#31978,road_name#31979,speed#31980,timestamp#31981,vehicle_count#31982] MongoRelation(MongoRDD[1898] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:28,412 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:33 +07)" executed successfully
2026-01-06 12:40:33,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:38 +07)" (scheduled at 2026-01-06 12:40:33.157382+07:00)
2026-01-06 12:40:33,159 - INFO -  Training Spark model...
2026-01-06 12:40:33,519 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_change#32353, vehicle_count_lag#32371, vehicle_count_change#32390, avg(speed#32211) windowspecdefinition(road_id#32197, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#32411]
+- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_change#32353, vehicle_count_lag#32371, CASE WHEN isnotnull(vehicle_count_lag#32371) THEN (vehicle_count#32221 - vehicle_count_lag#32371) ELSE 0.0 END AS vehicle_count_change#32390]
   +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_change#32353, vehicle_count_lag#32371]
      +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_change#32353, vehicle_count_lag#32371, vehicle_count_lag#32371]
         +- Window [lag(vehicle_count#32221, -1, null) windowspecdefinition(road_id#32197, timestamp#32200 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#32371], [road_id#32197], [timestamp#32200 ASC NULLS FIRST]
            +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_change#32353]
               +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, CASE WHEN isnotnull(speed_lag#32336) THEN (speed#32211 - speed_lag#32336) ELSE 0.0 END AS speed_change#32353]
                  +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336]
                     +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320, speed_lag#32336, speed_lag#32336]
                        +- Window [lag(speed#32211, -1, null) windowspecdefinition(road_id#32197, timestamp#32200 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#32336], [road_id#32197], [timestamp#32200 ASC NULLS FIRST]
                           +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, hour_cos#32320]
                              +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, hour_sin#32305, COS((0.2617993877991494 * cast(hour#32255 as double))) AS hour_cos#32320]
                                 +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, is_weekend#32291, SIN((0.2617993877991494 * cast(hour#32255 as double))) AS hour_sin#32305]
                                    +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, day_of_week#32278, CASE WHEN day_of_week#32278 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#32291]
                                       +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, is_peak#32266, dayofweek(cast(timestamp#32200 as date)) AS day_of_week#32278]
                                          +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour#32255, CASE WHEN hour#32255 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#32266]
                                             +- Project [_id#32193, congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221, hour(timestamp#32200, Some(Asia/Bangkok)) AS hour#32255]
                                                +- Project [_id#32193, cast(congestion_level#32194 as double) AS congestion_level#32231, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, vehicle_count#32221]
                                                   +- Project [_id#32193, congestion_level#32194, lat#32195, lon#32196, road_id#32197, road_name#32198, speed#32211, timestamp#32200, cast(vehicle_count#32201 as double) AS vehicle_count#32221]
                                                      +- Project [_id#32193, congestion_level#32194, lat#32195, lon#32196, road_id#32197, road_name#32198, cast(speed#32199 as double) AS speed#32211, timestamp#32200, vehicle_count#32201]
                                                         +- Relation [_id#32193,congestion_level#32194,lat#32195,lon#32196,road_id#32197,road_name#32198,speed#32199,timestamp#32200,vehicle_count#32201] MongoRelation(MongoRDD[1911] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:33,519 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:38 +07)" executed successfully
2026-01-06 12:40:38,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:43 +07)" (scheduled at 2026-01-06 12:40:38.157382+07:00)
2026-01-06 12:40:38,159 - INFO -  Training Spark model...
2026-01-06 12:40:38,511 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_change#32572, vehicle_count_lag#32590, vehicle_count_change#32609, avg(speed#32430) windowspecdefinition(road_id#32416, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#32630]
+- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_change#32572, vehicle_count_lag#32590, CASE WHEN isnotnull(vehicle_count_lag#32590) THEN (vehicle_count#32440 - vehicle_count_lag#32590) ELSE 0.0 END AS vehicle_count_change#32609]
   +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_change#32572, vehicle_count_lag#32590]
      +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_change#32572, vehicle_count_lag#32590, vehicle_count_lag#32590]
         +- Window [lag(vehicle_count#32440, -1, null) windowspecdefinition(road_id#32416, timestamp#32419 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#32590], [road_id#32416], [timestamp#32419 ASC NULLS FIRST]
            +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_change#32572]
               +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, CASE WHEN isnotnull(speed_lag#32555) THEN (speed#32430 - speed_lag#32555) ELSE 0.0 END AS speed_change#32572]
                  +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555]
                     +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539, speed_lag#32555, speed_lag#32555]
                        +- Window [lag(speed#32430, -1, null) windowspecdefinition(road_id#32416, timestamp#32419 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#32555], [road_id#32416], [timestamp#32419 ASC NULLS FIRST]
                           +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, hour_cos#32539]
                              +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, hour_sin#32524, COS((0.2617993877991494 * cast(hour#32474 as double))) AS hour_cos#32539]
                                 +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, is_weekend#32510, SIN((0.2617993877991494 * cast(hour#32474 as double))) AS hour_sin#32524]
                                    +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, day_of_week#32497, CASE WHEN day_of_week#32497 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#32510]
                                       +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, is_peak#32485, dayofweek(cast(timestamp#32419 as date)) AS day_of_week#32497]
                                          +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour#32474, CASE WHEN hour#32474 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#32485]
                                             +- Project [_id#32412, congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440, hour(timestamp#32419, Some(Asia/Bangkok)) AS hour#32474]
                                                +- Project [_id#32412, cast(congestion_level#32413 as double) AS congestion_level#32450, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, vehicle_count#32440]
                                                   +- Project [_id#32412, congestion_level#32413, lat#32414, lon#32415, road_id#32416, road_name#32417, speed#32430, timestamp#32419, cast(vehicle_count#32420 as double) AS vehicle_count#32440]
                                                      +- Project [_id#32412, congestion_level#32413, lat#32414, lon#32415, road_id#32416, road_name#32417, cast(speed#32418 as double) AS speed#32430, timestamp#32419, vehicle_count#32420]
                                                         +- Relation [_id#32412,congestion_level#32413,lat#32414,lon#32415,road_id#32416,road_name#32417,speed#32418,timestamp#32419,vehicle_count#32420] MongoRelation(MongoRDD[1924] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:38,511 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:43 +07)" executed successfully
2026-01-06 12:40:43,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:48 +07)" (scheduled at 2026-01-06 12:40:43.157382+07:00)
2026-01-06 12:40:43,159 - INFO -  Training Spark model...
2026-01-06 12:40:43,471 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_change#32791, vehicle_count_lag#32809, vehicle_count_change#32828, avg(speed#32649) windowspecdefinition(road_id#32635, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#32849]
+- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_change#32791, vehicle_count_lag#32809, CASE WHEN isnotnull(vehicle_count_lag#32809) THEN (vehicle_count#32659 - vehicle_count_lag#32809) ELSE 0.0 END AS vehicle_count_change#32828]
   +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_change#32791, vehicle_count_lag#32809]
      +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_change#32791, vehicle_count_lag#32809, vehicle_count_lag#32809]
         +- Window [lag(vehicle_count#32659, -1, null) windowspecdefinition(road_id#32635, timestamp#32638 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#32809], [road_id#32635], [timestamp#32638 ASC NULLS FIRST]
            +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_change#32791]
               +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, CASE WHEN isnotnull(speed_lag#32774) THEN (speed#32649 - speed_lag#32774) ELSE 0.0 END AS speed_change#32791]
                  +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774]
                     +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758, speed_lag#32774, speed_lag#32774]
                        +- Window [lag(speed#32649, -1, null) windowspecdefinition(road_id#32635, timestamp#32638 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#32774], [road_id#32635], [timestamp#32638 ASC NULLS FIRST]
                           +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, hour_cos#32758]
                              +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, hour_sin#32743, COS((0.2617993877991494 * cast(hour#32693 as double))) AS hour_cos#32758]
                                 +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, is_weekend#32729, SIN((0.2617993877991494 * cast(hour#32693 as double))) AS hour_sin#32743]
                                    +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, day_of_week#32716, CASE WHEN day_of_week#32716 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#32729]
                                       +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, is_peak#32704, dayofweek(cast(timestamp#32638 as date)) AS day_of_week#32716]
                                          +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour#32693, CASE WHEN hour#32693 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#32704]
                                             +- Project [_id#32631, congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659, hour(timestamp#32638, Some(Asia/Bangkok)) AS hour#32693]
                                                +- Project [_id#32631, cast(congestion_level#32632 as double) AS congestion_level#32669, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, vehicle_count#32659]
                                                   +- Project [_id#32631, congestion_level#32632, lat#32633, lon#32634, road_id#32635, road_name#32636, speed#32649, timestamp#32638, cast(vehicle_count#32639 as double) AS vehicle_count#32659]
                                                      +- Project [_id#32631, congestion_level#32632, lat#32633, lon#32634, road_id#32635, road_name#32636, cast(speed#32637 as double) AS speed#32649, timestamp#32638, vehicle_count#32639]
                                                         +- Relation [_id#32631,congestion_level#32632,lat#32633,lon#32634,road_id#32635,road_name#32636,speed#32637,timestamp#32638,vehicle_count#32639] MongoRelation(MongoRDD[1937] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:43,471 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:48 +07)" executed successfully
2026-01-06 12:40:48,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:53 +07)" (scheduled at 2026-01-06 12:40:48.157382+07:00)
2026-01-06 12:40:48,164 - INFO -  Training Spark model...
2026-01-06 12:40:48,417 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_change#33010, vehicle_count_lag#33028, vehicle_count_change#33047, avg(speed#32868) windowspecdefinition(road_id#32854, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#33068]
+- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_change#33010, vehicle_count_lag#33028, CASE WHEN isnotnull(vehicle_count_lag#33028) THEN (vehicle_count#32878 - vehicle_count_lag#33028) ELSE 0.0 END AS vehicle_count_change#33047]
   +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_change#33010, vehicle_count_lag#33028]
      +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_change#33010, vehicle_count_lag#33028, vehicle_count_lag#33028]
         +- Window [lag(vehicle_count#32878, -1, null) windowspecdefinition(road_id#32854, timestamp#32857 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#33028], [road_id#32854], [timestamp#32857 ASC NULLS FIRST]
            +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_change#33010]
               +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, CASE WHEN isnotnull(speed_lag#32993) THEN (speed#32868 - speed_lag#32993) ELSE 0.0 END AS speed_change#33010]
                  +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993]
                     +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977, speed_lag#32993, speed_lag#32993]
                        +- Window [lag(speed#32868, -1, null) windowspecdefinition(road_id#32854, timestamp#32857 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#32993], [road_id#32854], [timestamp#32857 ASC NULLS FIRST]
                           +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, hour_cos#32977]
                              +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, hour_sin#32962, COS((0.2617993877991494 * cast(hour#32912 as double))) AS hour_cos#32977]
                                 +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, is_weekend#32948, SIN((0.2617993877991494 * cast(hour#32912 as double))) AS hour_sin#32962]
                                    +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, day_of_week#32935, CASE WHEN day_of_week#32935 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#32948]
                                       +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, is_peak#32923, dayofweek(cast(timestamp#32857 as date)) AS day_of_week#32935]
                                          +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour#32912, CASE WHEN hour#32912 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#32923]
                                             +- Project [_id#32850, congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878, hour(timestamp#32857, Some(Asia/Bangkok)) AS hour#32912]
                                                +- Project [_id#32850, cast(congestion_level#32851 as double) AS congestion_level#32888, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, vehicle_count#32878]
                                                   +- Project [_id#32850, congestion_level#32851, lat#32852, lon#32853, road_id#32854, road_name#32855, speed#32868, timestamp#32857, cast(vehicle_count#32858 as double) AS vehicle_count#32878]
                                                      +- Project [_id#32850, congestion_level#32851, lat#32852, lon#32853, road_id#32854, road_name#32855, cast(speed#32856 as double) AS speed#32868, timestamp#32857, vehicle_count#32858]
                                                         +- Relation [_id#32850,congestion_level#32851,lat#32852,lon#32853,road_id#32854,road_name#32855,speed#32856,timestamp#32857,vehicle_count#32858] MongoRelation(MongoRDD[1950] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:48,417 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:53 +07)" executed successfully
2026-01-06 12:40:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:58 +07)" (scheduled at 2026-01-06 12:40:53.157382+07:00)
2026-01-06 12:40:53,160 - INFO -  Training Spark model...
2026-01-06 12:40:53,420 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_change#33229, vehicle_count_lag#33247, vehicle_count_change#33266, avg(speed#33087) windowspecdefinition(road_id#33073, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#33287]
+- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_change#33229, vehicle_count_lag#33247, CASE WHEN isnotnull(vehicle_count_lag#33247) THEN (vehicle_count#33097 - vehicle_count_lag#33247) ELSE 0.0 END AS vehicle_count_change#33266]
   +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_change#33229, vehicle_count_lag#33247]
      +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_change#33229, vehicle_count_lag#33247, vehicle_count_lag#33247]
         +- Window [lag(vehicle_count#33097, -1, null) windowspecdefinition(road_id#33073, timestamp#33076 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#33247], [road_id#33073], [timestamp#33076 ASC NULLS FIRST]
            +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_change#33229]
               +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, CASE WHEN isnotnull(speed_lag#33212) THEN (speed#33087 - speed_lag#33212) ELSE 0.0 END AS speed_change#33229]
                  +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212]
                     +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196, speed_lag#33212, speed_lag#33212]
                        +- Window [lag(speed#33087, -1, null) windowspecdefinition(road_id#33073, timestamp#33076 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#33212], [road_id#33073], [timestamp#33076 ASC NULLS FIRST]
                           +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, hour_cos#33196]
                              +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, hour_sin#33181, COS((0.2617993877991494 * cast(hour#33131 as double))) AS hour_cos#33196]
                                 +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, is_weekend#33167, SIN((0.2617993877991494 * cast(hour#33131 as double))) AS hour_sin#33181]
                                    +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, day_of_week#33154, CASE WHEN day_of_week#33154 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#33167]
                                       +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, is_peak#33142, dayofweek(cast(timestamp#33076 as date)) AS day_of_week#33154]
                                          +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour#33131, CASE WHEN hour#33131 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#33142]
                                             +- Project [_id#33069, congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097, hour(timestamp#33076, Some(Asia/Bangkok)) AS hour#33131]
                                                +- Project [_id#33069, cast(congestion_level#33070 as double) AS congestion_level#33107, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, vehicle_count#33097]
                                                   +- Project [_id#33069, congestion_level#33070, lat#33071, lon#33072, road_id#33073, road_name#33074, speed#33087, timestamp#33076, cast(vehicle_count#33077 as double) AS vehicle_count#33097]
                                                      +- Project [_id#33069, congestion_level#33070, lat#33071, lon#33072, road_id#33073, road_name#33074, cast(speed#33075 as double) AS speed#33087, timestamp#33076, vehicle_count#33077]
                                                         +- Relation [_id#33069,congestion_level#33070,lat#33071,lon#33072,road_id#33073,road_name#33074,speed#33075,timestamp#33076,vehicle_count#33077] MongoRelation(MongoRDD[1963] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:53,420 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:40:58 +07)" executed successfully
2026-01-06 12:40:58,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:03 +07)" (scheduled at 2026-01-06 12:40:58.157382+07:00)
2026-01-06 12:40:58,163 - INFO -  Training Spark model...
2026-01-06 12:40:58,382 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_change#33448, vehicle_count_lag#33466, vehicle_count_change#33485, avg(speed#33306) windowspecdefinition(road_id#33292, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#33506]
+- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_change#33448, vehicle_count_lag#33466, CASE WHEN isnotnull(vehicle_count_lag#33466) THEN (vehicle_count#33316 - vehicle_count_lag#33466) ELSE 0.0 END AS vehicle_count_change#33485]
   +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_change#33448, vehicle_count_lag#33466]
      +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_change#33448, vehicle_count_lag#33466, vehicle_count_lag#33466]
         +- Window [lag(vehicle_count#33316, -1, null) windowspecdefinition(road_id#33292, timestamp#33295 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#33466], [road_id#33292], [timestamp#33295 ASC NULLS FIRST]
            +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_change#33448]
               +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, CASE WHEN isnotnull(speed_lag#33431) THEN (speed#33306 - speed_lag#33431) ELSE 0.0 END AS speed_change#33448]
                  +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431]
                     +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415, speed_lag#33431, speed_lag#33431]
                        +- Window [lag(speed#33306, -1, null) windowspecdefinition(road_id#33292, timestamp#33295 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#33431], [road_id#33292], [timestamp#33295 ASC NULLS FIRST]
                           +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, hour_cos#33415]
                              +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, hour_sin#33400, COS((0.2617993877991494 * cast(hour#33350 as double))) AS hour_cos#33415]
                                 +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, is_weekend#33386, SIN((0.2617993877991494 * cast(hour#33350 as double))) AS hour_sin#33400]
                                    +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, day_of_week#33373, CASE WHEN day_of_week#33373 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#33386]
                                       +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, is_peak#33361, dayofweek(cast(timestamp#33295 as date)) AS day_of_week#33373]
                                          +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour#33350, CASE WHEN hour#33350 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#33361]
                                             +- Project [_id#33288, congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316, hour(timestamp#33295, Some(Asia/Bangkok)) AS hour#33350]
                                                +- Project [_id#33288, cast(congestion_level#33289 as double) AS congestion_level#33326, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, vehicle_count#33316]
                                                   +- Project [_id#33288, congestion_level#33289, lat#33290, lon#33291, road_id#33292, road_name#33293, speed#33306, timestamp#33295, cast(vehicle_count#33296 as double) AS vehicle_count#33316]
                                                      +- Project [_id#33288, congestion_level#33289, lat#33290, lon#33291, road_id#33292, road_name#33293, cast(speed#33294 as double) AS speed#33306, timestamp#33295, vehicle_count#33296]
                                                         +- Relation [_id#33288,congestion_level#33289,lat#33290,lon#33291,road_id#33292,road_name#33293,speed#33294,timestamp#33295,vehicle_count#33296] MongoRelation(MongoRDD[1976] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:40:58,382 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:03 +07)" executed successfully
2026-01-06 12:41:03,169 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:08 +07)" (scheduled at 2026-01-06 12:41:03.157382+07:00)
2026-01-06 12:41:03,169 - INFO -  Training Spark model...
2026-01-06 12:41:03,448 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_change#33667, vehicle_count_lag#33685, vehicle_count_change#33704, avg(speed#33525) windowspecdefinition(road_id#33511, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#33725]
+- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_change#33667, vehicle_count_lag#33685, CASE WHEN isnotnull(vehicle_count_lag#33685) THEN (vehicle_count#33535 - vehicle_count_lag#33685) ELSE 0.0 END AS vehicle_count_change#33704]
   +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_change#33667, vehicle_count_lag#33685]
      +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_change#33667, vehicle_count_lag#33685, vehicle_count_lag#33685]
         +- Window [lag(vehicle_count#33535, -1, null) windowspecdefinition(road_id#33511, timestamp#33514 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#33685], [road_id#33511], [timestamp#33514 ASC NULLS FIRST]
            +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_change#33667]
               +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, CASE WHEN isnotnull(speed_lag#33650) THEN (speed#33525 - speed_lag#33650) ELSE 0.0 END AS speed_change#33667]
                  +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650]
                     +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634, speed_lag#33650, speed_lag#33650]
                        +- Window [lag(speed#33525, -1, null) windowspecdefinition(road_id#33511, timestamp#33514 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#33650], [road_id#33511], [timestamp#33514 ASC NULLS FIRST]
                           +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, hour_cos#33634]
                              +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, hour_sin#33619, COS((0.2617993877991494 * cast(hour#33569 as double))) AS hour_cos#33634]
                                 +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, is_weekend#33605, SIN((0.2617993877991494 * cast(hour#33569 as double))) AS hour_sin#33619]
                                    +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, day_of_week#33592, CASE WHEN day_of_week#33592 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#33605]
                                       +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, is_peak#33580, dayofweek(cast(timestamp#33514 as date)) AS day_of_week#33592]
                                          +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour#33569, CASE WHEN hour#33569 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#33580]
                                             +- Project [_id#33507, congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535, hour(timestamp#33514, Some(Asia/Bangkok)) AS hour#33569]
                                                +- Project [_id#33507, cast(congestion_level#33508 as double) AS congestion_level#33545, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, vehicle_count#33535]
                                                   +- Project [_id#33507, congestion_level#33508, lat#33509, lon#33510, road_id#33511, road_name#33512, speed#33525, timestamp#33514, cast(vehicle_count#33515 as double) AS vehicle_count#33535]
                                                      +- Project [_id#33507, congestion_level#33508, lat#33509, lon#33510, road_id#33511, road_name#33512, cast(speed#33513 as double) AS speed#33525, timestamp#33514, vehicle_count#33515]
                                                         +- Relation [_id#33507,congestion_level#33508,lat#33509,lon#33510,road_id#33511,road_name#33512,speed#33513,timestamp#33514,vehicle_count#33515] MongoRelation(MongoRDD[1989] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:03,448 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:08 +07)" executed successfully
2026-01-06 12:41:08,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:13 +07)" (scheduled at 2026-01-06 12:41:08.157382+07:00)
2026-01-06 12:41:08,161 - INFO -  Training Spark model...
2026-01-06 12:41:08,161 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:42:08 +07)" (scheduled at 2026-01-06 12:41:08.157779+07:00)
2026-01-06 12:41:08,161 - INFO -  Training Spark model...
2026-01-06 12:41:08,454 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_change#34029, vehicle_count_lag#34048, vehicle_count_change#34084, avg(speed#33763) windowspecdefinition(road_id#33739, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#34141]
+- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_change#34029, vehicle_count_lag#34048, CASE WHEN isnotnull(vehicle_count_lag#34048) THEN (vehicle_count#33792 - vehicle_count_lag#34048) ELSE 0.0 END AS vehicle_count_change#34084]
   +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_change#34029, vehicle_count_lag#34048]
      +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_change#34029, vehicle_count_lag#34048, vehicle_count_lag#34048]
         +- Window [lag(vehicle_count#33792, -1, null) windowspecdefinition(road_id#33739, timestamp#33742 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34048], [road_id#33739], [timestamp#33742 ASC NULLS FIRST]
            +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_change#34029]
               +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, CASE WHEN isnotnull(speed_lag#33997) THEN (speed#33763 - speed_lag#33997) ELSE 0.0 END AS speed_change#34029]
                  +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997]
                     +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952, speed_lag#33997, speed_lag#33997]
                        +- Window [lag(speed#33763, -1, null) windowspecdefinition(road_id#33739, timestamp#33742 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#33997], [road_id#33739], [timestamp#33742 ASC NULLS FIRST]
                           +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, hour_cos#33952]
                              +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, hour_sin#33936, COS((0.2617993877991494 * cast(hour#33850 as double))) AS hour_cos#33952]
                                 +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, is_weekend#33909, SIN((0.2617993877991494 * cast(hour#33850 as double))) AS hour_sin#33936]
                                    +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, day_of_week#33884, CASE WHEN day_of_week#33884 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#33909]
                                       +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, is_peak#33872, dayofweek(cast(timestamp#33742 as date)) AS day_of_week#33884]
                                          +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour#33850, CASE WHEN hour#33850 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#33872]
                                             +- Project [_id#33735, congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792, hour(timestamp#33742, Some(Asia/Bangkok)) AS hour#33850]
                                                +- Project [_id#33735, cast(congestion_level#33736 as double) AS congestion_level#33823, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, vehicle_count#33792]
                                                   +- Project [_id#33735, congestion_level#33736, lat#33737, lon#33738, road_id#33739, road_name#33740, speed#33763, timestamp#33742, cast(vehicle_count#33743 as double) AS vehicle_count#33792]
                                                      +- Project [_id#33735, congestion_level#33736, lat#33737, lon#33738, road_id#33739, road_name#33740, cast(speed#33741 as double) AS speed#33763, timestamp#33742, vehicle_count#33743]
                                                         +- Relation [_id#33735,congestion_level#33736,lat#33737,lon#33738,road_id#33739,road_name#33740,speed#33741,timestamp#33742,vehicle_count#33743] MongoRelation(MongoRDD[2003] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:08,454 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:42:08 +07)" executed successfully
2026-01-06 12:41:08,455 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_change#34083, vehicle_count_lag#34121, vehicle_count_change#34142, avg(speed#33762) windowspecdefinition(road_id#33730, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#34163]
+- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_change#34083, vehicle_count_lag#34121, CASE WHEN isnotnull(vehicle_count_lag#34121) THEN (vehicle_count#33782 - vehicle_count_lag#34121) ELSE 0.0 END AS vehicle_count_change#34142]
   +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_change#34083, vehicle_count_lag#34121]
      +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_change#34083, vehicle_count_lag#34121, vehicle_count_lag#34121]
         +- Window [lag(vehicle_count#33782, -1, null) windowspecdefinition(road_id#33730, timestamp#33733 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34121], [road_id#33730], [timestamp#33733 ASC NULLS FIRST]
            +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_change#34083]
               +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, CASE WHEN isnotnull(speed_lag#34047) THEN (speed#33762 - speed_lag#34047) ELSE 0.0 END AS speed_change#34083]
                  +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047]
                     +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996, speed_lag#34047, speed_lag#34047]
                        +- Window [lag(speed#33762, -1, null) windowspecdefinition(road_id#33730, timestamp#33733 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#34047], [road_id#33730], [timestamp#33733 ASC NULLS FIRST]
                           +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, hour_cos#33996]
                              +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, hour_sin#33981, COS((0.2617993877991494 * cast(hour#33861 as double))) AS hour_cos#33996]
                                 +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, is_weekend#33951, SIN((0.2617993877991494 * cast(hour#33861 as double))) AS hour_sin#33981]
                                    +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, day_of_week#33910, CASE WHEN day_of_week#33910 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#33951]
                                       +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, is_peak#33897, dayofweek(cast(timestamp#33733 as date)) AS day_of_week#33910]
                                          +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour#33861, CASE WHEN hour#33861 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#33897]
                                             +- Project [_id#33726, congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782, hour(timestamp#33733, Some(Asia/Bangkok)) AS hour#33861]
                                                +- Project [_id#33726, cast(congestion_level#33727 as double) AS congestion_level#33793, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, vehicle_count#33782]
                                                   +- Project [_id#33726, congestion_level#33727, lat#33728, lon#33729, road_id#33730, road_name#33731, speed#33762, timestamp#33733, cast(vehicle_count#33734 as double) AS vehicle_count#33782]
                                                      +- Project [_id#33726, congestion_level#33727, lat#33728, lon#33729, road_id#33730, road_name#33731, cast(speed#33732 as double) AS speed#33762, timestamp#33733, vehicle_count#33734]
                                                         +- Relation [_id#33726,congestion_level#33727,lat#33728,lon#33729,road_id#33730,road_name#33731,speed#33732,timestamp#33733,vehicle_count#33734] MongoRelation(MongoRDD[2002] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:08,455 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:13 +07)" executed successfully
2026-01-06 12:41:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:18 +07)" (scheduled at 2026-01-06 12:41:13.157382+07:00)
2026-01-06 12:41:13,159 - INFO -  Training Spark model...
2026-01-06 12:41:13,386 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_change#34324, vehicle_count_lag#34342, vehicle_count_change#34361, avg(speed#34182) windowspecdefinition(road_id#34168, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#34382]
+- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_change#34324, vehicle_count_lag#34342, CASE WHEN isnotnull(vehicle_count_lag#34342) THEN (vehicle_count#34192 - vehicle_count_lag#34342) ELSE 0.0 END AS vehicle_count_change#34361]
   +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_change#34324, vehicle_count_lag#34342]
      +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_change#34324, vehicle_count_lag#34342, vehicle_count_lag#34342]
         +- Window [lag(vehicle_count#34192, -1, null) windowspecdefinition(road_id#34168, timestamp#34171 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34342], [road_id#34168], [timestamp#34171 ASC NULLS FIRST]
            +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_change#34324]
               +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, CASE WHEN isnotnull(speed_lag#34307) THEN (speed#34182 - speed_lag#34307) ELSE 0.0 END AS speed_change#34324]
                  +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307]
                     +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291, speed_lag#34307, speed_lag#34307]
                        +- Window [lag(speed#34182, -1, null) windowspecdefinition(road_id#34168, timestamp#34171 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#34307], [road_id#34168], [timestamp#34171 ASC NULLS FIRST]
                           +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, hour_cos#34291]
                              +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, hour_sin#34276, COS((0.2617993877991494 * cast(hour#34226 as double))) AS hour_cos#34291]
                                 +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, is_weekend#34262, SIN((0.2617993877991494 * cast(hour#34226 as double))) AS hour_sin#34276]
                                    +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, day_of_week#34249, CASE WHEN day_of_week#34249 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#34262]
                                       +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, is_peak#34237, dayofweek(cast(timestamp#34171 as date)) AS day_of_week#34249]
                                          +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour#34226, CASE WHEN hour#34226 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#34237]
                                             +- Project [_id#34164, congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192, hour(timestamp#34171, Some(Asia/Bangkok)) AS hour#34226]
                                                +- Project [_id#34164, cast(congestion_level#34165 as double) AS congestion_level#34202, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, vehicle_count#34192]
                                                   +- Project [_id#34164, congestion_level#34165, lat#34166, lon#34167, road_id#34168, road_name#34169, speed#34182, timestamp#34171, cast(vehicle_count#34172 as double) AS vehicle_count#34192]
                                                      +- Project [_id#34164, congestion_level#34165, lat#34166, lon#34167, road_id#34168, road_name#34169, cast(speed#34170 as double) AS speed#34182, timestamp#34171, vehicle_count#34172]
                                                         +- Relation [_id#34164,congestion_level#34165,lat#34166,lon#34167,road_id#34168,road_name#34169,speed#34170,timestamp#34171,vehicle_count#34172] MongoRelation(MongoRDD[2028] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:13,386 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:18 +07)" executed successfully
2026-01-06 12:41:18,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:23 +07)" (scheduled at 2026-01-06 12:41:18.157382+07:00)
2026-01-06 12:41:18,165 - INFO -  Training Spark model...
2026-01-06 12:41:18,386 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_change#34543, vehicle_count_lag#34561, vehicle_count_change#34580, avg(speed#34401) windowspecdefinition(road_id#34387, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#34601]
+- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_change#34543, vehicle_count_lag#34561, CASE WHEN isnotnull(vehicle_count_lag#34561) THEN (vehicle_count#34411 - vehicle_count_lag#34561) ELSE 0.0 END AS vehicle_count_change#34580]
   +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_change#34543, vehicle_count_lag#34561]
      +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_change#34543, vehicle_count_lag#34561, vehicle_count_lag#34561]
         +- Window [lag(vehicle_count#34411, -1, null) windowspecdefinition(road_id#34387, timestamp#34390 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34561], [road_id#34387], [timestamp#34390 ASC NULLS FIRST]
            +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_change#34543]
               +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, CASE WHEN isnotnull(speed_lag#34526) THEN (speed#34401 - speed_lag#34526) ELSE 0.0 END AS speed_change#34543]
                  +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526]
                     +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510, speed_lag#34526, speed_lag#34526]
                        +- Window [lag(speed#34401, -1, null) windowspecdefinition(road_id#34387, timestamp#34390 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#34526], [road_id#34387], [timestamp#34390 ASC NULLS FIRST]
                           +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, hour_cos#34510]
                              +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, hour_sin#34495, COS((0.2617993877991494 * cast(hour#34445 as double))) AS hour_cos#34510]
                                 +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, is_weekend#34481, SIN((0.2617993877991494 * cast(hour#34445 as double))) AS hour_sin#34495]
                                    +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, day_of_week#34468, CASE WHEN day_of_week#34468 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#34481]
                                       +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, is_peak#34456, dayofweek(cast(timestamp#34390 as date)) AS day_of_week#34468]
                                          +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour#34445, CASE WHEN hour#34445 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#34456]
                                             +- Project [_id#34383, congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411, hour(timestamp#34390, Some(Asia/Bangkok)) AS hour#34445]
                                                +- Project [_id#34383, cast(congestion_level#34384 as double) AS congestion_level#34421, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, vehicle_count#34411]
                                                   +- Project [_id#34383, congestion_level#34384, lat#34385, lon#34386, road_id#34387, road_name#34388, speed#34401, timestamp#34390, cast(vehicle_count#34391 as double) AS vehicle_count#34411]
                                                      +- Project [_id#34383, congestion_level#34384, lat#34385, lon#34386, road_id#34387, road_name#34388, cast(speed#34389 as double) AS speed#34401, timestamp#34390, vehicle_count#34391]
                                                         +- Relation [_id#34383,congestion_level#34384,lat#34385,lon#34386,road_id#34387,road_name#34388,speed#34389,timestamp#34390,vehicle_count#34391] MongoRelation(MongoRDD[2041] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:18,386 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:23 +07)" executed successfully
2026-01-06 12:41:23,165 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:28 +07)" (scheduled at 2026-01-06 12:41:23.157382+07:00)
2026-01-06 12:41:23,165 - INFO -  Training Spark model...
2026-01-06 12:41:23,389 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_change#34762, vehicle_count_lag#34780, vehicle_count_change#34799, avg(speed#34620) windowspecdefinition(road_id#34606, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#34820]
+- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_change#34762, vehicle_count_lag#34780, CASE WHEN isnotnull(vehicle_count_lag#34780) THEN (vehicle_count#34630 - vehicle_count_lag#34780) ELSE 0.0 END AS vehicle_count_change#34799]
   +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_change#34762, vehicle_count_lag#34780]
      +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_change#34762, vehicle_count_lag#34780, vehicle_count_lag#34780]
         +- Window [lag(vehicle_count#34630, -1, null) windowspecdefinition(road_id#34606, timestamp#34609 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34780], [road_id#34606], [timestamp#34609 ASC NULLS FIRST]
            +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_change#34762]
               +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, CASE WHEN isnotnull(speed_lag#34745) THEN (speed#34620 - speed_lag#34745) ELSE 0.0 END AS speed_change#34762]
                  +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745]
                     +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729, speed_lag#34745, speed_lag#34745]
                        +- Window [lag(speed#34620, -1, null) windowspecdefinition(road_id#34606, timestamp#34609 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#34745], [road_id#34606], [timestamp#34609 ASC NULLS FIRST]
                           +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, hour_cos#34729]
                              +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, hour_sin#34714, COS((0.2617993877991494 * cast(hour#34664 as double))) AS hour_cos#34729]
                                 +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, is_weekend#34700, SIN((0.2617993877991494 * cast(hour#34664 as double))) AS hour_sin#34714]
                                    +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, day_of_week#34687, CASE WHEN day_of_week#34687 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#34700]
                                       +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, is_peak#34675, dayofweek(cast(timestamp#34609 as date)) AS day_of_week#34687]
                                          +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour#34664, CASE WHEN hour#34664 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#34675]
                                             +- Project [_id#34602, congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630, hour(timestamp#34609, Some(Asia/Bangkok)) AS hour#34664]
                                                +- Project [_id#34602, cast(congestion_level#34603 as double) AS congestion_level#34640, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, vehicle_count#34630]
                                                   +- Project [_id#34602, congestion_level#34603, lat#34604, lon#34605, road_id#34606, road_name#34607, speed#34620, timestamp#34609, cast(vehicle_count#34610 as double) AS vehicle_count#34630]
                                                      +- Project [_id#34602, congestion_level#34603, lat#34604, lon#34605, road_id#34606, road_name#34607, cast(speed#34608 as double) AS speed#34620, timestamp#34609, vehicle_count#34610]
                                                         +- Relation [_id#34602,congestion_level#34603,lat#34604,lon#34605,road_id#34606,road_name#34607,speed#34608,timestamp#34609,vehicle_count#34610] MongoRelation(MongoRDD[2054] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:23,390 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:28 +07)" executed successfully
2026-01-06 12:41:28,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:33 +07)" (scheduled at 2026-01-06 12:41:28.157382+07:00)
2026-01-06 12:41:28,161 - INFO -  Training Spark model...
2026-01-06 12:41:28,407 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_change#34981, vehicle_count_lag#34999, vehicle_count_change#35018, avg(speed#34839) windowspecdefinition(road_id#34825, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#35039]
+- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_change#34981, vehicle_count_lag#34999, CASE WHEN isnotnull(vehicle_count_lag#34999) THEN (vehicle_count#34849 - vehicle_count_lag#34999) ELSE 0.0 END AS vehicle_count_change#35018]
   +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_change#34981, vehicle_count_lag#34999]
      +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_change#34981, vehicle_count_lag#34999, vehicle_count_lag#34999]
         +- Window [lag(vehicle_count#34849, -1, null) windowspecdefinition(road_id#34825, timestamp#34828 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#34999], [road_id#34825], [timestamp#34828 ASC NULLS FIRST]
            +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_change#34981]
               +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, CASE WHEN isnotnull(speed_lag#34964) THEN (speed#34839 - speed_lag#34964) ELSE 0.0 END AS speed_change#34981]
                  +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964]
                     +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948, speed_lag#34964, speed_lag#34964]
                        +- Window [lag(speed#34839, -1, null) windowspecdefinition(road_id#34825, timestamp#34828 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#34964], [road_id#34825], [timestamp#34828 ASC NULLS FIRST]
                           +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, hour_cos#34948]
                              +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, hour_sin#34933, COS((0.2617993877991494 * cast(hour#34883 as double))) AS hour_cos#34948]
                                 +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, is_weekend#34919, SIN((0.2617993877991494 * cast(hour#34883 as double))) AS hour_sin#34933]
                                    +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, day_of_week#34906, CASE WHEN day_of_week#34906 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#34919]
                                       +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, is_peak#34894, dayofweek(cast(timestamp#34828 as date)) AS day_of_week#34906]
                                          +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour#34883, CASE WHEN hour#34883 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#34894]
                                             +- Project [_id#34821, congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849, hour(timestamp#34828, Some(Asia/Bangkok)) AS hour#34883]
                                                +- Project [_id#34821, cast(congestion_level#34822 as double) AS congestion_level#34859, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, vehicle_count#34849]
                                                   +- Project [_id#34821, congestion_level#34822, lat#34823, lon#34824, road_id#34825, road_name#34826, speed#34839, timestamp#34828, cast(vehicle_count#34829 as double) AS vehicle_count#34849]
                                                      +- Project [_id#34821, congestion_level#34822, lat#34823, lon#34824, road_id#34825, road_name#34826, cast(speed#34827 as double) AS speed#34839, timestamp#34828, vehicle_count#34829]
                                                         +- Relation [_id#34821,congestion_level#34822,lat#34823,lon#34824,road_id#34825,road_name#34826,speed#34827,timestamp#34828,vehicle_count#34829] MongoRelation(MongoRDD[2067] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:28,407 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:33 +07)" executed successfully
2026-01-06 12:41:33,178 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:38 +07)" (scheduled at 2026-01-06 12:41:33.157382+07:00)
2026-01-06 12:41:33,179 - INFO -  Training Spark model...
2026-01-06 12:41:33,414 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_change#35200, vehicle_count_lag#35218, vehicle_count_change#35237, avg(speed#35058) windowspecdefinition(road_id#35044, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#35258]
+- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_change#35200, vehicle_count_lag#35218, CASE WHEN isnotnull(vehicle_count_lag#35218) THEN (vehicle_count#35068 - vehicle_count_lag#35218) ELSE 0.0 END AS vehicle_count_change#35237]
   +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_change#35200, vehicle_count_lag#35218]
      +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_change#35200, vehicle_count_lag#35218, vehicle_count_lag#35218]
         +- Window [lag(vehicle_count#35068, -1, null) windowspecdefinition(road_id#35044, timestamp#35047 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#35218], [road_id#35044], [timestamp#35047 ASC NULLS FIRST]
            +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_change#35200]
               +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, CASE WHEN isnotnull(speed_lag#35183) THEN (speed#35058 - speed_lag#35183) ELSE 0.0 END AS speed_change#35200]
                  +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183]
                     +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167, speed_lag#35183, speed_lag#35183]
                        +- Window [lag(speed#35058, -1, null) windowspecdefinition(road_id#35044, timestamp#35047 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#35183], [road_id#35044], [timestamp#35047 ASC NULLS FIRST]
                           +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, hour_cos#35167]
                              +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, hour_sin#35152, COS((0.2617993877991494 * cast(hour#35102 as double))) AS hour_cos#35167]
                                 +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, is_weekend#35138, SIN((0.2617993877991494 * cast(hour#35102 as double))) AS hour_sin#35152]
                                    +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, day_of_week#35125, CASE WHEN day_of_week#35125 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#35138]
                                       +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, is_peak#35113, dayofweek(cast(timestamp#35047 as date)) AS day_of_week#35125]
                                          +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour#35102, CASE WHEN hour#35102 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#35113]
                                             +- Project [_id#35040, congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068, hour(timestamp#35047, Some(Asia/Bangkok)) AS hour#35102]
                                                +- Project [_id#35040, cast(congestion_level#35041 as double) AS congestion_level#35078, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, vehicle_count#35068]
                                                   +- Project [_id#35040, congestion_level#35041, lat#35042, lon#35043, road_id#35044, road_name#35045, speed#35058, timestamp#35047, cast(vehicle_count#35048 as double) AS vehicle_count#35068]
                                                      +- Project [_id#35040, congestion_level#35041, lat#35042, lon#35043, road_id#35044, road_name#35045, cast(speed#35046 as double) AS speed#35058, timestamp#35047, vehicle_count#35048]
                                                         +- Relation [_id#35040,congestion_level#35041,lat#35042,lon#35043,road_id#35044,road_name#35045,speed#35046,timestamp#35047,vehicle_count#35048] MongoRelation(MongoRDD[2080] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:33,414 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:38 +07)" executed successfully
2026-01-06 12:41:38,179 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:43 +07)" (scheduled at 2026-01-06 12:41:38.157382+07:00)
2026-01-06 12:41:38,179 - INFO -  Training Spark model...
2026-01-06 12:41:38,426 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_change#35419, vehicle_count_lag#35437, vehicle_count_change#35456, avg(speed#35277) windowspecdefinition(road_id#35263, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#35477]
+- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_change#35419, vehicle_count_lag#35437, CASE WHEN isnotnull(vehicle_count_lag#35437) THEN (vehicle_count#35287 - vehicle_count_lag#35437) ELSE 0.0 END AS vehicle_count_change#35456]
   +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_change#35419, vehicle_count_lag#35437]
      +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_change#35419, vehicle_count_lag#35437, vehicle_count_lag#35437]
         +- Window [lag(vehicle_count#35287, -1, null) windowspecdefinition(road_id#35263, timestamp#35266 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#35437], [road_id#35263], [timestamp#35266 ASC NULLS FIRST]
            +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_change#35419]
               +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, CASE WHEN isnotnull(speed_lag#35402) THEN (speed#35277 - speed_lag#35402) ELSE 0.0 END AS speed_change#35419]
                  +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402]
                     +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386, speed_lag#35402, speed_lag#35402]
                        +- Window [lag(speed#35277, -1, null) windowspecdefinition(road_id#35263, timestamp#35266 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#35402], [road_id#35263], [timestamp#35266 ASC NULLS FIRST]
                           +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, hour_cos#35386]
                              +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, hour_sin#35371, COS((0.2617993877991494 * cast(hour#35321 as double))) AS hour_cos#35386]
                                 +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, is_weekend#35357, SIN((0.2617993877991494 * cast(hour#35321 as double))) AS hour_sin#35371]
                                    +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, day_of_week#35344, CASE WHEN day_of_week#35344 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#35357]
                                       +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, is_peak#35332, dayofweek(cast(timestamp#35266 as date)) AS day_of_week#35344]
                                          +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour#35321, CASE WHEN hour#35321 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#35332]
                                             +- Project [_id#35259, congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287, hour(timestamp#35266, Some(Asia/Bangkok)) AS hour#35321]
                                                +- Project [_id#35259, cast(congestion_level#35260 as double) AS congestion_level#35297, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, vehicle_count#35287]
                                                   +- Project [_id#35259, congestion_level#35260, lat#35261, lon#35262, road_id#35263, road_name#35264, speed#35277, timestamp#35266, cast(vehicle_count#35267 as double) AS vehicle_count#35287]
                                                      +- Project [_id#35259, congestion_level#35260, lat#35261, lon#35262, road_id#35263, road_name#35264, cast(speed#35265 as double) AS speed#35277, timestamp#35266, vehicle_count#35267]
                                                         +- Relation [_id#35259,congestion_level#35260,lat#35261,lon#35262,road_id#35263,road_name#35264,speed#35265,timestamp#35266,vehicle_count#35267] MongoRelation(MongoRDD[2093] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:38,426 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:43 +07)" executed successfully
2026-01-06 12:41:43,178 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:48 +07)" (scheduled at 2026-01-06 12:41:43.157382+07:00)
2026-01-06 12:41:43,179 - INFO -  Training Spark model...
2026-01-06 12:41:43,392 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_change#35638, vehicle_count_lag#35656, vehicle_count_change#35675, avg(speed#35496) windowspecdefinition(road_id#35482, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#35696]
+- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_change#35638, vehicle_count_lag#35656, CASE WHEN isnotnull(vehicle_count_lag#35656) THEN (vehicle_count#35506 - vehicle_count_lag#35656) ELSE 0.0 END AS vehicle_count_change#35675]
   +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_change#35638, vehicle_count_lag#35656]
      +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_change#35638, vehicle_count_lag#35656, vehicle_count_lag#35656]
         +- Window [lag(vehicle_count#35506, -1, null) windowspecdefinition(road_id#35482, timestamp#35485 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#35656], [road_id#35482], [timestamp#35485 ASC NULLS FIRST]
            +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_change#35638]
               +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, CASE WHEN isnotnull(speed_lag#35621) THEN (speed#35496 - speed_lag#35621) ELSE 0.0 END AS speed_change#35638]
                  +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621]
                     +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605, speed_lag#35621, speed_lag#35621]
                        +- Window [lag(speed#35496, -1, null) windowspecdefinition(road_id#35482, timestamp#35485 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#35621], [road_id#35482], [timestamp#35485 ASC NULLS FIRST]
                           +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, hour_cos#35605]
                              +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, hour_sin#35590, COS((0.2617993877991494 * cast(hour#35540 as double))) AS hour_cos#35605]
                                 +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, is_weekend#35576, SIN((0.2617993877991494 * cast(hour#35540 as double))) AS hour_sin#35590]
                                    +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, day_of_week#35563, CASE WHEN day_of_week#35563 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#35576]
                                       +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, is_peak#35551, dayofweek(cast(timestamp#35485 as date)) AS day_of_week#35563]
                                          +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour#35540, CASE WHEN hour#35540 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#35551]
                                             +- Project [_id#35478, congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506, hour(timestamp#35485, Some(Asia/Bangkok)) AS hour#35540]
                                                +- Project [_id#35478, cast(congestion_level#35479 as double) AS congestion_level#35516, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, vehicle_count#35506]
                                                   +- Project [_id#35478, congestion_level#35479, lat#35480, lon#35481, road_id#35482, road_name#35483, speed#35496, timestamp#35485, cast(vehicle_count#35486 as double) AS vehicle_count#35506]
                                                      +- Project [_id#35478, congestion_level#35479, lat#35480, lon#35481, road_id#35482, road_name#35483, cast(speed#35484 as double) AS speed#35496, timestamp#35485, vehicle_count#35486]
                                                         +- Relation [_id#35478,congestion_level#35479,lat#35480,lon#35481,road_id#35482,road_name#35483,speed#35484,timestamp#35485,vehicle_count#35486] MongoRelation(MongoRDD[2106] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:43,392 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:48 +07)" executed successfully
2026-01-06 12:41:48,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:53 +07)" (scheduled at 2026-01-06 12:41:48.157382+07:00)
2026-01-06 12:41:48,163 - INFO -  Training Spark model...
2026-01-06 12:41:48,391 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_change#35857, vehicle_count_lag#35875, vehicle_count_change#35894, avg(speed#35715) windowspecdefinition(road_id#35701, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#35915]
+- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_change#35857, vehicle_count_lag#35875, CASE WHEN isnotnull(vehicle_count_lag#35875) THEN (vehicle_count#35725 - vehicle_count_lag#35875) ELSE 0.0 END AS vehicle_count_change#35894]
   +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_change#35857, vehicle_count_lag#35875]
      +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_change#35857, vehicle_count_lag#35875, vehicle_count_lag#35875]
         +- Window [lag(vehicle_count#35725, -1, null) windowspecdefinition(road_id#35701, timestamp#35704 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#35875], [road_id#35701], [timestamp#35704 ASC NULLS FIRST]
            +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_change#35857]
               +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, CASE WHEN isnotnull(speed_lag#35840) THEN (speed#35715 - speed_lag#35840) ELSE 0.0 END AS speed_change#35857]
                  +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840]
                     +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824, speed_lag#35840, speed_lag#35840]
                        +- Window [lag(speed#35715, -1, null) windowspecdefinition(road_id#35701, timestamp#35704 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#35840], [road_id#35701], [timestamp#35704 ASC NULLS FIRST]
                           +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, hour_cos#35824]
                              +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, hour_sin#35809, COS((0.2617993877991494 * cast(hour#35759 as double))) AS hour_cos#35824]
                                 +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, is_weekend#35795, SIN((0.2617993877991494 * cast(hour#35759 as double))) AS hour_sin#35809]
                                    +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, day_of_week#35782, CASE WHEN day_of_week#35782 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#35795]
                                       +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, is_peak#35770, dayofweek(cast(timestamp#35704 as date)) AS day_of_week#35782]
                                          +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour#35759, CASE WHEN hour#35759 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#35770]
                                             +- Project [_id#35697, congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725, hour(timestamp#35704, Some(Asia/Bangkok)) AS hour#35759]
                                                +- Project [_id#35697, cast(congestion_level#35698 as double) AS congestion_level#35735, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, vehicle_count#35725]
                                                   +- Project [_id#35697, congestion_level#35698, lat#35699, lon#35700, road_id#35701, road_name#35702, speed#35715, timestamp#35704, cast(vehicle_count#35705 as double) AS vehicle_count#35725]
                                                      +- Project [_id#35697, congestion_level#35698, lat#35699, lon#35700, road_id#35701, road_name#35702, cast(speed#35703 as double) AS speed#35715, timestamp#35704, vehicle_count#35705]
                                                         +- Relation [_id#35697,congestion_level#35698,lat#35699,lon#35700,road_id#35701,road_name#35702,speed#35703,timestamp#35704,vehicle_count#35705] MongoRelation(MongoRDD[2119] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:48,392 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:53 +07)" executed successfully
2026-01-06 12:41:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:58 +07)" (scheduled at 2026-01-06 12:41:53.157382+07:00)
2026-01-06 12:41:53,160 - INFO -  Training Spark model...
2026-01-06 12:41:53,442 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_change#36076, vehicle_count_lag#36094, vehicle_count_change#36113, avg(speed#35934) windowspecdefinition(road_id#35920, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#36134]
+- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_change#36076, vehicle_count_lag#36094, CASE WHEN isnotnull(vehicle_count_lag#36094) THEN (vehicle_count#35944 - vehicle_count_lag#36094) ELSE 0.0 END AS vehicle_count_change#36113]
   +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_change#36076, vehicle_count_lag#36094]
      +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_change#36076, vehicle_count_lag#36094, vehicle_count_lag#36094]
         +- Window [lag(vehicle_count#35944, -1, null) windowspecdefinition(road_id#35920, timestamp#35923 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#36094], [road_id#35920], [timestamp#35923 ASC NULLS FIRST]
            +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_change#36076]
               +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, CASE WHEN isnotnull(speed_lag#36059) THEN (speed#35934 - speed_lag#36059) ELSE 0.0 END AS speed_change#36076]
                  +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059]
                     +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043, speed_lag#36059, speed_lag#36059]
                        +- Window [lag(speed#35934, -1, null) windowspecdefinition(road_id#35920, timestamp#35923 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#36059], [road_id#35920], [timestamp#35923 ASC NULLS FIRST]
                           +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, hour_cos#36043]
                              +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, hour_sin#36028, COS((0.2617993877991494 * cast(hour#35978 as double))) AS hour_cos#36043]
                                 +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, is_weekend#36014, SIN((0.2617993877991494 * cast(hour#35978 as double))) AS hour_sin#36028]
                                    +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, day_of_week#36001, CASE WHEN day_of_week#36001 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#36014]
                                       +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, is_peak#35989, dayofweek(cast(timestamp#35923 as date)) AS day_of_week#36001]
                                          +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour#35978, CASE WHEN hour#35978 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#35989]
                                             +- Project [_id#35916, congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944, hour(timestamp#35923, Some(Asia/Bangkok)) AS hour#35978]
                                                +- Project [_id#35916, cast(congestion_level#35917 as double) AS congestion_level#35954, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, vehicle_count#35944]
                                                   +- Project [_id#35916, congestion_level#35917, lat#35918, lon#35919, road_id#35920, road_name#35921, speed#35934, timestamp#35923, cast(vehicle_count#35924 as double) AS vehicle_count#35944]
                                                      +- Project [_id#35916, congestion_level#35917, lat#35918, lon#35919, road_id#35920, road_name#35921, cast(speed#35922 as double) AS speed#35934, timestamp#35923, vehicle_count#35924]
                                                         +- Relation [_id#35916,congestion_level#35917,lat#35918,lon#35919,road_id#35920,road_name#35921,speed#35922,timestamp#35923,vehicle_count#35924] MongoRelation(MongoRDD[2132] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:53,443 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:41:58 +07)" executed successfully
2026-01-06 12:41:58,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:03 +07)" (scheduled at 2026-01-06 12:41:58.157382+07:00)
2026-01-06 12:41:58,164 - INFO -  Training Spark model...
2026-01-06 12:41:58,379 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_change#36295, vehicle_count_lag#36313, vehicle_count_change#36332, avg(speed#36153) windowspecdefinition(road_id#36139, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#36353]
+- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_change#36295, vehicle_count_lag#36313, CASE WHEN isnotnull(vehicle_count_lag#36313) THEN (vehicle_count#36163 - vehicle_count_lag#36313) ELSE 0.0 END AS vehicle_count_change#36332]
   +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_change#36295, vehicle_count_lag#36313]
      +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_change#36295, vehicle_count_lag#36313, vehicle_count_lag#36313]
         +- Window [lag(vehicle_count#36163, -1, null) windowspecdefinition(road_id#36139, timestamp#36142 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#36313], [road_id#36139], [timestamp#36142 ASC NULLS FIRST]
            +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_change#36295]
               +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, CASE WHEN isnotnull(speed_lag#36278) THEN (speed#36153 - speed_lag#36278) ELSE 0.0 END AS speed_change#36295]
                  +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278]
                     +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262, speed_lag#36278, speed_lag#36278]
                        +- Window [lag(speed#36153, -1, null) windowspecdefinition(road_id#36139, timestamp#36142 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#36278], [road_id#36139], [timestamp#36142 ASC NULLS FIRST]
                           +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, hour_cos#36262]
                              +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, hour_sin#36247, COS((0.2617993877991494 * cast(hour#36197 as double))) AS hour_cos#36262]
                                 +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, is_weekend#36233, SIN((0.2617993877991494 * cast(hour#36197 as double))) AS hour_sin#36247]
                                    +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, day_of_week#36220, CASE WHEN day_of_week#36220 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#36233]
                                       +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, is_peak#36208, dayofweek(cast(timestamp#36142 as date)) AS day_of_week#36220]
                                          +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour#36197, CASE WHEN hour#36197 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#36208]
                                             +- Project [_id#36135, congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163, hour(timestamp#36142, Some(Asia/Bangkok)) AS hour#36197]
                                                +- Project [_id#36135, cast(congestion_level#36136 as double) AS congestion_level#36173, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, vehicle_count#36163]
                                                   +- Project [_id#36135, congestion_level#36136, lat#36137, lon#36138, road_id#36139, road_name#36140, speed#36153, timestamp#36142, cast(vehicle_count#36143 as double) AS vehicle_count#36163]
                                                      +- Project [_id#36135, congestion_level#36136, lat#36137, lon#36138, road_id#36139, road_name#36140, cast(speed#36141 as double) AS speed#36153, timestamp#36142, vehicle_count#36143]
                                                         +- Relation [_id#36135,congestion_level#36136,lat#36137,lon#36138,road_id#36139,road_name#36140,speed#36141,timestamp#36142,vehicle_count#36143] MongoRelation(MongoRDD[2145] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:41:58,380 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:03 +07)" executed successfully
2026-01-06 12:42:03,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:08 +07)" (scheduled at 2026-01-06 12:42:03.157382+07:00)
2026-01-06 12:42:03,159 - INFO -  Training Spark model...
2026-01-06 12:42:03,429 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_change#36514, vehicle_count_lag#36532, vehicle_count_change#36551, avg(speed#36372) windowspecdefinition(road_id#36358, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#36572]
+- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_change#36514, vehicle_count_lag#36532, CASE WHEN isnotnull(vehicle_count_lag#36532) THEN (vehicle_count#36382 - vehicle_count_lag#36532) ELSE 0.0 END AS vehicle_count_change#36551]
   +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_change#36514, vehicle_count_lag#36532]
      +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_change#36514, vehicle_count_lag#36532, vehicle_count_lag#36532]
         +- Window [lag(vehicle_count#36382, -1, null) windowspecdefinition(road_id#36358, timestamp#36361 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#36532], [road_id#36358], [timestamp#36361 ASC NULLS FIRST]
            +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_change#36514]
               +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, CASE WHEN isnotnull(speed_lag#36497) THEN (speed#36372 - speed_lag#36497) ELSE 0.0 END AS speed_change#36514]
                  +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497]
                     +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481, speed_lag#36497, speed_lag#36497]
                        +- Window [lag(speed#36372, -1, null) windowspecdefinition(road_id#36358, timestamp#36361 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#36497], [road_id#36358], [timestamp#36361 ASC NULLS FIRST]
                           +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, hour_cos#36481]
                              +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, hour_sin#36466, COS((0.2617993877991494 * cast(hour#36416 as double))) AS hour_cos#36481]
                                 +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, is_weekend#36452, SIN((0.2617993877991494 * cast(hour#36416 as double))) AS hour_sin#36466]
                                    +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, day_of_week#36439, CASE WHEN day_of_week#36439 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#36452]
                                       +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, is_peak#36427, dayofweek(cast(timestamp#36361 as date)) AS day_of_week#36439]
                                          +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour#36416, CASE WHEN hour#36416 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#36427]
                                             +- Project [_id#36354, congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382, hour(timestamp#36361, Some(Asia/Bangkok)) AS hour#36416]
                                                +- Project [_id#36354, cast(congestion_level#36355 as double) AS congestion_level#36392, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, vehicle_count#36382]
                                                   +- Project [_id#36354, congestion_level#36355, lat#36356, lon#36357, road_id#36358, road_name#36359, speed#36372, timestamp#36361, cast(vehicle_count#36362 as double) AS vehicle_count#36382]
                                                      +- Project [_id#36354, congestion_level#36355, lat#36356, lon#36357, road_id#36358, road_name#36359, cast(speed#36360 as double) AS speed#36372, timestamp#36361, vehicle_count#36362]
                                                         +- Relation [_id#36354,congestion_level#36355,lat#36356,lon#36357,road_id#36358,road_name#36359,speed#36360,timestamp#36361,vehicle_count#36362] MongoRelation(MongoRDD[2158] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:03,429 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:08 +07)" executed successfully
2026-01-06 12:42:08,173 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:13 +07)" (scheduled at 2026-01-06 12:42:08.157382+07:00)
2026-01-06 12:42:08,174 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:43:08 +07)" (scheduled at 2026-01-06 12:42:08.157779+07:00)
2026-01-06 12:42:08,174 - INFO -  Training Spark model...
2026-01-06 12:42:08,174 - INFO -  Training Spark model...
2026-01-06 12:42:08,440 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_change#36876, vehicle_count_lag#36895, vehicle_count_change#36930, avg(speed#36610) windowspecdefinition(road_id#36577, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#36988]
+- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_change#36876, vehicle_count_lag#36895, CASE WHEN isnotnull(vehicle_count_lag#36895) THEN (vehicle_count#36630 - vehicle_count_lag#36895) ELSE 0.0 END AS vehicle_count_change#36930]
   +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_change#36876, vehicle_count_lag#36895]
      +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_change#36876, vehicle_count_lag#36895, vehicle_count_lag#36895]
         +- Window [lag(vehicle_count#36630, -1, null) windowspecdefinition(road_id#36577, timestamp#36580 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#36895], [road_id#36577], [timestamp#36580 ASC NULLS FIRST]
            +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_change#36876]
               +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, CASE WHEN isnotnull(speed_lag#36844) THEN (speed#36610 - speed_lag#36844) ELSE 0.0 END AS speed_change#36876]
                  +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844]
                     +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812, speed_lag#36844, speed_lag#36844]
                        +- Window [lag(speed#36610, -1, null) windowspecdefinition(road_id#36577, timestamp#36580 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#36844], [road_id#36577], [timestamp#36580 ASC NULLS FIRST]
                           +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, hour_cos#36812]
                              +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, hour_sin#36783, COS((0.2617993877991494 * cast(hour#36697 as double))) AS hour_cos#36812]
                                 +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, is_weekend#36769, SIN((0.2617993877991494 * cast(hour#36697 as double))) AS hour_sin#36783]
                                    +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, day_of_week#36744, CASE WHEN day_of_week#36744 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#36769]
                                       +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, is_peak#36720, dayofweek(cast(timestamp#36580 as date)) AS day_of_week#36744]
                                          +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour#36697, CASE WHEN hour#36697 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#36720]
                                             +- Project [_id#36573, congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630, hour(timestamp#36580, Some(Asia/Bangkok)) AS hour#36697]
                                                +- Project [_id#36573, cast(congestion_level#36574 as double) AS congestion_level#36649, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, vehicle_count#36630]
                                                   +- Project [_id#36573, congestion_level#36574, lat#36575, lon#36576, road_id#36577, road_name#36578, speed#36610, timestamp#36580, cast(vehicle_count#36581 as double) AS vehicle_count#36630]
                                                      +- Project [_id#36573, congestion_level#36574, lat#36575, lon#36576, road_id#36577, road_name#36578, cast(speed#36579 as double) AS speed#36610, timestamp#36580, vehicle_count#36581]
                                                         +- Relation [_id#36573,congestion_level#36574,lat#36575,lon#36576,road_id#36577,road_name#36578,speed#36579,timestamp#36580,vehicle_count#36581] MongoRelation(MongoRDD[2172] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:08,441 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:13 +07)" executed successfully
2026-01-06 12:42:08,441 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_change#36931, vehicle_count_lag#36968, vehicle_count_change#36989, avg(speed#36609) windowspecdefinition(road_id#36586, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#37010]
+- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_change#36931, vehicle_count_lag#36968, CASE WHEN isnotnull(vehicle_count_lag#36968) THEN (vehicle_count#36629 - vehicle_count_lag#36968) ELSE 0.0 END AS vehicle_count_change#36989]
   +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_change#36931, vehicle_count_lag#36968]
      +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_change#36931, vehicle_count_lag#36968, vehicle_count_lag#36968]
         +- Window [lag(vehicle_count#36629, -1, null) windowspecdefinition(road_id#36586, timestamp#36589 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#36968], [road_id#36586], [timestamp#36589 ASC NULLS FIRST]
            +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_change#36931]
               +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, CASE WHEN isnotnull(speed_lag#36894) THEN (speed#36609 - speed_lag#36894) ELSE 0.0 END AS speed_change#36931]
                  +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894]
                     +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843, speed_lag#36894, speed_lag#36894]
                        +- Window [lag(speed#36609, -1, null) windowspecdefinition(road_id#36586, timestamp#36589 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#36894], [road_id#36586], [timestamp#36589 ASC NULLS FIRST]
                           +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, hour_cos#36843]
                              +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, hour_sin#36813, COS((0.2617993877991494 * cast(hour#36708 as double))) AS hour_cos#36843]
                                 +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, is_weekend#36784, SIN((0.2617993877991494 * cast(hour#36708 as double))) AS hour_sin#36813]
                                    +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, day_of_week#36743, CASE WHEN day_of_week#36743 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#36784]
                                       +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, is_peak#36719, dayofweek(cast(timestamp#36589 as date)) AS day_of_week#36743]
                                          +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour#36708, CASE WHEN hour#36708 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#36719]
                                             +- Project [_id#36582, congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629, hour(timestamp#36589, Some(Asia/Bangkok)) AS hour#36708]
                                                +- Project [_id#36582, cast(congestion_level#36583 as double) AS congestion_level#36650, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, vehicle_count#36629]
                                                   +- Project [_id#36582, congestion_level#36583, lat#36584, lon#36585, road_id#36586, road_name#36587, speed#36609, timestamp#36589, cast(vehicle_count#36590 as double) AS vehicle_count#36629]
                                                      +- Project [_id#36582, congestion_level#36583, lat#36584, lon#36585, road_id#36586, road_name#36587, cast(speed#36588 as double) AS speed#36609, timestamp#36589, vehicle_count#36590]
                                                         +- Relation [_id#36582,congestion_level#36583,lat#36584,lon#36585,road_id#36586,road_name#36587,speed#36588,timestamp#36589,vehicle_count#36590] MongoRelation(MongoRDD[2171] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:08,441 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:43:08 +07)" executed successfully
2026-01-06 12:42:13,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:18 +07)" (scheduled at 2026-01-06 12:42:13.157382+07:00)
2026-01-06 12:42:13,159 - INFO -  Training Spark model...
2026-01-06 12:42:13,374 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_change#37171, vehicle_count_lag#37189, vehicle_count_change#37208, avg(speed#37029) windowspecdefinition(road_id#37015, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#37229]
+- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_change#37171, vehicle_count_lag#37189, CASE WHEN isnotnull(vehicle_count_lag#37189) THEN (vehicle_count#37039 - vehicle_count_lag#37189) ELSE 0.0 END AS vehicle_count_change#37208]
   +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_change#37171, vehicle_count_lag#37189]
      +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_change#37171, vehicle_count_lag#37189, vehicle_count_lag#37189]
         +- Window [lag(vehicle_count#37039, -1, null) windowspecdefinition(road_id#37015, timestamp#37018 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#37189], [road_id#37015], [timestamp#37018 ASC NULLS FIRST]
            +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_change#37171]
               +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, CASE WHEN isnotnull(speed_lag#37154) THEN (speed#37029 - speed_lag#37154) ELSE 0.0 END AS speed_change#37171]
                  +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154]
                     +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138, speed_lag#37154, speed_lag#37154]
                        +- Window [lag(speed#37029, -1, null) windowspecdefinition(road_id#37015, timestamp#37018 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#37154], [road_id#37015], [timestamp#37018 ASC NULLS FIRST]
                           +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, hour_cos#37138]
                              +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, hour_sin#37123, COS((0.2617993877991494 * cast(hour#37073 as double))) AS hour_cos#37138]
                                 +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, is_weekend#37109, SIN((0.2617993877991494 * cast(hour#37073 as double))) AS hour_sin#37123]
                                    +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, day_of_week#37096, CASE WHEN day_of_week#37096 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#37109]
                                       +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, is_peak#37084, dayofweek(cast(timestamp#37018 as date)) AS day_of_week#37096]
                                          +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour#37073, CASE WHEN hour#37073 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#37084]
                                             +- Project [_id#37011, congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039, hour(timestamp#37018, Some(Asia/Bangkok)) AS hour#37073]
                                                +- Project [_id#37011, cast(congestion_level#37012 as double) AS congestion_level#37049, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, vehicle_count#37039]
                                                   +- Project [_id#37011, congestion_level#37012, lat#37013, lon#37014, road_id#37015, road_name#37016, speed#37029, timestamp#37018, cast(vehicle_count#37019 as double) AS vehicle_count#37039]
                                                      +- Project [_id#37011, congestion_level#37012, lat#37013, lon#37014, road_id#37015, road_name#37016, cast(speed#37017 as double) AS speed#37029, timestamp#37018, vehicle_count#37019]
                                                         +- Relation [_id#37011,congestion_level#37012,lat#37013,lon#37014,road_id#37015,road_name#37016,speed#37017,timestamp#37018,vehicle_count#37019] MongoRelation(MongoRDD[2197] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:13,375 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:18 +07)" executed successfully
2026-01-06 12:42:18,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:23 +07)" (scheduled at 2026-01-06 12:42:18.157382+07:00)
2026-01-06 12:42:18,162 - INFO -  Training Spark model...
2026-01-06 12:42:18,456 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_change#37390, vehicle_count_lag#37408, vehicle_count_change#37427, avg(speed#37248) windowspecdefinition(road_id#37234, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#37448]
+- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_change#37390, vehicle_count_lag#37408, CASE WHEN isnotnull(vehicle_count_lag#37408) THEN (vehicle_count#37258 - vehicle_count_lag#37408) ELSE 0.0 END AS vehicle_count_change#37427]
   +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_change#37390, vehicle_count_lag#37408]
      +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_change#37390, vehicle_count_lag#37408, vehicle_count_lag#37408]
         +- Window [lag(vehicle_count#37258, -1, null) windowspecdefinition(road_id#37234, timestamp#37237 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#37408], [road_id#37234], [timestamp#37237 ASC NULLS FIRST]
            +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_change#37390]
               +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, CASE WHEN isnotnull(speed_lag#37373) THEN (speed#37248 - speed_lag#37373) ELSE 0.0 END AS speed_change#37390]
                  +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373]
                     +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357, speed_lag#37373, speed_lag#37373]
                        +- Window [lag(speed#37248, -1, null) windowspecdefinition(road_id#37234, timestamp#37237 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#37373], [road_id#37234], [timestamp#37237 ASC NULLS FIRST]
                           +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, hour_cos#37357]
                              +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, hour_sin#37342, COS((0.2617993877991494 * cast(hour#37292 as double))) AS hour_cos#37357]
                                 +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, is_weekend#37328, SIN((0.2617993877991494 * cast(hour#37292 as double))) AS hour_sin#37342]
                                    +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, day_of_week#37315, CASE WHEN day_of_week#37315 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#37328]
                                       +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, is_peak#37303, dayofweek(cast(timestamp#37237 as date)) AS day_of_week#37315]
                                          +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour#37292, CASE WHEN hour#37292 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#37303]
                                             +- Project [_id#37230, congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258, hour(timestamp#37237, Some(Asia/Bangkok)) AS hour#37292]
                                                +- Project [_id#37230, cast(congestion_level#37231 as double) AS congestion_level#37268, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, vehicle_count#37258]
                                                   +- Project [_id#37230, congestion_level#37231, lat#37232, lon#37233, road_id#37234, road_name#37235, speed#37248, timestamp#37237, cast(vehicle_count#37238 as double) AS vehicle_count#37258]
                                                      +- Project [_id#37230, congestion_level#37231, lat#37232, lon#37233, road_id#37234, road_name#37235, cast(speed#37236 as double) AS speed#37248, timestamp#37237, vehicle_count#37238]
                                                         +- Relation [_id#37230,congestion_level#37231,lat#37232,lon#37233,road_id#37234,road_name#37235,speed#37236,timestamp#37237,vehicle_count#37238] MongoRelation(MongoRDD[2210] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:18,456 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:23 +07)" executed successfully
2026-01-06 12:42:23,168 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:28 +07)" (scheduled at 2026-01-06 12:42:23.157382+07:00)
2026-01-06 12:42:23,168 - INFO -  Training Spark model...
2026-01-06 12:42:23,407 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_change#37609, vehicle_count_lag#37627, vehicle_count_change#37646, avg(speed#37467) windowspecdefinition(road_id#37453, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#37667]
+- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_change#37609, vehicle_count_lag#37627, CASE WHEN isnotnull(vehicle_count_lag#37627) THEN (vehicle_count#37477 - vehicle_count_lag#37627) ELSE 0.0 END AS vehicle_count_change#37646]
   +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_change#37609, vehicle_count_lag#37627]
      +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_change#37609, vehicle_count_lag#37627, vehicle_count_lag#37627]
         +- Window [lag(vehicle_count#37477, -1, null) windowspecdefinition(road_id#37453, timestamp#37456 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#37627], [road_id#37453], [timestamp#37456 ASC NULLS FIRST]
            +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_change#37609]
               +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, CASE WHEN isnotnull(speed_lag#37592) THEN (speed#37467 - speed_lag#37592) ELSE 0.0 END AS speed_change#37609]
                  +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592]
                     +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576, speed_lag#37592, speed_lag#37592]
                        +- Window [lag(speed#37467, -1, null) windowspecdefinition(road_id#37453, timestamp#37456 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#37592], [road_id#37453], [timestamp#37456 ASC NULLS FIRST]
                           +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, hour_cos#37576]
                              +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, hour_sin#37561, COS((0.2617993877991494 * cast(hour#37511 as double))) AS hour_cos#37576]
                                 +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, is_weekend#37547, SIN((0.2617993877991494 * cast(hour#37511 as double))) AS hour_sin#37561]
                                    +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, day_of_week#37534, CASE WHEN day_of_week#37534 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#37547]
                                       +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, is_peak#37522, dayofweek(cast(timestamp#37456 as date)) AS day_of_week#37534]
                                          +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour#37511, CASE WHEN hour#37511 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#37522]
                                             +- Project [_id#37449, congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477, hour(timestamp#37456, Some(Asia/Bangkok)) AS hour#37511]
                                                +- Project [_id#37449, cast(congestion_level#37450 as double) AS congestion_level#37487, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, vehicle_count#37477]
                                                   +- Project [_id#37449, congestion_level#37450, lat#37451, lon#37452, road_id#37453, road_name#37454, speed#37467, timestamp#37456, cast(vehicle_count#37457 as double) AS vehicle_count#37477]
                                                      +- Project [_id#37449, congestion_level#37450, lat#37451, lon#37452, road_id#37453, road_name#37454, cast(speed#37455 as double) AS speed#37467, timestamp#37456, vehicle_count#37457]
                                                         +- Relation [_id#37449,congestion_level#37450,lat#37451,lon#37452,road_id#37453,road_name#37454,speed#37455,timestamp#37456,vehicle_count#37457] MongoRelation(MongoRDD[2223] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:23,407 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:28 +07)" executed successfully
2026-01-06 12:42:28,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:33 +07)" (scheduled at 2026-01-06 12:42:28.157382+07:00)
2026-01-06 12:42:28,159 - INFO -  Training Spark model...
2026-01-06 12:42:28,375 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_change#37828, vehicle_count_lag#37846, vehicle_count_change#37865, avg(speed#37686) windowspecdefinition(road_id#37672, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#37886]
+- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_change#37828, vehicle_count_lag#37846, CASE WHEN isnotnull(vehicle_count_lag#37846) THEN (vehicle_count#37696 - vehicle_count_lag#37846) ELSE 0.0 END AS vehicle_count_change#37865]
   +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_change#37828, vehicle_count_lag#37846]
      +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_change#37828, vehicle_count_lag#37846, vehicle_count_lag#37846]
         +- Window [lag(vehicle_count#37696, -1, null) windowspecdefinition(road_id#37672, timestamp#37675 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#37846], [road_id#37672], [timestamp#37675 ASC NULLS FIRST]
            +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_change#37828]
               +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, CASE WHEN isnotnull(speed_lag#37811) THEN (speed#37686 - speed_lag#37811) ELSE 0.0 END AS speed_change#37828]
                  +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811]
                     +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795, speed_lag#37811, speed_lag#37811]
                        +- Window [lag(speed#37686, -1, null) windowspecdefinition(road_id#37672, timestamp#37675 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#37811], [road_id#37672], [timestamp#37675 ASC NULLS FIRST]
                           +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, hour_cos#37795]
                              +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, hour_sin#37780, COS((0.2617993877991494 * cast(hour#37730 as double))) AS hour_cos#37795]
                                 +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, is_weekend#37766, SIN((0.2617993877991494 * cast(hour#37730 as double))) AS hour_sin#37780]
                                    +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, day_of_week#37753, CASE WHEN day_of_week#37753 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#37766]
                                       +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, is_peak#37741, dayofweek(cast(timestamp#37675 as date)) AS day_of_week#37753]
                                          +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour#37730, CASE WHEN hour#37730 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#37741]
                                             +- Project [_id#37668, congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696, hour(timestamp#37675, Some(Asia/Bangkok)) AS hour#37730]
                                                +- Project [_id#37668, cast(congestion_level#37669 as double) AS congestion_level#37706, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, vehicle_count#37696]
                                                   +- Project [_id#37668, congestion_level#37669, lat#37670, lon#37671, road_id#37672, road_name#37673, speed#37686, timestamp#37675, cast(vehicle_count#37676 as double) AS vehicle_count#37696]
                                                      +- Project [_id#37668, congestion_level#37669, lat#37670, lon#37671, road_id#37672, road_name#37673, cast(speed#37674 as double) AS speed#37686, timestamp#37675, vehicle_count#37676]
                                                         +- Relation [_id#37668,congestion_level#37669,lat#37670,lon#37671,road_id#37672,road_name#37673,speed#37674,timestamp#37675,vehicle_count#37676] MongoRelation(MongoRDD[2236] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:28,375 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:33 +07)" executed successfully
2026-01-06 12:42:33,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:38 +07)" (scheduled at 2026-01-06 12:42:33.157382+07:00)
2026-01-06 12:42:33,159 - INFO -  Training Spark model...
2026-01-06 12:42:33,370 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_change#38047, vehicle_count_lag#38065, vehicle_count_change#38084, avg(speed#37905) windowspecdefinition(road_id#37891, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#38105]
+- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_change#38047, vehicle_count_lag#38065, CASE WHEN isnotnull(vehicle_count_lag#38065) THEN (vehicle_count#37915 - vehicle_count_lag#38065) ELSE 0.0 END AS vehicle_count_change#38084]
   +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_change#38047, vehicle_count_lag#38065]
      +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_change#38047, vehicle_count_lag#38065, vehicle_count_lag#38065]
         +- Window [lag(vehicle_count#37915, -1, null) windowspecdefinition(road_id#37891, timestamp#37894 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#38065], [road_id#37891], [timestamp#37894 ASC NULLS FIRST]
            +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_change#38047]
               +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, CASE WHEN isnotnull(speed_lag#38030) THEN (speed#37905 - speed_lag#38030) ELSE 0.0 END AS speed_change#38047]
                  +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030]
                     +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014, speed_lag#38030, speed_lag#38030]
                        +- Window [lag(speed#37905, -1, null) windowspecdefinition(road_id#37891, timestamp#37894 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#38030], [road_id#37891], [timestamp#37894 ASC NULLS FIRST]
                           +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, hour_cos#38014]
                              +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, hour_sin#37999, COS((0.2617993877991494 * cast(hour#37949 as double))) AS hour_cos#38014]
                                 +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, is_weekend#37985, SIN((0.2617993877991494 * cast(hour#37949 as double))) AS hour_sin#37999]
                                    +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, day_of_week#37972, CASE WHEN day_of_week#37972 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#37985]
                                       +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, is_peak#37960, dayofweek(cast(timestamp#37894 as date)) AS day_of_week#37972]
                                          +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour#37949, CASE WHEN hour#37949 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#37960]
                                             +- Project [_id#37887, congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915, hour(timestamp#37894, Some(Asia/Bangkok)) AS hour#37949]
                                                +- Project [_id#37887, cast(congestion_level#37888 as double) AS congestion_level#37925, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, vehicle_count#37915]
                                                   +- Project [_id#37887, congestion_level#37888, lat#37889, lon#37890, road_id#37891, road_name#37892, speed#37905, timestamp#37894, cast(vehicle_count#37895 as double) AS vehicle_count#37915]
                                                      +- Project [_id#37887, congestion_level#37888, lat#37889, lon#37890, road_id#37891, road_name#37892, cast(speed#37893 as double) AS speed#37905, timestamp#37894, vehicle_count#37895]
                                                         +- Relation [_id#37887,congestion_level#37888,lat#37889,lon#37890,road_id#37891,road_name#37892,speed#37893,timestamp#37894,vehicle_count#37895] MongoRelation(MongoRDD[2249] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:33,370 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:38 +07)" executed successfully
2026-01-06 12:42:38,180 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:43 +07)" (scheduled at 2026-01-06 12:42:38.157382+07:00)
2026-01-06 12:42:38,180 - INFO -  Training Spark model...
2026-01-06 12:42:38,402 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_change#38266, vehicle_count_lag#38284, vehicle_count_change#38303, avg(speed#38124) windowspecdefinition(road_id#38110, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#38324]
+- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_change#38266, vehicle_count_lag#38284, CASE WHEN isnotnull(vehicle_count_lag#38284) THEN (vehicle_count#38134 - vehicle_count_lag#38284) ELSE 0.0 END AS vehicle_count_change#38303]
   +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_change#38266, vehicle_count_lag#38284]
      +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_change#38266, vehicle_count_lag#38284, vehicle_count_lag#38284]
         +- Window [lag(vehicle_count#38134, -1, null) windowspecdefinition(road_id#38110, timestamp#38113 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#38284], [road_id#38110], [timestamp#38113 ASC NULLS FIRST]
            +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_change#38266]
               +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, CASE WHEN isnotnull(speed_lag#38249) THEN (speed#38124 - speed_lag#38249) ELSE 0.0 END AS speed_change#38266]
                  +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249]
                     +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233, speed_lag#38249, speed_lag#38249]
                        +- Window [lag(speed#38124, -1, null) windowspecdefinition(road_id#38110, timestamp#38113 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#38249], [road_id#38110], [timestamp#38113 ASC NULLS FIRST]
                           +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, hour_cos#38233]
                              +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, hour_sin#38218, COS((0.2617993877991494 * cast(hour#38168 as double))) AS hour_cos#38233]
                                 +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, is_weekend#38204, SIN((0.2617993877991494 * cast(hour#38168 as double))) AS hour_sin#38218]
                                    +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, day_of_week#38191, CASE WHEN day_of_week#38191 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#38204]
                                       +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, is_peak#38179, dayofweek(cast(timestamp#38113 as date)) AS day_of_week#38191]
                                          +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour#38168, CASE WHEN hour#38168 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#38179]
                                             +- Project [_id#38106, congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134, hour(timestamp#38113, Some(Asia/Bangkok)) AS hour#38168]
                                                +- Project [_id#38106, cast(congestion_level#38107 as double) AS congestion_level#38144, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, vehicle_count#38134]
                                                   +- Project [_id#38106, congestion_level#38107, lat#38108, lon#38109, road_id#38110, road_name#38111, speed#38124, timestamp#38113, cast(vehicle_count#38114 as double) AS vehicle_count#38134]
                                                      +- Project [_id#38106, congestion_level#38107, lat#38108, lon#38109, road_id#38110, road_name#38111, cast(speed#38112 as double) AS speed#38124, timestamp#38113, vehicle_count#38114]
                                                         +- Relation [_id#38106,congestion_level#38107,lat#38108,lon#38109,road_id#38110,road_name#38111,speed#38112,timestamp#38113,vehicle_count#38114] MongoRelation(MongoRDD[2262] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:38,402 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:43 +07)" executed successfully
2026-01-06 12:42:43,175 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:48 +07)" (scheduled at 2026-01-06 12:42:43.157382+07:00)
2026-01-06 12:42:43,176 - INFO -  Training Spark model...
2026-01-06 12:42:43,431 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_change#38485, vehicle_count_lag#38503, vehicle_count_change#38522, avg(speed#38343) windowspecdefinition(road_id#38329, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#38543]
+- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_change#38485, vehicle_count_lag#38503, CASE WHEN isnotnull(vehicle_count_lag#38503) THEN (vehicle_count#38353 - vehicle_count_lag#38503) ELSE 0.0 END AS vehicle_count_change#38522]
   +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_change#38485, vehicle_count_lag#38503]
      +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_change#38485, vehicle_count_lag#38503, vehicle_count_lag#38503]
         +- Window [lag(vehicle_count#38353, -1, null) windowspecdefinition(road_id#38329, timestamp#38332 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#38503], [road_id#38329], [timestamp#38332 ASC NULLS FIRST]
            +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_change#38485]
               +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, CASE WHEN isnotnull(speed_lag#38468) THEN (speed#38343 - speed_lag#38468) ELSE 0.0 END AS speed_change#38485]
                  +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468]
                     +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452, speed_lag#38468, speed_lag#38468]
                        +- Window [lag(speed#38343, -1, null) windowspecdefinition(road_id#38329, timestamp#38332 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#38468], [road_id#38329], [timestamp#38332 ASC NULLS FIRST]
                           +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, hour_cos#38452]
                              +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, hour_sin#38437, COS((0.2617993877991494 * cast(hour#38387 as double))) AS hour_cos#38452]
                                 +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, is_weekend#38423, SIN((0.2617993877991494 * cast(hour#38387 as double))) AS hour_sin#38437]
                                    +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, day_of_week#38410, CASE WHEN day_of_week#38410 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#38423]
                                       +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, is_peak#38398, dayofweek(cast(timestamp#38332 as date)) AS day_of_week#38410]
                                          +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour#38387, CASE WHEN hour#38387 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#38398]
                                             +- Project [_id#38325, congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353, hour(timestamp#38332, Some(Asia/Bangkok)) AS hour#38387]
                                                +- Project [_id#38325, cast(congestion_level#38326 as double) AS congestion_level#38363, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, vehicle_count#38353]
                                                   +- Project [_id#38325, congestion_level#38326, lat#38327, lon#38328, road_id#38329, road_name#38330, speed#38343, timestamp#38332, cast(vehicle_count#38333 as double) AS vehicle_count#38353]
                                                      +- Project [_id#38325, congestion_level#38326, lat#38327, lon#38328, road_id#38329, road_name#38330, cast(speed#38331 as double) AS speed#38343, timestamp#38332, vehicle_count#38333]
                                                         +- Relation [_id#38325,congestion_level#38326,lat#38327,lon#38328,road_id#38329,road_name#38330,speed#38331,timestamp#38332,vehicle_count#38333] MongoRelation(MongoRDD[2275] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:43,431 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:48 +07)" executed successfully
2026-01-06 12:42:48,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:53 +07)" (scheduled at 2026-01-06 12:42:48.157382+07:00)
2026-01-06 12:42:48,159 - INFO -  Training Spark model...
2026-01-06 12:42:48,387 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_change#38704, vehicle_count_lag#38722, vehicle_count_change#38741, avg(speed#38562) windowspecdefinition(road_id#38548, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#38762]
+- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_change#38704, vehicle_count_lag#38722, CASE WHEN isnotnull(vehicle_count_lag#38722) THEN (vehicle_count#38572 - vehicle_count_lag#38722) ELSE 0.0 END AS vehicle_count_change#38741]
   +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_change#38704, vehicle_count_lag#38722]
      +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_change#38704, vehicle_count_lag#38722, vehicle_count_lag#38722]
         +- Window [lag(vehicle_count#38572, -1, null) windowspecdefinition(road_id#38548, timestamp#38551 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#38722], [road_id#38548], [timestamp#38551 ASC NULLS FIRST]
            +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_change#38704]
               +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, CASE WHEN isnotnull(speed_lag#38687) THEN (speed#38562 - speed_lag#38687) ELSE 0.0 END AS speed_change#38704]
                  +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687]
                     +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671, speed_lag#38687, speed_lag#38687]
                        +- Window [lag(speed#38562, -1, null) windowspecdefinition(road_id#38548, timestamp#38551 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#38687], [road_id#38548], [timestamp#38551 ASC NULLS FIRST]
                           +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, hour_cos#38671]
                              +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, hour_sin#38656, COS((0.2617993877991494 * cast(hour#38606 as double))) AS hour_cos#38671]
                                 +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, is_weekend#38642, SIN((0.2617993877991494 * cast(hour#38606 as double))) AS hour_sin#38656]
                                    +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, day_of_week#38629, CASE WHEN day_of_week#38629 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#38642]
                                       +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, is_peak#38617, dayofweek(cast(timestamp#38551 as date)) AS day_of_week#38629]
                                          +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour#38606, CASE WHEN hour#38606 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#38617]
                                             +- Project [_id#38544, congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572, hour(timestamp#38551, Some(Asia/Bangkok)) AS hour#38606]
                                                +- Project [_id#38544, cast(congestion_level#38545 as double) AS congestion_level#38582, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, vehicle_count#38572]
                                                   +- Project [_id#38544, congestion_level#38545, lat#38546, lon#38547, road_id#38548, road_name#38549, speed#38562, timestamp#38551, cast(vehicle_count#38552 as double) AS vehicle_count#38572]
                                                      +- Project [_id#38544, congestion_level#38545, lat#38546, lon#38547, road_id#38548, road_name#38549, cast(speed#38550 as double) AS speed#38562, timestamp#38551, vehicle_count#38552]
                                                         +- Relation [_id#38544,congestion_level#38545,lat#38546,lon#38547,road_id#38548,road_name#38549,speed#38550,timestamp#38551,vehicle_count#38552] MongoRelation(MongoRDD[2288] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:48,387 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:53 +07)" executed successfully
2026-01-06 12:42:53,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:58 +07)" (scheduled at 2026-01-06 12:42:53.157382+07:00)
2026-01-06 12:42:53,159 - INFO -  Training Spark model...
2026-01-06 12:42:53,418 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_change#38923, vehicle_count_lag#38941, vehicle_count_change#38960, avg(speed#38781) windowspecdefinition(road_id#38767, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#38981]
+- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_change#38923, vehicle_count_lag#38941, CASE WHEN isnotnull(vehicle_count_lag#38941) THEN (vehicle_count#38791 - vehicle_count_lag#38941) ELSE 0.0 END AS vehicle_count_change#38960]
   +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_change#38923, vehicle_count_lag#38941]
      +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_change#38923, vehicle_count_lag#38941, vehicle_count_lag#38941]
         +- Window [lag(vehicle_count#38791, -1, null) windowspecdefinition(road_id#38767, timestamp#38770 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#38941], [road_id#38767], [timestamp#38770 ASC NULLS FIRST]
            +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_change#38923]
               +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, CASE WHEN isnotnull(speed_lag#38906) THEN (speed#38781 - speed_lag#38906) ELSE 0.0 END AS speed_change#38923]
                  +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906]
                     +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890, speed_lag#38906, speed_lag#38906]
                        +- Window [lag(speed#38781, -1, null) windowspecdefinition(road_id#38767, timestamp#38770 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#38906], [road_id#38767], [timestamp#38770 ASC NULLS FIRST]
                           +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, hour_cos#38890]
                              +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, hour_sin#38875, COS((0.2617993877991494 * cast(hour#38825 as double))) AS hour_cos#38890]
                                 +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, is_weekend#38861, SIN((0.2617993877991494 * cast(hour#38825 as double))) AS hour_sin#38875]
                                    +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, day_of_week#38848, CASE WHEN day_of_week#38848 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#38861]
                                       +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, is_peak#38836, dayofweek(cast(timestamp#38770 as date)) AS day_of_week#38848]
                                          +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour#38825, CASE WHEN hour#38825 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#38836]
                                             +- Project [_id#38763, congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791, hour(timestamp#38770, Some(Asia/Bangkok)) AS hour#38825]
                                                +- Project [_id#38763, cast(congestion_level#38764 as double) AS congestion_level#38801, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, vehicle_count#38791]
                                                   +- Project [_id#38763, congestion_level#38764, lat#38765, lon#38766, road_id#38767, road_name#38768, speed#38781, timestamp#38770, cast(vehicle_count#38771 as double) AS vehicle_count#38791]
                                                      +- Project [_id#38763, congestion_level#38764, lat#38765, lon#38766, road_id#38767, road_name#38768, cast(speed#38769 as double) AS speed#38781, timestamp#38770, vehicle_count#38771]
                                                         +- Relation [_id#38763,congestion_level#38764,lat#38765,lon#38766,road_id#38767,road_name#38768,speed#38769,timestamp#38770,vehicle_count#38771] MongoRelation(MongoRDD[2301] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:53,418 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:42:58 +07)" executed successfully
2026-01-06 12:42:58,169 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:03 +07)" (scheduled at 2026-01-06 12:42:58.157382+07:00)
2026-01-06 12:42:58,169 - INFO -  Training Spark model...
2026-01-06 12:42:58,385 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_change#39142, vehicle_count_lag#39160, vehicle_count_change#39179, avg(speed#39000) windowspecdefinition(road_id#38986, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#39200]
+- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_change#39142, vehicle_count_lag#39160, CASE WHEN isnotnull(vehicle_count_lag#39160) THEN (vehicle_count#39010 - vehicle_count_lag#39160) ELSE 0.0 END AS vehicle_count_change#39179]
   +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_change#39142, vehicle_count_lag#39160]
      +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_change#39142, vehicle_count_lag#39160, vehicle_count_lag#39160]
         +- Window [lag(vehicle_count#39010, -1, null) windowspecdefinition(road_id#38986, timestamp#38989 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#39160], [road_id#38986], [timestamp#38989 ASC NULLS FIRST]
            +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_change#39142]
               +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, CASE WHEN isnotnull(speed_lag#39125) THEN (speed#39000 - speed_lag#39125) ELSE 0.0 END AS speed_change#39142]
                  +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125]
                     +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109, speed_lag#39125, speed_lag#39125]
                        +- Window [lag(speed#39000, -1, null) windowspecdefinition(road_id#38986, timestamp#38989 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#39125], [road_id#38986], [timestamp#38989 ASC NULLS FIRST]
                           +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, hour_cos#39109]
                              +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, hour_sin#39094, COS((0.2617993877991494 * cast(hour#39044 as double))) AS hour_cos#39109]
                                 +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, is_weekend#39080, SIN((0.2617993877991494 * cast(hour#39044 as double))) AS hour_sin#39094]
                                    +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, day_of_week#39067, CASE WHEN day_of_week#39067 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#39080]
                                       +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, is_peak#39055, dayofweek(cast(timestamp#38989 as date)) AS day_of_week#39067]
                                          +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour#39044, CASE WHEN hour#39044 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#39055]
                                             +- Project [_id#38982, congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010, hour(timestamp#38989, Some(Asia/Bangkok)) AS hour#39044]
                                                +- Project [_id#38982, cast(congestion_level#38983 as double) AS congestion_level#39020, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, vehicle_count#39010]
                                                   +- Project [_id#38982, congestion_level#38983, lat#38984, lon#38985, road_id#38986, road_name#38987, speed#39000, timestamp#38989, cast(vehicle_count#38990 as double) AS vehicle_count#39010]
                                                      +- Project [_id#38982, congestion_level#38983, lat#38984, lon#38985, road_id#38986, road_name#38987, cast(speed#38988 as double) AS speed#39000, timestamp#38989, vehicle_count#38990]
                                                         +- Relation [_id#38982,congestion_level#38983,lat#38984,lon#38985,road_id#38986,road_name#38987,speed#38988,timestamp#38989,vehicle_count#38990] MongoRelation(MongoRDD[2314] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:42:58,386 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:03 +07)" executed successfully
2026-01-06 12:43:03,171 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:08 +07)" (scheduled at 2026-01-06 12:43:03.157382+07:00)
2026-01-06 12:43:03,171 - INFO -  Training Spark model...
2026-01-06 12:43:03,391 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_change#39361, vehicle_count_lag#39379, vehicle_count_change#39398, avg(speed#39219) windowspecdefinition(road_id#39205, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#39419]
+- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_change#39361, vehicle_count_lag#39379, CASE WHEN isnotnull(vehicle_count_lag#39379) THEN (vehicle_count#39229 - vehicle_count_lag#39379) ELSE 0.0 END AS vehicle_count_change#39398]
   +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_change#39361, vehicle_count_lag#39379]
      +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_change#39361, vehicle_count_lag#39379, vehicle_count_lag#39379]
         +- Window [lag(vehicle_count#39229, -1, null) windowspecdefinition(road_id#39205, timestamp#39208 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#39379], [road_id#39205], [timestamp#39208 ASC NULLS FIRST]
            +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_change#39361]
               +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, CASE WHEN isnotnull(speed_lag#39344) THEN (speed#39219 - speed_lag#39344) ELSE 0.0 END AS speed_change#39361]
                  +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344]
                     +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328, speed_lag#39344, speed_lag#39344]
                        +- Window [lag(speed#39219, -1, null) windowspecdefinition(road_id#39205, timestamp#39208 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#39344], [road_id#39205], [timestamp#39208 ASC NULLS FIRST]
                           +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, hour_cos#39328]
                              +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, hour_sin#39313, COS((0.2617993877991494 * cast(hour#39263 as double))) AS hour_cos#39328]
                                 +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, is_weekend#39299, SIN((0.2617993877991494 * cast(hour#39263 as double))) AS hour_sin#39313]
                                    +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, day_of_week#39286, CASE WHEN day_of_week#39286 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#39299]
                                       +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, is_peak#39274, dayofweek(cast(timestamp#39208 as date)) AS day_of_week#39286]
                                          +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour#39263, CASE WHEN hour#39263 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#39274]
                                             +- Project [_id#39201, congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229, hour(timestamp#39208, Some(Asia/Bangkok)) AS hour#39263]
                                                +- Project [_id#39201, cast(congestion_level#39202 as double) AS congestion_level#39239, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, vehicle_count#39229]
                                                   +- Project [_id#39201, congestion_level#39202, lat#39203, lon#39204, road_id#39205, road_name#39206, speed#39219, timestamp#39208, cast(vehicle_count#39209 as double) AS vehicle_count#39229]
                                                      +- Project [_id#39201, congestion_level#39202, lat#39203, lon#39204, road_id#39205, road_name#39206, cast(speed#39207 as double) AS speed#39219, timestamp#39208, vehicle_count#39209]
                                                         +- Relation [_id#39201,congestion_level#39202,lat#39203,lon#39204,road_id#39205,road_name#39206,speed#39207,timestamp#39208,vehicle_count#39209] MongoRelation(MongoRDD[2327] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:03,392 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:08 +07)" executed successfully
2026-01-06 12:43:08,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:13 +07)" (scheduled at 2026-01-06 12:43:08.157382+07:00)
2026-01-06 12:43:08,160 - INFO -  Training Spark model...
2026-01-06 12:43:08,161 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:44:08 +07)" (scheduled at 2026-01-06 12:43:08.157779+07:00)
2026-01-06 12:43:08,161 - INFO -  Training Spark model...
2026-01-06 12:43:08,483 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_change#39741, vehicle_count_lag#39777, vehicle_count_change#39815, avg(speed#39456) windowspecdefinition(road_id#39428, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#39856]
+- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_change#39741, vehicle_count_lag#39777, CASE WHEN isnotnull(vehicle_count_lag#39777) THEN (vehicle_count#39476 - vehicle_count_lag#39777) ELSE 0.0 END AS vehicle_count_change#39815]
   +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_change#39741, vehicle_count_lag#39777]
      +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_change#39741, vehicle_count_lag#39777, vehicle_count_lag#39777]
         +- Window [lag(vehicle_count#39476, -1, null) windowspecdefinition(road_id#39428, timestamp#39434 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#39777], [road_id#39428], [timestamp#39434 ASC NULLS FIRST]
            +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_change#39741]
               +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, CASE WHEN isnotnull(speed_lag#39723) THEN (speed#39456 - speed_lag#39723) ELSE 0.0 END AS speed_change#39741]
                  +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723]
                     +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690, speed_lag#39723, speed_lag#39723]
                        +- Window [lag(speed#39456, -1, null) windowspecdefinition(road_id#39428, timestamp#39434 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#39723], [road_id#39428], [timestamp#39434 ASC NULLS FIRST]
                           +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, hour_cos#39690]
                              +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, hour_sin#39659, COS((0.2617993877991494 * cast(hour#39544 as double))) AS hour_cos#39690]
                                 +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, is_weekend#39617, SIN((0.2617993877991494 * cast(hour#39544 as double))) AS hour_sin#39659]
                                    +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, day_of_week#39590, CASE WHEN day_of_week#39590 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#39617]
                                       +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, is_peak#39566, dayofweek(cast(timestamp#39434 as date)) AS day_of_week#39590]
                                          +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour#39544, CASE WHEN hour#39544 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#39566]
                                             +- Project [_id#39420, congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476, hour(timestamp#39434, Some(Asia/Bangkok)) AS hour#39544]
                                                +- Project [_id#39420, cast(congestion_level#39422 as double) AS congestion_level#39497, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, vehicle_count#39476]
                                                   +- Project [_id#39420, congestion_level#39422, lat#39424, lon#39426, road_id#39428, road_name#39430, speed#39456, timestamp#39434, cast(vehicle_count#39436 as double) AS vehicle_count#39476]
                                                      +- Project [_id#39420, congestion_level#39422, lat#39424, lon#39426, road_id#39428, road_name#39430, cast(speed#39432 as double) AS speed#39456, timestamp#39434, vehicle_count#39436]
                                                         +- Relation [_id#39420,congestion_level#39422,lat#39424,lon#39426,road_id#39428,road_name#39430,speed#39432,timestamp#39434,vehicle_count#39436] MongoRelation(MongoRDD[2341] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:08,483 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_change#39740, vehicle_count_lag#39776, vehicle_count_change#39814, avg(speed#39457) windowspecdefinition(road_id#39429, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#39857]
+- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_change#39740, vehicle_count_lag#39776, CASE WHEN isnotnull(vehicle_count_lag#39776) THEN (vehicle_count#39477 - vehicle_count_lag#39776) ELSE 0.0 END AS vehicle_count_change#39814]
   +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_change#39740, vehicle_count_lag#39776]
      +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_change#39740, vehicle_count_lag#39776, vehicle_count_lag#39776]
         +- Window [lag(vehicle_count#39477, -1, null) windowspecdefinition(road_id#39429, timestamp#39435 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#39776], [road_id#39429], [timestamp#39435 ASC NULLS FIRST]
            +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_change#39740]
               +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, CASE WHEN isnotnull(speed_lag#39706) THEN (speed#39457 - speed_lag#39706) ELSE 0.0 END AS speed_change#39740]
                  +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706]
                     +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674, speed_lag#39706, speed_lag#39706]
                        +- Window [lag(speed#39457, -1, null) windowspecdefinition(road_id#39429, timestamp#39435 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#39706], [road_id#39429], [timestamp#39435 ASC NULLS FIRST]
                           +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, hour_cos#39674]
                              +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, hour_sin#39644, COS((0.2617993877991494 * cast(hour#39555 as double))) AS hour_cos#39674]
                                 +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, is_weekend#39616, SIN((0.2617993877991494 * cast(hour#39555 as double))) AS hour_sin#39644]
                                    +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, day_of_week#39603, CASE WHEN day_of_week#39603 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#39616]
                                       +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, is_peak#39567, dayofweek(cast(timestamp#39435 as date)) AS day_of_week#39603]
                                          +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour#39555, CASE WHEN hour#39555 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#39567]
                                             +- Project [_id#39421, congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477, hour(timestamp#39435, Some(Asia/Bangkok)) AS hour#39555]
                                                +- Project [_id#39421, cast(congestion_level#39423 as double) AS congestion_level#39496, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, vehicle_count#39477]
                                                   +- Project [_id#39421, congestion_level#39423, lat#39425, lon#39427, road_id#39429, road_name#39431, speed#39457, timestamp#39435, cast(vehicle_count#39437 as double) AS vehicle_count#39477]
                                                      +- Project [_id#39421, congestion_level#39423, lat#39425, lon#39427, road_id#39429, road_name#39431, cast(speed#39433 as double) AS speed#39457, timestamp#39435, vehicle_count#39437]
                                                         +- Relation [_id#39421,congestion_level#39423,lat#39425,lon#39427,road_id#39429,road_name#39431,speed#39433,timestamp#39435,vehicle_count#39437] MongoRelation(MongoRDD[2340] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:08,483 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:13 +07)" executed successfully
2026-01-06 12:43:08,483 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:44:08 +07)" executed successfully
2026-01-06 12:43:13,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:18 +07)" (scheduled at 2026-01-06 12:43:13.157382+07:00)
2026-01-06 12:43:13,161 - INFO -  Training Spark model...
2026-01-06 12:43:13,382 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_change#40018, vehicle_count_lag#40036, vehicle_count_change#40055, avg(speed#39876) windowspecdefinition(road_id#39862, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#40076]
+- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_change#40018, vehicle_count_lag#40036, CASE WHEN isnotnull(vehicle_count_lag#40036) THEN (vehicle_count#39886 - vehicle_count_lag#40036) ELSE 0.0 END AS vehicle_count_change#40055]
   +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_change#40018, vehicle_count_lag#40036]
      +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_change#40018, vehicle_count_lag#40036, vehicle_count_lag#40036]
         +- Window [lag(vehicle_count#39886, -1, null) windowspecdefinition(road_id#39862, timestamp#39865 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#40036], [road_id#39862], [timestamp#39865 ASC NULLS FIRST]
            +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_change#40018]
               +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, CASE WHEN isnotnull(speed_lag#40001) THEN (speed#39876 - speed_lag#40001) ELSE 0.0 END AS speed_change#40018]
                  +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001]
                     +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985, speed_lag#40001, speed_lag#40001]
                        +- Window [lag(speed#39876, -1, null) windowspecdefinition(road_id#39862, timestamp#39865 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#40001], [road_id#39862], [timestamp#39865 ASC NULLS FIRST]
                           +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, hour_cos#39985]
                              +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, hour_sin#39970, COS((0.2617993877991494 * cast(hour#39920 as double))) AS hour_cos#39985]
                                 +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, is_weekend#39956, SIN((0.2617993877991494 * cast(hour#39920 as double))) AS hour_sin#39970]
                                    +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, day_of_week#39943, CASE WHEN day_of_week#39943 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#39956]
                                       +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, is_peak#39931, dayofweek(cast(timestamp#39865 as date)) AS day_of_week#39943]
                                          +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour#39920, CASE WHEN hour#39920 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#39931]
                                             +- Project [_id#39858, congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886, hour(timestamp#39865, Some(Asia/Bangkok)) AS hour#39920]
                                                +- Project [_id#39858, cast(congestion_level#39859 as double) AS congestion_level#39896, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, vehicle_count#39886]
                                                   +- Project [_id#39858, congestion_level#39859, lat#39860, lon#39861, road_id#39862, road_name#39863, speed#39876, timestamp#39865, cast(vehicle_count#39866 as double) AS vehicle_count#39886]
                                                      +- Project [_id#39858, congestion_level#39859, lat#39860, lon#39861, road_id#39862, road_name#39863, cast(speed#39864 as double) AS speed#39876, timestamp#39865, vehicle_count#39866]
                                                         +- Relation [_id#39858,congestion_level#39859,lat#39860,lon#39861,road_id#39862,road_name#39863,speed#39864,timestamp#39865,vehicle_count#39866] MongoRelation(MongoRDD[2366] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:13,383 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:18 +07)" executed successfully
2026-01-06 12:43:18,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:23 +07)" (scheduled at 2026-01-06 12:43:18.157382+07:00)
2026-01-06 12:43:18,160 - INFO -  Training Spark model...
2026-01-06 12:43:18,383 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_change#40237, vehicle_count_lag#40255, vehicle_count_change#40274, avg(speed#40095) windowspecdefinition(road_id#40081, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#40295]
+- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_change#40237, vehicle_count_lag#40255, CASE WHEN isnotnull(vehicle_count_lag#40255) THEN (vehicle_count#40105 - vehicle_count_lag#40255) ELSE 0.0 END AS vehicle_count_change#40274]
   +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_change#40237, vehicle_count_lag#40255]
      +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_change#40237, vehicle_count_lag#40255, vehicle_count_lag#40255]
         +- Window [lag(vehicle_count#40105, -1, null) windowspecdefinition(road_id#40081, timestamp#40084 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#40255], [road_id#40081], [timestamp#40084 ASC NULLS FIRST]
            +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_change#40237]
               +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, CASE WHEN isnotnull(speed_lag#40220) THEN (speed#40095 - speed_lag#40220) ELSE 0.0 END AS speed_change#40237]
                  +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220]
                     +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204, speed_lag#40220, speed_lag#40220]
                        +- Window [lag(speed#40095, -1, null) windowspecdefinition(road_id#40081, timestamp#40084 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#40220], [road_id#40081], [timestamp#40084 ASC NULLS FIRST]
                           +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, hour_cos#40204]
                              +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, hour_sin#40189, COS((0.2617993877991494 * cast(hour#40139 as double))) AS hour_cos#40204]
                                 +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, is_weekend#40175, SIN((0.2617993877991494 * cast(hour#40139 as double))) AS hour_sin#40189]
                                    +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, day_of_week#40162, CASE WHEN day_of_week#40162 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#40175]
                                       +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, is_peak#40150, dayofweek(cast(timestamp#40084 as date)) AS day_of_week#40162]
                                          +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour#40139, CASE WHEN hour#40139 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#40150]
                                             +- Project [_id#40077, congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105, hour(timestamp#40084, Some(Asia/Bangkok)) AS hour#40139]
                                                +- Project [_id#40077, cast(congestion_level#40078 as double) AS congestion_level#40115, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, vehicle_count#40105]
                                                   +- Project [_id#40077, congestion_level#40078, lat#40079, lon#40080, road_id#40081, road_name#40082, speed#40095, timestamp#40084, cast(vehicle_count#40085 as double) AS vehicle_count#40105]
                                                      +- Project [_id#40077, congestion_level#40078, lat#40079, lon#40080, road_id#40081, road_name#40082, cast(speed#40083 as double) AS speed#40095, timestamp#40084, vehicle_count#40085]
                                                         +- Relation [_id#40077,congestion_level#40078,lat#40079,lon#40080,road_id#40081,road_name#40082,speed#40083,timestamp#40084,vehicle_count#40085] MongoRelation(MongoRDD[2379] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:18,384 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:23 +07)" executed successfully
2026-01-06 12:43:23,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:28 +07)" (scheduled at 2026-01-06 12:43:23.157382+07:00)
2026-01-06 12:43:23,160 - INFO -  Training Spark model...
2026-01-06 12:43:23,516 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_change#40456, vehicle_count_lag#40474, vehicle_count_change#40493, avg(speed#40314) windowspecdefinition(road_id#40300, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#40514]
+- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_change#40456, vehicle_count_lag#40474, CASE WHEN isnotnull(vehicle_count_lag#40474) THEN (vehicle_count#40324 - vehicle_count_lag#40474) ELSE 0.0 END AS vehicle_count_change#40493]
   +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_change#40456, vehicle_count_lag#40474]
      +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_change#40456, vehicle_count_lag#40474, vehicle_count_lag#40474]
         +- Window [lag(vehicle_count#40324, -1, null) windowspecdefinition(road_id#40300, timestamp#40303 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#40474], [road_id#40300], [timestamp#40303 ASC NULLS FIRST]
            +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_change#40456]
               +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, CASE WHEN isnotnull(speed_lag#40439) THEN (speed#40314 - speed_lag#40439) ELSE 0.0 END AS speed_change#40456]
                  +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439]
                     +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423, speed_lag#40439, speed_lag#40439]
                        +- Window [lag(speed#40314, -1, null) windowspecdefinition(road_id#40300, timestamp#40303 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#40439], [road_id#40300], [timestamp#40303 ASC NULLS FIRST]
                           +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, hour_cos#40423]
                              +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, hour_sin#40408, COS((0.2617993877991494 * cast(hour#40358 as double))) AS hour_cos#40423]
                                 +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, is_weekend#40394, SIN((0.2617993877991494 * cast(hour#40358 as double))) AS hour_sin#40408]
                                    +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, day_of_week#40381, CASE WHEN day_of_week#40381 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#40394]
                                       +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, is_peak#40369, dayofweek(cast(timestamp#40303 as date)) AS day_of_week#40381]
                                          +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour#40358, CASE WHEN hour#40358 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#40369]
                                             +- Project [_id#40296, congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324, hour(timestamp#40303, Some(Asia/Bangkok)) AS hour#40358]
                                                +- Project [_id#40296, cast(congestion_level#40297 as double) AS congestion_level#40334, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, vehicle_count#40324]
                                                   +- Project [_id#40296, congestion_level#40297, lat#40298, lon#40299, road_id#40300, road_name#40301, speed#40314, timestamp#40303, cast(vehicle_count#40304 as double) AS vehicle_count#40324]
                                                      +- Project [_id#40296, congestion_level#40297, lat#40298, lon#40299, road_id#40300, road_name#40301, cast(speed#40302 as double) AS speed#40314, timestamp#40303, vehicle_count#40304]
                                                         +- Relation [_id#40296,congestion_level#40297,lat#40298,lon#40299,road_id#40300,road_name#40301,speed#40302,timestamp#40303,vehicle_count#40304] MongoRelation(MongoRDD[2392] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:23,516 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:28 +07)" executed successfully
2026-01-06 12:43:28,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:33 +07)" (scheduled at 2026-01-06 12:43:28.157382+07:00)
2026-01-06 12:43:28,161 - INFO -  Training Spark model...
2026-01-06 12:43:28,430 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_change#40675, vehicle_count_lag#40693, vehicle_count_change#40712, avg(speed#40533) windowspecdefinition(road_id#40519, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#40733]
+- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_change#40675, vehicle_count_lag#40693, CASE WHEN isnotnull(vehicle_count_lag#40693) THEN (vehicle_count#40543 - vehicle_count_lag#40693) ELSE 0.0 END AS vehicle_count_change#40712]
   +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_change#40675, vehicle_count_lag#40693]
      +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_change#40675, vehicle_count_lag#40693, vehicle_count_lag#40693]
         +- Window [lag(vehicle_count#40543, -1, null) windowspecdefinition(road_id#40519, timestamp#40522 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#40693], [road_id#40519], [timestamp#40522 ASC NULLS FIRST]
            +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_change#40675]
               +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, CASE WHEN isnotnull(speed_lag#40658) THEN (speed#40533 - speed_lag#40658) ELSE 0.0 END AS speed_change#40675]
                  +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658]
                     +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642, speed_lag#40658, speed_lag#40658]
                        +- Window [lag(speed#40533, -1, null) windowspecdefinition(road_id#40519, timestamp#40522 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#40658], [road_id#40519], [timestamp#40522 ASC NULLS FIRST]
                           +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, hour_cos#40642]
                              +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, hour_sin#40627, COS((0.2617993877991494 * cast(hour#40577 as double))) AS hour_cos#40642]
                                 +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, is_weekend#40613, SIN((0.2617993877991494 * cast(hour#40577 as double))) AS hour_sin#40627]
                                    +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, day_of_week#40600, CASE WHEN day_of_week#40600 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#40613]
                                       +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, is_peak#40588, dayofweek(cast(timestamp#40522 as date)) AS day_of_week#40600]
                                          +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour#40577, CASE WHEN hour#40577 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#40588]
                                             +- Project [_id#40515, congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543, hour(timestamp#40522, Some(Asia/Bangkok)) AS hour#40577]
                                                +- Project [_id#40515, cast(congestion_level#40516 as double) AS congestion_level#40553, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, vehicle_count#40543]
                                                   +- Project [_id#40515, congestion_level#40516, lat#40517, lon#40518, road_id#40519, road_name#40520, speed#40533, timestamp#40522, cast(vehicle_count#40523 as double) AS vehicle_count#40543]
                                                      +- Project [_id#40515, congestion_level#40516, lat#40517, lon#40518, road_id#40519, road_name#40520, cast(speed#40521 as double) AS speed#40533, timestamp#40522, vehicle_count#40523]
                                                         +- Relation [_id#40515,congestion_level#40516,lat#40517,lon#40518,road_id#40519,road_name#40520,speed#40521,timestamp#40522,vehicle_count#40523] MongoRelation(MongoRDD[2405] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:28,430 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:33 +07)" executed successfully
2026-01-06 12:43:33,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:38 +07)" (scheduled at 2026-01-06 12:43:33.157382+07:00)
2026-01-06 12:43:33,163 - INFO -  Training Spark model...
2026-01-06 12:43:33,423 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_change#40894, vehicle_count_lag#40912, vehicle_count_change#40931, avg(speed#40752) windowspecdefinition(road_id#40738, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#40952]
+- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_change#40894, vehicle_count_lag#40912, CASE WHEN isnotnull(vehicle_count_lag#40912) THEN (vehicle_count#40762 - vehicle_count_lag#40912) ELSE 0.0 END AS vehicle_count_change#40931]
   +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_change#40894, vehicle_count_lag#40912]
      +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_change#40894, vehicle_count_lag#40912, vehicle_count_lag#40912]
         +- Window [lag(vehicle_count#40762, -1, null) windowspecdefinition(road_id#40738, timestamp#40741 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#40912], [road_id#40738], [timestamp#40741 ASC NULLS FIRST]
            +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_change#40894]
               +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, CASE WHEN isnotnull(speed_lag#40877) THEN (speed#40752 - speed_lag#40877) ELSE 0.0 END AS speed_change#40894]
                  +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877]
                     +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861, speed_lag#40877, speed_lag#40877]
                        +- Window [lag(speed#40752, -1, null) windowspecdefinition(road_id#40738, timestamp#40741 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#40877], [road_id#40738], [timestamp#40741 ASC NULLS FIRST]
                           +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, hour_cos#40861]
                              +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, hour_sin#40846, COS((0.2617993877991494 * cast(hour#40796 as double))) AS hour_cos#40861]
                                 +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, is_weekend#40832, SIN((0.2617993877991494 * cast(hour#40796 as double))) AS hour_sin#40846]
                                    +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, day_of_week#40819, CASE WHEN day_of_week#40819 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#40832]
                                       +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, is_peak#40807, dayofweek(cast(timestamp#40741 as date)) AS day_of_week#40819]
                                          +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour#40796, CASE WHEN hour#40796 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#40807]
                                             +- Project [_id#40734, congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762, hour(timestamp#40741, Some(Asia/Bangkok)) AS hour#40796]
                                                +- Project [_id#40734, cast(congestion_level#40735 as double) AS congestion_level#40772, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, vehicle_count#40762]
                                                   +- Project [_id#40734, congestion_level#40735, lat#40736, lon#40737, road_id#40738, road_name#40739, speed#40752, timestamp#40741, cast(vehicle_count#40742 as double) AS vehicle_count#40762]
                                                      +- Project [_id#40734, congestion_level#40735, lat#40736, lon#40737, road_id#40738, road_name#40739, cast(speed#40740 as double) AS speed#40752, timestamp#40741, vehicle_count#40742]
                                                         +- Relation [_id#40734,congestion_level#40735,lat#40736,lon#40737,road_id#40738,road_name#40739,speed#40740,timestamp#40741,vehicle_count#40742] MongoRelation(MongoRDD[2418] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:33,423 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:38 +07)" executed successfully
2026-01-06 12:43:38,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:43 +07)" (scheduled at 2026-01-06 12:43:38.157382+07:00)
2026-01-06 12:43:38,162 - INFO -  Training Spark model...
2026-01-06 12:43:38,362 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_change#41113, vehicle_count_lag#41131, vehicle_count_change#41150, avg(speed#40971) windowspecdefinition(road_id#40957, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#41171]
+- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_change#41113, vehicle_count_lag#41131, CASE WHEN isnotnull(vehicle_count_lag#41131) THEN (vehicle_count#40981 - vehicle_count_lag#41131) ELSE 0.0 END AS vehicle_count_change#41150]
   +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_change#41113, vehicle_count_lag#41131]
      +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_change#41113, vehicle_count_lag#41131, vehicle_count_lag#41131]
         +- Window [lag(vehicle_count#40981, -1, null) windowspecdefinition(road_id#40957, timestamp#40960 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#41131], [road_id#40957], [timestamp#40960 ASC NULLS FIRST]
            +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_change#41113]
               +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, CASE WHEN isnotnull(speed_lag#41096) THEN (speed#40971 - speed_lag#41096) ELSE 0.0 END AS speed_change#41113]
                  +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096]
                     +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080, speed_lag#41096, speed_lag#41096]
                        +- Window [lag(speed#40971, -1, null) windowspecdefinition(road_id#40957, timestamp#40960 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#41096], [road_id#40957], [timestamp#40960 ASC NULLS FIRST]
                           +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, hour_cos#41080]
                              +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, hour_sin#41065, COS((0.2617993877991494 * cast(hour#41015 as double))) AS hour_cos#41080]
                                 +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, is_weekend#41051, SIN((0.2617993877991494 * cast(hour#41015 as double))) AS hour_sin#41065]
                                    +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, day_of_week#41038, CASE WHEN day_of_week#41038 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#41051]
                                       +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, is_peak#41026, dayofweek(cast(timestamp#40960 as date)) AS day_of_week#41038]
                                          +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour#41015, CASE WHEN hour#41015 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#41026]
                                             +- Project [_id#40953, congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981, hour(timestamp#40960, Some(Asia/Bangkok)) AS hour#41015]
                                                +- Project [_id#40953, cast(congestion_level#40954 as double) AS congestion_level#40991, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, vehicle_count#40981]
                                                   +- Project [_id#40953, congestion_level#40954, lat#40955, lon#40956, road_id#40957, road_name#40958, speed#40971, timestamp#40960, cast(vehicle_count#40961 as double) AS vehicle_count#40981]
                                                      +- Project [_id#40953, congestion_level#40954, lat#40955, lon#40956, road_id#40957, road_name#40958, cast(speed#40959 as double) AS speed#40971, timestamp#40960, vehicle_count#40961]
                                                         +- Relation [_id#40953,congestion_level#40954,lat#40955,lon#40956,road_id#40957,road_name#40958,speed#40959,timestamp#40960,vehicle_count#40961] MongoRelation(MongoRDD[2431] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:38,362 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:43 +07)" executed successfully
2026-01-06 12:43:43,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:48 +07)" (scheduled at 2026-01-06 12:43:43.157382+07:00)
2026-01-06 12:43:43,162 - INFO -  Training Spark model...
2026-01-06 12:43:43,395 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_change#41332, vehicle_count_lag#41350, vehicle_count_change#41369, avg(speed#41190) windowspecdefinition(road_id#41176, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#41390]
+- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_change#41332, vehicle_count_lag#41350, CASE WHEN isnotnull(vehicle_count_lag#41350) THEN (vehicle_count#41200 - vehicle_count_lag#41350) ELSE 0.0 END AS vehicle_count_change#41369]
   +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_change#41332, vehicle_count_lag#41350]
      +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_change#41332, vehicle_count_lag#41350, vehicle_count_lag#41350]
         +- Window [lag(vehicle_count#41200, -1, null) windowspecdefinition(road_id#41176, timestamp#41179 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#41350], [road_id#41176], [timestamp#41179 ASC NULLS FIRST]
            +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_change#41332]
               +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, CASE WHEN isnotnull(speed_lag#41315) THEN (speed#41190 - speed_lag#41315) ELSE 0.0 END AS speed_change#41332]
                  +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315]
                     +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299, speed_lag#41315, speed_lag#41315]
                        +- Window [lag(speed#41190, -1, null) windowspecdefinition(road_id#41176, timestamp#41179 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#41315], [road_id#41176], [timestamp#41179 ASC NULLS FIRST]
                           +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, hour_cos#41299]
                              +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, hour_sin#41284, COS((0.2617993877991494 * cast(hour#41234 as double))) AS hour_cos#41299]
                                 +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, is_weekend#41270, SIN((0.2617993877991494 * cast(hour#41234 as double))) AS hour_sin#41284]
                                    +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, day_of_week#41257, CASE WHEN day_of_week#41257 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#41270]
                                       +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, is_peak#41245, dayofweek(cast(timestamp#41179 as date)) AS day_of_week#41257]
                                          +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour#41234, CASE WHEN hour#41234 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#41245]
                                             +- Project [_id#41172, congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200, hour(timestamp#41179, Some(Asia/Bangkok)) AS hour#41234]
                                                +- Project [_id#41172, cast(congestion_level#41173 as double) AS congestion_level#41210, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, vehicle_count#41200]
                                                   +- Project [_id#41172, congestion_level#41173, lat#41174, lon#41175, road_id#41176, road_name#41177, speed#41190, timestamp#41179, cast(vehicle_count#41180 as double) AS vehicle_count#41200]
                                                      +- Project [_id#41172, congestion_level#41173, lat#41174, lon#41175, road_id#41176, road_name#41177, cast(speed#41178 as double) AS speed#41190, timestamp#41179, vehicle_count#41180]
                                                         +- Relation [_id#41172,congestion_level#41173,lat#41174,lon#41175,road_id#41176,road_name#41177,speed#41178,timestamp#41179,vehicle_count#41180] MongoRelation(MongoRDD[2444] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:43,395 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:48 +07)" executed successfully
2026-01-06 12:43:48,171 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:53 +07)" (scheduled at 2026-01-06 12:43:48.157382+07:00)
2026-01-06 12:43:48,171 - INFO -  Training Spark model...
2026-01-06 12:43:48,384 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_change#41551, vehicle_count_lag#41569, vehicle_count_change#41588, avg(speed#41409) windowspecdefinition(road_id#41395, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#41609]
+- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_change#41551, vehicle_count_lag#41569, CASE WHEN isnotnull(vehicle_count_lag#41569) THEN (vehicle_count#41419 - vehicle_count_lag#41569) ELSE 0.0 END AS vehicle_count_change#41588]
   +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_change#41551, vehicle_count_lag#41569]
      +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_change#41551, vehicle_count_lag#41569, vehicle_count_lag#41569]
         +- Window [lag(vehicle_count#41419, -1, null) windowspecdefinition(road_id#41395, timestamp#41398 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#41569], [road_id#41395], [timestamp#41398 ASC NULLS FIRST]
            +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_change#41551]
               +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, CASE WHEN isnotnull(speed_lag#41534) THEN (speed#41409 - speed_lag#41534) ELSE 0.0 END AS speed_change#41551]
                  +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534]
                     +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518, speed_lag#41534, speed_lag#41534]
                        +- Window [lag(speed#41409, -1, null) windowspecdefinition(road_id#41395, timestamp#41398 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#41534], [road_id#41395], [timestamp#41398 ASC NULLS FIRST]
                           +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, hour_cos#41518]
                              +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, hour_sin#41503, COS((0.2617993877991494 * cast(hour#41453 as double))) AS hour_cos#41518]
                                 +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, is_weekend#41489, SIN((0.2617993877991494 * cast(hour#41453 as double))) AS hour_sin#41503]
                                    +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, day_of_week#41476, CASE WHEN day_of_week#41476 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#41489]
                                       +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, is_peak#41464, dayofweek(cast(timestamp#41398 as date)) AS day_of_week#41476]
                                          +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour#41453, CASE WHEN hour#41453 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#41464]
                                             +- Project [_id#41391, congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419, hour(timestamp#41398, Some(Asia/Bangkok)) AS hour#41453]
                                                +- Project [_id#41391, cast(congestion_level#41392 as double) AS congestion_level#41429, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, vehicle_count#41419]
                                                   +- Project [_id#41391, congestion_level#41392, lat#41393, lon#41394, road_id#41395, road_name#41396, speed#41409, timestamp#41398, cast(vehicle_count#41399 as double) AS vehicle_count#41419]
                                                      +- Project [_id#41391, congestion_level#41392, lat#41393, lon#41394, road_id#41395, road_name#41396, cast(speed#41397 as double) AS speed#41409, timestamp#41398, vehicle_count#41399]
                                                         +- Relation [_id#41391,congestion_level#41392,lat#41393,lon#41394,road_id#41395,road_name#41396,speed#41397,timestamp#41398,vehicle_count#41399] MongoRelation(MongoRDD[2457] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:48,384 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:53 +07)" executed successfully
2026-01-06 12:43:53,194 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:58 +07)" (scheduled at 2026-01-06 12:43:53.157382+07:00)
2026-01-06 12:43:53,195 - INFO -  Training Spark model...
2026-01-06 12:43:53,470 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_change#41770, vehicle_count_lag#41788, vehicle_count_change#41807, avg(speed#41628) windowspecdefinition(road_id#41614, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#41828]
+- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_change#41770, vehicle_count_lag#41788, CASE WHEN isnotnull(vehicle_count_lag#41788) THEN (vehicle_count#41638 - vehicle_count_lag#41788) ELSE 0.0 END AS vehicle_count_change#41807]
   +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_change#41770, vehicle_count_lag#41788]
      +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_change#41770, vehicle_count_lag#41788, vehicle_count_lag#41788]
         +- Window [lag(vehicle_count#41638, -1, null) windowspecdefinition(road_id#41614, timestamp#41617 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#41788], [road_id#41614], [timestamp#41617 ASC NULLS FIRST]
            +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_change#41770]
               +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, CASE WHEN isnotnull(speed_lag#41753) THEN (speed#41628 - speed_lag#41753) ELSE 0.0 END AS speed_change#41770]
                  +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753]
                     +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737, speed_lag#41753, speed_lag#41753]
                        +- Window [lag(speed#41628, -1, null) windowspecdefinition(road_id#41614, timestamp#41617 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#41753], [road_id#41614], [timestamp#41617 ASC NULLS FIRST]
                           +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, hour_cos#41737]
                              +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, hour_sin#41722, COS((0.2617993877991494 * cast(hour#41672 as double))) AS hour_cos#41737]
                                 +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, is_weekend#41708, SIN((0.2617993877991494 * cast(hour#41672 as double))) AS hour_sin#41722]
                                    +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, day_of_week#41695, CASE WHEN day_of_week#41695 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#41708]
                                       +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, is_peak#41683, dayofweek(cast(timestamp#41617 as date)) AS day_of_week#41695]
                                          +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour#41672, CASE WHEN hour#41672 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#41683]
                                             +- Project [_id#41610, congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638, hour(timestamp#41617, Some(Asia/Bangkok)) AS hour#41672]
                                                +- Project [_id#41610, cast(congestion_level#41611 as double) AS congestion_level#41648, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, vehicle_count#41638]
                                                   +- Project [_id#41610, congestion_level#41611, lat#41612, lon#41613, road_id#41614, road_name#41615, speed#41628, timestamp#41617, cast(vehicle_count#41618 as double) AS vehicle_count#41638]
                                                      +- Project [_id#41610, congestion_level#41611, lat#41612, lon#41613, road_id#41614, road_name#41615, cast(speed#41616 as double) AS speed#41628, timestamp#41617, vehicle_count#41618]
                                                         +- Relation [_id#41610,congestion_level#41611,lat#41612,lon#41613,road_id#41614,road_name#41615,speed#41616,timestamp#41617,vehicle_count#41618] MongoRelation(MongoRDD[2470] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:53,470 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:43:58 +07)" executed successfully
2026-01-06 12:43:58,161 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:03 +07)" (scheduled at 2026-01-06 12:43:58.157382+07:00)
2026-01-06 12:43:58,161 - INFO -  Training Spark model...
2026-01-06 12:43:58,380 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_change#41989, vehicle_count_lag#42007, vehicle_count_change#42026, avg(speed#41847) windowspecdefinition(road_id#41833, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#42047]
+- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_change#41989, vehicle_count_lag#42007, CASE WHEN isnotnull(vehicle_count_lag#42007) THEN (vehicle_count#41857 - vehicle_count_lag#42007) ELSE 0.0 END AS vehicle_count_change#42026]
   +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_change#41989, vehicle_count_lag#42007]
      +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_change#41989, vehicle_count_lag#42007, vehicle_count_lag#42007]
         +- Window [lag(vehicle_count#41857, -1, null) windowspecdefinition(road_id#41833, timestamp#41836 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#42007], [road_id#41833], [timestamp#41836 ASC NULLS FIRST]
            +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_change#41989]
               +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, CASE WHEN isnotnull(speed_lag#41972) THEN (speed#41847 - speed_lag#41972) ELSE 0.0 END AS speed_change#41989]
                  +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972]
                     +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956, speed_lag#41972, speed_lag#41972]
                        +- Window [lag(speed#41847, -1, null) windowspecdefinition(road_id#41833, timestamp#41836 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#41972], [road_id#41833], [timestamp#41836 ASC NULLS FIRST]
                           +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, hour_cos#41956]
                              +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, hour_sin#41941, COS((0.2617993877991494 * cast(hour#41891 as double))) AS hour_cos#41956]
                                 +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, is_weekend#41927, SIN((0.2617993877991494 * cast(hour#41891 as double))) AS hour_sin#41941]
                                    +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, day_of_week#41914, CASE WHEN day_of_week#41914 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#41927]
                                       +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, is_peak#41902, dayofweek(cast(timestamp#41836 as date)) AS day_of_week#41914]
                                          +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour#41891, CASE WHEN hour#41891 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#41902]
                                             +- Project [_id#41829, congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857, hour(timestamp#41836, Some(Asia/Bangkok)) AS hour#41891]
                                                +- Project [_id#41829, cast(congestion_level#41830 as double) AS congestion_level#41867, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, vehicle_count#41857]
                                                   +- Project [_id#41829, congestion_level#41830, lat#41831, lon#41832, road_id#41833, road_name#41834, speed#41847, timestamp#41836, cast(vehicle_count#41837 as double) AS vehicle_count#41857]
                                                      +- Project [_id#41829, congestion_level#41830, lat#41831, lon#41832, road_id#41833, road_name#41834, cast(speed#41835 as double) AS speed#41847, timestamp#41836, vehicle_count#41837]
                                                         +- Relation [_id#41829,congestion_level#41830,lat#41831,lon#41832,road_id#41833,road_name#41834,speed#41835,timestamp#41836,vehicle_count#41837] MongoRelation(MongoRDD[2483] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:43:58,380 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:03 +07)" executed successfully
2026-01-06 12:44:03,179 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:08 +07)" (scheduled at 2026-01-06 12:44:03.157382+07:00)
2026-01-06 12:44:03,180 - INFO -  Training Spark model...
2026-01-06 12:44:03,437 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_change#42208, vehicle_count_lag#42226, vehicle_count_change#42245, avg(speed#42066) windowspecdefinition(road_id#42052, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#42266]
+- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_change#42208, vehicle_count_lag#42226, CASE WHEN isnotnull(vehicle_count_lag#42226) THEN (vehicle_count#42076 - vehicle_count_lag#42226) ELSE 0.0 END AS vehicle_count_change#42245]
   +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_change#42208, vehicle_count_lag#42226]
      +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_change#42208, vehicle_count_lag#42226, vehicle_count_lag#42226]
         +- Window [lag(vehicle_count#42076, -1, null) windowspecdefinition(road_id#42052, timestamp#42055 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#42226], [road_id#42052], [timestamp#42055 ASC NULLS FIRST]
            +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_change#42208]
               +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, CASE WHEN isnotnull(speed_lag#42191) THEN (speed#42066 - speed_lag#42191) ELSE 0.0 END AS speed_change#42208]
                  +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191]
                     +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175, speed_lag#42191, speed_lag#42191]
                        +- Window [lag(speed#42066, -1, null) windowspecdefinition(road_id#42052, timestamp#42055 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#42191], [road_id#42052], [timestamp#42055 ASC NULLS FIRST]
                           +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, hour_cos#42175]
                              +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, hour_sin#42160, COS((0.2617993877991494 * cast(hour#42110 as double))) AS hour_cos#42175]
                                 +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, is_weekend#42146, SIN((0.2617993877991494 * cast(hour#42110 as double))) AS hour_sin#42160]
                                    +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, day_of_week#42133, CASE WHEN day_of_week#42133 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#42146]
                                       +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, is_peak#42121, dayofweek(cast(timestamp#42055 as date)) AS day_of_week#42133]
                                          +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour#42110, CASE WHEN hour#42110 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#42121]
                                             +- Project [_id#42048, congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076, hour(timestamp#42055, Some(Asia/Bangkok)) AS hour#42110]
                                                +- Project [_id#42048, cast(congestion_level#42049 as double) AS congestion_level#42086, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, vehicle_count#42076]
                                                   +- Project [_id#42048, congestion_level#42049, lat#42050, lon#42051, road_id#42052, road_name#42053, speed#42066, timestamp#42055, cast(vehicle_count#42056 as double) AS vehicle_count#42076]
                                                      +- Project [_id#42048, congestion_level#42049, lat#42050, lon#42051, road_id#42052, road_name#42053, cast(speed#42054 as double) AS speed#42066, timestamp#42055, vehicle_count#42056]
                                                         +- Relation [_id#42048,congestion_level#42049,lat#42050,lon#42051,road_id#42052,road_name#42053,speed#42054,timestamp#42055,vehicle_count#42056] MongoRelation(MongoRDD[2496] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:03,437 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:08 +07)" executed successfully
2026-01-06 12:44:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:13 +07)" (scheduled at 2026-01-06 12:44:08.157382+07:00)
2026-01-06 12:44:08,159 - INFO -  Training Spark model...
2026-01-06 12:44:08,159 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:45:08 +07)" (scheduled at 2026-01-06 12:44:08.157779+07:00)
2026-01-06 12:44:08,159 - INFO -  Training Spark model...
2026-01-06 12:44:08,534 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_change#42554, vehicle_count_lag#42588, vehicle_count_change#42608, avg(speed#42313) windowspecdefinition(road_id#42289, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#42663]
+- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_change#42554, vehicle_count_lag#42588, CASE WHEN isnotnull(vehicle_count_lag#42588) THEN (vehicle_count#42333 - vehicle_count_lag#42588) ELSE 0.0 END AS vehicle_count_change#42608]
   +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_change#42554, vehicle_count_lag#42588]
      +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_change#42554, vehicle_count_lag#42588, vehicle_count_lag#42588]
         +- Window [lag(vehicle_count#42333, -1, null) windowspecdefinition(road_id#42289, timestamp#42292 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#42588], [road_id#42289], [timestamp#42292 ASC NULLS FIRST]
            +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_change#42554]
               +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, CASE WHEN isnotnull(speed_lag#42522) THEN (speed#42313 - speed_lag#42522) ELSE 0.0 END AS speed_change#42554]
                  +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522]
                     +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492, speed_lag#42522, speed_lag#42522]
                        +- Window [lag(speed#42313, -1, null) windowspecdefinition(road_id#42289, timestamp#42292 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#42522], [road_id#42289], [timestamp#42292 ASC NULLS FIRST]
                           +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, hour_cos#42492]
                              +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, hour_sin#42465, COS((0.2617993877991494 * cast(hour#42391 as double))) AS hour_cos#42492]
                                 +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, is_weekend#42438, SIN((0.2617993877991494 * cast(hour#42391 as double))) AS hour_sin#42465]
                                    +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, day_of_week#42425, CASE WHEN day_of_week#42425 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#42438]
                                       +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, is_peak#42413, dayofweek(cast(timestamp#42292 as date)) AS day_of_week#42425]
                                          +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour#42391, CASE WHEN hour#42391 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#42413]
                                             +- Project [_id#42285, congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333, hour(timestamp#42292, Some(Asia/Bangkok)) AS hour#42391]
                                                +- Project [_id#42285, cast(congestion_level#42286 as double) AS congestion_level#42364, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, vehicle_count#42333]
                                                   +- Project [_id#42285, congestion_level#42286, lat#42287, lon#42288, road_id#42289, road_name#42290, speed#42313, timestamp#42292, cast(vehicle_count#42293 as double) AS vehicle_count#42333]
                                                      +- Project [_id#42285, congestion_level#42286, lat#42287, lon#42288, road_id#42289, road_name#42290, cast(speed#42291 as double) AS speed#42313, timestamp#42292, vehicle_count#42293]
                                                         +- Relation [_id#42285,congestion_level#42286,lat#42287,lon#42288,road_id#42289,road_name#42290,speed#42291,timestamp#42292,vehicle_count#42293] MongoRelation(MongoRDD[2510] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:08,534 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:13 +07)" executed successfully
2026-01-06 12:44:08,535 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_change#42644, vehicle_count_lag#42664, vehicle_count_change#42683, avg(speed#42303) windowspecdefinition(road_id#42271, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#42704]
+- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_change#42644, vehicle_count_lag#42664, CASE WHEN isnotnull(vehicle_count_lag#42664) THEN (vehicle_count#42323 - vehicle_count_lag#42664) ELSE 0.0 END AS vehicle_count_change#42683]
   +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_change#42644, vehicle_count_lag#42664]
      +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_change#42644, vehicle_count_lag#42664, vehicle_count_lag#42664]
         +- Window [lag(vehicle_count#42323, -1, null) windowspecdefinition(road_id#42271, timestamp#42274 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#42664], [road_id#42271], [timestamp#42274 ASC NULLS FIRST]
            +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_change#42644]
               +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, CASE WHEN isnotnull(speed_lag#42607) THEN (speed#42303 - speed_lag#42607) ELSE 0.0 END AS speed_change#42644]
                  +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607]
                     +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555, speed_lag#42607, speed_lag#42607]
                        +- Window [lag(speed#42303, -1, null) windowspecdefinition(road_id#42271, timestamp#42274 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#42607], [road_id#42271], [timestamp#42274 ASC NULLS FIRST]
                           +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, hour_cos#42555]
                              +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, hour_sin#42523, COS((0.2617993877991494 * cast(hour#42402 as double))) AS hour_cos#42555]
                                 +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, is_weekend#42508, SIN((0.2617993877991494 * cast(hour#42402 as double))) AS hour_sin#42523]
                                    +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, day_of_week#42464, CASE WHEN day_of_week#42464 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#42508]
                                       +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, is_peak#42452, dayofweek(cast(timestamp#42274 as date)) AS day_of_week#42464]
                                          +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour#42402, CASE WHEN hour#42402 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#42452]
                                             +- Project [_id#42267, congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323, hour(timestamp#42274, Some(Asia/Bangkok)) AS hour#42402]
                                                +- Project [_id#42267, cast(congestion_level#42268 as double) AS congestion_level#42334, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, vehicle_count#42323]
                                                   +- Project [_id#42267, congestion_level#42268, lat#42269, lon#42270, road_id#42271, road_name#42272, speed#42303, timestamp#42274, cast(vehicle_count#42275 as double) AS vehicle_count#42323]
                                                      +- Project [_id#42267, congestion_level#42268, lat#42269, lon#42270, road_id#42271, road_name#42272, cast(speed#42273 as double) AS speed#42303, timestamp#42274, vehicle_count#42275]
                                                         +- Relation [_id#42267,congestion_level#42268,lat#42269,lon#42270,road_id#42271,road_name#42272,speed#42273,timestamp#42274,vehicle_count#42275] MongoRelation(MongoRDD[2509] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:08,535 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:45:08 +07)" executed successfully
2026-01-06 12:44:13,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:18 +07)" (scheduled at 2026-01-06 12:44:13.157382+07:00)
2026-01-06 12:44:13,163 - INFO -  Training Spark model...
2026-01-06 12:44:13,379 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_change#42865, vehicle_count_lag#42883, vehicle_count_change#42902, avg(speed#42723) windowspecdefinition(road_id#42709, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#42923]
+- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_change#42865, vehicle_count_lag#42883, CASE WHEN isnotnull(vehicle_count_lag#42883) THEN (vehicle_count#42733 - vehicle_count_lag#42883) ELSE 0.0 END AS vehicle_count_change#42902]
   +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_change#42865, vehicle_count_lag#42883]
      +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_change#42865, vehicle_count_lag#42883, vehicle_count_lag#42883]
         +- Window [lag(vehicle_count#42733, -1, null) windowspecdefinition(road_id#42709, timestamp#42712 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#42883], [road_id#42709], [timestamp#42712 ASC NULLS FIRST]
            +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_change#42865]
               +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, CASE WHEN isnotnull(speed_lag#42848) THEN (speed#42723 - speed_lag#42848) ELSE 0.0 END AS speed_change#42865]
                  +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848]
                     +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832, speed_lag#42848, speed_lag#42848]
                        +- Window [lag(speed#42723, -1, null) windowspecdefinition(road_id#42709, timestamp#42712 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#42848], [road_id#42709], [timestamp#42712 ASC NULLS FIRST]
                           +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, hour_cos#42832]
                              +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, hour_sin#42817, COS((0.2617993877991494 * cast(hour#42767 as double))) AS hour_cos#42832]
                                 +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, is_weekend#42803, SIN((0.2617993877991494 * cast(hour#42767 as double))) AS hour_sin#42817]
                                    +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, day_of_week#42790, CASE WHEN day_of_week#42790 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#42803]
                                       +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, is_peak#42778, dayofweek(cast(timestamp#42712 as date)) AS day_of_week#42790]
                                          +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour#42767, CASE WHEN hour#42767 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#42778]
                                             +- Project [_id#42705, congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733, hour(timestamp#42712, Some(Asia/Bangkok)) AS hour#42767]
                                                +- Project [_id#42705, cast(congestion_level#42706 as double) AS congestion_level#42743, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, vehicle_count#42733]
                                                   +- Project [_id#42705, congestion_level#42706, lat#42707, lon#42708, road_id#42709, road_name#42710, speed#42723, timestamp#42712, cast(vehicle_count#42713 as double) AS vehicle_count#42733]
                                                      +- Project [_id#42705, congestion_level#42706, lat#42707, lon#42708, road_id#42709, road_name#42710, cast(speed#42711 as double) AS speed#42723, timestamp#42712, vehicle_count#42713]
                                                         +- Relation [_id#42705,congestion_level#42706,lat#42707,lon#42708,road_id#42709,road_name#42710,speed#42711,timestamp#42712,vehicle_count#42713] MongoRelation(MongoRDD[2535] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:13,379 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:18 +07)" executed successfully
2026-01-06 12:44:18,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:23 +07)" (scheduled at 2026-01-06 12:44:18.157382+07:00)
2026-01-06 12:44:18,164 - INFO -  Training Spark model...
2026-01-06 12:44:18,386 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_change#43084, vehicle_count_lag#43102, vehicle_count_change#43121, avg(speed#42942) windowspecdefinition(road_id#42928, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#43142]
+- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_change#43084, vehicle_count_lag#43102, CASE WHEN isnotnull(vehicle_count_lag#43102) THEN (vehicle_count#42952 - vehicle_count_lag#43102) ELSE 0.0 END AS vehicle_count_change#43121]
   +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_change#43084, vehicle_count_lag#43102]
      +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_change#43084, vehicle_count_lag#43102, vehicle_count_lag#43102]
         +- Window [lag(vehicle_count#42952, -1, null) windowspecdefinition(road_id#42928, timestamp#42931 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#43102], [road_id#42928], [timestamp#42931 ASC NULLS FIRST]
            +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_change#43084]
               +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, CASE WHEN isnotnull(speed_lag#43067) THEN (speed#42942 - speed_lag#43067) ELSE 0.0 END AS speed_change#43084]
                  +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067]
                     +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051, speed_lag#43067, speed_lag#43067]
                        +- Window [lag(speed#42942, -1, null) windowspecdefinition(road_id#42928, timestamp#42931 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#43067], [road_id#42928], [timestamp#42931 ASC NULLS FIRST]
                           +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, hour_cos#43051]
                              +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, hour_sin#43036, COS((0.2617993877991494 * cast(hour#42986 as double))) AS hour_cos#43051]
                                 +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, is_weekend#43022, SIN((0.2617993877991494 * cast(hour#42986 as double))) AS hour_sin#43036]
                                    +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, day_of_week#43009, CASE WHEN day_of_week#43009 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#43022]
                                       +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, is_peak#42997, dayofweek(cast(timestamp#42931 as date)) AS day_of_week#43009]
                                          +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour#42986, CASE WHEN hour#42986 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#42997]
                                             +- Project [_id#42924, congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952, hour(timestamp#42931, Some(Asia/Bangkok)) AS hour#42986]
                                                +- Project [_id#42924, cast(congestion_level#42925 as double) AS congestion_level#42962, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, vehicle_count#42952]
                                                   +- Project [_id#42924, congestion_level#42925, lat#42926, lon#42927, road_id#42928, road_name#42929, speed#42942, timestamp#42931, cast(vehicle_count#42932 as double) AS vehicle_count#42952]
                                                      +- Project [_id#42924, congestion_level#42925, lat#42926, lon#42927, road_id#42928, road_name#42929, cast(speed#42930 as double) AS speed#42942, timestamp#42931, vehicle_count#42932]
                                                         +- Relation [_id#42924,congestion_level#42925,lat#42926,lon#42927,road_id#42928,road_name#42929,speed#42930,timestamp#42931,vehicle_count#42932] MongoRelation(MongoRDD[2548] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:18,386 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:23 +07)" executed successfully
2026-01-06 12:44:23,159 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:28 +07)" (scheduled at 2026-01-06 12:44:23.157382+07:00)
2026-01-06 12:44:23,159 - INFO -  Training Spark model...
2026-01-06 12:44:23,372 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_change#43303, vehicle_count_lag#43321, vehicle_count_change#43340, avg(speed#43161) windowspecdefinition(road_id#43147, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#43361]
+- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_change#43303, vehicle_count_lag#43321, CASE WHEN isnotnull(vehicle_count_lag#43321) THEN (vehicle_count#43171 - vehicle_count_lag#43321) ELSE 0.0 END AS vehicle_count_change#43340]
   +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_change#43303, vehicle_count_lag#43321]
      +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_change#43303, vehicle_count_lag#43321, vehicle_count_lag#43321]
         +- Window [lag(vehicle_count#43171, -1, null) windowspecdefinition(road_id#43147, timestamp#43150 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#43321], [road_id#43147], [timestamp#43150 ASC NULLS FIRST]
            +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_change#43303]
               +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, CASE WHEN isnotnull(speed_lag#43286) THEN (speed#43161 - speed_lag#43286) ELSE 0.0 END AS speed_change#43303]
                  +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286]
                     +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270, speed_lag#43286, speed_lag#43286]
                        +- Window [lag(speed#43161, -1, null) windowspecdefinition(road_id#43147, timestamp#43150 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#43286], [road_id#43147], [timestamp#43150 ASC NULLS FIRST]
                           +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, hour_cos#43270]
                              +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, hour_sin#43255, COS((0.2617993877991494 * cast(hour#43205 as double))) AS hour_cos#43270]
                                 +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, is_weekend#43241, SIN((0.2617993877991494 * cast(hour#43205 as double))) AS hour_sin#43255]
                                    +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, day_of_week#43228, CASE WHEN day_of_week#43228 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#43241]
                                       +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, is_peak#43216, dayofweek(cast(timestamp#43150 as date)) AS day_of_week#43228]
                                          +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour#43205, CASE WHEN hour#43205 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#43216]
                                             +- Project [_id#43143, congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171, hour(timestamp#43150, Some(Asia/Bangkok)) AS hour#43205]
                                                +- Project [_id#43143, cast(congestion_level#43144 as double) AS congestion_level#43181, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, vehicle_count#43171]
                                                   +- Project [_id#43143, congestion_level#43144, lat#43145, lon#43146, road_id#43147, road_name#43148, speed#43161, timestamp#43150, cast(vehicle_count#43151 as double) AS vehicle_count#43171]
                                                      +- Project [_id#43143, congestion_level#43144, lat#43145, lon#43146, road_id#43147, road_name#43148, cast(speed#43149 as double) AS speed#43161, timestamp#43150, vehicle_count#43151]
                                                         +- Relation [_id#43143,congestion_level#43144,lat#43145,lon#43146,road_id#43147,road_name#43148,speed#43149,timestamp#43150,vehicle_count#43151] MongoRelation(MongoRDD[2561] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:23,372 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:28 +07)" executed successfully
2026-01-06 12:44:28,164 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:33 +07)" (scheduled at 2026-01-06 12:44:28.157382+07:00)
2026-01-06 12:44:28,164 - INFO -  Training Spark model...
2026-01-06 12:44:28,423 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_change#43522, vehicle_count_lag#43540, vehicle_count_change#43559, avg(speed#43380) windowspecdefinition(road_id#43366, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#43580]
+- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_change#43522, vehicle_count_lag#43540, CASE WHEN isnotnull(vehicle_count_lag#43540) THEN (vehicle_count#43390 - vehicle_count_lag#43540) ELSE 0.0 END AS vehicle_count_change#43559]
   +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_change#43522, vehicle_count_lag#43540]
      +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_change#43522, vehicle_count_lag#43540, vehicle_count_lag#43540]
         +- Window [lag(vehicle_count#43390, -1, null) windowspecdefinition(road_id#43366, timestamp#43369 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#43540], [road_id#43366], [timestamp#43369 ASC NULLS FIRST]
            +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_change#43522]
               +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, CASE WHEN isnotnull(speed_lag#43505) THEN (speed#43380 - speed_lag#43505) ELSE 0.0 END AS speed_change#43522]
                  +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505]
                     +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489, speed_lag#43505, speed_lag#43505]
                        +- Window [lag(speed#43380, -1, null) windowspecdefinition(road_id#43366, timestamp#43369 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#43505], [road_id#43366], [timestamp#43369 ASC NULLS FIRST]
                           +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, hour_cos#43489]
                              +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, hour_sin#43474, COS((0.2617993877991494 * cast(hour#43424 as double))) AS hour_cos#43489]
                                 +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, is_weekend#43460, SIN((0.2617993877991494 * cast(hour#43424 as double))) AS hour_sin#43474]
                                    +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, day_of_week#43447, CASE WHEN day_of_week#43447 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#43460]
                                       +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, is_peak#43435, dayofweek(cast(timestamp#43369 as date)) AS day_of_week#43447]
                                          +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour#43424, CASE WHEN hour#43424 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#43435]
                                             +- Project [_id#43362, congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390, hour(timestamp#43369, Some(Asia/Bangkok)) AS hour#43424]
                                                +- Project [_id#43362, cast(congestion_level#43363 as double) AS congestion_level#43400, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, vehicle_count#43390]
                                                   +- Project [_id#43362, congestion_level#43363, lat#43364, lon#43365, road_id#43366, road_name#43367, speed#43380, timestamp#43369, cast(vehicle_count#43370 as double) AS vehicle_count#43390]
                                                      +- Project [_id#43362, congestion_level#43363, lat#43364, lon#43365, road_id#43366, road_name#43367, cast(speed#43368 as double) AS speed#43380, timestamp#43369, vehicle_count#43370]
                                                         +- Relation [_id#43362,congestion_level#43363,lat#43364,lon#43365,road_id#43366,road_name#43367,speed#43368,timestamp#43369,vehicle_count#43370] MongoRelation(MongoRDD[2574] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:28,423 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:33 +07)" executed successfully
2026-01-06 12:44:33,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:38 +07)" (scheduled at 2026-01-06 12:44:33.157382+07:00)
2026-01-06 12:44:33,164 - INFO -  Training Spark model...
2026-01-06 12:44:33,412 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_change#43741, vehicle_count_lag#43759, vehicle_count_change#43778, avg(speed#43599) windowspecdefinition(road_id#43585, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#43799]
+- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_change#43741, vehicle_count_lag#43759, CASE WHEN isnotnull(vehicle_count_lag#43759) THEN (vehicle_count#43609 - vehicle_count_lag#43759) ELSE 0.0 END AS vehicle_count_change#43778]
   +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_change#43741, vehicle_count_lag#43759]
      +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_change#43741, vehicle_count_lag#43759, vehicle_count_lag#43759]
         +- Window [lag(vehicle_count#43609, -1, null) windowspecdefinition(road_id#43585, timestamp#43588 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#43759], [road_id#43585], [timestamp#43588 ASC NULLS FIRST]
            +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_change#43741]
               +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, CASE WHEN isnotnull(speed_lag#43724) THEN (speed#43599 - speed_lag#43724) ELSE 0.0 END AS speed_change#43741]
                  +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724]
                     +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708, speed_lag#43724, speed_lag#43724]
                        +- Window [lag(speed#43599, -1, null) windowspecdefinition(road_id#43585, timestamp#43588 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#43724], [road_id#43585], [timestamp#43588 ASC NULLS FIRST]
                           +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, hour_cos#43708]
                              +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, hour_sin#43693, COS((0.2617993877991494 * cast(hour#43643 as double))) AS hour_cos#43708]
                                 +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, is_weekend#43679, SIN((0.2617993877991494 * cast(hour#43643 as double))) AS hour_sin#43693]
                                    +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, day_of_week#43666, CASE WHEN day_of_week#43666 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#43679]
                                       +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, is_peak#43654, dayofweek(cast(timestamp#43588 as date)) AS day_of_week#43666]
                                          +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour#43643, CASE WHEN hour#43643 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#43654]
                                             +- Project [_id#43581, congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609, hour(timestamp#43588, Some(Asia/Bangkok)) AS hour#43643]
                                                +- Project [_id#43581, cast(congestion_level#43582 as double) AS congestion_level#43619, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, vehicle_count#43609]
                                                   +- Project [_id#43581, congestion_level#43582, lat#43583, lon#43584, road_id#43585, road_name#43586, speed#43599, timestamp#43588, cast(vehicle_count#43589 as double) AS vehicle_count#43609]
                                                      +- Project [_id#43581, congestion_level#43582, lat#43583, lon#43584, road_id#43585, road_name#43586, cast(speed#43587 as double) AS speed#43599, timestamp#43588, vehicle_count#43589]
                                                         +- Relation [_id#43581,congestion_level#43582,lat#43583,lon#43584,road_id#43585,road_name#43586,speed#43587,timestamp#43588,vehicle_count#43589] MongoRelation(MongoRDD[2587] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:33,412 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:38 +07)" executed successfully
2026-01-06 12:44:38,162 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:43 +07)" (scheduled at 2026-01-06 12:44:38.157382+07:00)
2026-01-06 12:44:38,162 - INFO -  Training Spark model...
2026-01-06 12:44:38,400 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_change#43960, vehicle_count_lag#43978, vehicle_count_change#43997, avg(speed#43818) windowspecdefinition(road_id#43804, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#44018]
+- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_change#43960, vehicle_count_lag#43978, CASE WHEN isnotnull(vehicle_count_lag#43978) THEN (vehicle_count#43828 - vehicle_count_lag#43978) ELSE 0.0 END AS vehicle_count_change#43997]
   +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_change#43960, vehicle_count_lag#43978]
      +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_change#43960, vehicle_count_lag#43978, vehicle_count_lag#43978]
         +- Window [lag(vehicle_count#43828, -1, null) windowspecdefinition(road_id#43804, timestamp#43807 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#43978], [road_id#43804], [timestamp#43807 ASC NULLS FIRST]
            +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_change#43960]
               +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, CASE WHEN isnotnull(speed_lag#43943) THEN (speed#43818 - speed_lag#43943) ELSE 0.0 END AS speed_change#43960]
                  +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943]
                     +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927, speed_lag#43943, speed_lag#43943]
                        +- Window [lag(speed#43818, -1, null) windowspecdefinition(road_id#43804, timestamp#43807 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#43943], [road_id#43804], [timestamp#43807 ASC NULLS FIRST]
                           +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, hour_cos#43927]
                              +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, hour_sin#43912, COS((0.2617993877991494 * cast(hour#43862 as double))) AS hour_cos#43927]
                                 +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, is_weekend#43898, SIN((0.2617993877991494 * cast(hour#43862 as double))) AS hour_sin#43912]
                                    +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, day_of_week#43885, CASE WHEN day_of_week#43885 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#43898]
                                       +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, is_peak#43873, dayofweek(cast(timestamp#43807 as date)) AS day_of_week#43885]
                                          +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour#43862, CASE WHEN hour#43862 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#43873]
                                             +- Project [_id#43800, congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828, hour(timestamp#43807, Some(Asia/Bangkok)) AS hour#43862]
                                                +- Project [_id#43800, cast(congestion_level#43801 as double) AS congestion_level#43838, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, vehicle_count#43828]
                                                   +- Project [_id#43800, congestion_level#43801, lat#43802, lon#43803, road_id#43804, road_name#43805, speed#43818, timestamp#43807, cast(vehicle_count#43808 as double) AS vehicle_count#43828]
                                                      +- Project [_id#43800, congestion_level#43801, lat#43802, lon#43803, road_id#43804, road_name#43805, cast(speed#43806 as double) AS speed#43818, timestamp#43807, vehicle_count#43808]
                                                         +- Relation [_id#43800,congestion_level#43801,lat#43802,lon#43803,road_id#43804,road_name#43805,speed#43806,timestamp#43807,vehicle_count#43808] MongoRelation(MongoRDD[2600] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:38,400 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:43 +07)" executed successfully
2026-01-06 12:44:43,163 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:48 +07)" (scheduled at 2026-01-06 12:44:43.157382+07:00)
2026-01-06 12:44:43,163 - INFO -  Training Spark model...
2026-01-06 12:44:43,379 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_change#44179, vehicle_count_lag#44197, vehicle_count_change#44216, avg(speed#44037) windowspecdefinition(road_id#44023, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#44237]
+- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_change#44179, vehicle_count_lag#44197, CASE WHEN isnotnull(vehicle_count_lag#44197) THEN (vehicle_count#44047 - vehicle_count_lag#44197) ELSE 0.0 END AS vehicle_count_change#44216]
   +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_change#44179, vehicle_count_lag#44197]
      +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_change#44179, vehicle_count_lag#44197, vehicle_count_lag#44197]
         +- Window [lag(vehicle_count#44047, -1, null) windowspecdefinition(road_id#44023, timestamp#44026 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#44197], [road_id#44023], [timestamp#44026 ASC NULLS FIRST]
            +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_change#44179]
               +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, CASE WHEN isnotnull(speed_lag#44162) THEN (speed#44037 - speed_lag#44162) ELSE 0.0 END AS speed_change#44179]
                  +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162]
                     +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146, speed_lag#44162, speed_lag#44162]
                        +- Window [lag(speed#44037, -1, null) windowspecdefinition(road_id#44023, timestamp#44026 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#44162], [road_id#44023], [timestamp#44026 ASC NULLS FIRST]
                           +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, hour_cos#44146]
                              +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, hour_sin#44131, COS((0.2617993877991494 * cast(hour#44081 as double))) AS hour_cos#44146]
                                 +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, is_weekend#44117, SIN((0.2617993877991494 * cast(hour#44081 as double))) AS hour_sin#44131]
                                    +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, day_of_week#44104, CASE WHEN day_of_week#44104 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#44117]
                                       +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, is_peak#44092, dayofweek(cast(timestamp#44026 as date)) AS day_of_week#44104]
                                          +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour#44081, CASE WHEN hour#44081 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#44092]
                                             +- Project [_id#44019, congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047, hour(timestamp#44026, Some(Asia/Bangkok)) AS hour#44081]
                                                +- Project [_id#44019, cast(congestion_level#44020 as double) AS congestion_level#44057, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, vehicle_count#44047]
                                                   +- Project [_id#44019, congestion_level#44020, lat#44021, lon#44022, road_id#44023, road_name#44024, speed#44037, timestamp#44026, cast(vehicle_count#44027 as double) AS vehicle_count#44047]
                                                      +- Project [_id#44019, congestion_level#44020, lat#44021, lon#44022, road_id#44023, road_name#44024, cast(speed#44025 as double) AS speed#44037, timestamp#44026, vehicle_count#44027]
                                                         +- Relation [_id#44019,congestion_level#44020,lat#44021,lon#44022,road_id#44023,road_name#44024,speed#44025,timestamp#44026,vehicle_count#44027] MongoRelation(MongoRDD[2613] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:43,379 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:48 +07)" executed successfully
2026-01-06 12:44:48,169 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:53 +07)" (scheduled at 2026-01-06 12:44:48.157382+07:00)
2026-01-06 12:44:48,170 - INFO -  Training Spark model...
2026-01-06 12:44:48,401 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_change#44398, vehicle_count_lag#44416, vehicle_count_change#44435, avg(speed#44256) windowspecdefinition(road_id#44242, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#44456]
+- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_change#44398, vehicle_count_lag#44416, CASE WHEN isnotnull(vehicle_count_lag#44416) THEN (vehicle_count#44266 - vehicle_count_lag#44416) ELSE 0.0 END AS vehicle_count_change#44435]
   +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_change#44398, vehicle_count_lag#44416]
      +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_change#44398, vehicle_count_lag#44416, vehicle_count_lag#44416]
         +- Window [lag(vehicle_count#44266, -1, null) windowspecdefinition(road_id#44242, timestamp#44245 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#44416], [road_id#44242], [timestamp#44245 ASC NULLS FIRST]
            +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_change#44398]
               +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, CASE WHEN isnotnull(speed_lag#44381) THEN (speed#44256 - speed_lag#44381) ELSE 0.0 END AS speed_change#44398]
                  +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381]
                     +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365, speed_lag#44381, speed_lag#44381]
                        +- Window [lag(speed#44256, -1, null) windowspecdefinition(road_id#44242, timestamp#44245 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#44381], [road_id#44242], [timestamp#44245 ASC NULLS FIRST]
                           +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, hour_cos#44365]
                              +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, hour_sin#44350, COS((0.2617993877991494 * cast(hour#44300 as double))) AS hour_cos#44365]
                                 +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, is_weekend#44336, SIN((0.2617993877991494 * cast(hour#44300 as double))) AS hour_sin#44350]
                                    +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, day_of_week#44323, CASE WHEN day_of_week#44323 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#44336]
                                       +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, is_peak#44311, dayofweek(cast(timestamp#44245 as date)) AS day_of_week#44323]
                                          +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour#44300, CASE WHEN hour#44300 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#44311]
                                             +- Project [_id#44238, congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266, hour(timestamp#44245, Some(Asia/Bangkok)) AS hour#44300]
                                                +- Project [_id#44238, cast(congestion_level#44239 as double) AS congestion_level#44276, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, vehicle_count#44266]
                                                   +- Project [_id#44238, congestion_level#44239, lat#44240, lon#44241, road_id#44242, road_name#44243, speed#44256, timestamp#44245, cast(vehicle_count#44246 as double) AS vehicle_count#44266]
                                                      +- Project [_id#44238, congestion_level#44239, lat#44240, lon#44241, road_id#44242, road_name#44243, cast(speed#44244 as double) AS speed#44256, timestamp#44245, vehicle_count#44246]
                                                         +- Relation [_id#44238,congestion_level#44239,lat#44240,lon#44241,road_id#44242,road_name#44243,speed#44244,timestamp#44245,vehicle_count#44246] MongoRelation(MongoRDD[2626] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:48,401 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:53 +07)" executed successfully
2026-01-06 12:44:53,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:58 +07)" (scheduled at 2026-01-06 12:44:53.157382+07:00)
2026-01-06 12:44:53,159 - INFO -  Training Spark model...
2026-01-06 12:44:53,399 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_change#44617, vehicle_count_lag#44635, vehicle_count_change#44654, avg(speed#44475) windowspecdefinition(road_id#44461, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#44675]
+- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_change#44617, vehicle_count_lag#44635, CASE WHEN isnotnull(vehicle_count_lag#44635) THEN (vehicle_count#44485 - vehicle_count_lag#44635) ELSE 0.0 END AS vehicle_count_change#44654]
   +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_change#44617, vehicle_count_lag#44635]
      +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_change#44617, vehicle_count_lag#44635, vehicle_count_lag#44635]
         +- Window [lag(vehicle_count#44485, -1, null) windowspecdefinition(road_id#44461, timestamp#44464 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#44635], [road_id#44461], [timestamp#44464 ASC NULLS FIRST]
            +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_change#44617]
               +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, CASE WHEN isnotnull(speed_lag#44600) THEN (speed#44475 - speed_lag#44600) ELSE 0.0 END AS speed_change#44617]
                  +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600]
                     +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584, speed_lag#44600, speed_lag#44600]
                        +- Window [lag(speed#44475, -1, null) windowspecdefinition(road_id#44461, timestamp#44464 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#44600], [road_id#44461], [timestamp#44464 ASC NULLS FIRST]
                           +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, hour_cos#44584]
                              +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, hour_sin#44569, COS((0.2617993877991494 * cast(hour#44519 as double))) AS hour_cos#44584]
                                 +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, is_weekend#44555, SIN((0.2617993877991494 * cast(hour#44519 as double))) AS hour_sin#44569]
                                    +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, day_of_week#44542, CASE WHEN day_of_week#44542 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#44555]
                                       +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, is_peak#44530, dayofweek(cast(timestamp#44464 as date)) AS day_of_week#44542]
                                          +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour#44519, CASE WHEN hour#44519 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#44530]
                                             +- Project [_id#44457, congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485, hour(timestamp#44464, Some(Asia/Bangkok)) AS hour#44519]
                                                +- Project [_id#44457, cast(congestion_level#44458 as double) AS congestion_level#44495, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, vehicle_count#44485]
                                                   +- Project [_id#44457, congestion_level#44458, lat#44459, lon#44460, road_id#44461, road_name#44462, speed#44475, timestamp#44464, cast(vehicle_count#44465 as double) AS vehicle_count#44485]
                                                      +- Project [_id#44457, congestion_level#44458, lat#44459, lon#44460, road_id#44461, road_name#44462, cast(speed#44463 as double) AS speed#44475, timestamp#44464, vehicle_count#44465]
                                                         +- Relation [_id#44457,congestion_level#44458,lat#44459,lon#44460,road_id#44461,road_name#44462,speed#44463,timestamp#44464,vehicle_count#44465] MongoRelation(MongoRDD[2639] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:53,399 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:44:58 +07)" executed successfully
2026-01-06 12:44:58,172 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:03 +07)" (scheduled at 2026-01-06 12:44:58.157382+07:00)
2026-01-06 12:44:58,173 - INFO -  Training Spark model...
2026-01-06 12:44:58,428 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_change#44836, vehicle_count_lag#44854, vehicle_count_change#44873, avg(speed#44694) windowspecdefinition(road_id#44680, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#44894]
+- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_change#44836, vehicle_count_lag#44854, CASE WHEN isnotnull(vehicle_count_lag#44854) THEN (vehicle_count#44704 - vehicle_count_lag#44854) ELSE 0.0 END AS vehicle_count_change#44873]
   +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_change#44836, vehicle_count_lag#44854]
      +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_change#44836, vehicle_count_lag#44854, vehicle_count_lag#44854]
         +- Window [lag(vehicle_count#44704, -1, null) windowspecdefinition(road_id#44680, timestamp#44683 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#44854], [road_id#44680], [timestamp#44683 ASC NULLS FIRST]
            +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_change#44836]
               +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, CASE WHEN isnotnull(speed_lag#44819) THEN (speed#44694 - speed_lag#44819) ELSE 0.0 END AS speed_change#44836]
                  +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819]
                     +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803, speed_lag#44819, speed_lag#44819]
                        +- Window [lag(speed#44694, -1, null) windowspecdefinition(road_id#44680, timestamp#44683 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#44819], [road_id#44680], [timestamp#44683 ASC NULLS FIRST]
                           +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, hour_cos#44803]
                              +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, hour_sin#44788, COS((0.2617993877991494 * cast(hour#44738 as double))) AS hour_cos#44803]
                                 +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, is_weekend#44774, SIN((0.2617993877991494 * cast(hour#44738 as double))) AS hour_sin#44788]
                                    +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, day_of_week#44761, CASE WHEN day_of_week#44761 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#44774]
                                       +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, is_peak#44749, dayofweek(cast(timestamp#44683 as date)) AS day_of_week#44761]
                                          +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour#44738, CASE WHEN hour#44738 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#44749]
                                             +- Project [_id#44676, congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704, hour(timestamp#44683, Some(Asia/Bangkok)) AS hour#44738]
                                                +- Project [_id#44676, cast(congestion_level#44677 as double) AS congestion_level#44714, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, vehicle_count#44704]
                                                   +- Project [_id#44676, congestion_level#44677, lat#44678, lon#44679, road_id#44680, road_name#44681, speed#44694, timestamp#44683, cast(vehicle_count#44684 as double) AS vehicle_count#44704]
                                                      +- Project [_id#44676, congestion_level#44677, lat#44678, lon#44679, road_id#44680, road_name#44681, cast(speed#44682 as double) AS speed#44694, timestamp#44683, vehicle_count#44684]
                                                         +- Relation [_id#44676,congestion_level#44677,lat#44678,lon#44679,road_id#44680,road_name#44681,speed#44682,timestamp#44683,vehicle_count#44684] MongoRelation(MongoRDD[2652] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:44:58,428 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:03 +07)" executed successfully
2026-01-06 12:45:03,160 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:08 +07)" (scheduled at 2026-01-06 12:45:03.157382+07:00)
2026-01-06 12:45:03,161 - INFO -  Training Spark model...
2026-01-06 12:45:03,375 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_change#45055, vehicle_count_lag#45073, vehicle_count_change#45092, avg(speed#44913) windowspecdefinition(road_id#44899, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#45113]
+- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_change#45055, vehicle_count_lag#45073, CASE WHEN isnotnull(vehicle_count_lag#45073) THEN (vehicle_count#44923 - vehicle_count_lag#45073) ELSE 0.0 END AS vehicle_count_change#45092]
   +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_change#45055, vehicle_count_lag#45073]
      +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_change#45055, vehicle_count_lag#45073, vehicle_count_lag#45073]
         +- Window [lag(vehicle_count#44923, -1, null) windowspecdefinition(road_id#44899, timestamp#44902 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#45073], [road_id#44899], [timestamp#44902 ASC NULLS FIRST]
            +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_change#45055]
               +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, CASE WHEN isnotnull(speed_lag#45038) THEN (speed#44913 - speed_lag#45038) ELSE 0.0 END AS speed_change#45055]
                  +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038]
                     +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022, speed_lag#45038, speed_lag#45038]
                        +- Window [lag(speed#44913, -1, null) windowspecdefinition(road_id#44899, timestamp#44902 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#45038], [road_id#44899], [timestamp#44902 ASC NULLS FIRST]
                           +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, hour_cos#45022]
                              +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, hour_sin#45007, COS((0.2617993877991494 * cast(hour#44957 as double))) AS hour_cos#45022]
                                 +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, is_weekend#44993, SIN((0.2617993877991494 * cast(hour#44957 as double))) AS hour_sin#45007]
                                    +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, day_of_week#44980, CASE WHEN day_of_week#44980 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#44993]
                                       +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, is_peak#44968, dayofweek(cast(timestamp#44902 as date)) AS day_of_week#44980]
                                          +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour#44957, CASE WHEN hour#44957 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#44968]
                                             +- Project [_id#44895, congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923, hour(timestamp#44902, Some(Asia/Bangkok)) AS hour#44957]
                                                +- Project [_id#44895, cast(congestion_level#44896 as double) AS congestion_level#44933, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, vehicle_count#44923]
                                                   +- Project [_id#44895, congestion_level#44896, lat#44897, lon#44898, road_id#44899, road_name#44900, speed#44913, timestamp#44902, cast(vehicle_count#44903 as double) AS vehicle_count#44923]
                                                      +- Project [_id#44895, congestion_level#44896, lat#44897, lon#44898, road_id#44899, road_name#44900, cast(speed#44901 as double) AS speed#44913, timestamp#44902, vehicle_count#44903]
                                                         +- Relation [_id#44895,congestion_level#44896,lat#44897,lon#44898,road_id#44899,road_name#44900,speed#44901,timestamp#44902,vehicle_count#44903] MongoRelation(MongoRDD[2665] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:45:03,375 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:08 +07)" executed successfully
2026-01-06 12:45:08,158 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:13 +07)" (scheduled at 2026-01-06 12:45:08.157382+07:00)
2026-01-06 12:45:08,159 - INFO -  Training Spark model...
2026-01-06 12:45:08,159 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:46:08 +07)" (scheduled at 2026-01-06 12:45:08.157779+07:00)
2026-01-06 12:45:08,159 - INFO -  Training Spark model...
2026-01-06 12:45:08,413 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_change#45417, vehicle_count_lag#45452, vehicle_count_change#45490, avg(speed#45151) windowspecdefinition(road_id#45118, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#45530]
+- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_change#45417, vehicle_count_lag#45452, CASE WHEN isnotnull(vehicle_count_lag#45452) THEN (vehicle_count#45170 - vehicle_count_lag#45452) ELSE 0.0 END AS vehicle_count_change#45490]
   +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_change#45417, vehicle_count_lag#45452]
      +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_change#45417, vehicle_count_lag#45452, vehicle_count_lag#45452]
         +- Window [lag(vehicle_count#45170, -1, null) windowspecdefinition(road_id#45118, timestamp#45121 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#45452], [road_id#45118], [timestamp#45121 ASC NULLS FIRST]
            +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_change#45417]
               +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, CASE WHEN isnotnull(speed_lag#45385) THEN (speed#45151 - speed_lag#45385) ELSE 0.0 END AS speed_change#45417]
                  +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385]
                     +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353, speed_lag#45385, speed_lag#45385]
                        +- Window [lag(speed#45151, -1, null) windowspecdefinition(road_id#45118, timestamp#45121 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#45385], [road_id#45118], [timestamp#45121 ASC NULLS FIRST]
                           +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, hour_cos#45353]
                              +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, hour_sin#45324, COS((0.2617993877991494 * cast(hour#45249 as double))) AS hour_cos#45353]
                                 +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, is_weekend#45297, SIN((0.2617993877991494 * cast(hour#45249 as double))) AS hour_sin#45324]
                                    +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, day_of_week#45272, CASE WHEN day_of_week#45272 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#45297]
                                       +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, is_peak#45260, dayofweek(cast(timestamp#45121 as date)) AS day_of_week#45272]
                                          +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour#45249, CASE WHEN hour#45249 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#45260]
                                             +- Project [_id#45114, congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170, hour(timestamp#45121, Some(Asia/Bangkok)) AS hour#45249]
                                                +- Project [_id#45114, cast(congestion_level#45115 as double) AS congestion_level#45190, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, vehicle_count#45170]
                                                   +- Project [_id#45114, congestion_level#45115, lat#45116, lon#45117, road_id#45118, road_name#45119, speed#45151, timestamp#45121, cast(vehicle_count#45122 as double) AS vehicle_count#45170]
                                                      +- Project [_id#45114, congestion_level#45115, lat#45116, lon#45117, road_id#45118, road_name#45119, cast(speed#45120 as double) AS speed#45151, timestamp#45121, vehicle_count#45122]
                                                         +- Relation [_id#45114,congestion_level#45115,lat#45116,lon#45117,road_id#45118,road_name#45119,speed#45120,timestamp#45121,vehicle_count#45122] MongoRelation(MongoRDD[2680] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:45:08,413 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:13 +07)" executed successfully
2026-01-06 12:45:08,414 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_change#45453, vehicle_count_lag#45489, vehicle_count_change#45528, avg(speed#45150) windowspecdefinition(road_id#45127, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#45551]
+- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_change#45453, vehicle_count_lag#45489, CASE WHEN isnotnull(vehicle_count_lag#45489) THEN (vehicle_count#45171 - vehicle_count_lag#45489) ELSE 0.0 END AS vehicle_count_change#45528]
   +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_change#45453, vehicle_count_lag#45489]
      +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_change#45453, vehicle_count_lag#45489, vehicle_count_lag#45489]
         +- Window [lag(vehicle_count#45171, -1, null) windowspecdefinition(road_id#45127, timestamp#45130 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#45489], [road_id#45127], [timestamp#45130 ASC NULLS FIRST]
            +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_change#45453]
               +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, CASE WHEN isnotnull(speed_lag#45418) THEN (speed#45150 - speed_lag#45418) ELSE 0.0 END AS speed_change#45453]
                  +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418]
                     +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384, speed_lag#45418, speed_lag#45418]
                        +- Window [lag(speed#45150, -1, null) windowspecdefinition(road_id#45127, timestamp#45130 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#45418], [road_id#45127], [timestamp#45130 ASC NULLS FIRST]
                           +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, hour_cos#45384]
                              +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, hour_sin#45354, COS((0.2617993877991494 * cast(hour#45238 as double))) AS hour_cos#45384]
                                 +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, is_weekend#45325, SIN((0.2617993877991494 * cast(hour#45238 as double))) AS hour_sin#45354]
                                    +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, day_of_week#45298, CASE WHEN day_of_week#45298 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#45325]
                                       +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, is_peak#45285, dayofweek(cast(timestamp#45130 as date)) AS day_of_week#45298]
                                          +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour#45238, CASE WHEN hour#45238 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#45285]
                                             +- Project [_id#45123, congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171, hour(timestamp#45130, Some(Asia/Bangkok)) AS hour#45238]
                                                +- Project [_id#45123, cast(congestion_level#45124 as double) AS congestion_level#45191, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, vehicle_count#45171]
                                                   +- Project [_id#45123, congestion_level#45124, lat#45125, lon#45126, road_id#45127, road_name#45128, speed#45150, timestamp#45130, cast(vehicle_count#45131 as double) AS vehicle_count#45171]
                                                      +- Project [_id#45123, congestion_level#45124, lat#45125, lon#45126, road_id#45127, road_name#45128, cast(speed#45129 as double) AS speed#45150, timestamp#45130, vehicle_count#45131]
                                                         +- Relation [_id#45123,congestion_level#45124,lat#45125,lon#45126,road_id#45127,road_name#45128,speed#45129,timestamp#45130,vehicle_count#45131] MongoRelation(MongoRDD[2678] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:45:08,414 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 12:46:08 +07)" executed successfully
2026-01-06 12:45:13,176 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:18 +07)" (scheduled at 2026-01-06 12:45:13.157382+07:00)
2026-01-06 12:45:13,177 - INFO -  Training Spark model...
2026-01-06 12:45:13,390 - ERROR - Training error: cannot resolve '(PARTITION BY road_id RANGE BETWEEN -10800L FOLLOWING AND CURRENT ROW)' due to data type mismatch: A range window frame cannot be used in an unordered window specification.;
'Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_change#45712, vehicle_count_lag#45730, vehicle_count_change#45749, avg(speed#45570) windowspecdefinition(road_id#45556, specifiedwindowframe(RangeFrame, -10800, currentrow$())) AS avg_speed_road#45770]
+- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_change#45712, vehicle_count_lag#45730, CASE WHEN isnotnull(vehicle_count_lag#45730) THEN (vehicle_count#45580 - vehicle_count_lag#45730) ELSE 0.0 END AS vehicle_count_change#45749]
   +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_change#45712, vehicle_count_lag#45730]
      +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_change#45712, vehicle_count_lag#45730, vehicle_count_lag#45730]
         +- Window [lag(vehicle_count#45580, -1, null) windowspecdefinition(road_id#45556, timestamp#45559 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS vehicle_count_lag#45730], [road_id#45556], [timestamp#45559 ASC NULLS FIRST]
            +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_change#45712]
               +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, CASE WHEN isnotnull(speed_lag#45695) THEN (speed#45570 - speed_lag#45695) ELSE 0.0 END AS speed_change#45712]
                  +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695]
                     +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679, speed_lag#45695, speed_lag#45695]
                        +- Window [lag(speed#45570, -1, null) windowspecdefinition(road_id#45556, timestamp#45559 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS speed_lag#45695], [road_id#45556], [timestamp#45559 ASC NULLS FIRST]
                           +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, hour_cos#45679]
                              +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, hour_sin#45664, COS((0.2617993877991494 * cast(hour#45614 as double))) AS hour_cos#45679]
                                 +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, is_weekend#45650, SIN((0.2617993877991494 * cast(hour#45614 as double))) AS hour_sin#45664]
                                    +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, day_of_week#45637, CASE WHEN day_of_week#45637 IN (1,7) THEN 1.0 ELSE 0.0 END AS is_weekend#45650]
                                       +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, is_peak#45625, dayofweek(cast(timestamp#45559 as date)) AS day_of_week#45637]
                                          +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour#45614, CASE WHEN hour#45614 IN (7,8,9,17,18,19) THEN 1.0 ELSE 0.0 END AS is_peak#45625]
                                             +- Project [_id#45552, congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580, hour(timestamp#45559, Some(Asia/Bangkok)) AS hour#45614]
                                                +- Project [_id#45552, cast(congestion_level#45553 as double) AS congestion_level#45590, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, vehicle_count#45580]
                                                   +- Project [_id#45552, congestion_level#45553, lat#45554, lon#45555, road_id#45556, road_name#45557, speed#45570, timestamp#45559, cast(vehicle_count#45560 as double) AS vehicle_count#45580]
                                                      +- Project [_id#45552, congestion_level#45553, lat#45554, lon#45555, road_id#45556, road_name#45557, cast(speed#45558 as double) AS speed#45570, timestamp#45559, vehicle_count#45560]
                                                         +- Relation [_id#45552,congestion_level#45553,lat#45554,lon#45555,road_id#45556,road_name#45557,speed#45558,timestamp#45559,vehicle_count#45560] MongoRelation(MongoRDD[2704] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(congestion_level,DoubleType,true), StructField(lat,DoubleType,true), StructField(lon,DoubleType,true), StructField(road_id,StringType,true), StructField(road_name,StringType,true), StructField(speed,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(vehicle_count,IntegerType,true))))

2026-01-06 12:45:13,390 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 12:45:18 +07)" executed successfully
                                                                                                                        2026-01-06 16:00:09,960 - INFO -  Initializing PySpark Session...
2026-01-06 16:00:13,624 - INFO - ‚úì Spark Session Created!
2026-01-06 16:00:13,625 - INFO - Loading existing model from models/traffic_pipeline
2026-01-06 16:00:22,370 - INFO - ‚úì Loaded saved pipeline model
2026-01-06 16:00:22,370 - INFO - Starting Spark Prediction Service (predictions interval: 5s, training interval: 60s)...
2026-01-06 16:00:22,384 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:00:22,384 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:00:22,385 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 16:00:22,385 - INFO - Added job "SparkPredictionService.train_model" to job store "default"
2026-01-06 16:00:22,385 - INFO - Scheduler started
2026-01-06 16:00:27,386 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:27 +07)" (scheduled at 2026-01-06 16:00:27.384257+07:00)
2026-01-06 16:00:27,387 - INFO -  Running predictions...
2026-01-06 16:00:30,485 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:30,485 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:32 +07)" executed successfully
2026-01-06 16:00:32,391 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:37 +07)" (scheduled at 2026-01-06 16:00:32.384257+07:00)
2026-01-06 16:00:32,391 - INFO -  Running predictions...
2026-01-06 16:00:33,576 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:33,577 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:37 +07)" executed successfully
2026-01-06 16:00:37,390 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:42 +07)" (scheduled at 2026-01-06 16:00:37.384257+07:00)
2026-01-06 16:00:37,390 - INFO -  Running predictions...
2026-01-06 16:00:38,605 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:38,607 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:42 +07)" executed successfully
2026-01-06 16:00:42,391 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:47 +07)" (scheduled at 2026-01-06 16:00:42.384257+07:00)
2026-01-06 16:00:42,392 - INFO -  Running predictions...
2026-01-06 16:00:43,401 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:43,401 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:47 +07)" executed successfully
2026-01-06 16:00:47,395 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:52 +07)" (scheduled at 2026-01-06 16:00:47.384257+07:00)
2026-01-06 16:00:47,396 - INFO -  Running predictions...
2026-01-06 16:00:48,282 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:48,283 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:52 +07)" executed successfully
2026-01-06 16:00:52,385 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:57 +07)" (scheduled at 2026-01-06 16:00:52.384257+07:00)
2026-01-06 16:00:52,385 - INFO -  Running predictions...
2026-01-06 16:00:53,265 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:53,265 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:00:57 +07)" executed successfully
2026-01-06 16:00:57,385 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:02 +07)" (scheduled at 2026-01-06 16:00:57.384257+07:00)
2026-01-06 16:00:57,385 - INFO -  Running predictions...
2026-01-06 16:00:58,163 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:00:58,163 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:02 +07)" executed successfully
2026-01-06 16:01:02,393 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:07 +07)" (scheduled at 2026-01-06 16:01:02.384257+07:00)
2026-01-06 16:01:02,393 - INFO -  Running predictions...
2026-01-06 16:01:03,362 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:01:03,364 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:07 +07)" executed successfully
2026-01-06 16:01:07,385 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:12 +07)" (scheduled at 2026-01-06 16:01:07.384257+07:00)
2026-01-06 16:01:07,385 - INFO -  Running predictions...
2026-01-06 16:01:08,199 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:01:08,199 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:01:12 +07)" executed successfully
2026-01-06 16:01:09,096 - INFO - Stopping Spark Session...
2026-01-06 16:01:10,045 - INFO - Closing down clientserver connection
2026-01-06 16:01:10,046 - INFO - Scheduler has been shut down
2026-01-06 16:01:10,047 - INFO - Closing down clientserver connection
2026-01-06 16:08:53,181 - INFO -  Initializing PySpark Session...
2026-01-06 16:08:56,352 - INFO - ‚úì Spark Session Created!
2026-01-06 16:08:56,352 - INFO - Loading existing model from models/traffic_pipeline
2026-01-06 16:09:04,695 - INFO - ‚úì Loaded saved pipeline model
2026-01-06 16:09:04,696 - INFO - Starting Spark Prediction Service (predictions: 5s, training: 60s)...
2026-01-06 16:09:04,712 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:09:04,712 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:09:04,713 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 16:09:04,713 - INFO - Added job "SparkPredictionService.train_model" to job store "default"
2026-01-06 16:09:04,713 - INFO - Scheduler started
2026-01-06 16:09:09,715 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:09 +07)" (scheduled at 2026-01-06 16:09:09.712397+07:00)
2026-01-06 16:09:09,716 - INFO -  Running predictions...
2026-01-06 16:09:12,387 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:12,388 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:14 +07)" executed successfully
2026-01-06 16:09:14,714 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:19 +07)" (scheduled at 2026-01-06 16:09:14.712397+07:00)
2026-01-06 16:09:14,714 - INFO -  Running predictions...
2026-01-06 16:09:16,075 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:16,075 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:19 +07)" executed successfully
2026-01-06 16:09:19,712 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:24 +07)" (scheduled at 2026-01-06 16:09:19.712397+07:00)
2026-01-06 16:09:19,713 - INFO -  Running predictions...
2026-01-06 16:09:21,052 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:21,053 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:24 +07)" executed successfully
2026-01-06 16:09:24,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:29 +07)" (scheduled at 2026-01-06 16:09:24.712397+07:00)
2026-01-06 16:09:24,713 - INFO -  Running predictions...
2026-01-06 16:09:25,781 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:25,782 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:29 +07)" executed successfully
2026-01-06 16:09:29,714 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:34 +07)" (scheduled at 2026-01-06 16:09:29.712397+07:00)
2026-01-06 16:09:29,715 - INFO -  Running predictions...
2026-01-06 16:09:31,023 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:31,023 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:34 +07)" executed successfully
2026-01-06 16:09:34,714 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:39 +07)" (scheduled at 2026-01-06 16:09:34.712397+07:00)
2026-01-06 16:09:34,715 - INFO -  Running predictions...
2026-01-06 16:09:36,068 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:36,068 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:39 +07)" executed successfully
2026-01-06 16:09:39,717 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:44 +07)" (scheduled at 2026-01-06 16:09:39.712397+07:00)
2026-01-06 16:09:39,718 - INFO -  Running predictions...
2026-01-06 16:09:40,944 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:40,944 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:44 +07)" executed successfully
2026-01-06 16:09:44,733 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:49 +07)" (scheduled at 2026-01-06 16:09:44.712397+07:00)
2026-01-06 16:09:44,734 - INFO -  Running predictions...
2026-01-06 16:09:45,595 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:45,598 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:49 +07)" executed successfully
2026-01-06 16:09:49,716 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:54 +07)" (scheduled at 2026-01-06 16:09:49.712397+07:00)
2026-01-06 16:09:49,717 - INFO -  Running predictions...
2026-01-06 16:09:50,599 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:50,601 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:54 +07)" executed successfully
2026-01-06 16:09:54,716 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:59 +07)" (scheduled at 2026-01-06 16:09:54.712397+07:00)
2026-01-06 16:09:54,716 - INFO -  Running predictions...
2026-01-06 16:09:55,594 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:09:55,594 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:09:59 +07)" executed successfully
2026-01-06 16:09:59,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:04 +07)" (scheduled at 2026-01-06 16:09:59.712397+07:00)
2026-01-06 16:09:59,715 - INFO -  Running predictions...
2026-01-06 16:10:00,899 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:00,899 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:04 +07)" executed successfully
2026-01-06 16:10:04,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:09 +07)" (scheduled at 2026-01-06 16:10:04.712397+07:00)
2026-01-06 16:10:04,713 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:10:04 +07)" (scheduled at 2026-01-06 16:10:04.712800+07:00)
2026-01-06 16:10:04,714 - INFO -  Running predictions...
2026-01-06 16:10:04,715 - INFO -  Training Spark model...
2026-01-06 16:10:05,918 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:05,919 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:09 +07)" executed successfully
2026-01-06 16:10:09,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:14 +07)" (scheduled at 2026-01-06 16:10:09.712397+07:00)
2026-01-06 16:10:09,713 - INFO -  Running predictions...
2026-01-06 16:10:11,170 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:11,171 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:14 +07)" executed successfully
2026-01-06 16:10:14,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:19 +07)" (scheduled at 2026-01-06 16:10:14.712397+07:00)
2026-01-06 16:10:14,713 - INFO -  Running predictions...
2026-01-06 16:10:16,017 - INFO - ‚úì Model trained successfully!
2026-01-06 16:10:16,112 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:16,113 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:19 +07)" executed successfully
2026-01-06 16:10:17,633 - INFO - ‚úì Pipeline model saved to models/traffic_pipeline
2026-01-06 16:10:17,635 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:11:04 +07)" executed successfully
2026-01-06 16:10:19,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:24 +07)" (scheduled at 2026-01-06 16:10:19.712397+07:00)
2026-01-06 16:10:19,713 - INFO -  Running predictions...
2026-01-06 16:10:20,498 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:20,501 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:24 +07)" executed successfully
2026-01-06 16:10:24,713 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:29 +07)" (scheduled at 2026-01-06 16:10:24.712397+07:00)
2026-01-06 16:10:24,713 - INFO -  Running predictions...
2026-01-06 16:10:25,629 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:25,629 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:29 +07)" executed successfully
2026-01-06 16:10:29,714 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:34 +07)" (scheduled at 2026-01-06 16:10:29.712397+07:00)
2026-01-06 16:10:29,714 - INFO -  Running predictions...
2026-01-06 16:10:30,542 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:30,542 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:34 +07)" executed successfully
2026-01-06 16:10:34,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:39 +07)" (scheduled at 2026-01-06 16:10:34.712397+07:00)
2026-01-06 16:10:34,725 - INFO -  Running predictions...
2026-01-06 16:10:35,516 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:35,516 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:39 +07)" executed successfully
2026-01-06 16:10:39,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:44 +07)" (scheduled at 2026-01-06 16:10:39.712397+07:00)
2026-01-06 16:10:39,729 - INFO -  Running predictions...
2026-01-06 16:10:40,545 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:40,545 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:44 +07)" executed successfully
2026-01-06 16:10:44,714 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:49 +07)" (scheduled at 2026-01-06 16:10:44.712397+07:00)
2026-01-06 16:10:44,714 - INFO -  Running predictions...
2026-01-06 16:10:45,568 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:45,568 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:49 +07)" executed successfully
2026-01-06 16:10:49,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:54 +07)" (scheduled at 2026-01-06 16:10:49.712397+07:00)
2026-01-06 16:10:49,727 - INFO -  Running predictions...
2026-01-06 16:10:50,389 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:50,389 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:54 +07)" executed successfully
2026-01-06 16:10:54,717 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:59 +07)" (scheduled at 2026-01-06 16:10:54.712397+07:00)
2026-01-06 16:10:54,717 - INFO -  Running predictions...
2026-01-06 16:10:55,437 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:10:55,437 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:10:59 +07)" executed successfully
2026-01-06 16:10:59,715 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:11:04 +07)" (scheduled at 2026-01-06 16:10:59.712397+07:00)
2026-01-06 16:10:59,716 - INFO -  Running predictions...
2026-01-06 16:11:00,503 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:11:00,504 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:11:04 +07)" executed successfully
2026-01-06 16:11:04,715 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:11:09 +07)" (scheduled at 2026-01-06 16:11:04.712397+07:00)
2026-01-06 16:11:04,715 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:12:04 +07)" (scheduled at 2026-01-06 16:11:04.712800+07:00)
2026-01-06 16:11:04,716 - INFO -  Running predictions...
2026-01-06 16:11:04,716 - INFO -  Training Spark model...
2026-01-06 16:11:05,081 - INFO - Stopping Spark Session...
2026-01-06 16:11:05,118 - ERROR - Training error: An error occurred while calling o5973.fit.
: org.apache.spark.SparkException: Job 181 cancelled as part of cancellation of all jobs
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2346)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$doCancelAllJobs$2(DAGScheduler.scala:1053)
	at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:1052)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2603)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)

2026-01-06 16:11:05,118 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:12:04 +07)" executed successfully
2026-01-06 16:11:05,262 - ERROR - Prediction error: An error occurred while calling o3511.transform.
: java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.updateBlockInfo(BlockManagerMaster.scala:104)
	at org.apache.spark.storage.BlockManager.tryToReportBlockStatus(BlockManager.scala:864)
	at org.apache.spark.storage.BlockManager.reportBlockStatus(BlockManager.scala:843)
	at org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:1979)
	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1450)
	at org.apache.spark.storage.BlockManager$BlockStoreUpdater.save(BlockManager.scala:370)
	at org.apache.spark.storage.BlockManager.putBytes(BlockManager.scala:1385)
	at org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeBlocks$1(TorrentBroadcast.scala:150)
	at org.apache.spark.broadcast.TorrentBroadcast.$anonfun$writeBlocks$1$adapted(TorrentBroadcast.scala:144)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:144)
	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:95)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)
	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:74)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1525)
	at org.apache.spark.ml.regression.RandomForestRegressionModel.transform(RandomForestRegressor.scala:230)
	at jdk.internal.reflect.GeneratedMethodAccessor174.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)

2026-01-06 16:11:05,262 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:11:09 +07)" executed successfully
2026-01-06 16:11:05,418 - INFO - Closing down clientserver connection
2026-01-06 16:11:05,418 - INFO - Closing down clientserver connection
2026-01-06 16:11:05,419 - INFO - Scheduler has been shut down
2026-01-06 16:12:59,624 - INFO -  Initializing PySpark Session...
2026-01-06 16:13:03,714 - INFO - ‚úì Spark Session Created!
2026-01-06 16:13:03,714 - INFO - Loading existing model from models/traffic_pipeline
2026-01-06 16:13:14,702 - INFO - ‚úì Loaded saved pipeline model
2026-01-06 16:13:14,703 - INFO - Starting Spark Prediction Service (predictions: 5s, training: 60s)...
2026-01-06 16:13:14,722 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:13:14,723 - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2026-01-06 16:13:14,723 - INFO - Added job "SparkPredictionService.make_predictions" to job store "default"
2026-01-06 16:13:14,723 - INFO - Added job "SparkPredictionService.train_model" to job store "default"
2026-01-06 16:13:14,723 - INFO - Scheduler started
2026-01-06 16:13:19,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:19 +07)" (scheduled at 2026-01-06 16:13:19.722817+07:00)
2026-01-06 16:13:19,729 - INFO -  Running predictions...
2026-01-06 16:13:22,560 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:22,560 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:24 +07)" executed successfully
2026-01-06 16:13:24,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:29 +07)" (scheduled at 2026-01-06 16:13:24.722817+07:00)
2026-01-06 16:13:24,728 - INFO -  Running predictions...
2026-01-06 16:13:25,826 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:25,826 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:29 +07)" executed successfully
2026-01-06 16:13:29,731 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:34 +07)" (scheduled at 2026-01-06 16:13:29.722817+07:00)
2026-01-06 16:13:29,731 - INFO -  Running predictions...
2026-01-06 16:13:30,705 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:30,706 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:34 +07)" executed successfully
2026-01-06 16:13:34,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:39 +07)" (scheduled at 2026-01-06 16:13:34.722817+07:00)
2026-01-06 16:13:34,724 - INFO -  Running predictions...
2026-01-06 16:13:35,888 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:35,888 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:39 +07)" executed successfully
2026-01-06 16:13:39,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:44 +07)" (scheduled at 2026-01-06 16:13:39.722817+07:00)
2026-01-06 16:13:39,731 - INFO -  Running predictions...
2026-01-06 16:13:40,655 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:40,655 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:44 +07)" executed successfully
2026-01-06 16:13:44,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:49 +07)" (scheduled at 2026-01-06 16:13:44.722817+07:00)
2026-01-06 16:13:44,730 - INFO -  Running predictions...
2026-01-06 16:13:45,598 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:45,600 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:49 +07)" executed successfully
2026-01-06 16:13:49,730 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:54 +07)" (scheduled at 2026-01-06 16:13:49.722817+07:00)
2026-01-06 16:13:49,730 - INFO -  Running predictions...
2026-01-06 16:13:50,728 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:50,728 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:54 +07)" executed successfully
2026-01-06 16:13:54,728 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:59 +07)" (scheduled at 2026-01-06 16:13:54.722817+07:00)
2026-01-06 16:13:54,728 - INFO -  Running predictions...
2026-01-06 16:13:55,576 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:13:55,576 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:13:59 +07)" executed successfully
2026-01-06 16:13:59,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:04 +07)" (scheduled at 2026-01-06 16:13:59.722817+07:00)
2026-01-06 16:13:59,725 - INFO -  Running predictions...
2026-01-06 16:14:00,569 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:00,569 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:04 +07)" executed successfully
2026-01-06 16:14:04,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:09 +07)" (scheduled at 2026-01-06 16:14:04.722817+07:00)
2026-01-06 16:14:04,723 - INFO -  Running predictions...
2026-01-06 16:14:05,617 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:05,617 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:09 +07)" executed successfully
2026-01-06 16:14:09,729 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:14 +07)" (scheduled at 2026-01-06 16:14:09.722817+07:00)
2026-01-06 16:14:09,730 - INFO -  Running predictions...
2026-01-06 16:14:10,566 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:10,566 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:14 +07)" executed successfully
2026-01-06 16:14:14,748 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:19 +07)" (scheduled at 2026-01-06 16:14:14.722817+07:00)
2026-01-06 16:14:14,748 - INFO -  Running predictions...
2026-01-06 16:14:14,748 - INFO - Running job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:14:14 +07)" (scheduled at 2026-01-06 16:14:14.723160+07:00)
2026-01-06 16:14:14,749 - INFO -  Training Spark model...
2026-01-06 16:14:15,780 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:15,780 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:19 +07)" executed successfully
2026-01-06 16:14:19,726 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:24 +07)" (scheduled at 2026-01-06 16:14:19.722817+07:00)
2026-01-06 16:14:19,726 - INFO -  Running predictions...
2026-01-06 16:14:21,412 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:21,412 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:24 +07)" executed successfully
2026-01-06 16:14:24,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:29 +07)" (scheduled at 2026-01-06 16:14:24.722817+07:00)
2026-01-06 16:14:24,724 - INFO -  Running predictions...
2026-01-06 16:14:26,211 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:26,214 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:29 +07)" executed successfully
2026-01-06 16:14:26,272 - INFO - ‚úì Model trained successfully!
2026-01-06 16:14:28,022 - INFO - ‚úì Pipeline model saved to models/traffic_pipeline
2026-01-06 16:14:28,025 - INFO - Job "SparkPredictionService.train_model (trigger: interval[0:01:00], next run at: 2026-01-06 16:15:14 +07)" executed successfully
2026-01-06 16:14:29,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:34 +07)" (scheduled at 2026-01-06 16:14:29.722817+07:00)
2026-01-06 16:14:29,725 - INFO -  Running predictions...
2026-01-06 16:14:30,962 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:30,962 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:34 +07)" executed successfully
2026-01-06 16:14:34,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:39 +07)" (scheduled at 2026-01-06 16:14:34.722817+07:00)
2026-01-06 16:14:34,724 - INFO -  Running predictions...
2026-01-06 16:14:35,586 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:35,586 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:39 +07)" executed successfully
2026-01-06 16:14:39,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:44 +07)" (scheduled at 2026-01-06 16:14:39.722817+07:00)
2026-01-06 16:14:39,725 - INFO -  Running predictions...
2026-01-06 16:14:40,773 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:40,773 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:44 +07)" executed successfully
2026-01-06 16:14:44,723 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:49 +07)" (scheduled at 2026-01-06 16:14:44.722817+07:00)
2026-01-06 16:14:44,723 - INFO -  Running predictions...
2026-01-06 16:14:45,715 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:45,715 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:49 +07)" executed successfully
2026-01-06 16:14:49,724 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:54 +07)" (scheduled at 2026-01-06 16:14:49.722817+07:00)
2026-01-06 16:14:49,724 - INFO -  Running predictions...
2026-01-06 16:14:50,675 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:50,675 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:54 +07)" executed successfully
2026-01-06 16:14:54,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:59 +07)" (scheduled at 2026-01-06 16:14:54.722817+07:00)
2026-01-06 16:14:54,725 - INFO -  Running predictions...
2026-01-06 16:14:55,655 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:14:55,655 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:14:59 +07)" executed successfully
2026-01-06 16:14:59,727 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:15:04 +07)" (scheduled at 2026-01-06 16:14:59.722817+07:00)
2026-01-06 16:14:59,728 - INFO -  Running predictions...
2026-01-06 16:15:00,558 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:15:00,558 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:15:04 +07)" executed successfully
2026-01-06 16:15:04,725 - INFO - Running job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:15:09 +07)" (scheduled at 2026-01-06 16:15:04.722817+07:00)
2026-01-06 16:15:04,725 - INFO -  Running predictions...
2026-01-06 16:15:05,569 - INFO - ‚úì Predictions saved for 15 roads
2026-01-06 16:15:05,569 - INFO - Job "SparkPredictionService.make_predictions (trigger: interval[0:00:05], next run at: 2026-01-06 16:15:09 +07)" executed successfully
2026-01-06 16:15:06,266 - INFO - Stopping Spark Session...
2026-01-06 16:15:06,473 - INFO - Closing down clientserver connection
2026-01-06 16:15:06,473 - INFO - Closing down clientserver connection
2026-01-06 16:15:06,474 - INFO - Scheduler has been shut down
2026-01-06 16:15:06,474 - INFO - Closing down clientserver connection
